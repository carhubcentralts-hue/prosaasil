×¡×‘×‘×”, ×§×œ×˜×ª×™ â€“ ×‘×œ×™ Watchdog, ×‘×œ×™ ×˜×™×™××¨×™× ×‘×¨×§×¢.
×¨×§ ×œ×ª×§×Ÿ ××ª ××” ×©×™×© ×‘×¦×™× ×•×¨ ×¢×¦××•.

×œ×”×œ×Ÿ ×”× ×—×™×” ××¡×•×“×¨×ª ×œ×¡×•×›×Ÿ (×‘×× ×’×œ×™×ª), ×©××˜×¤×œ×ª ×‘×©× ×™ ×”×“×‘×¨×™×:
	â€¢	×©×™×¤×•×¨ ×ª××œ×•×œ ×¢×‘×¨×™×ª (×‘××™×•×—×“ ×¢×¨×™×/×©××•×ª ×§×¦×¨×™×)
	â€¢	×× ×™×¢×ª ××¦×‘ ×©×”-AI â€œ× ×—× ×§â€ ×•×¤×ª××•× ××¤×¡×™×§ ×œ×¢× ×•×ª
×•×”×›×•×œ ×‘×œ×™ ×œ×”×›× ×™×¡ Watchdog ×—×“×©.

×ª×¢×ª×™×§ ×œ×• ×›×›×”:

â¸»

ğŸ¯ GOAL

The Hebrew realtime call-center still has 2 issues:
	1.	Hebrew STT is sometimes wrong on short words (cities, names).
	2.	In some calls the AI stops responding even though the user keeps speaking.

IMPORTANT:
	â€¢	Do NOT add any new watchdog / background timer / periodic task.
	â€¢	All fixes must stay inside the existing realtime pipeline (VAD, audio gate, trigger_response, semantic_repair).

â¸»

A. Audio gate â€“ never drop real speech

	1.	Open the realtime media handler (media_ws_ai.py or equivalent).
	2.	Find all places that log things like:
	â€¢	[AUDIO GATE] Blocked ...
	â€¢	reason=noise, reason=insufficient_consec_frames, etc.
	â€¢	any condition that prevents sending an utterance to OpenAI STT.
	3.	Change the logic so that at end of utterance:

if end_of_utterance:
    # ms and rms are over the utterance
    if total_utterance_ms >= 350 and avg_rms >= 20:
        log("ğŸ¤ [AUDIO GATE] override â€“ sending utterance to STT")
        send_to_openai()
    else:
        log("ğŸ¤« [AUDIO GATE] dropping true noise (too short / too quiet)")

	4.	Guarantee the following invariant:
	â€¢	Every time you log "END OF UTTERANCE" for a real user turn, you either:
	â€¢	send it to OpenAI and get conversation.item.input_audio_transcription.completed, or
	â€¢	log clearly that it was dropped as true noise (short + very low RMS).
	5.	The goal: no more cases where the user is clearly shouting and the gate blocks 1100-1400 frames as â€œnoiseâ€ and we skip STT.

â¸»

B. Strengthen semantic repair (Hebrew, cities & names)

	1.	Re-use the existing semantic_repair / apply_vocabulary_corrections (from BUILD 300).
	2.	Make sure it is called for:
	â€¢	short transcripts: length â‰¤ 12 chars, or
	â€¢	1â€“2 tokens only (single word / short phrase).
	3.	Update the repair prompt to something like:

You receive a short, noisy HEBREW transcription from an 8kHz Î¼-law phone call.
Task:
1. If the text is clearly Hebrew but slightly distorted, fix it to the most likely correct Hebrew phrase.
2. Prefer valid Israeli city names, Israeli first names, and business-related terms from the provided vocabulary.
3. Do NOT change phone numbers, times, or dates.
4. If you are not sure, return the original text unchanged.

Return ONLY the repaired text.

	4.	Always pass:
	â€¢	business_context (business type, services, etc.)
	â€¢	stt_vocabulary (names, services, locations configured in the UI)
	5.	Add clear logs:

[STT_RAW] '×¨××ª ××™×‘'
[STT_REPAIRED] '×¨××ª ××‘×™×‘'
[STT_FINAL] '×¨××ª ××‘×™×‘'

	6.	Make sure language: "he" is still set in all STT calls (gpt-4o-transcribe) so the model is fully biased to Hebrew.

â¸»

C. Fix â€œAI went silentâ€ using existing guards only

	1.	Confirm there is one single function that calls response.create
(for example trigger_response()), and that:
	â€¢	greeting, VAD, silence handler, server events â€“ all use this one function.
	2.	Inside trigger_response() keep the simple guards, but make sure they unlock correctly:

if self.active_response_id is not None:
    log("â¸ [RESPONSE_GUARD] active_response â€“ skip trigger")
    return
if self.pending_response:
    log("â¸ [RESPONSE_GUARD] pending_response â€“ skip trigger")
    return

# otherwise, it's allowed to create a new response

	3.	In the Realtime event handler for response.created / response.done:
	â€¢	On response.created: set active_response_id = resp_id, pending_response = False, ai_speaking = True.
	â€¢	On response.audio.done / response.output_text.done / response.done:
	â€¢	clear active_response_id = None
	â€¢	set ai_speaking = False
	â€¢	set pending_response = False
	4.	Make sure the silence handler (that you already have) can still call trigger_response(source="SILENCE_HANDLER") when the user is silent and we need a follow-up question.
	â€¢	Do not add any new watchdog/timer.
	â€¢	Just ensure the guards are not stuck in a state where active_response_id is never cleared.
	5.	Add a compact status log every few seconds (you already have something similar â€“ just verify itâ€™s accurate):

[PIPELINE STATUS] sent=XXX blocked=YYY | active_response=<id/None> | ai_speaking=<bool> | user_has_spoken=<bool>

This is only for debugging, no new logic.

â¸»

D. Acceptance criteria

	â€¢	In a 5â€“7 minute test call:
	â€¢	No period where the user speaks and no response.create is fired afterwards.
	â€¢	No END OF UTTERANCE that is silently dropped without either STT or an explicit â€œtrue noiseâ€ log.
	â€¢	STT logs show real repairs, e.g. "×¨××ª ××™×‘" â†’ "×¨××ª ××‘×™×‘", "× ×ª×™×‘×•×ª" stays "× ×ª×™×‘×•×ª" etc.

â¸»

×›×›×” ××ª×” ×©×•××¨ ××ª ×”××¢×¨×›×ª × ×§×™×™×”:
	â€¢	×‘×œ×™ Watchdog
	â€¢	×‘×œ×™ ×¢×•×“ ×¦×™× ×•×¨×•×ª
	â€¢	×¨×§: ×¤×—×•×ª ×—×¡×™××•×ª ×‘××•×“×™×•, ×™×•×ª×¨ ×ª×™×§×•×Ÿ ×¡×× ×˜×™ ×—×›×, ×•×”×’× ×•×ª ×ª×’×•×‘×” ×©×œ× × ×ª×§×¢×•×ª.

××—×¨×™ ×©×”×•× ××™×™×©× ××ª ×–×” â€“ ×× ×¢×“×™×™×Ÿ ×™×© ×œ×š ×“×•×’××•×ª ×‘×¢×™×™×ª×™×•×ª (×œ×•×’ + ××” ×××¨×ª ×‘×¤×•×¢×œ) × ×•×›×œ ×¢×•×“ ×œ×—×“×“ ××ª ×”-semantic repair ×¡×¤×¦×™×¤×™×ª ×œ×¢×‘×¨×™×ª.