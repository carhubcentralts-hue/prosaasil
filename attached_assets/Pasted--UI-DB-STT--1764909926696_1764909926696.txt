××¢×•×œ×”, ×‘×•× × ×¢×©×” ×œ×• ×”× ×—×™×™×ª ××¨×›×™×˜×§×˜ ××¡×•×“×¨×ª ×‘×× ×’×œ×™×ª, ×©×ª×¡×’×•×¨ ××ª ×›×œ ×”×¤×™× ×•×ª â€“ UI â†’ DB â†’ STT â†’ ×ª×™×§×•× ×™× â†’ ×œ×•×’×™×.
×ª×Ÿ ×œ×• ××ª ×–×” ××—×“ ×œ××—×“:

â¸»

ğŸ§  BUILD 204 â€“ Dynamic STT & Vocabulary â€“ Stabilization & Hardening

You are the architect and senior backend engineer for the ProSaaS call center system.
Your goal in this build is not to add new features, but to stabilize and harden the dynamic STT pipeline so that:
	1.	All STT-related data configured in the UI actually flows:
	â€¢	UI â†’ API â†’ DB â†’ STT prompt â†’ AI behavior
	2.	RapidFuzz-based corrections are:
	â€¢	Helpful, conservative, and never destructive
	3.	The system has one clear, simple STT pipeline per channel (voice / WhatsApp) with good logging and no hidden surprises.

Treat this as BUILD 204 â€“ STT Hardening Mode.

â¸»

0. Preparation & Verification
	1.	Locate the relevant components:
	â€¢	server/services/openai_realtime_client.py (or equivalent STT client)
	â€¢	server/media_ws_ai.py (or equivalent Twilio media WS handler)
	â€¢	server/services/stt_dynamic_service.py (or wherever build_dynamic_stt_prompt, apply_vocabulary_corrections, semantic_post_process live)
	â€¢	Business settings models & API:
	â€¢	models.py / business_settings.py
	â€¢	routes / controllers for /api/business/settings or similar
	â€¢	Frontend settings UI (React):
	â€¢	Business settings / STT settings page
	2.	Confirm that Migration 32 (or equivalent) is applied:
	â€¢	Fields on the business/settings entity:
	â€¢	stt_vocabulary_json (JSON)
	â€¢	business_context (string / text)
	â€¢	If not applied â†’ run migration, or create it as needed.

â¸»

1. Data Model & Validation â€“ Make It Safe

Goal: Ensure STT vocabulary and business context are correctly modeled and validated at the DB/API layer.
	1.	Data model expectations:
	â€¢	stt_vocabulary_json structure:

{
  "services": ["×ª×¡×¤×•×¨×ª", "×¤×Ÿ", "×’×•×•× ×™×"],
  "products": ["×©××¤×•", "××¡×›×”"],
  "staff": ["×“× ×”", "×™×•×¡×™"],
  "locations": ["×ª×œ ××‘×™×‘", "×¨××ª ×’×Ÿ"]
}


	â€¢	business_context: short free-text description, e.g.:
â€œ××¡×¤×¨×” ×™×•×§×¨×ª×™×ª ×‘×ª×œ ××‘×™×‘, ××ª××—×” ×‘×”×—×œ×§×•×ª ×•×ª×¡×¤×•×¨×•×ª ×’×‘×¨×™×.â€

	2.	Enforce backend validation (in schema / model / pydantic / marshmallow or custom):
	â€¢	Max 20 items per category.
	â€¢	Max 50 chars per item.
	â€¢	business_context max 500 chars.
	â€¢	Strip whitespace, normalize Hebrew (trim spaces, remove duplicates).
	â€¢	Reject / clean empty strings.
	3.	On invalid input:
	â€¢	Return structured 400 error with clear message:
	â€¢	e.g. "services must contain at most 20 items, each up to 50 chars".

â¸»

2. Wiring UI â†’ API â†’ DB â€“ No Dead Fields

Goal: Make sure everything user sets in the UI actually reaches the DB and is later used in STT.
	1.	In the frontend settings page:
	â€¢	Ensure there is a visible STT section:
	â€¢	Business context (multi-line text input).
	â€¢	4 vocabulary lists:
	â€¢	Services
	â€¢	Products
	â€¢	Staff
	â€¢	Locations
	â€¢	Simple UX: comma-separated input, or â€œtagâ€ chips.
	2.	On load:
	â€¢	Fetch current settings from /api/business/settings (or equivalent).
	â€¢	Populate all fields from stt_vocabulary_json + business_context.
	3.	On save:
	â€¢	Build the exact JSON object expected by backend:

stt_vocabulary_json: {
  services: string[];
  products: string[];
  staff: string[];
  locations: string[];
},
business_context: string;


	â€¢	Send via PUT/PATCH to settings API.
	â€¢	Handle validation errors and show them to the user.

	4.	Verify:
	â€¢	When editing and saving vocab in the UI:
	â€¢	The DB row is updated.
	â€¢	A subsequent GET returns the new values.

â¸»

3. Dynamic STT Prompt â€“ Single Source of Truth

Goal: Make sure every transcription call uses one central function to build the STT prompt based on the business settings.
	1.	In stt_dynamic_service.py (or similar), define:

def build_dynamic_stt_prompt(business) -> str:
    """
    Build a short, focused STT prompt in Hebrew for this business.
    Length target: ~80-120 chars max.
    Must gracefully handle missing/empty fields.
    """


	2.	Logic example (pseudocode):

def build_dynamic_stt_prompt(business) -> str:
    name = business.display_name or business.legal_name or ""
    ctx  = (business.business_context or "").strip()

    vocab = business.stt_vocabulary_json or {}
    services = (vocab.get("services") or [])[:3]
    staff    = (vocab.get("staff") or [])[:3]
    locations = (vocab.get("locations") or [])[:3]

    # Build small fragments
    parts = []

    if name:
        parts.append(f"×©×™×—×” ×‘×¢×‘×¨×™×ª ×œ×¢×¡×§ '{name}'.")

    if ctx:
        # Optionally shorten ctx if too long
        short_ctx = ctx[:120]
        parts.append(short_ctx)

    if services:
        parts.append(f"×©×™×¨×•×ª×™×: {', '.join(services)}.")
    if staff:
        parts.append(f"×¦×•×•×ª: {', '.join(staff)}.")
    if locations:
        parts.append(f"××™×§×•××™×: {', '.join(locations)}.")

    prompt = " ".join(parts).strip()
    # Hard cap to avoid overlong prompt
    return prompt[:400]


	3.	Integration:
	â€¢	Find all places where STT/transcription config is built:
	â€¢	Live voice (Twilio / realtime)
	â€¢	WhatsApp voice notes (if applicable)
	â€¢	Replace any hardcoded prompt / static context with a call to build_dynamic_stt_prompt(business).
	4.	Remove old hardcoded â€œcities listâ€ logic:
	â€¢	No static â€œIsrael cities dictionaryâ€ in code.
	â€¢	All domain vocabulary must come from each businessâ€™ settings.

â¸»

4. RapidFuzz Corrections â€“ Conservative, Not Aggressive

Goal: RapidFuzz should correct obvious near-miss words, but never â€œrewrite realityâ€ or damage critical info.
	1.	In apply_vocabulary_corrections(text, business):
a) Never touch:
	â€¢	Numbers (\d+): dates, times, amounts, phone numbers.
	â€¢	Tokens that look like phone numbers (\d{7,}).
	â€¢	Pure punctuation.
	â€¢	Very short tokens (length < 3 or 4).
b) Only consider:
	â€¢	Hebrew words with length â‰¥ 3 or 4.
	â€¢	Words that are not already exact matches in any vocab list.
	2.	Matching rules:
	â€¢	Combined vocabulary set from services + products + staff + locations.
	â€¢	Use a safe threshold, e.g. 75â€“80% similarity.
	â€¢	Prefer single best match, donâ€™t apply multiple candidates.
Pseudocode:

from rapidfuzz import process, fuzz

def apply_vocabulary_corrections(text: str, business) -> Tuple[str, dict]:
    vocab = business.stt_vocabulary_json or {}
    dictionary = set()
    for key in ("services", "products", "staff", "locations"):
        for item in vocab.get(key) or []:
            item = (item or "").strip()
            if item:
                dictionary.add(item)

    if not dictionary:
        return text, {}

    words = text.split()
    corrections = {}
    corrected_words = []

    for w in words:
        clean = w.strip(".,!?;:")  # basic strip

        # Skip short tokens / numbers
        if len(clean) < 3 or clean.isdigit():
            corrected_words.append(w)
            continue

        # Exact match â€“ no need to correct
        if clean in dictionary:
            corrected_words.append(w)
            continue

        best_match, score, _ = process.extractOne(
            clean,
            dictionary,
            scorer=fuzz.WRatio
        )

        if score >= 78:  # tuned threshold
            corrections[clean] = best_match
            # Replace only core word, keep punct if needed
            corrected_words.append(w.replace(clean, best_match))
        else:
            corrected_words.append(w)

    corrected_text = " ".join(corrected_words)
    return corrected_text, corrections


	3.	Logging:
	â€¢	Every time RapidFuzz changes something, log:

[STT_CORRECTION] original='×ª×¤×•×¨×ª', corrected='×ª×¡×¤×•×¨×ª', score=92, business_id=...


	â€¢	For debugging: keep both raw STT and corrected STT.

	4.	Apply corrections only once per final utterance:
	â€¢	Do not run it repeatedly on partial segments.
	â€¢	Integrate it in the same place where you currently finalize transcripts and push them into conversation_history.

â¸»

5. Semantic Post-Processing (GPT-4o-mini) â€“ Feature Flag Only

Goal: semantic_post_process must not be silently active on all calls.
	1.	Wrap semantic_post_process behind a clear feature flag, e.g.:
	â€¢	Env var: STT_SEMANTIC_POST_PROCESS_ENABLED=false
	â€¢	Or business-level setting.
	2.	Default: OFF in production.
	3.	If/when used:
	â€¢	Only call it for short, clearly problematic utterances.
	â€¢	Pass both:
	â€¢	raw_text
	â€¢	corrected_text (after vocabulary).
	â€¢	business_context and vocabulary summary.
	4.	Log its activity clearly:

[STT_SEMANTIC] raw='×ª×¤×•×¨×ª', corrected='×ª×¡×¤×•×¨×ª', semantic='×ª×¡×¤×•×¨×ª ×§×¦×¨×” ×œ×’×‘×¨×™×'



â¸»

6. Logging & Observability â€“ Make Debugging Easy

Goal: Be able to debug STT issues easily from logs.

For each final user utterance, log one consolidated line with:
	â€¢	call_id / conversation_id
	â€¢	raw_text â€“ from OpenAI
	â€¢	corrected_text â€“ after vocabulary corrections
	â€¢	prompt_used â€“ the dynamic STT prompt (trimmed)
	â€¢	business_id
	â€¢	Whether semantic post-processing was applied

Example:

[STT_FINAL]
call_id=...
business_id=...
prompt="×©×™×—×” ×‘×¢×‘×¨×™×ª ×œ×¢×¡×§ '××•×¡×š ××‘×™'. ×©×™×¨×•×ª×™×: ×˜×™×¤×•×œ, ×‘×œ××™×, ×—×©××œ."
raw="×ª×¤×•×¨×ª"
corrected="×ª×¡×¤×•×¨×ª"
semantic_used=false

This will let the owner quickly see if:
	â€¢	The prompt is correct.
	â€¢	The raw STT is good.
	â€¢	Vocabulary corrections behave as expected.

â¸»

7. Voice & WhatsApp â€“ Shared Logic

If you have STT for:
	â€¢	Live calls (Twilio â†’ Realtime â†’ STT)
	â€¢	WhatsApp audio messages

Then:
	1.	Use the same build_dynamic_stt_prompt for both.
	2.	Use the same apply_vocabulary_corrections for both.
	3.	Only the audio transport changes, not the logic:
	â€¢	Twilio stream vs uploaded audio file, etc.

â¸»

8. Sanity Tests (You Must Run Them)

After implementing:
	1.	Configure a test business (hair salon) in the UI:
	â€¢	Context: â€œ××¡×¤×¨×” ×‘×ª×œ ××‘×™×‘â€¦â€
	â€¢	Services: ×ª×¡×¤×•×¨×ª, ×”×—×œ×§×”, ×¤×Ÿ
	â€¢	Staff: ×©×™, ×¨×•× ×™
	â€¢	Locations: ×ª×œ ××‘×™×‘
	2.	Place a live call and say:
	â€¢	â€œ×× ×™ ×¨×•×¦×” ×ª×¡×¤×•×¨×ª ××¦×œ ×©×™â€
	â€¢	â€œ×‘×™×•× ×©×œ×™×©×™ ×‘××¨×‘×¢â€
	â€¢	â€œ×ª×¤×•×¨×ª ××¦×œ ×©×™â€ (intentionally wrong pronunciation)
	3.	Verify in logs:
	â€¢	Prompt contains business name + some services/staff.
	â€¢	Raw STT text from OpenAI.
	â€¢	Corrected text (where relevant).
	â€¢	No numbers/times/phones modified.
	â€¢	No crashes or unexpected behavior.

â¸»

If you follow all of the above, the result should be:
	â€¢	One clean STT pipeline
	â€¢	UI settings that genuinely affect the bot
	â€¢	Safer, smarter STT corrections per business
	â€¢	Much easier debugging when something sounds â€œoffâ€

×ª×Ÿ ×œ×• ××ª ×–×” ××—×“ ×œ××—×“ ×‘×ª×•×¨ ×”×”× ×—×™×” ×œ×‘×™×œ×“ ×”×‘×. ×× ×ª×¨×¦×” ××—×¨×™ ×–×”, × ×‘× ×” ×’× ×œ×• checklist ×§×¦×¨ ×‘×¢×‘×¨×™×ª ×©×™×¢×‘×•×¨ ×¢×œ×™×• ×œ×¤× ×™ ×©×”×•× ××•××¨ ×œ×š â€œDONEâ€.