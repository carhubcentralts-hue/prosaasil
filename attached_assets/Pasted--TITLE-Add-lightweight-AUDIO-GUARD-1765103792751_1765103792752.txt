הנה הנחיה באנגלית שאתה יכול להדביק לארכיטקט בריפליט כמו שהיא:

⸻

TITLE: Add lightweight AUDIO_GUARD for noisy PSTN calls (Twilio → OpenAI Realtime)

ROLE

You are a senior audio-pipeline engineer working on the AgentLocator project.
The system already uses Twilio PSTN + OpenAI Realtime for phone calls.

Your task is to add a single, simple, low-risk audio guard layer on the input audio path (Twilio → OpenAI), behind a feature flag that is ON by default in code (no .env).

This must improve robustness on noisy PSTN calls (music, TV, people talking in the background) without touching business / CRM logic and without re-introducing heavy, complex filters.

⸻

1. Scope and constraints (very important)
	1.	Work only on the audio pipeline between:
	•	Twilio media stream → internal audio queues → OpenAI Realtime API
	•	Specifically the code that pushes frames into the realtime_audio_in_queue (or equivalent) and the gap-recovery logic that logs [AUDIO GAP] / GAP RECOVERY.
	2.	Do NOT modify:
	•	Lead / CRM / appointment / NLP logic
	•	Smart hangup logic, goodbye detection, loop guards
	•	SIMPLE_MODE behavior, DB schema, routes, or business settings
	3.	The new layer must be:
	•	Small and self-contained (one helper module or a few small functions)
	•	Fully guarded behind a flag in code: AUDIO_GUARD_ENABLED = True
	•	No environment variables for this; the flag is changed only in code.
	4.	Performance requirements:
	•	No blocking I/O in the audio path
	•	Minimal CPU; keep operations per frame O(n) on the frame size only
	•	Added latency per utterance must be < 50 ms
	•	If you detect that it might add more latency, keep the guard as simple as possible.

⸻

2. Add a global guard flag (code-only, no .env)
	1.	Create or reuse a central config module (for example server/config.py or similar) and add:

# Audio guard for noisy PSTN → OpenAI path
AUDIO_GUARD_ENABLED: bool = True  # default ON, changed only in code


	2.	Import this flag only where needed in the audio pipeline (e.g. the module that handles Twilio media frames and enqueues them into realtime_audio_in_queue).
	3.	Make sure the system still runs correctly if AUDIO_GUARD_ENABLED is set to False (i.e., the pipeline behaves exactly as before).

⸻

3. Implement dynamic noise floor & speech threshold

In the audio sender / handler where you receive raw audio frames from Twilio (20ms G.711 μ-law frames):
	1.	Maintain these state variables inside the audio-pipeline object (not globals):

self.noise_floor = 20.0          # initial guess, may be adjusted
self.speech_threshold_factor = 4.0
self.audio_guard_prev_rms = 0.0


	2.	For each 20ms frame, compute at least:
	•	rms (you already log RMS today – reuse or factor it out)
	•	zcr (zero-crossing rate): count how many times the PCM sample sign changes
	3.	Continuously update the noise floor only when the frame is “probably silence” (e.g. RMS below current threshold):

if rms < self.noise_floor * self.speech_threshold_factor:
    self.noise_floor = 0.9 * self.noise_floor + 0.1 * rms


	4.	Derive a dynamic speech threshold:

effective_threshold = self.noise_floor * self.speech_threshold_factor


	5.	Store self.audio_guard_prev_rms = rms for later use.

⸻

4. Implement a small is_probable_speech helper

Create a helper inside the audio pipeline module:

def _is_probable_speech(
    rms: float,
    zcr: float,
    effective_threshold: float,
    prev_rms: float
) -> bool:
    # hard silence
    if rms < 0.5 * effective_threshold:
        return False

    # clearly loud segment (speech or loud noise) – let OpenAI decide
    if rms >= 1.5 * effective_threshold:
        return True

    # mid-range: use ZCR and small dynamics to distinguish speech vs. flat noise
    # heuristic values – keep them simple and documented
    MIN_ZCR_FOR_SPEECH = 0.02      # tune but keep low and simple
    MIN_RMS_DELTA_FOR_SPEECH = 5.0 # small change between frames

    if zcr >= MIN_ZCR_FOR_SPEECH:
        return True

    if abs(rms - prev_rms) >= MIN_RMS_DELTA_FOR_SPEECH:
        return True

    return False

Keep this function pure and fast.
You may tune constants slightly based on logs, but keep them simple, no magic complexity.

⸻

5. Lightweight music-like background detection

Still in the same module, add a tiny state machine:
	1.	Extra state:

self.music_mode = False
self.music_frames_counter = 0
self.music_cooldown_frames = 0


	2.	When AUDIO_GUARD_ENABLED is True and before enqueuing the frame:
	•	Detect potential music when:
	•	rms is consistently above effective_threshold
	•	ZCR is moderately high
	•	This persists for a short continuous window (e.g. 300–500 ms)
Pseudocode:

if rms > effective_threshold and zcr > 0.03:
    self.music_frames_counter += 1
else:
    self.music_frames_counter = 0

if not self.music_mode and self.music_frames_counter >= 15:  # ~300ms at 20ms/frame
    self.music_mode = True
    self.music_cooldown_frames = 100  # e.g. 2s
    log.info("[AUDIO_GUARD] Entering music_mode (rms=%.1f, zcr=%.3f)", rms, zcr)

if self.music_mode:
    self.music_cooldown_frames -= 1
    if self.music_cooldown_frames <= 0:
        self.music_mode = False
        self.music_frames_counter = 0
        log.info("[AUDIO_GUARD] Leaving music_mode")


	3.	While self.music_mode is True and AUDIO_GUARD_ENABLED is True:
	•	Do not enqueue these frames into realtime_audio_in_queue.
	•	Just drop them silently (with occasional logs, not per frame).

⸻

6. Apply the guard before sending to OpenAI

Where you currently push frames into realtime_audio_in_queue:

if AUDIO_GUARD_ENABLED:
    rms = ...   # reuse existing calculation
    zcr = ...   # compute as described
    effective_threshold = self.noise_floor * self.speech_threshold_factor

    if self.music_mode:
        # already handled by section 5: drop frame
        # (optionally log once every N frames)
        continue

    if not _is_probable_speech(rms, zcr, effective_threshold, self.audio_guard_prev_rms):
        # drop clear non-speech noise
        # use a rate-limited log helper so logs are not spammy
        self._maybe_log_non_speech_drop(rms, zcr, effective_threshold)
        self.audio_guard_prev_rms = rms
        continue

    self.audio_guard_prev_rms = rms

# existing code:
realtime_audio_in_queue.put(frame, timeout=...)

Add a helper _maybe_log_non_speech_drop that logs at most once every X frames or Y seconds to avoid log spam.

⸻

7. Disable complex GAP_RECOVERY when audio guard is ON

Find the existing logic that prints logs like:
	•	⚠️ [AUDIO GAP] ...
	•	GAP RECOVERY
	•	Inserted silence frames

Wrap this logic so that it is disabled when AUDIO_GUARD_ENABLED is True:

if AUDIO_GUARD_ENABLED:
    # In guard mode we do NOT synthesize extra silence frames.
    # Let the real timing from Twilio + OpenAI be used as-is.
    pass
else:
    # existing gap recovery / insertion code

Add a startup log in the audio pipeline:

log.info(
    "[AUDIO_GUARD] Enabled=%s (dynamic noise floor, speech gating, music_mode, gap_recovery=%s)",
    AUDIO_GUARD_ENABLED,
    "OFF" if AUDIO_GUARD_ENABLED else "ON",
)


⸻

8. Logging & safety checks
	1.	Add a small, periodic summary log (e.g. every 5 seconds or every N frames):

log.debug(
    "[AUDIO_GUARD] noise_floor=%.1f, threshold=%.1f, music_mode=%s",
    self.noise_floor,
    self.noise_floor * self.speech_threshold_factor,
    self.music_mode,
)


	2.	Never log every single frame – use counters / timestamps to throttle logs.
	3.	Verify:
	•	The system compiles and runs (python -m py_compile where appropriate).
	•	The WebSocket loop and Twilio handlers are not blocked by new code (only arithmetic on the frame).

⸻

9. Final verification checklist

Before you finish, verify and summarize:
	1.	Code safety
	•	AUDIO_GUARD_ENABLED exists, defaults to True, no .env used.
	•	When set to False, the behavior is identical to previous build.
	2.	Isolation
	•	Only audio-pipeline modules changed; no CRM / lead / DB / routes touched.
	3.	Behavior
	•	Non-speech noise and strong background music are dropped before reaching OpenAI.
	•	Dynamic noise floor and threshold are in use (confirmed via debug logs).
	•	GAP_RECOVERY is effectively disabled when AUDIO_GUARD_ENABLED is True.
	4.	Performance
	•	There is no additional blocking or waiting; all processing is per frame and cheap.
	•	No noticeable added latency in logs between speech_started and the first OpenAI response.
	5.	Provide a short summary in the logs or comments describing:
	•	Which functions/files were changed
	•	How to toggle AUDIO_GUARD_ENABLED if needed

⸻

Implement all of this carefully and conservatively.
The goal is more stable, realistic calls on noisy PSTN lines with minimal code risk and an easy kill-switch via AUDIO_GUARD_ENABLED.