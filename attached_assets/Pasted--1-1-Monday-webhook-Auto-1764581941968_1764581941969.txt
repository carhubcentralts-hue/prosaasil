×”×‘× ×ª×™ ×œ×’××¨×™.
×”× ×” ×”× ×—×™×” ××—×ª, ××¡×•×“×¨×ª, ×‘×× ×’×œ×™×ª, ×œ×”×“×‘×§×” 1:1 ×œ×¡×•×›×Ÿ ×‘×¨×™×¤×œ×™×˜. ×–×” ×›×•×œ×œ Monday webhook + Auto hangup + Bot speaks first + Barge-in, ×¢× ×›×‘×•×“ ××œ× ×œ×¤×¨×•×™×§×˜ ×•×œ×©×¨×ª ×”×—×™×¦×•× ×™.

â¸»

SYSTEM / PROJECT CONTEXT â€“ READ FIRST, DO NOT CHANGE

You are working on my ProSaaS AI Call Center + CRM project.

Tech stack (already working in production):
	â€¢	Backend: Python (Flask/FastAPI style), Twilio voice calls (including Realtime / media stream), WhatsApp (Baileys + Meta Cloud), AI services.
	â€¢	Frontend: React + TypeScript (multi-tenant CRM, business settings, AI settings, WhatsApp, calls, etc.).
	â€¢	DB: Postgres (Neon) with existing migration system.
	â€¢	Deployment: Docker + docker-compose + nginx on an external server (Contabo) that pulls from this Git repo and runs docker compose there.

Important:
The code in this repo is already working in production. Your job is to extend it safely.

â¸»

HARD RULES (DO NOT BREAK THESE)
	1.	Do NOT touch deployment / infra files:
	â€¢	Do NOT edit: .env, docker-compose.yml, Dockerfile*, docker/nginx.conf, or any external server scripts.
	â€¢	Do NOT add new services to docker-compose.
	2.	Do NOT modify anything in external server repos.
Only change the current repo (the one you see in Replit). I will handle git push, git pull and docker compose on the external server myself.
	3.	Do NOT break existing behavior:
	â€¢	Existing Twilio call flows must keep working.
	â€¢	Existing WhatsApp flows (Baileys + Meta) must keep working.
	â€¢	Existing CRM, settings pages, AI prompts, dashboards must continue working as they do now.
	4.	New features must be:
	â€¢	Per-business configurable (feature flags / settings per business).
	â€¢	Off by default, so current businesses are not affected until they enable them.
	â€¢	Backwards compatible with current API responses (no field renames, only additions).

At the end, the repo must build and run cleanly (backend + frontend) with no new errors.

â¸»

GOAL

Implement the following features in this repo:
	1.	Monday.com webhook integration
	â€¢	Per-business fields in DB + UI.
	â€¢	When enabled, every completed call will send its full transcript and call metadata to a business-specific Monday webhook URL.
	2.	Auto hang-up logic
	â€¢	Optional per-business flags to:
	â€¢	Hang up automatically once all required lead details are collected, OR
	â€¢	Hang up when the customer clearly says â€œbye / ×ª×•×“×” / ××™×Ÿ ×¦×•×¨×š / ×œ×”×™×ª×¨××•×ªâ€, etc.
	3.	Bot speaks first (play greeting before listening)
	â€¢	Optional per-business flag: the bot says the greeting first, then starts listening.
	4.	Improved barge-in behavior
	â€¢	Make barge-in more natural: interrupt TTS only when the user is clearly speaking, not on small noises.

All of this must be done inside the existing architecture, without touching infra files.

â¸»

1) Monday.com Webhook â€“ Send Call Transcripts

1.1 Backend model & settings API
	1.	Locate the Business (or equivalent) model used for business-level settings.
	â€¢	This is the same model behind /api/business/current and /api/business/current/settings.
	2.	Add these fields to the business/settings model (names must be exactly):

	â€¢	monday_webhook_url â€“ nullable string.
	â€¢	send_call_transcripts_to_monday â€“ boolean, default False.

	3.	Add a DB migration using the existing migration mechanism (for example db_migrate.py or Alembic scripts):

	â€¢	Add the two columns with safe defaults (NULL for URL, False for the flag).
	â€¢	Do NOT drop or alter existing columns.

	4.	Update the API that returns current business settings, e.g.:

	â€¢	GET /api/business/current
	â€¢	GET /api/business/current/settings

Make sure the JSON response includes:

{
  "monday_webhook_url": "... or null ...",
  "send_call_transcripts_to_monday": true/false,
  ...
}

	5.	Update the settings update endpoint (likely PUT /api/business/current/settings) to:

	â€¢	Accept monday_webhook_url (string, may be empty).
	â€¢	Accept send_call_transcripts_to_monday (boolean).
	â€¢	Save them on the business/settings model.
	â€¢	Keep all existing behavior for other fields.

â¸»

1.2 Monday webhook service

Create or extend a dedicated service module, e.g.
server/services/monday_webhook_service.py:

Implement:

import logging
import requests

logger = logging.getLogger(__name__)

def send_call_transcript_to_monday(*, business, call, transcript: str) -> None:
    """
    If the business enabled Monday integration, send a JSON payload with call
    details + transcript to the configured monday_webhook_url.

    This function must NEVER break the main call flow. If it fails,
    log a warning and return.
    """

Behavior:
	â€¢	Read business.monday_webhook_url and business.send_call_transcripts_to_monday.
	â€¢	If URL is empty/None or flag is False â†’ return immediately.
	â€¢	Otherwise send a POST with JSON, for example:

{
  "source": "prosaas_call_center",
  "business_id": ...,
  "business_name": "...",
  "call_id": ...,
  "call_sid": "...",
  "direction": "inbound" | "outbound",
  "from_number": "...",
  "to_number": "...",
  "started_at": "ISO8601",
  "ended_at": "ISO8601",
  "duration_sec": 123,
  "transcript": "full call transcript text"
}

	â€¢	Wrap requests.post in try/except:
	â€¢	Log logger.warning on errors.
	â€¢	Do NOT raise exceptions.

â¸»

1.3 Hook into call finalization
	1.	Locate the code that finalizes a call and stores the final transcript.
This is usually in a route or service like routes_calls.py, call_processing, or a background job that processes recordings.
	2.	After the final transcript is:

	â€¢	Assembled (all segments / messages joined).
	â€¢	Saved to DB.
	â€¢	Committed (if using a transaction).

Add a call:

from server.services.monday_webhook_service import send_call_transcript_to_monday

send_call_transcript_to_monday(
    business=call.business,  # or however you access the related business
    call=call,
    transcript=final_transcript_text,  # use the actual full text
)

Wrap this call in a try/except if necessary so it never breaks the main flow.

â¸»

2) UI â€“ Monday Integration Section in System Settings

Goal: in the System Settings â†’ Business tab (where business name, phone, email are), add a section:
	â€¢	â€œ××™× ×˜×’×¨×¦×™×” ×¢× Monday.comâ€
	â€¢	Text input: Monday Webhook URL
	â€¢	Checkbox: â€œ×©×œ×— ×ª××œ×•×œ×™ ×©×™×—×•×ª ××•×˜×•××˜×™×ª ×œ-Mondayâ€

Steps:
	1.	Open the React settings page, e.g. client/src/pages/settings/SettingsPage.tsx (the one you already use for business settings, appointments, integrations, etc.).
	2.	Extend the BusinessSettings TypeScript interface to include:

monday_webhook_url?: string | null;
send_call_transcripts_to_monday?: boolean;

	3.	In the useQuery that loads /api/business/current:

	â€¢	Map the backend fields into the businessSettings state.
	â€¢	Make sure default values are safe:
	â€¢	monday_webhook_url â†’ empty string if missing.
	â€¢	send_call_transcripts_to_monday â†’ false if missing.

	4.	In the Business tab UI, under the existing â€œBusiness detailsâ€ card, add another Card:

	â€¢	Title: â€œ××™× ×˜×’×¨×¦×™×” ×¢× Monday.comâ€.
	â€¢	Inside:
	â€¢	<input> (dir=â€œltrâ€) bound to businessSettings.monday_webhook_url.
	â€¢	<input type="checkbox"> bound to businessSettings.send_call_transcripts_to_monday.
	â€¢	Short helper text in Hebrew explaining that if this is enabled, every completed call transcript will be sent to Monday.

	5.	When clicking the global â€œ×©××•×¨ ×”×’×“×¨×•×ªâ€ button for the Business tab:

	â€¢	Ensure the PUT /api/business/current/settings payload includes:
	â€¢	monday_webhook_url
	â€¢	send_call_transcripts_to_monday
together with the existing fields.

â¸»

3) Auto Hang-Up Logic

3.1 Business settings

Add two boolean fields on the business/settings model:
	â€¢	auto_end_after_lead_capture â€“ default False.
	â€¢	auto_end_on_goodbye â€“ default False.

Expose them in:
	â€¢	GET /api/business/current / settings
	â€¢	PUT /api/business/current/settings

Add them to the Settings UI (Business or AI tab) as checkboxes, e.g.:
	â€¢	â€œ× ×ª×§ ×©×™×—×” ××•×˜×•××˜×™×ª ××—×¨×™ ×§×‘×œ×ª ×›×œ ×¤×¨×˜×™ ×”×œ×™×“â€
	â€¢	â€œ× ×ª×§ ×©×™×—×” ×›×©×œ×§×•×— ××•××¨ ×‘×™×™ / ×ª×•×“×” / ××™×Ÿ ×¦×•×¨×šâ€

3.2 Call logic
	1.	Find the AI call session code (Twilio realtime/media stream handler) that:

	â€¢	Receives user speech.
	â€¢	Transcribes it.
	â€¢	Sends context to the AI model.
	â€¢	Streams TTS back.

	2.	In the call session state, maintain:

self.lead_captured = False
self.goodbye_detected = False
self.pending_hangup = False

	3.	After each user utterance (transcribed text), update these flags:

	â€¢	If you already track required lead fields (name, phone, service, date, etc.) and they are all present â†’ self.lead_captured = True.
	â€¢	If the user text contains clear goodbye expressions (Hebrew + simple English), like:
	â€¢	â€œ×ª×•×“×”â€, â€œ×ª×•×“×” ×¨×‘×”â€, â€œ××™×Ÿ ×¦×•×¨×šâ€, â€œ×–×”×•â€, â€œ×‘×™×™â€, â€œ×œ×”×ª×¨××•×ªâ€
	â€¢	â€œthanksâ€, â€œthatâ€™s allâ€, â€œno needâ€, â€œbyeâ€
â†’ self.goodbye_detected = True.

	4.	After generating the botâ€™s next response:

	â€¢	If business.auto_end_after_lead_capture is True and self.lead_captured is True:
	â€¢	Mark self.pending_hangup = True.
	â€¢	Else if business.auto_end_on_goodbye is True and self.goodbye_detected is True:
	â€¢	Mark self.pending_hangup = True.

	5.	When the final TTS chunk of that response has been sent:

	â€¢	If self.pending_hangup is True:
	â€¢	Use the existing Twilio integration to end the call cleanly:
	â€¢	For TwiML: send <Hangup/> or end the flow.
	â€¢	For realtime/media-stream: call the Twilio REST API to update the call status to completed, or send the official disconnect message.
	â€¢	Ensure you only do this once.

â¸»

4) Bot Speaks First (Greeting Before Listening)

4.1 Setting

Add a boolean field:
	â€¢	bot_speaks_first (or play_greeting_before_listening), default False.

Expose it via the same business/AI settings APIs.
In the AI calls settings UI (where you configure the call greeting text), add a checkbox:
	â€¢	Label (Hebrew): â€œ×”×‘×•×˜ ××“×‘×¨ ×¨××©×•×Ÿ (× ×™×’×•×Ÿ ×”×•×“×¢×ª ×¤×ª×™×—×” ×œ×¤× ×™ ×©××§×©×™×‘×™× ×œ×œ×§×•×—)â€.

4.2 Call flow
	1.	On call start, when the AI session is created:

	â€¢	Read business.bot_speaks_first (or similar).
	â€¢	Read the greeting_message already used for calls.

	2.	If bot_speaks_first is True:

	â€¢	Immediately enqueue a bot TTS message with the greeting as the first turn.
	â€¢	Do not start user speech recognition until greeting TTS is started.
(You may allow barge-in during the greeting if barge-in is enabled, see next section.)

	3.	If bot_speaks_first is False:

	â€¢	Keep the current â€œuser speaks firstâ€ behavior exactly as today.

â¸»

5) Improve Barge-In Behavior

Goal: user must be able to interrupt the bot naturally, but we donâ€™t want to cut off TTS for small noises.

5.1 Locate current barge-in code

Search in the backend for:
	â€¢	barge, barge_in, interrupt_tts, VAD, speech_threshold, RMS, etc.

Identify:
	â€¢	Where the system knows the bot is speaking (TTS in progress).
	â€¢	Where incoming audio from the user is evaluated for barge-in.

5.2 Improve logic (keep API unchanged)

Add/adjust:
	1.	Clear flags in the session:

self.bot_speaking = True/False
self.user_turn_open = True/False

	2.	While self.bot_speaking is True and incoming audio frames from the user arrive:

	â€¢	Compute average RMS/energy over a short sliding window.
	â€¢	Consider it a valid barge-in only if:
	â€¢	RMS is above a BARGE_IN_SPEECH_THRESHOLD, and
	â€¢	This condition is sustained for at least 250â€“300 ms.

	3.	On valid barge-in:

	â€¢	Stop/flush current TTS stream (if API exists for that).
	â€¢	Set self.bot_speaking = False, self.user_turn_open = True.
	â€¢	Start or continue STT for that user utterance.

	4.	Define constants at the top of the file, commented:

BASE_SPEECH_THRESHOLD = ...
BARGE_IN_SPEECH_THRESHOLD = BASE_SPEECH_THRESHOLD * 1.2
BARGE_IN_MIN_MS = 250

	5.	If the call is in pending_hangup state (from section 3), you can either disable barge-in or handle carefully to avoid weird â€œextra turnsâ€ after the bot has already indicated conversation is over.

Do not change any external API; only adjust internal logic.

â¸»

6) FINAL CHECKLIST (BEFORE YOU STOP)
	1.	Backend:
	â€¢	All migrations run successfully locally.
	â€¢	/api/business/current and /api/business/current/settings work and include the new fields without breaking old ones.
	â€¢	Calls complete successfully as before.
	â€¢	When Monday integration is enabled and webhook URL is set, each completed call sends one HTTP POST to the Monday URL with the JSON payload.
	2.	Frontend:
	â€¢	Settings page loads properly.
	â€¢	Business tab shows:
	â€¢	Monday Webhook URL input.
	â€¢	â€œsend transcripts to Mondayâ€ checkbox.
	â€¢	AI/Call behavior settings show:
	â€¢	Auto end after lead capture.
	â€¢	Auto end on goodbye.
	â€¢	Bot speaks first.
	â€¢	Settings can be changed and saved, and the new values persist after reload.
	3.	Calls:
	â€¢	With all new flags disabled â†’ behavior is exactly as it was before.
	â€¢	With Monday enabled + webhook present â†’ new call transcript is sent.
	â€¢	With auto-end flags enabled â†’ call ends automatically in the correct scenarios.
	â€¢	With bot-speaks-first enabled â†’ greeting plays immediately on call start.
	â€¢	Barge-in still works and feels more natural.
	4.	Do NOT touch:
	â€¢	.env
	â€¢	docker-compose.yml
	â€¢	Dockerfile*
	â€¢	docker/nginx.conf
	â€¢	Any external server repository.

I (the user) will handle git add/commit/push and the git pull + docker compose on the external server.

â¸»

ğŸ§· Paste this entire instruction block into the Replit AI agent as-is.