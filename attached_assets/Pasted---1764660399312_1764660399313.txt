×”×‘× ×ª×™, ××ª×” ×¨×•×¦×” ×”× ×—×™×™×ªÖ¾×¢×œ ××—×ª, ××œ××”, ×©××›×¡×” ×’× ××ª ×”×‘×¨×›×•×ª, ×’× ××ª ×”× ×™×ª×•×§×™× ×”×—×›××™× ×œ×¤×™ ×¤×¨×•××¤×˜ ×•×œ×¤×™ ×“×™×‘×•×¨, ×•×’× ×©×œ× ×™×”×™×• × ×™×ª×•×§×™ â€œ×œ× ×¨×•×¦×” / ××™×Ÿ ×¦×•×¨×šâ€ â€“ ×”×›×•×œ ××•×ª×× ×œ×¤×¨×•×™×§×˜ ×©×œ×š.

×œ×”×œ×Ÿ ×˜×§×¡×˜ ×©××ª×” ×™×›×•×œ ×œ×”×¢×ª×™×§Ö¾×œ×”×“×‘×™×§ ×›××• ×©×”×•× ×œ×¡×•×›×Ÿ ×‘×¨×™×¤×œ×™×˜ (×‘×× ×’×œ×™×ª, ×¢× ×“×•×’×××•×ª ×‘×¢×‘×¨×™×ª):

â¸»

ğŸ”§ Task: Fix greeting playback, smart hangup logic, and call behavior for external server

You are working on the AI call center project in this Replit (Archive.zip version the user uploaded).
Current problems reported in PRODUCTION (external server):
	1.	Greeting issues
	â€¢	Greeting starts after ~3â€“6 seconds instead of ~1â€“2 seconds.
	â€¢	Greeting sometimes gets cut in the middle.
	â€¢	There are two greeting mechanisms:
	1.	Twilio TwiML <Play> or similar at call start
	2.	OpenAI Realtime greeting via WebSocket.
The interaction between them causes cutting and latency.
	â€¢	Barge-in sometimes cancels the greeting or other bot speech too aggressively.
	2.	Hangup behavior
	â€¢	We now have call-behavior settings (auto end, bot speaks first, etc.), but:
	â€¢	When the user says things like â€œ×œ× ×¨×•×¦×”â€, â€œ×œ× ×¦×¨×™×šâ€, â€œ××™×Ÿ ×¦×•×¨×šâ€ â€“ the bot sometimes hangs up immediately, which is wrong.
	â€¢	When the bot finishes collecting all required details (lead details), it does not always hang up even when auto-end is enabled.
	â€¢	When the user says â€œ×‘×™×™â€ / â€œ×œ×”×ª×¨××•×ªâ€ etc., the system sometimes cuts them off with a rude, immediate hangup instead of a polite closing sentence.
	â€¢	We must support different prompts: in some prompts we only need city + service type (no phone), in others we might need more fields. Hangup rules must be prompt/business aware â€“ not hard-coded to always require a phone number.
	3.	Voice consistency
	â€¢	During some calls, the voice of the assistant suddenly changes mid-conversation (e.g. different OpenAI voice or TTS params).
	â€¢	We need one consistent voice per call.

Your job: analyze the existing code in this project and implement a robust, production-grade behavior for greeting, barge-in, and hangup logic â€“ without breaking the external server setup.

â¸»

1ï¸âƒ£ Greeting: single source, fast, never cut

1.1 Remove duplicate greeting paths
	1.	Scan the server for Twilio voice routes, typically files like:
	â€¢	server/routes_twilio.py (or similar)
	â€¢	any TwiML generation functions for incoming calls
	2.	Goal: there must be no TwiML <Play> greeting audio at the start of the call when we are using the OpenAI Realtime greeting.
	â€¢	If you find something like:

<Response>
  <Play>https://...</Play>
  <Connect>
    <Stream>...</Stream>
  </Connect>
</Response>

Replace it so that the call goes directly to <Connect><Stream> with no <Play> before it. All greeting audio should be generated only by the OpenAI Realtime session and our Python handler.

	3.	Make sure only one greeting mechanism exists:
	â€¢	Call starts â†’ Twilio connects WebSocket â†’ our media WS handler starts OpenAI Realtime â†’ greeting is played from there.

1.2 Optimize greeting loading and playback

In the media WebSocket AI handler (file likely named media_ws_ai.py or similar):
	1.	There should be a place where we:
	â€¢	Identify the business (using Twilio phone number / business_id)
	â€¢	Load business settings, prompts, and greeting text from DB
	â€¢	Create / configure OpenAI Realtime session
	2.	Ensure the following behavior:
	â€¢	Combined DB query:
Load business info, call behavior settings, and greeting text in one query or one ORM call, not several separate queries.
	â€¢	Parallel OpenAI connection:
As soon as the WebSocket connects and we know the business_id, start connecting to OpenAI Realtime in parallel with DB queries â€“ donâ€™t wait for DB to finish before opening the Realtime connection.
	â€¢	Store greeting text in a field like:

self.greeting_text: Optional[str]
self.greeting_response_id: Optional[str]
self.greeting_sent: bool = False
self.is_playing_greeting: bool = False



1.3 Greeting playback logic

Implement / verify this exact logic:
	1.	At call start, after OpenAI Realtime session is configured and self.greeting_text is non-empty, and if bot_speaks_first or similar flag is enabled:

async def send_greeting(self):
    if self.greeting_sent or not self.greeting_text:
        return
    self.is_playing_greeting = True
    self.barge_in_enabled_after_greeting = False

    response = await self.openai_client.responses.create(
        # use the same model & voice we use for all messages
        force_parsed=True,
        instructions=None,
        input=[{
          "role": "assistant",
          "content": [
            {"type": "input_text", "text": self.greeting_text}
          ]
        }]
    )
    self.greeting_response_id = response.id
    self.greeting_sent = True


	2.	In the Realtime event handler (response.audio_transcript.done or equivalent):

async def handle_response_done(self, event):
    if event.response_id == self.greeting_response_id:
        # greeting finished playing
        self.is_playing_greeting = False
        self.barge_in_enabled_after_greeting = True


	3.	While self.is_playing_greeting is True:
	â€¢	Do NOT send response.cancel to OpenAI for the greeting.
	â€¢	Do NOT treat user audio as barge-in (see section 2 below).

This guarantees greeting is never cut, and barge-in only starts after the greeting finished.

â¸»

2ï¸âƒ£ Barge-in: safe, not cutting greeting

In your audio/VAD handler:
	1.	Maintain a flag:

self.barge_in_enabled_after_greeting: bool = False

Set it to True only once greeting finished (see above).

	2.	Barge-in decision should be:

def should_barge_in(self, rms: float, duration_ms: int) -> bool:
    if self.is_playing_greeting:
        return False  # never interrupt greeting
    if not self.barge_in_enabled_after_greeting:
        return False  # before greeting finished, no barge-in
    return rms > 200 and duration_ms >= 180


	3.	When barge-in triggers:
	â€¢	Only cancel the current AI response if there is one active.
	â€¢	Never send multiple cancels.
	â€¢	Donâ€™t start a new AI response until you fully processed the user speech.

â¸»

3ï¸âƒ£ Smart Hangup Logic â€“ prompt aware & polite

We need hangup rules that depend on:
	â€¢	Business / prompt configuration (which fields are required for this flow).
	â€¢	User explicit goodbye.
	â€¢	Bot explicit closing message.

And never hang up just because the user said â€œ×œ× ×¨×•×¦×” / ××™×Ÿ ×¦×•×¨×šâ€.

3.1 Phrase detection helpers

Implement 3 functions in the call handler (or a dedicated module):

GOODBYE_PHRASES = [
    # Hebrew
    "×‘×™×™", "×œ×”×ª×¨××•×ª", "×™××œ×œ×” ×‘×™×™", "×™×•× ×˜×•×‘, ×œ×”×ª×¨××•×ª",
    "×œ×™×œ×” ×˜×•×‘, ×œ×”×ª×¨××•×ª", "×‘×™×™ ×ª×•×“×”", "×–×”×• ×ª×•×“×”, ×‘×™×™", "×¡×™×™×× ×• ×ª×•×“×”",
    # English
    "bye", "goodbye", "see you", "talk to you later", "thanks, bye"
]

DECLINE_ONLY_PHRASES = [
    "×œ× ×¨×•×¦×”", "×œ× ×¦×¨×™×š", "××™×Ÿ ×¦×•×¨×š", "×œ× ××¢×•× ×™×™×Ÿ",
    "×œ× ××¢× ×™×™×Ÿ", "×œ× ×¢×›×©×™×•", "×œ× ××ª××™× ×œ×™", "×¢×–×•×‘ ×ª×•×“×”"
]

def normalize_text(text: str) -> str:
    return text.strip().lower()

def is_goodbye_phrase(text: str) -> bool:
    t = normalize_text(text)
    return any(p in t for p in GOODBYE_PHRASES)

def is_decline_without_goodbye(text: str) -> bool:
    t = normalize_text(text)
    if any(p in t for p in GOODBYE_PHRASES):
        return False  # handled separately as goodbye
    return any(p in t for p in DECLINE_ONLY_PHRASES)

3.2 Internal flags

In the call/session class add:

self.pending_hangup_reason: Optional[str] = None
self.ai_marked_conversation_done: bool = False

3.3 User transcript handler

Where you process user text (STT â†’ text), apply this order:

async def handle_user_text(self, text: str):
    t = normalize_text(text)

    if is_goodbye_phrase(t) and self.auto_end_on_goodbye:
        # user explicitly said goodbye
        self.pending_hangup_reason = "user_goodbye"
        await self.send_polite_closing_message()
        # hangup will be triggered after closing message audio finishes
        return

    if is_decline_without_goodbye(t):
        # user not interested, but no goodbye
        await self.send_polite_decline_reply()
        # IMPORTANT: do NOT set any hangup flag here.
        return

    # Normal handling (lead capture, FAQ, etc.)
    await self.process_business_logic(text)

Implement:

async def send_polite_closing_message(self):
    # one short, polite line only, no long conversation here
    closing_text = (
        "×‘×©××—×”, ×ª×•×“×” ×©×“×™×‘×¨×ª ××™×ª×™. ×× ×ª×¦×˜×¨×š ××©×”×• × ×•×¡×£ ×‘×¢×ª×™×“, ×ª××™×“ ××¤×©×¨ ×œ×¤× ×•×ª ××œ×™× ×•. ×œ×”×ª×¨××•×ª!"
    )
    # send via OpenAI response (same model & voice)
    self.ai_marked_conversation_done = True
    await self.send_ai_text_as_assistant(closing_text)

async def send_polite_decline_reply(self):
    reply = (
        "×”×›×•×œ ×˜×•×‘, ×ª×•×“×” ×©×“×™×‘×¨×ª ××™×ª×™. ×× ×ª×ª×—×¨×˜ ×‘×¢×ª×™×“ ×ª××™×“ ××¤×©×¨ ×œ×¤× ×•×ª ××œ×™× ×• ×©×•×‘."
    )
    await self.send_ai_text_as_assistant(reply)

3.4 Bot-driven â€œconversation finishedâ€

For prompt-dependent flows (for example: some prompts only require service category + problem + city, others also phone, email, etc.):
	1.	Reuse the existing business configuration that lists required lead fields for each prompt/business (if it doesnâ€™t exist, add something like required_lead_fields: List[str] to business settings).
	2.	When your lead-capture logic sees that all required fields are present:

if self.has_all_required_lead_fields() and self.auto_end_after_lead_capture:
    self.pending_hangup_reason = "lead_complete"
    self.ai_marked_conversation_done = True
    await self.send_lead_complete_closing_message()
    # hangup after audio finishes


	3.	has_all_required_lead_fields() must not be hard-coded to â€œhas phone + nameâ€. It should check the configured list (e.g. ["service_category", "problem_description", "city"]).

3.5 Hangup timing â€“ never cut speech

In the Realtime assistant audio done handler (where you already handle response.audio_transcript.done):

async def handle_assistant_audio_done(self, event):
    # This is called every time an assistant message finishes playing

    if self.ai_marked_conversation_done or self.pending_hangup_reason:
        # Now it's safe to hang up
        await self.safe_hangup_call()

safe_hangup_call() should:
	â€¢	Stop OpenAI streaming.
	â€¢	Send the proper Twilio command to end the call.
	â€¢	Log the pending_hangup_reason and final transcript for debugging and analytics.

This guarantees:
	â€¢	User says goodbye â†’ bot responds politely â†’ only after that message finishes â†’ hangup.
	â€¢	Bot finishes its own closing script â†’ hangup afterwards.
	â€¢	Decline phrases (â€œ×œ× ×¨×•×¦×” / ××™×Ÿ ×¦×•×¨×šâ€) â†’ polite answer, no hangup unless they also say goodbye.

â¸»

4ï¸âƒ£ Voice consistency
	1.	Find where OpenAI Realtime session is configured (model + voice) and where TTS/voice settings are applied.
	2.	Set all voice-related parameters once per call, for example:

self.model = business_settings.openai_model or "gpt-4o-realtime"
self.voice = business_settings.voice_id or "he-IL-default"

	3.	Use the same model + voice for:
	â€¢	Greeting
	â€¢	Normal responses
	â€¢	Closing messages
	4.	Ensure no per-message overrides are changing the voice mid-call.
If you find places where different voices are used for system messages vs. user messages, remove that and standardize on one voice.

â¸»

5ï¸âƒ£ WhatsApp side (quick sanity check)

Even though current WhatsApp code â€œlooks fineâ€, still:
	1.	Verify that WhatsApp handlers:
	â€¢	Always send the full assistant message in one WhatsApp message.
	â€¢	Do not split messages or cut them based on token count incorrectly.
	2.	Log full incoming and outgoing WhatsApp texts for a few test conversations to confirm there is no truncation.

â¸»

6ï¸âƒ£ Final checklist before you stop

Please verify, with real test calls on the external server:
	1.	âœ… Greeting starts within ~1â€“2 seconds of call start and never gets cut.
	2.	âœ… User talking during greeting does not interrupt it.
	3.	âœ… After greeting, barge-in works and doesnâ€™t feel over-aggressive.
	4.	âœ… Saying â€œ×œ× ×¨×•×¦×” / ×œ× ×¦×¨×™×š / ××™×Ÿ ×¦×•×¨×šâ€ â†’ polite answer, call stays open.
	5.	âœ… Saying â€œ×œ× ×¦×¨×™×š, ×‘×™×™â€ â†’ bot answers with a short polite closing sentence and only then hangs up.
	6.	âœ… After all configured lead fields are collected and auto-end is enabled â†’ bot gives closing line and then hangs up.
	7.	âœ… Voice stays the same throughout the entire call.
	8.	âœ… WhatsApp messages are not cut in the middle.

Only when all of the above are true, the build is considered ready for production.

â¸»

×–×”×•, ×–×• ×”× ×—×™×™×ªÖ¾×¢×œ ××œ××”, ×›×•×œ×œ ×”×‘×¨×›×”, ×”Ö¾barge-in, ×”× ×™×ª×•×§×™× ×”×—×›××™×, ×•×”×§×•×œ ×”×§×‘×•×¢.
×¤×©×•×˜ ×ª×¢×©×” copy-paste ×œ×¡×•×›×Ÿ ×‘×¨×™×¤×œ×™×˜.