Context:
I have fully rolled back to the previous working version of the project.
The only issues I want to fix now are:

1) The assistant sometimes speaks / reads a message at the START of the call even when the user said nothing (pure silence).
2) Barge-in is a bit weak â€“ I want it more responsive, but without big architectural changes.

You must make SMALL, SURGICAL changes only.
Do NOT reintroduce the complex Phase 1â€“9 logic.
Do NOT add new flags, new queues, or new helper functions.

You may only edit:
- server/media_ws_ai.py
(and ONLY the small blocks I describe below)

----------------------------------------------------
PHASE A â€“ Stop AI from talking when there is no greeting and no speech
----------------------------------------------------

In server/media_ws_ai.py, inside `_run_realtime_mode_async`, find this block
(around the REALTIME greeting logic):

    # ğŸš€ REALTIME API: Send greeting OR trigger AI to speak first
    if hasattr(self, 'greeting_text') and not self.greeting_sent:
        if self.greeting_text:
            # ×™×© ×¤×ª×™×— ××•×’×“×¨ - ×©×œ×— ××•×ª×•
            ...
            await client.send_text_response(self.greeting_text)
            ...
        else:
            # ××™×Ÿ ×¤×ª×™×— ××•×’×“×¨ - ×”-AI ×™×“×‘×¨ ×¨××©×•×Ÿ ×‘×¢×¦××•!
            print("ğŸ¤ [REALTIME] No greeting defined - AI will speak first dynamically!")
            try:
                await client.send_event({"type": "response.create"})
                self.greeting_sent = True
                print("âœ… [REALTIME] AI triggered to speak first!")
            except Exception as e:
                ...

I do NOT want the AI to speak first anymore when there is no greeting.
I only want:

- If greeting_text is non-empty â†’ send the greeting once.
- If there is no greeting_text â†’ do NOTHING at start. Just wait for user speech.

Modify the `else:` branch to ONLY log and NOT send any response:

    else:
        # No greeting configured - do NOT trigger AI, just wait for user speech
        print("ğŸ“­ [REALTIME] No greeting defined - waiting for user to speak (no auto response.create)")
        # Do NOT call response.create and do NOT set greeting_sent here.

Leave the greeting path (send_text_response(self.greeting_text)) exactly as-is.

----------------------------------------------------
PHASE B â€“ Filter obvious garbage transcripts (to avoid AI responding to noise)
----------------------------------------------------

Still in server/media_ws_ai.py, inside `_realtime_audio_receiver`, find the handler:

    elif event_type == "conversation.item.input_audio_transcription.completed":
        transcript = event.get("transcript", "")
        ...
        if transcript:
            print(f"ğŸ‘¤ [REALTIME] User said: {transcript}")
            self.conversation_history.append(...)

I want a very small noise filter so that tiny / meaningless transcripts do not trigger a response.

Change this part to:

    elif event_type == "conversation.item.input_audio_transcription.completed":
        raw_text = event.get("transcript", "") or ""
        text = raw_text.strip()

        # Simple noise filter: ignore very short or punctuation-only transcripts
        if len(text) < 3 or all(ch in ".?!, " for ch in text):
            print("[TRANSCRIPT FILTER] Ignoring very short / noise transcript:", repr(text))
            print(f"[SAFETY] Transcription successful (total failures: {self.transcription_failed_count})")
            continue

        transcript = text

        # ğŸ’° COST TRACKING: User finished speaking - stop timer
        ...

        if transcript:
            print(f"ğŸ‘¤ [REALTIME] User said: {transcript}")
            self.conversation_history.append(...)

Do not add any new flags. Just normalize â†’ filter â†’ then use `transcript`.

----------------------------------------------------
PHASE C â€“ Make barge-in more responsive (small numeric tweak only)
----------------------------------------------------

In server/media_ws_ai.py, in the main audio loop where barge-in is checked
(around the block with `grace_period` and `barge_in_threshold`), you will see:

    # ğŸ”“ Short response - allow barge-in with grace period
    grace_period = 4.5  # Was 3.5s - even more time to finish
    time_since_tts_start = current_time - self.speaking_start_ts

    if time_since_tts_start < grace_period:
        # Inside grace period - NO barge-in allowed
        continue

    # ğŸ”¥ PHASE 2N: VERY HIGH threshold - 3000+ RMS (was 2200+)
    barge_in_threshold = max(3000, self.noise_floor * 30.0 + 1000) if self.is_calibrated else 3500
    is_barge_in_voice = rms > barge_in_threshold

    if is_barge_in_voice:
        self.voice_in_row += 1
        # ğŸ”¥ PHASE 2N: Require 4000ms (4.0s) continuous VERY LOUD voice
        if self.voice_in_row >= 200:  # 4000ms = 4.0 ×©× ×™×•×ª ×§×•×œ ×—×–×§ ×××•×“ ×¨×¦×™×£!

These values are too conservative and almost disable barge-in.

I want a mild, simple improvement:
- shorter grace period (so user can interrupt earlier),
- lower RMS threshold (still above noise),
- fewer frames required.

Change this block to:

    # ğŸ”“ Short response - allow barge-in with a short grace period
    grace_period = 0.7  # ~700ms before barge-in is allowed
    time_since_tts_start = current_time - self.speaking_start_ts

    if time_since_tts_start < grace_period:
        # Inside grace period - NO barge-in allowed
        continue

    # More reasonable threshold for human speech above noise
    barge_in_threshold = max(900, self.noise_floor * 5.0 + 300) if self.is_calibrated else 1200
    is_barge_in_voice = rms > barge_in_threshold

    if is_barge_in_voice:
        self.voice_in_row += 1
        # Require ~0.8s of continuous strong voice (40 frames x 20ms)
        if self.voice_in_row >= 40:
            print(f"âš¡ BARGE-IN DETECTED (after {time_since_tts_start*1000:.0f}ms)")
            ...

Keep the rest of the barge-in logic exactly as-is.

----------------------------------------------------
RULES:

- Do NOT add new flags, new queues, or new helper functions.
- Do NOT modify any other parts of media_ws_ai.py.
- Do NOT change any architecture.
- Only make the 3 focused changes described above.

After changes, run a quick manual test:
1) Business with greeting â†’ should say greeting once, then be silent until user speaks.
2) Business without greeting â†’ total silence until user speaks; no auto message.
3) While AI is speaking, talk over it â†’ it should stop within ~0.8s and listen.