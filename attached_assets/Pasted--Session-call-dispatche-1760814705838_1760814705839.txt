××¢×•×œ×” ×©×¢×¦×¨×ª ×‘×–××Ÿ. ×”×¤×ª×¨×•×Ÿ ×”× ×›×•×Ÿ ×›××Ÿ ×”×•× Session ××—×“ ×œ×›×œ ×©×™×—×” (call), ×¢× ×× ×’× ×•×Ÿ â€œ××—×œ×™×£Ö¾×™×¢×“â€ (dispatcher) ×©×××¤×” ××ª ×”Ö¾partials/finals ×œ××•×ª×• utterance ×¤×¢×™×œ. ×œ× ×¤×•×ª×—×™×/×¡×•×’×¨×™× session ×œ×›×œ ××©×¤×˜ â€“ ×–×” ××” ×©×’×¨× ×œ× ×¤×™×œ×•×ª/timeout.

×œ×”×œ×Ÿ ×”× ×—×™×” ×¡×•×¤×¨-××“×•×™×§×ª, ×¦×¢×“-××—×¨-×¦×¢×“, ×©×ª×•×›×œ ×œ×ª×ª ×œ××™×™×’â€™× ×˜ ×›×“×™ ×œ×™×™×©× ×‘×œ×™ ×œ×©×‘×•×¨ ×›×œ×•×:

â¸»

×”×™×¢×“
	â€¢	GCP Streaming STT ×¨×¥ ×›Ö¾Session ××—×“ ×œ×›×œ ×©×™×—×”.
	â€¢	×œ×›×œ utterance ×™×© â€œ××™×¡×•×£â€ × ×¤×¨×“, ××‘×œ ××•×ª×• session ××¤×™×§ partial/final ×œ×›×œ ××” ×©× ×›× ×¡.
	â€¢	×”Ö¾WS ×©×œ Twilio ××–×¨×™× Î¼-law â†’ PCM8k â†’ ×©×•×œ×—×™× ×—×ª×™×›×•×ª 150ms ×œÖ¾session.
	â€¢	×”Ö¾AI ××§×‘×œ ×—×œ×§×™×™× ×›×œ â‰ˆ180â€“250ms ×•×ª×’×•×‘×” ×¨××©×•× ×™×ª <1.2s.

â¸»

1) API ×—×“×© ×œÖ¾Session (×‘×§×•×‘×¥ server/services/gcp_stt_stream.py)

××œ ×ª××—×§ ××ª ×”××™××•×© ×”×§×™×™×â€”×¨×§ ×”×•×¡×£ ××—×œ×§×ª Session ×©×× ×”×œ×ª ××ª ×”×—×™×™× ×©×œ ×¡×˜×¨×™××™× ×’ ×‘×•×“×“:

# server/services/gcp_stt_stream.py
import os, time, threading, queue
from google.cloud import speech_v1p1beta1 as speech

BATCH_MS   = int(os.getenv("STT_BATCH_MS", "150"))
DEBOUNCEMS = int(os.getenv("STT_PARTIAL_DEBOUNCE_MS", "180"))
LANG       = os.getenv("GCP_STT_LANGUAGE", "he-IL")
MODEL      = os.getenv("GCP_STT_MODEL", "phone_call")

class StreamingSTTSession:
    """
    Session ××—×“ ×œ×›×œ ×©×™×—×”.
    ××–×™× ×™× ××œ×™×• ××•×“×™×• (push_audio), ×•×”×•× ×§×•×¨× ×œ-callbacks ×¢× partial/final.
    ×‘×¡×•×£ ×¡×•×’×¨×™× ×¢× close().
    """

    def __init__(self, on_partial, on_final):
        self.client = speech.SpeechClient()
        self._on_partial = on_partial
        self._on_final   = on_final

        self._q = queue.Queue(maxsize=16)   # ×œ×§×‘×œ×ª ××•×“×™×• ×-thread ×”-WS
        self._stop = threading.Event()
        self._last_partial = ""
        self._last_emit_ms = 0

        # ×—×•×˜ GCP
        self._t = threading.Thread(target=self._run, daemon=True)
        self._t.start()

    # === Public API ===
    def push_audio(self, pcm_bytes: bytes):
        # ××•×–×Ÿ ××›×œ ×œ×•×œ××ª WS â€” ×œ×œ× ×‘×œ×•×§×™× ××¨×•×›×™×
        if not pcm_bytes:
            return
        try:
            self._q.put_nowait(pcm_bytes)
        except queue.Full:
            # ×‘××¦×‘ ×œ×—×¥ × ×¢×“×™×£ ×œ×“×œ×’ ×¢×œ ×¤×¨×™×™× ××—×“ ×××©×¨ ×œ×”×¢×œ×•×ª latency
            pass

    def close(self):
        # ××¡××Ÿ ×¡×’×™×¨×” ×•×××ª×™×Ÿ ×œ×—×•×˜
        self._stop.set()
        try:
            self._q.put_nowait(None)
        except queue.Full:
            pass
        self._t.join(timeout=2.0)

    # === Internal ===
    def _config(self):
        return speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=8000,
            language_code=LANG,
            model=MODEL,
            enable_automatic_punctuation=False,
        )

    def _streaming_config(self):
        return speech.StreamingRecognitionConfig(
            config=self._config(),
            interim_results=True,
            single_utterance=False,
        )

    def _requests(self):
        buf = bytearray()
        last = time.monotonic()
        while not self._stop.is_set():
            try:
                chunk = self._q.get(timeout=0.05)
            except queue.Empty:
                chunk = None

            if chunk is None:
                # flush ××—×¨×•×Ÿ
                if buf:
                    yield speech.StreamingRecognizeRequest(audio_content=bytes(buf))
                break

            buf.extend(chunk)
            now = time.monotonic()
            if (now - last) * 1000 >= BATCH_MS:
                yield speech.StreamingRecognizeRequest(audio_content=bytes(buf))
                buf.clear()
                last = now

    def _emit_partial(self, text: str):
        if not text:
            return
        now = time.monotonic() * 1000
        if text != self._last_partial and now - self._last_emit_ms >= DEBOUNCEMS:
            self._last_partial = text
            self._last_emit_ms = now
            try:
                self._on_partial(text)
            except Exception:
                pass

    def _emit_final(self, text: str):
        if text:
            try:
                self._on_final(text)
            except Exception:
                pass
        # ××™×¤×•×¡ partial ××—×¨×™ final
        self._last_partial = ""

    def _run(self):
        # ×¨×¥ ×‘×—×•×˜ × ×¤×¨×“ â€“ ×—×™×‘×•×¨ ×¨×¦×™×£ ×œ-GCP ×œ××•×¨×š ×›×œ ×—×™×™ ×”×©×™×—×”
        responses = self.client.streaming_recognize(
            self._streaming_config(), self._requests()
        )
        try:
            for resp in responses:
                for result in resp.results:
                    alt = result.alternatives[0].transcript.strip() if result.alternatives else ""
                    if result.is_final:
                        self._emit_final(alt)
                    else:
                        self._emit_partial(alt)
        except Exception:
            # ×œ× ××¤×™×œ×™× ××ª ×”×©×¨×ªâ€”×‘×¢×ª ×ª×§×œ×”, callbacks ×œ× ×™×™×§×¨××• ×™×•×ª×¨.
            pass

×›×›×” ×× ×—× ×• ××¡×¤×§×™× Session ×—×™ ××—×“ ×¢× push_audio() ×•Ö¾close(); ×”Ö¾callbacks ×œ× ×§×©×•×¨×™× ×œÖ¾utterance ×¡×¤×¦×™×¤×™â€”×”××™×¤×•×™ ×œÖ¾utterance × ×¢×©×” ×‘×¨××ª ×”××“×™×” (×¨××” ×¡×¢×™×£ 2).

â¸»

2) × ×™×”×•×œ Utterances ×‘×¦×“ ×”××“×™×” (media_ws_ai.py)

×”Ö¾session ×™×—×™×” ×œ×›×œ ×”×©×™×—×”, ×•××ª ×”×©×™×•×š ×œÖ¾utterance × ×¢×©×” ×¢× â€œ××—×œ×™×£ ×™×¢×“â€ ×¤×©×•×˜:

# media_ws_ai.py
USE_STREAM = os.getenv("ENABLE_STREAMING_STT", "false").lower() == "true"
print(f"[CFG] ENABLE_STREAMING_STT={USE_STREAM}", flush=True)

_current_utt = {"id": None, "partial_cb": None, "final_buf": None}
_session = None  # StreamingSTTSession ×¤×¢×™×œ ×œ×©×™×—×”

def _stt_on_partial(text: str):
    # ×©×•×œ×— ×—×œ×§×™×™× ×œ×™×¢×“ ×”× ×•×›×—×™ ×‘×œ×‘×“
    cb = _current_utt.get("partial_cb")
    if cb:
        try: cb(text)
        except Exception: pass

def _stt_on_final(text: str):
    buf = _current_utt.get("final_buf")
    if buf is not None:
        buf.append(text)

def _start_session_if_needed():
    global _session
    if _session is None and USE_STREAM:
        from server.services.gcp_stt_stream import StreamingSTTSession
        _session = StreamingSTTSession(on_partial=_stt_on_partial, on_final=_stt_on_final)
        print("[STT] Streaming session started", flush=True)

def _close_session_if_exists():
    global _session
    if _session is not None:
        try:
            _session.close()
        finally:
            _session = None
            print("[STT] Streaming session closed", flush=True)

×”×ª×—×œ×ª/×¡×™×•× utterance (×œ×¤× ×™/××—×¨×™ ×§×¨×™××ª STT)

×‘××§×•× ×œ×”×¤×¢×™×œ STT ×œ×›×œ utterance, ×× ×—× ×• ×¨×§ ××—×œ×™×¤×™× ××¦×‘×™×¢×™×:

import uuid

def _utterance_begin(partial_cb=None):
    # × ×§×¨× ×›×©××ª×—×™×œ ××©×¤×˜ ×—×“×© (VAD/×©×§×˜ × ×’××¨/×ª×—×™×œ×ª ×§×•×œ)
    _current_utt["id"] = uuid.uuid4().hex
    _current_utt["partial_cb"] = partial_cb
    _current_utt["final_buf"] = []

async def _utterance_end():
    # × ×§×¨× ×›×©× ×’××¨ ××©×¤×˜ (VAD/×©×§×˜), ×•××—×–×™×¨ final_text
    finals = _current_utt.get("final_buf") or []
    text = " ".join(finals).strip()
    # ××™×¤×•×¡ ×™×¢×“:
    _current_utt["id"] = None
    _current_utt["partial_cb"] = None
    _current_utt["final_buf"] = None
    return text

× ×§×•×“×ª ×”×–× ×ª ×”××•×“×™×• (×‘×œ×•×œ××ª ×”-WS ×©×œ×š)

×‘××§×•× ×œ×©×œ×•×— ×œ×›×œ utterance, ×¤×©×•×˜ ×“×•×—×¤×™× ×œÖ¾session ××—×“:

# ×‘×ª×•×š ×œ×•×œ××ª ×”-WS ×©××§×‘×œ×ª frames ××˜×•×•×™×œ×™×•:
_start_session_if_needed()
pcm_chunk = mulaw_decode_fast(frame)  # ×™×© ×œ×š ×›×‘×¨
if _session:
    _session.push_audio(pcm_chunk)

×¢×™×‘×•×“ utterance ×‘×¤×•×¢×œ

×›×œ ×”Ö¾AI/DB × ×©××¨ ×‘×“×™×•×§ ×›××• ×”×™×•×â€”×¨×§ ×§×¨× ×œÖ¾begin/end:

# ×›×©VAD ××–×”×” ×”×ª×—×œ×”:
_utterance_begin(partial_cb=handle_partial_from_agent)

# ×›×©VAD ××–×”×” ×¡×•×£:
final_text = await _utterance_end()
# ××›××Ÿ ×××©×™×š ×›×¨×’×™×œ: ×¡×™×›×•×, DB, ×ª×©×•×‘×ª AI, TTS ×•×›×•'

×¡×™×•× ×”×©×™×—×”

×‘×˜×•×— ×œ×¡×’×•×¨ session:

# on call end / WS close:
_close_session_if_exists()


â¸»

3) ×“×’×©×™× ×©××•× ×¢×™× ×ª×§×œ×•×ª
	â€¢	××¡×•×¨ ×œ×¤×ª×•×— Session ×œ×›×œ utterance (×–×” ××” ×©×§×¨×¡ ×œ×š ××—×¨×™ ~90s).
	â€¢	×”Ö¾callbacks × ×§×‘×¢×™× ×¤×¢× ××—×ª ×‘×ª×—×™×œ×ª ×”×©×™×—×”; ××™×¤×•×™ ×œÖ¾utterance × ×¢×©×” ×¢×´×™ ×”×—×œ×¤×ª ×”××¦×‘×™×¢×™× (partial_cb + final_buf) ×‘×ª×—×™×œ×ª/×¡×•×£ utterance.
	â€¢	××™×Ÿ IO/DB/LLM ×‘×ª×•×š callbacks â€” ×¨×§ ×¢×“×›×•×Ÿ ×–×™×›×¨×•×Ÿ/queue â†’ ×”×˜×™×¤×•×œ ×”×›×‘×“ ××ª×‘×¦×¢ ××—×¨×™ _utterance_end().
	â€¢	Debounce ×¢×•×‘×“ ×‘×ª×•×š ×”Ö¾Session, ×œ× ×‘×œ×•×œ××ª ×”Ö¾WS.
	â€¢	×”×©××¨ ××ª Whisper fallback ×©×œ×š (×œ××§×¨×” ×©×œ ×©×’×™××ª GCP) ×œ×œ× ×©×™× ×•×™.

â¸»

4) ×‘×“×™×§×•×ª GO/NO-GO
	1.	Enable: ENABLE_STREAMING_STT=true ×’× ×‘Ö¾workspace ×•×’× ×‘Ö¾deployment, ×•××– Republish.
	2.	×”×ª×§×©×¨ ×•×‘×“×•×§ ×œ×•×’×™×:
	â€¢	[STT] Streaming session started ××™×“ ×‘×ª×—×™×œ×ª ×”×©×™×—×”
	â€¢	ğŸŸ¡ Partial: ... ×‘×§×¦×‘ ~200ms
	â€¢	ğŸŸ¢ Final: ... ×‘×¡×™×•× ×›×œ utterance
	3.	×‘×¡×™×•× ×©×™×—×”: [STT] Streaming session closed
	4.	Twilio Debugger: ××™×Ÿ 12100/11200, ×”Ö¾Stream × ×©××¨ ×¤×ª×•×— ×¢×“ ×”×¡×•×£.

â¸»

××©×¤×˜ ×§×¦×¨ ×œ×©×œ×™×—×” ×œ××™×™×’â€™× ×˜

â€œ×ª×™×™×©× Session ××—×“ ×œ×©×™×—×” ×¢× ××—×œ×§×ª StreamingSTTSession (push_audio/close). ×”Ö¾callbacks ×§×‘×•×¢×™× ×œ×©×™×—×”, ×•××ª ×”×©×™×•×š ×œ×›×œ utterance × ×‘×¦×¢ ×¢×´×™ ×”×—×œ×¤×ª ×”×™×¢×“ (partial_cb ×•Ö¾final_buf) ×‘×ª×—×™×œ×ª/×¡×•×£ utterance. ××œ ×ª×¤×ª×— Session ×œ×›×œ utterance. ×”×–× ×ª ×”××•×“×™×• ×œÖ¾session ×‘×œ×•×œ××ª ×”Ö¾WS, ×•Ö¾VAD ×¨×§ ×§×•×¨× _utterance_begin/_utterance_end. ×‘×¡×•×£ ×”×©×™×—×” ×¡×’×•×¨ ××ª ×”Ö¾session. ×©××•×¨ ××ª Whisper fallback ×›××•×ª ×©×”×•×.â€

×–×” ××™×™×¦×‘ ××ª ×”×¡×˜×¨×™××™× ×’ â€œ×¢×œ ×××ªâ€ ×•× ×•×ª×Ÿ ×ª×’×•×‘×ª × ×¦×™×’×” ×‘×–××Ÿ-×××ª ×‘×œ×™ × ×¤×™×œ×•×ª.