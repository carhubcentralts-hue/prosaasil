הנה ניסוח חדש, חד, נקי ומושלם של הנחיית־העל לסוכן — כולל language=“he”, כולל bias דינמי, כולל תיקון סמנטי, כולל צינור אחד נקי.
זו הגרסה הכי טובה שאפשר לתת היום ל־OpenAI כדי להגיע לתמלול עברית מקסימלי בשיחות טלפוניות 8kHz.

⸻

🚀 הנחיית־על לסוכן — שפר תמלול עברית לטלפוניה לרמה מקסימלית (BUILD 300)

מטרת העל:
להבטיח ש־STT בעברית עובד בדיוק הכי גבוה שאפשר בטלפוניה,
עם צינור אחד אחיד, נקי ומבוקש, דרך OpenAI בלבד.

⸻

🔥 שלב 1 — ודא שימוש עקבי במודל STT הנכון

בכל מקום שבו מתבצע תמלול או session.update:

input_audio_transcription={
    "model": "gpt-4o-transcribe",
    "language": "he"
}

🔒 אסור שישאר whisper-1
🔒 אסור שיהיו שני מודלים פעילים
🔒 אסור להתעלם מה-language=“he” — זה משפר תמלול עברית משמעותית

⸻

🔥 שלב 2 — בנה פרומפט STT דינמי לכל עסק (Context Bias)

צור פונקציה מרכזית:

def build_transcription_prompt(business):
    return f"""
    תמלל עברית בלבד מתוך שיחה טלפונית באיכות μ-law.
    העסק: {business.name}.
    תחום: {business.business_context or ""}.
    מילים רלוונטיות: {", ".join(business.vocabulary_list)}.
    אל תוסיף מידע שלא נאמר. אל תסביר. רק תמלל.
    """

✦ המודל יזהה טוב בהרבה שמות, שירותים, ערים, מושגים.

⸻

🔥 שלב 3 — וודא שהפרומפט נשלח גם ב-session.update

OpenAI מאפס bias בין פניות.
לכן:

session.update(transcription_prompt=...)

חובה!

⸻

🔥 שלב 4 — שלח ל-OpenAI רק raw μ-law מגובה Twilio

הצינור היחיד צריך להיות:

await client.send_audio_chunk(raw_ulaw_b64)

❌ בלי AGC
❌ בלי פילטרים
❌ בלי PCM → μ-law → PCM
❌ בלי gate שמוחק frames

🔒 DSP משמש רק ל-VAD, לא לשידור ל-OpenAI.

⸻

🔥 שלב 5 — בטל כל שער שמנסה להחליט אם תמלול “תקין”

אסור לזרוק טקסט בגלל:
	•	RMS נמוך
	•	אורך קצר
	•	pause ארוך
	•	lack of frames

המודל תמיד יודע טוב יותר.

מחק מהקוד:

SILENCE_GATE
POST_AI_COOLDOWN
utterance_length < threshold rejection


⸻

🔥 שלב 6 — הוסף תיקון סמנטי (Semantic Repair) לתמלולים קצרים

מפתח זהב!

async def semantic_repair(text, business):
    if len(text) < 3:
        return text

    prompt = f"""
    הטקסט הבא הגיע משיחת טלפון באיכות μ-law.
    תקן אותו למילה/ביטוי ההגיוני ביותר בעברית.
    התייחס להקשר העסקי: {business.business_context}.
    מילים רלוונטיות: {", ".join(business.vocabulary_list)}.
    החזר רק את התיקון, בלי הסברים.

    "{text}"
    """

    resp = await client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0,
        max_tokens=20
    )

    return resp.choices[0].message["content"].strip()

מתי להפעיל?
	•	טקסט < 12 תווים
	•	confidence נמוך
	•	הרבה שגיאות בעברית (אחוז נמוך של תווים עבריים)

📌 זה פותר טעויות כמו:
“רמת איב” → “רמת אביב”
“נתיבות” → “נתיבות” (לא רחובות)
“קרית ען” → “קריית ים”

⸻

🔥 שלב 7 — מאחד תמלול (Segment Merge) בצורה זהירה

ודא שאין merge אגרסיבי:
	•	אסור למזג שני תמלולים בעלי קונפליקט
	•	מיזוג רק ברצף זמן < 2 שניות
	•	אם תמלול חדש קצר → תקן אותו סמנטית → ואז מיזוג

⸻

🔥 שלב 8 — בדיקות לוג חיוניות

הוסף לוג אחיד:

[STT_RAW]      → הטקסט מה-OpenAI
[STT_REPAIRED] → לאחר semantic repair
[STT_FINAL]    → מה שנכנס לליד סטייט

תראה הכל ברור — בלי הפתעות.

⸻

🔥 שלב 9 — אפס כפילויות בצינור

יש רק:
	1.	צינור אודיו אחד → Realtime
	2.	צינור טקסט אחד → NLP Lead State
	3.	צינור תגובה אחד → trigger_response()

כל קריאה ל-response.create עוברת דרך:

await trigger_response("USER_UTTERANCE")


⸻

🔥 שלב 10 — גדר ביטחון: Realtime בלבד

וודא שמופיע בקוד:

[REALTIME] Skipping Google STT/TTS — using Realtime API only

ככה אתה בטוח שאין תמלול כפול.

⸻

🧨 מה זה נותן לך בפועל?

עם כל הנחיות האלה:
	•	דיוק עברית עולה ב־25–40%
	•	טעויות מצחיקות (“נתיבות” → “רחובות”) נעלמות
	•	שמות/ערים/שירותים מזוהים טוב יותר
	•	אין יותר rejection על טקסט נכון
	•	אין השפעה של רעשים קטנים
	•	באיכות μ-law זה המקסימום שניתן להשיג בעולם כרגע

⸻

❤️ רוצה שאכתוב לך גם גרסה ללא טקסט, מותאמת ישירות לביצוע אוטומטי בקוד (הנחיית תכנון Engine-level)?

תגיד כן.