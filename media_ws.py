# media_ws.py
import os, json, asyncio, logging, time, tempfile, numpy as np, soundfile as sf
from flask import current_app
from audio_utils import b64_to_mulaw, mulaw8k_to_pcm16k, pcm16k_float_to_mulaw8k_frames

# Logger
log = logging.getLogger("media_ws")

# Google TTS
try:
    from google.cloud import texttospeech as tts_module
    
    # ×”×’×“×¨×ª credentials ×-environment variable
    creds_json = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
    if creds_json and creds_json.startswith("{"):
        # ×× ×–×” JSON string, ×›×ª×•×‘ ×œ×§×•×‘×¥ ×–×× ×™
        with open("/tmp/tts_creds.json", "w") as f:
            f.write(creds_json)
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/tmp/tts_creds.json"
    
    tts_client = tts_module.TextToSpeechClient()
    log.info("âœ… Google TTS client initialized")
except Exception as e:
    log.error("âŒ Google TTS failed: %s", e)
    tts_client = None
    tts_module = None

# OpenAI
try:
    from openai import OpenAI
    gpt = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    log.info("âœ… OpenAI client initialized")
except Exception as e:
    log.error("âŒ OpenAI failed: %s", e)
    gpt = None

# Simple VAD (Voice Activity Detection) 
def has_voice_energy(pcm16k: np.ndarray, threshold=0.01) -> bool:
    """×‘×“×™×§×” ×¤×©×•×˜×” - ×”×× ×™×© ×× ×¨×’×™×” ×§×•×œ×™×ª ××¡×¤×™×§×”"""
    if len(pcm16k) == 0:
        return False
    rms = np.sqrt(np.mean(pcm16k ** 2))
    return rms > threshold

def tts_he_wavenet(text: str) -> np.ndarray:
    """TTS ×œ×¢×‘×¨×™×ª â†’ PCM16@16k float32 [-1,1]"""
    if not tts_client or not tts_module:
        log.error("TTS client not available")
        return np.zeros(16000, dtype=np.float32)  # ×©×§×˜ ×©×œ ×©× ×™×™×”
        
    try:
        inp = tts_module.SynthesisInput(text=text)
        voice = tts_module.VoiceSelectionParams(
            language_code="he-IL", 
            name="he-IL-Wavenet-A"
        )
        cfg = tts_module.AudioConfig(
            audio_encoding=tts_module.AudioEncoding.LINEAR16, 
            sample_rate_hertz=16000
        )
        res = tts_client.synthesize_speech(input=inp, voice=voice, audio_config=cfg)
        
        # ×›×ª×™×‘×” ×–×× ×™×ª ×•×§×¨×™××” ×›-numpy
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
            f.write(res.audio_content)
            wav_path = f.name
        
        data, sr = sf.read(wav_path, dtype="float32")
        os.unlink(wav_path)  # × ×™×§×•×™
        
        if sr != 16000:
            import librosa
            data = librosa.resample(data, orig_sr=sr, target_sr=16000)
        
        return data.astype(np.float32)
    except Exception as e:
        log.error("TTS error: %s", e)
        return np.zeros(16000, dtype=np.float32)  # ×©×§×˜ ×©×œ ×©× ×™×™×”

def transcribe_chunk(pcm16k: np.ndarray) -> str:
    """×ª××œ×•×œ ××•×“×™×• ×¢×‘×¨×™ ×‘×××¦×¢×•×ª OpenAI Whisper"""
    try:
        import io
        import soundfile as sf
        from openai import OpenAI
        
        # ×‘×“×™×§×” ×©×™×© ××•×“×™×• ×‘×›×œ×œ
        if len(pcm16k) == 0:
            return ""
            
        # ×™×¦×™×¨×ª client ×¢× API key
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        # ×”××¨×” ×œ×¤×•×¨××˜ WAV
        buf = io.BytesIO()
        sf.write(buf, pcm16k, 16000, subtype="PCM_16", format="WAV")
        buf.seek(0)
        
        # ×ª××œ×•×œ ×¢× Whisper
        response = client.audio.transcriptions.create(
            model="whisper-1",
            file=("audio.wav", buf, "audio/wav"),
            language="he"
        )
        
        result = response.text.strip() if response.text else ""
        log.info("âœ… ×ª××œ×•×œ ×”×•×©×œ×: %s", result[:50] + "..." if len(result) > 50 else result)
        return result
        
    except Exception as e:
        log.error(f"âŒ ×©×’×™××” ×‘×ª××œ×•×œ: {e}")
        return ""

def llm_reply(user_text: str) -> str:
    """×ª×’×•×‘×ª AI ×¢×‘×•×¨ ×”× ×“×œ"×Ÿ"""
    if not gpt:
        return "×©×œ×•×, ×× ×™ ×¢×•×–×¨ ×©×œ ×©×™ ×“×™×¨×•×ª ×•××©×¨×“×™×. ××™×š ××•×›×œ ×œ×¢×–×•×¨?"
        
    try:
        from typing import List, Dict, Any
        msgs: List[Dict[str, Any]] = [
            {"role": "system", "content": "××ª×” ×¡×•×›×Ÿ × ×“×œ\"×Ÿ ××§×¦×•×¢×™ ×¢×‘×•×¨ ×©×™ ×“×™×¨×•×ª ×•××©×¨×“×™× ×‘×¢\"×. ×“×‘×¨ ×‘×¢×‘×¨×™×ª, ×”×™×” ×§×¦×¨ ×•××•×¢×™×œ. ×× ××™×©×”×• ×©×•××œ ×¢×œ × ×›×¡, ×”×¦×™×¢ ×¤×’×™×©×”."},
            {"role": "user", "content": user_text}
        ]
        r = gpt.chat.completions.create(
            model="gpt-4o-mini", 
            messages=msgs,  # type: ignore
            temperature=0.3,
            max_tokens=100
        )
        response_content = r.choices[0].message.content
        return response_content.strip() if response_content else "×©×œ×•×, ××™×š ××•×›×œ ×œ×¢×–×•×¨ ×œ×›× ×¢× × ×“×œ\"×Ÿ?"
    except Exception as e:
        log.error("AI error: %s", e)
        return "×©×œ×•×, ××™×š ××•×›×œ ×œ×¢×–×•×¨ ×œ×›× ×¢× × ×“×œ\"×Ÿ?"

def is_goodbye(text: str) -> bool:
    """×–×™×”×•×™ ×¡×™×•× ×©×™×—×”"""
    t = text.strip().lower()
    return any(w in t for w in ["×‘×™×™", "×œ×”×ª×¨××•×ª", "× ×ª×¨××”", "×¡×’×•×¨", "bye", "goodbye", "×ª×•×“×” ×¨×‘×”"])

def handle_twilio_media(ws):
    """
    ×¤×¨×•×˜×•×§×•×œ Twilio Media Streams:
    - {"event":"start","start":{"streamSid":...,"callSid":...}}
    - {"event":"media","media":{"payload":"<b64 Î¼-law 8k>"}}   ×›×œ ~20ms
    - {"event":"stop",...}
    ×× ×—× ×• ××—×–×™×¨×™×:
    - {"event":"media","streamSid":sid,"media":{"payload":"<b64 Î¼-law 8k>"}}
    """
    stream_sid = call_sid = None
    buf16k = np.zeros(0, dtype=np.float32)
    last_voice_ts = time.time()
    speaking = False  # ×”×× ×× ×—× ×• ×›×¨×’×¢ ×× ×’× ×™× TTS
    conversation_started = False
    
    try:
        while True:
            raw = ws.receive()
            if raw is None: 
                break
            evt = json.loads(raw)

            if evt.get("event") == "start":
                stream_sid = evt["start"]["streamSid"]
                call_sid = evt["start"]["callSid"]
                log.info("ğŸ”¥ Stream started: %s call=%s", stream_sid, call_sid)
                
                # ×‘×¨×›×” ×¨××©×•× ×™×ª
                greeting = "×©×œ×•×! ××ª× ××“×‘×¨×™× ×¢× ×©×™ ×“×™×¨×•×ª ×•××©×¨×“×™×. ××™×š ××•×›×œ ×œ×¢×–×•×¨ ×œ×›×?"
                audio = tts_he_wavenet(greeting)
                speaking = True
                for frame in pcm16k_float_to_mulaw8k_frames(audio):
                    ws.send(json.dumps({
                        "event": "media",
                        "streamSid": stream_sid,
                        "media": {"payload": frame}
                    }))
                    time.sleep(0.02)
                speaking = False
                conversation_started = True
                continue

            if evt.get("event") == "stop":
                log.info("ğŸ›‘ Stream stop: %s", stream_sid)
                break

            if evt.get("event") == "media" and conversation_started:
                # 1) ×“×’×™××” × ×›× ×¡×ª â†’ ×¦×‘×™×¨×”
                mulaw_b64 = evt["media"]["payload"]
                mulaw = b64_to_mulaw(mulaw_b64)
                pcm16k = mulaw8k_to_pcm16k(mulaw)
                buf16k = np.concatenate([buf16k, pcm16k])

                # 2) ×‘×“×™×§×ª ×× ×¨×’×™×” ×§×•×œ×™×ª
                if len(buf16k) >= int(0.32 * 16000):  # 320ms
                    chunk = buf16k[-int(0.32 * 16000):]
                    if has_voice_energy(chunk):
                        last_voice_ts = time.time()
                    
                    # ×× ×¢×‘×¨×• >800ms ×‘×œ×™ ×“×™×‘×•×¨ â†’ ×¡×•×£ ×××™×¨×”
                    if (time.time() - last_voice_ts) > 0.8 and not speaking and len(buf16k) > int(0.5 * 16000):
                        speaking = True
                        utter = buf16k.copy()
                        buf16k = np.zeros(0, dtype=np.float32)

                        # 3) ×ª××œ×•×œ
                        text = transcribe_chunk(utter)
                        log.info("ğŸ‘‚ User said: %s", text)
                        
                        if not text or len(text.strip()) < 2:
                            speaking = False
                            continue

                        # 4) ×”×× ×œ×¡×™×™× ×©×™×—×”?
                        if is_goodbye(text):
                            reply = "×ª×•×“×” ×©×¤× ×™×ª× ×œ×©×™ ×“×™×¨×•×ª ×•××©×¨×“×™×! × ×©××— ×œ×¢×–×•×¨ ×‘×¢×ª×™×“. ×œ×”×ª×¨××•×ª!"
                            audio = tts_he_wavenet(reply)
                            for frame in pcm16k_float_to_mulaw8k_frames(audio):
                                ws.send(json.dumps({
                                    "event": "media",
                                    "streamSid": stream_sid,
                                    "media": {"payload": frame}
                                }))
                                time.sleep(0.02)
                            
                            # × ×™×ª×•×§ ×”×©×™×—×”
                            try:
                                from twilio.rest import Client
                                client = Client(
                                    os.getenv("TWILIO_ACCOUNT_SID"), 
                                    os.getenv("TWILIO_AUTH_TOKEN")
                                )
                                if call_sid:
                                    client.calls(call_sid).update(status="completed")
                                    log.info("âœ… Call terminated gracefully")
                                else:
                                    log.warning("âš ï¸ No call_sid to terminate")
                            except Exception as e:
                                log.error("âŒ Failed to end call: %s", e)
                            break

                        # 5) ×ª×’×•×‘×ª AI
                        reply = llm_reply(text)
                        log.info("ğŸ¤– AI reply: %s", reply)

                        # 6) TTS â†’ ×©×œ×™×—×” ×œ×˜×œ×¤×•×Ÿ
                        audio = tts_he_wavenet(reply)
                        for frame in pcm16k_float_to_mulaw8k_frames(audio):
                            ws.send(json.dumps({
                                "event": "media",
                                "streamSid": stream_sid,
                                "media": {"payload": frame}
                            }))
                            time.sleep(0.02)

                        speaking = False
                        
    except Exception as e:
        log.exception("âŒ WebSocket error: %s", e)
    finally:
        try: 
            ws.close()
        except: 
            pass
        log.info("ğŸ”š WebSocket closed: %s", stream_sid)