# ===========================================
# ProSaaS - Production Overrides with Service Separation
# ===========================================
#
# Use with: docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d
#
# This file implements production optimization:
# - Service separation: API / Calls / Worker / WhatsApp
# - Redis for queue management
# - WebSocket optimization with proper upgrades
# - Resource limits per service
# - SSL/TLS configuration for Nginx reverse proxy
# - External managed database (no local postgres)
#
# SSL Setup:
# 1. Obtain SSL certificates (from Cloudflare Origin Certificate)
# 2. Place certificates in the repository at:
#    - docker/nginx/ssl/prosaas-origin.crt
#    - docker/nginx/ssl/prosaas-origin.key
# 3. The nginx container will mount these certificates from the repo directory
#
# ===========================================
# Compose v2 (no version key)
services:
  # ===========================================
  # Nginx Reverse Proxy - Production SSL + Separate Services
  # ===========================================
  nginx:
    build:
      context: .
      dockerfile: Dockerfile.nginx
      args:
        USE_SSL: "true"
    volumes:
      # Only mount SSL certificates (read-only)
      - ./docker/nginx/ssl:/etc/nginx/ssl:ro
    # P3-4: Docker hardening - read-only filesystem
    read_only: true
    tmpfs:
      - /tmp
      - /var/cache/nginx
      - /var/run
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETUID
      - SETGID
      - NET_BIND_SERVICE
    # Add production service dependencies
    depends_on:
      prosaas-api:
        condition: service_started
      prosaas-calls:
        condition: service_started
      frontend:
        condition: service_started
      n8n:
        condition: service_started
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost/health >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 10
    networks:
      - prosaas-net

  # ===========================================
  # Redis - Production Overrides
  # ===========================================
  redis:
    # Override to not expose port in production
    ports: []
    networks:
      - prosaas-net

  # ===========================================
  # Migration Service - Production Configuration
  # Runs DB migrations BEFORE any services start
  # ===========================================
  migrate:
    build:
      context: .
      dockerfile: Dockerfile.backend.light
    environment:
      # âœ… SOFT PREFER: Prefers DIRECT but automatically falls back to POOLER
      # If DATABASE_URL_DIRECT is not available/unreachable, uses POOLER
      # This ensures deployment doesn't fail due to network issues
      DATABASE_URL_DIRECT: ${DATABASE_URL_DIRECT:-${DATABASE_URL}}
      DATABASE_URL_POOLER: ${DATABASE_URL_POOLER:-${DATABASE_URL}}
      SERVICE_ROLE: migrate
      FLASK_ENV: production
      # ðŸ”¥ CRITICAL: Must be exactly "1" (not "true", not true, not "1" in quotes from env)
      RUN_MIGRATIONS: "1"
      # ðŸ”¥ LOGGING - Production mode (minimal logs)
      LOG_LEVEL: INFO
      PYTHONUNBUFFERED: 1

  # ===========================================
  # Index Builder Service - Builds performance indexes
  # Runs AFTER migrations to create indexes separately
  # Never fails deployment - exits 0 even on errors
  # ===========================================
  indexer:
    build:
      context: .
      dockerfile: Dockerfile.backend.light
    restart: "no"  # Run once and exit
    env_file:
      - .env
    environment:
      # âœ… POOLER-SAFE: Index building now works on POOLER with proper settings
      # Uses AUTOCOMMIT + CREATE INDEX CONCURRENTLY + proper timeouts
      DATABASE_URL_DIRECT: ${DATABASE_URL_DIRECT:-${DATABASE_URL}}
      DATABASE_URL_POOLER: ${DATABASE_URL_POOLER:-${DATABASE_URL}}
      SERVICE_ROLE: indexer
      FLASK_ENV: production
      # ðŸ”¥ LOGGING - Production mode
      LOG_LEVEL: INFO
      PYTHONUNBUFFERED: 1
    # ðŸ”¥ DNS FIX: Use external DNS to prevent transient failures
    dns:
      - 1.1.1.1
      - 8.8.8.8
    dns_search: ["."]
    dns_opt:
      - ndots:0
      - timeout:2
      - attempts:2
    command: ["python", "server/db_build_indexes.py"]
    depends_on:
      migrate:
        condition: service_completed_successfully
    networks:
      - prosaas-net

  # ===========================================
  # Backfill Service - Runs data backfill operations
  # Runs AFTER migrations and indexes
  # Never fails deployment - exits 0 even on errors
  # Designed for production stability:
  # - Uses central registry system (db_backfills.py)
  # - Uses small batches (100 rows) to reduce lock contention
  # - Uses FOR UPDATE SKIP LOCKED to avoid blocking
  # - Time-boxed execution (10 minutes by default)
  # - Idempotent and safe to run multiple times
  # - POOLER-SAFE with proper timeouts and batch sizes
  # ===========================================
  backfill:
    build:
      context: .
      dockerfile: Dockerfile.backend.light
    restart: "no"  # Run once and exit
    env_file:
      - .env
    environment:
      # âœ… POOLER-SAFE: Backfill now works on POOLER with proper settings
      # Uses small batches + SKIP LOCKED + proper timeouts
      DATABASE_URL_DIRECT: ${DATABASE_URL_DIRECT:-${DATABASE_URL}}
      DATABASE_URL_POOLER: ${DATABASE_URL_POOLER:-${DATABASE_URL}}
      SERVICE_ROLE: backfill
      FLASK_ENV: production
      # ðŸ”¥ LOGGING - Production mode
      LOG_LEVEL: INFO
      PYTHONUNBUFFERED: 1
    # ðŸ”¥ DNS FIX: Use external DNS to prevent transient failures
    dns:
      - 1.1.1.1
      - 8.8.8.8
    dns_search: ["."]
    dns_opt:
      - ndots:0
      - timeout:2
      - attempts:2
    # Run central backfill runner (ONE SOURCE OF TRUTH)
    command: ["python", "server/db_run_backfills.py", "--all", "--max-minutes=10"]
    depends_on:
      migrate:
        condition: service_completed_successfully
      indexer:
        condition: service_completed_successfully
    networks:
      - prosaas-net

  # ===========================================
  # Disable local database in production
  # (Use managed DB like Railway, Supabase, Neon, etc.)
  # ===========================================
  db:
    profiles:
      - local-db-only  # Won't start unless explicitly requested

  # ===========================================
  # Worker Service - Production Overrides
  # Worker is defined in base docker-compose.yml
  # This overrides dependencies and resource limits for production
  # ===========================================
  worker:
    environment:
      # ðŸ”¥ CRITICAL: Use POOLER connection for worker traffic
      DATABASE_URL_DIRECT: ${DATABASE_URL_DIRECT:-${DATABASE_URL}}
      DATABASE_URL_POOLER: ${DATABASE_URL_POOLER:-${DATABASE_URL}}
      FLASK_ENV: production
      RUN_MIGRATIONS_ON_START: 0
      RUN_MIGRATIONS: "0"
      PRODUCTION: ${PRODUCTION:-1}
      RQ_QUEUES: high,default,low,receipts,receipts_sync,maintenance,recordings,broadcasts
      # ðŸ”¥ SCHEDULERS: Enable schedulers only in worker to prevent duplicate cleanup logs
      ENABLE_SCHEDULERS: "true"
      # ðŸ”¥ GOOGLE STT - Service Account Credentials
      GOOGLE_APPLICATION_CREDENTIALS: /root/secrets/gcp-stt-sa.json
      # ðŸ”¥ LOGGING - Production mode (minimal logs)
      LOG_LEVEL: INFO
      PYTHONUNBUFFERED: 1
    # P3-4: Docker hardening - more permissive for Playwright but still secure
    security_opt:
      - no-new-privileges:true
    tmpfs:
      - /tmp
    volumes:
      # ðŸ”¥ RECORDINGS: Shared volume for downloaded recordings
      - recordings_data:/app/server/recordings
      # ðŸ”¥ GOOGLE STT - Mount service account JSON (read-only)
      - /root/secrets/gcp-stt-sa.json:/root/secrets/gcp-stt-sa.json:ro
    # ðŸ”¥ DNS FIX: Use external DNS to prevent transient failures
    dns:
      - 1.1.1.1
      - 8.8.8.8
    dns_search: ["."]
    dns_opt:
      - ndots:0
      - timeout:2
      - attempts:2
    # Add production service dependencies
    depends_on:
      redis:
        condition: service_healthy
      migrate:
        condition: service_completed_successfully
      prosaas-api:
        condition: service_healthy
    networks:
      - prosaas-net
  
  prosaas-api:
    build:
      context: .
      dockerfile: Dockerfile.backend.light
    restart: unless-stopped
    env_file:
      - .env
    environment:
      # ðŸ”¥ CRITICAL: Use POOLER connection for API traffic
      DATABASE_URL_DIRECT: ${DATABASE_URL_DIRECT:-${DATABASE_URL}}
      DATABASE_URL_POOLER: ${DATABASE_URL_POOLER:-${DATABASE_URL}}
      FLASK_ENV: production
      PUBLIC_BASE_URL: ${PUBLIC_BASE_URL}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      TWILIO_ACCOUNT_SID: ${TWILIO_ACCOUNT_SID}
      TWILIO_AUTH_TOKEN: ${TWILIO_AUTH_TOKEN}
      # ðŸ”¥ MIGRATIONS - Disabled since migrate service handles it
      RUN_MIGRATIONS_ON_START: 0
      RUN_MIGRATIONS: "0"
      PRODUCTION: ${PRODUCTION:-1}
      ATTACHMENT_STORAGE_DRIVER: ${ATTACHMENT_STORAGE_DRIVER:-r2}
      ATTACHMENT_SECRET: ${ATTACHMENT_SECRET}
      R2_ACCOUNT_ID: ${R2_ACCOUNT_ID}
      R2_BUCKET_NAME: ${R2_BUCKET_NAME}
      R2_ACCESS_KEY_ID: ${R2_ACCESS_KEY_ID}
      R2_SECRET_ACCESS_KEY: ${R2_SECRET_ACCESS_KEY}
      R2_ENDPOINT: ${R2_ENDPOINT}
      REDIS_URL: redis://redis:6379/0
      SERVICE_ROLE: api
      # ðŸ”¥ TTS WARMUP: Optional - disable TTS warmup if needed (does not affect DB)
      # Set to "true" to skip TTS client warmup (useful for faster deployments)
      DISABLE_TTS_WARMUP: ${DISABLE_TTS_WARMUP:-false}
      # ðŸ”¥ SCHEDULERS: Disable schedulers in API service (only worker should run them)
      ENABLE_SCHEDULERS: "false"
      # ðŸ”¥ GOOGLE STT - Service Account Credentials
      GOOGLE_APPLICATION_CREDENTIALS: /root/secrets/gcp-stt-sa.json
      # ðŸ”¥ LOGGING - Production mode (minimal logs)
      LOG_LEVEL: INFO
      PYTHONUNBUFFERED: 1
    # P3-4: Docker hardening
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    ulimits:
      nofile:
        soft: 65535
        hard: 65535
    # ðŸ”¥ DNS FIX: Use external DNS to prevent transient failures
    dns:
      - 1.1.1.1
      - 8.8.8.8
    dns_search: ["."]
    dns_opt:
      - ndots:0
      - timeout:2
      - attempts:2
    expose:
      - "5000"
    volumes:
      # ðŸ”¥ RECORDINGS: Shared volume for downloaded recordings  
      - recordings_data:/app/server/recordings
      # ðŸ”¥ GOOGLE STT - Mount service account JSON (read-only)
      - /root/secrets/gcp-stt-sa.json:/root/secrets/gcp-stt-sa.json:ro
    depends_on:
      redis:
        condition: service_healthy
      migrate:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:5000/health"]
      interval: 10s
      timeout: 3s
      retries: 30
      start_period: 20s
    networks:
      - prosaas-net

  # ===========================================
  # Calls Service (WebSocket + Twilio streaming only)
  # Handles: /ws/twilio-media, Twilio webhooks for calls
  # Optimized for: High concurrency, low latency, backpressure
  # 
  # âš ï¸ CRITICAL: SINGLE WORKER ONLY
  # State (stream_registry, call sessions) is IN-MEMORY
  # Multi-worker would cause lost call context and crashes
  # See: STATE_MANAGEMENT_CONSTRAINTS.md
  # ===========================================
  prosaas-calls:
    build:
      context: .
      dockerfile: Dockerfile.backend.light
    restart: unless-stopped
    env_file:
      - .env
    environment:
      # ðŸ”¥ CRITICAL: Use POOLER connection for calls traffic
      DATABASE_URL_DIRECT: ${DATABASE_URL_DIRECT:-${DATABASE_URL}}
      DATABASE_URL_POOLER: ${DATABASE_URL_POOLER:-${DATABASE_URL}}
      FLASK_ENV: production
      PUBLIC_BASE_URL: ${PUBLIC_BASE_URL}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      TWILIO_ACCOUNT_SID: ${TWILIO_ACCOUNT_SID}
      TWILIO_AUTH_TOKEN: ${TWILIO_AUTH_TOKEN}
      RUN_MIGRATIONS_ON_START: 0
      RUN_MIGRATIONS: "0"
      PRODUCTION: ${PRODUCTION:-1}
      ATTACHMENT_STORAGE_DRIVER: ${ATTACHMENT_STORAGE_DRIVER:-r2}
      ATTACHMENT_SECRET: ${ATTACHMENT_SECRET}
      R2_ACCOUNT_ID: ${R2_ACCOUNT_ID}
      R2_BUCKET_NAME: ${R2_BUCKET_NAME}
      R2_ACCESS_KEY_ID: ${R2_ACCESS_KEY_ID}
      R2_SECRET_ACCESS_KEY: ${R2_SECRET_ACCESS_KEY}
      R2_ENDPOINT: ${R2_ENDPOINT}
      REDIS_URL: redis://redis:6379/0
      SERVICE_ROLE: calls
      PORT: 5050
      # ðŸ”¥ P2+Calls: Maximum concurrent calls limit (server-wide, 0 = unlimited)
      MAX_CONCURRENT_CALLS: 0
      # ðŸ”¥ TTS WARMUP: Optional - disable TTS warmup if needed (does not affect DB)
      # Set to "true" to skip TTS client warmup (useful for faster deployments)
      DISABLE_TTS_WARMUP: ${DISABLE_TTS_WARMUP:-false}
      # ðŸ”¥ SCHEDULERS: Disable schedulers in calls service (only worker should run them)
      ENABLE_SCHEDULERS: "false"
      # ðŸ”¥ GOOGLE STT - Service Account Credentials
      GOOGLE_APPLICATION_CREDENTIALS: /root/secrets/gcp-stt-sa.json
      # ðŸ”¥ LOGGING - Production mode (minimal logs)
      LOG_LEVEL: INFO
      PYTHONUNBUFFERED: 1
    # P3-4: Docker hardening
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    ulimits:
      nofile:
        soft: 65535
        hard: 65535
    # ðŸ”¥ DNS FIX: Use external DNS to prevent transient failures
    dns:
      - 1.1.1.1
      - 8.8.8.8
    dns_search: ["."]
    dns_opt:
      - ndots:0
      - timeout:2
      - attempts:2
    # âš ï¸ CRITICAL: --workers MUST be 1 (not 4!)
    # Reason: stream_registry is in-memory, not Redis
    # Multi-worker = lost call state = crashes
    # To scale: Refactor stream_registry to Redis first
    # ðŸ”¥ PRODUCTION LOGGING: --log-level info to minimize access logs
    command: ["uvicorn", "asgi:app", "--host", "0.0.0.0", "--port", "5050", "--ws", "websockets", "--timeout-keep-alive", "75", "--timeout-graceful-shutdown", "30", "--log-level", "info"]
    expose:
      - "5050"
    volumes:
      - recordings_data:/app/server/recordings
      # ðŸ”¥ GOOGLE STT - Mount service account JSON (read-only)
      - /root/secrets/gcp-stt-sa.json:/root/secrets/gcp-stt-sa.json:ro
    depends_on:
      redis:
        condition: service_healthy
      migrate:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5050/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - prosaas-net

  # ===========================================
  # Baileys WhatsApp Service - Production settings
  # ===========================================
  baileys:
    environment:
      # ðŸ”¥ FIX #1: Override backend URL to use prosaas-api service in production
      FLASK_BASE_URL: http://prosaas-api:5000
      BACKEND_BASE_URL: http://prosaas-api:5000
      # ðŸ”¥ LOGGING - Production mode (minimal logs)
      LOG_LEVEL: INFO
    depends_on:
      prosaas-api:
        condition: service_healthy
    networks:
      - prosaas-net

  # ===========================================
  # Frontend - Production settings
  # Remove backend dependency since frontend is static files
  # ===========================================
  frontend:
    depends_on: []
    # P3-4: Docker hardening - read-only filesystem
    read_only: true
    tmpfs:
      - /tmp
      - /var/cache/nginx
      - /var/run
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETUID
      - SETGID
      - NET_BIND_SERVICE
    # Production healthcheck - longer start_period for safety
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://127.0.0.1/health >/dev/null 2>&1 || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 10
      start_period: 40s
    networks:
      - prosaas-net

  # ===========================================
  # n8n - Production settings
  # Add network configuration
  # ===========================================
  n8n:
    networks:
      - prosaas-net

# ===========================================
# Docker Networks (shared)
# ===========================================
networks:
  prosaas-net:
    external: true
    name: ${DOCKER_NETWORK_NAME:-prosaas-net}

# ===========================================
# Volumes (shared)
# ===========================================
volumes:
  recordings_data:
  whatsapp_auth:
  n8n_data:
