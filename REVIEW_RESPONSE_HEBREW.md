# ×ª×©×•×‘×” ×œ×‘×“×™×§×ª "100% ×ª×§×™×Ÿ"

## 1. ×”×¡×§×¨×™×¤×˜ deploy_production.sh - ×”×§×˜×¢×™× ×”×§×¨×™×˜×™×™×

### ×©×•×¨×•×ª 115-148: ×”×¨×¦×ª docker compose ×¢× ×©× ×™ ×”×§×‘×¦×™× + run --rm migrate

```bash
# Step 1: Build images
docker compose \
    -f "$BASE_COMPOSE" \
    -f "$PROD_COMPOSE" \
    build --no-cache

# Step 2: Run migrations (×§×¨×™×˜×™!)
log_info "Executing migrations..."
docker compose \
    -f "$BASE_COMPOSE" \
    -f "$PROD_COMPOSE" \
    run --rm migrate

# Check if migrations succeeded
MIGRATE_EXIT_CODE=$?
if [ $MIGRATE_EXIT_CODE -ne 0 ]; then
    log_error "Migrations failed with exit code $MIGRATE_EXIT_CODE"
    log_error "Cannot proceed with deployment"
    exit 1
fi

# Step 3: Start services (×¨×§ ××—×¨×™ ×©migrations ×¢×‘×¨×•!)
docker compose \
    -f "$BASE_COMPOSE" \
    -f "$PROD_COMPOSE" \
    up -d \
    --remove-orphans
```

**âœ… ×ª×©×•×‘×•×ª ×œ×—×©×©×•×ª 4 ×•-5:**
- âœ… ××©×ª××© ×‘×“×™×•×§ ×‘-`docker compose -f docker-compose.yml -f docker-compose.prod.yml`
- âœ… ××©×ª××© ×‘-`run --rm migrate` (×œ× `up -d migrate`)
- âœ… ×‘×•×“×§ exit code ×•×™×•×¦× ×× migrations × ×›×©×œ×•
- âœ… ××¨×™×¥ `up -d` ×¨×§ ××—×¨×™ ×©migrations ×”×¦×œ×™×—×•

---

## 2. ×”××™×’×¨×¦×™×•×ª 115-117 - ×”×‘×œ×•×§×™× ×©×©×•× ×•

### Migration 115 - business_calendars (×©×•×¨×•×ª 5956-6033)

```python
# Step 1: Create table OR verify if exists
if not check_table_exists('business_calendars'):
    # Create full table with all columns
    exec_ddl(db.engine, """
        CREATE TABLE business_calendars (
            id SERIAL PRIMARY KEY,
            business_id INTEGER NOT NULL REFERENCES business(id) ON DELETE CASCADE,
            name VARCHAR(255) NOT NULL,
            type_key VARCHAR(64),
            provider VARCHAR(32) DEFAULT 'internal' NOT NULL,
            calendar_external_id VARCHAR(255),
            is_active BOOLEAN DEFAULT TRUE NOT NULL,
            priority INTEGER DEFAULT 0 NOT NULL,
            default_duration_minutes INTEGER DEFAULT 60,
            buffer_before_minutes INTEGER DEFAULT 0,
            buffer_after_minutes INTEGER DEFAULT 0,
            allowed_tags JSONB DEFAULT '[]'::jsonb NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
else:
    # Table exists - add missing columns from later phases
    if not check_column_exists('business_calendars', 'buffer_before_minutes'):
        exec_ddl(db.engine, "ALTER TABLE business_calendars ADD COLUMN buffer_before_minutes INTEGER DEFAULT 0")
    
    if not check_column_exists('business_calendars', 'buffer_after_minutes'):
        exec_ddl(db.engine, "ALTER TABLE business_calendars ADD COLUMN buffer_after_minutes INTEGER DEFAULT 0")

# CRITICAL: Indexes created REGARDLESS of table age
if not check_index_exists('idx_business_calendars_business_active'):
    exec_ddl(db.engine, """
        CREATE INDEX idx_business_calendars_business_active 
        ON business_calendars(business_id, is_active)
    """)

if not check_index_exists('idx_business_calendars_priority'):
    exec_ddl(db.engine, """
        CREATE INDEX idx_business_calendars_priority 
        ON business_calendars(business_id, priority)
    """)
```

### Migration 116 - scheduled_message_rules (×©×•×¨×•×ª 6248-6309)

```python
# Table creation or verification
if not check_table_exists('scheduled_message_rules'):
    exec_ddl(db.engine, """CREATE TABLE scheduled_message_rules (...)""")
else:
    # Add missing columns
    if not check_column_exists('scheduled_message_rules', 'send_window_start'):
        exec_ddl(db.engine, "ALTER TABLE scheduled_message_rules ADD COLUMN send_window_start VARCHAR(5)")
    
    if not check_column_exists('scheduled_message_rules', 'send_window_end'):
        exec_ddl(db.engine, "ALTER TABLE scheduled_message_rules ADD COLUMN send_window_end VARCHAR(5)")

# CRITICAL: Index created regardless
if not check_index_exists('idx_scheduled_rules_business_active'):
    exec_ddl(db.engine, """
        CREATE INDEX idx_scheduled_rules_business_active 
        ON scheduled_message_rules(business_id, is_active)
    """)
```

### Migration 116 - scheduled_messages_queue (×©×•×¨×•×ª 6356-6480)

```python
if not check_table_exists('scheduled_messages_queue'):
    exec_ddl(db.engine, """CREATE TABLE scheduled_messages_queue (...)""")
else:
    # Add missing columns from later phases
    if not check_column_exists('scheduled_messages_queue', 'locked_at'):
        exec_ddl(db.engine, "ALTER TABLE scheduled_messages_queue ADD COLUMN locked_at TIMESTAMP")
    
    if not check_column_exists('scheduled_messages_queue', 'sent_at'):
        exec_ddl(db.engine, "ALTER TABLE scheduled_messages_queue ADD COLUMN sent_at TIMESTAMP")
    
    if not check_column_exists('scheduled_messages_queue', 'error_message'):
        exec_ddl(db.engine, "ALTER TABLE scheduled_messages_queue ADD COLUMN error_message TEXT")

# CRITICAL: All 6 indexes created regardless
if not check_index_exists('idx_scheduled_queue_scheduled_for'):
    exec_ddl(db.engine, "CREATE INDEX idx_scheduled_queue_scheduled_for ON scheduled_messages_queue(scheduled_for)")

if not check_index_exists('idx_scheduled_queue_status'):
    exec_ddl(db.engine, "CREATE INDEX idx_scheduled_queue_status ON scheduled_messages_queue(status)")

if not check_index_exists('idx_scheduled_queue_business_status_scheduled'):
    exec_ddl(db.engine, "CREATE INDEX idx_scheduled_queue_business_status_scheduled ON scheduled_messages_queue(business_id, status, scheduled_for)")

if not check_index_exists('idx_scheduled_queue_rule_status'):
    exec_ddl(db.engine, "CREATE INDEX idx_scheduled_queue_rule_status ON scheduled_messages_queue(rule_id, status)")

if not check_index_exists('idx_scheduled_queue_lead'):
    exec_ddl(db.engine, "CREATE INDEX idx_scheduled_queue_lead ON scheduled_messages_queue(lead_id)")

if not check_index_exists('idx_scheduled_queue_dedupe'):
    exec_ddl(db.engine, "CREATE UNIQUE INDEX idx_scheduled_queue_dedupe ON scheduled_messages_queue(dedupe_key)")
```

**âœ… ×ª×©×•×‘×” ×œ×—×©×© 1 (××™×“××¤×•×˜× ×˜×™×•×ª ×©×œ indexes):**
- âœ… ×›×œ ××™× ×“×§×¡ × ×‘×“×§ ×¢× `check_index_exists()` ×•× ×•×¦×¨ ×× ×—×¡×¨
- âœ… ×–×” ×§×•×¨×” **×‘×œ×™ ×ª×œ×•×ª** ×× ×”×˜×‘×œ×” × ×•×¦×¨×” ×¢×›×©×™×• ××• ×§×™×™××ª ××œ×¤× ×™
- âœ… UNIQUE constraints ×›×œ×•×œ×™× (×¨××” `idx_scheduled_queue_dedupe`)
- âœ… Foreign keys ×›×‘×¨ ×‘×”×’×“×¨×ª ×”×˜×‘×œ×” ×¢×¦××” (`REFERENCES business(id) ON DELETE CASCADE`)

---

## 3. Schema Check ×‘-server/worker.py (×©×•×¨×•×ª 138-165)

```python
# ğŸ”¥ QUICK SCHEMA CHECK: Verify critical tables exist
logger.info("ğŸ” Performing quick schema check...")
try:
    with app.app_context():
        from server.db import db
        from sqlalchemy import text
        
        # Check a few critical tables that the worker needs
        critical_tables = ['business', 'leads', 'receipts', 'gmail_receipts']
        missing_tables = []
        
        for table in critical_tables:
            result = db.session.execute(text("""
                SELECT table_name FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = :table_name
            """), {"table_name": table})
            if not result.fetchone():
                missing_tables.append(table)
        
        if missing_tables:
            logger.error("=" * 80)
            logger.error(f"âŒ CRITICAL: DB schema appears outdated!")
            logger.error(f"âŒ Missing tables: {missing_tables}")
            logger.error("âŒ Please run migrations first:")
            logger.error("âŒ   docker compose -f docker-compose.yml -f docker-compose.prod.yml run --rm migrate")
            logger.error("=" * 80)
            sys.exit(1)
        else:
            logger.info("âœ… Schema check passed - all critical tables present")
        
except Exception as e:
    logger.warning(f"âš ï¸ Could not perform schema check: {e}")
    logger.warning("âš ï¸ Continuing anyway, but worker may fail if schema is outdated")
```

**âœ… ×ª×©×•×‘×” ×œ×—×©×© 3 (schema check ×œ× ×§×©×•×— ××“×™):**
- âœ… ×‘×•×“×§ ×¨×§ 4 ×˜×‘×œ××•×ª **×§×¨×™×˜×™×•×ª** ×©×”worker ×—×™×™×‘
- âœ… ×œ× ×‘×•×“×§ ×˜×‘×œ××•×ª ××•×¤×¦×™×•× ×œ×™×•×ª ××• ×¡×¤×¦×™×¤×™×•×ª ×œ×¤×™×¦'×¨
- âœ… ×× ×”×‘×“×™×§×” × ×›×©×œ×ª (exception) - **××“×¤×™×¡ ××–×”×¨×” ×××©×™×š** (×œ× ××¤×™×œ)
- âœ… ×”×•×“×¢×ª ×”×©×’×™××” ×‘×¨×•×¨×” ×•××›×•×•× ×ª ×œ×¤×ª×¨×•×Ÿ: "run migrate"

---

## 4. exec_ddl() Function - DDL ×œ×œ× db.session (×©×•×¨×•×ª 105-123)

```python
def exec_ddl(engine, sql: str):
    """
    Execute a single DDL statement in its own transaction.
    
    This is critical for Postgres: if a DDL statement fails within a transaction,
    the entire transaction enters FAILED state and all previous work is rolled back.
    
    By executing each DDL statement in its own transaction, we ensure that:
    1. Successful column additions are committed even if later statements fail
    2. Failed statements don't pollute the transaction state
    3. We can continue with other operations after a failure
    
    Args:
        engine: SQLAlchemy engine
        sql: DDL statement to execute
    """
    from sqlalchemy import text
    with engine.begin() as conn:  # begin() = auto commit/rollback
        conn.execute(text(sql))
```

**âœ… ×ª×©×•×‘×” ×œ×—×©×© 2 (DDL ×‘×œ×™ rollback):**
- âœ… ×›×œ DDL ×¨×¥ ×“×¨×š `exec_ddl(db.engine, ...)` - ×œ× `db.session.execute()`
- âœ… `engine.begin()` ×™×•×¦×¨ transaction × ×¤×¨×“×ª ×œ×›×œ DDL
- âœ… auto-commit/rollback ××•×˜×•××˜×™ - ××™×Ÿ "×”×¨×¢×œ×”" ×©×œ session
- âœ… ×× DDL × ×›×©×œ - ×¨×§ ×”×•× rollback, ×œ× ×›×œ ×”-session

**×”×¢×¨×”:** ×™×© ×¢×“×™×™×Ÿ ×›××” ××§×•××•×ª ×™×©× ×™× ×‘××™×’×¨×¦×™×•×ª ×©××©×ª××©×™× ×‘-`db.session.execute()`, ××‘×œ:
- ×”× ×œ× ×‘-115/116/117 (×”××™×’×¨×¦×™×•×ª ×©×ª×™×§× ×•)
- ×”× ×¢× `db.session.rollback()` ××¤×•×¨×© ×‘catch
- ×œ× × ×’×¢× ×• ×‘×”× ×›×“×™ ×œ×©××•×¨ ×¢×œ "minimal changes"

---

## ×¡×™×›×•×: ×ª×©×•×‘×•×ª ×œ-5 ×”×—×©×©×•×ª

| ×—×©×© | ×¡×˜×˜×•×¡ | ×”×¡×‘×¨ |
|-----|-------|------|
| 1ï¸âƒ£ ××™×“××¤×•×˜× ×˜×™×•×ª ×›×•×œ×œ×ª indexes | âœ… **×ª×§×™×Ÿ** | ×›×œ ××™× ×“×§×¡ × ×‘×“×§ ×•× ×•×¦×¨ ×‘× ×¤×¨×“ ×’× ×× ×˜×‘×œ×” ×§×™×™××ª |
| 2ï¸âƒ£ DDL ×œ×œ× db.session | âœ… **×ª×§×™×Ÿ** | ×›×œ DDL ×‘-115-117 ×“×¨×š `exec_ddl()` ×¢× transaction × ×¤×¨×“×ª |
| 3ï¸âƒ£ Schema check ×œ× ×§×©×•×— | âœ… **×ª×§×™×Ÿ** | ×¨×§ 4 ×˜×‘×œ××•×ª ×§×¨×™×˜×™×•×ª, exception ×œ× ××¤×™×œ |
| 4ï¸âƒ£ Compose files × ×›×•× ×™× | âœ… **×ª×§×™×Ÿ** | `-f docker-compose.yml -f docker-compose.prod.yml` ×‘×›×œ ××§×•× |
| 5ï¸âƒ£ run --rm migrate | âœ… **×ª×§×™×Ÿ** | `run --rm migrate`, ×œ× `up -d migrate` |

---

## ×”××œ×¦×” ×¡×•×¤×™×ª

**âœ… ×”×§×•×“ ×¤×•×ª×¨ ××ª ×”×‘×¢×™×•×ª ×”××§×•×¨×™×•×ª ×•×”×•× ×ª×§×™×Ÿ ×œmerge**

**××‘×œ** - ×™×© × ×§×•×“×” ××—×ª ×©×›×“××™ ×œ×©×§×•×œ (×œ× critical):

### ××•×¤×¦×™×•× ×œ×™: ×œ×”×•×¡×™×£ timeout ×œbuild

×‘-`scripts/deploy_production.sh` ×©×•×¨×” 115-118, ××¤×©×¨ ×œ×”×•×¡×™×£:

```bash
docker compose \
    -f "$BASE_COMPOSE" \
    -f "$PROD_COMPOSE" \
    build --no-cache \
    --progress=plain    # <-- ×›×“×™ ×œ×¨××•×ª ×‘×“×™×•×§ ××” ×§×•×¨×”
```

×–×” ×œ× ××©× ×” ×¤×•× ×§×¦×™×•× ×œ×™×•×ª ××‘×œ ×¢×•×–×¨ ×‘debugging ×× build ×ª×§×•×¢.

---

## ××™×©×•×¨ ×¡×•×¤×™

×›×œ 5 ×”×—×©×©×•×ª ××˜×•×¤×œ×™× × ×›×•×Ÿ. ×”×§×•×“:
1. âœ… ×¤×•×ª×¨ "××™×’×¨×¦×™×•×ª ××—×¨×™ × ×§×•×“×” ××¡×•×™××ª ×œ× × ×›× ×¡×•×ª"
2. âœ… ×¤×•×ª×¨ "worker ×©×‘×•×¨"
3. âœ… ×œ× ×™×™×›×©×œ ×‘×¤×¨×•×“ ×‘×’×œ×œ compose files ×©×’×•×™×™×
4. âœ… ×œ× ×™×™×›×©×œ ×‘×’×œ×œ migrate ×©×œ× ×¨×¥
5. âœ… ×œ× ×™×™×›×©×œ ×‘×’×œ×œ DDL transaction ××–×•×”××ª

**100% ××•×›×Ÿ ×œ-merge** ğŸ‰
