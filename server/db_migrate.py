"""
Database migrations - additive only, with strict data protection

üîí DATA PROTECTION GUARANTEE:
- FAQs and leads are NEVER deleted - migrations will FAIL if data loss is detected
- Migrations are mostly additive (CREATE TABLE, ADD COLUMN, CREATE INDEX)
- Limited exception: Deduplication DELETE for corrupted data (duplicate messages/calls only)
- NO TRUNCATE, NO DROP TABLE on any tables
- Automatic verification with rollback on unexpected data loss
"""
from server.db import db
from datetime import datetime
import logging
import sys

# Configure logging with explicit format
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    stream=sys.stderr,
    force=True  # Override any existing configuration
)
log = logging.getLogger(__name__)

# Explicit checkpoint logging
def checkpoint(message):
    """Log checkpoint that always prints to stderr"""
    msg = f"üîß MIGRATION CHECKPOINT: {message}"
    log.info(msg)
    print(msg, file=sys.stderr, flush=True)
    sys.stderr.flush()

def check_column_exists(table_name, column_name):
    """Check if column exists in table using independent connection"""
    from sqlalchemy import text
    try:
        # Use engine.connect() instead of db.session to avoid polluting the main transaction
        with db.engine.connect() as conn:
            result = conn.execute(text("""
                SELECT column_name FROM information_schema.columns 
                WHERE table_schema = 'public' AND table_name = :table_name AND column_name = :column_name
            """), {"table_name": table_name, "column_name": column_name})
            return result.fetchone() is not None
    except Exception as e:
        log.warning(f"Error checking if column {column_name} exists in {table_name}: {e}")
        return False

def check_table_exists(table_name):
    """Check if table exists using independent connection"""
    from sqlalchemy import text
    try:
        # Use engine.connect() instead of db.session to avoid polluting the main transaction
        with db.engine.connect() as conn:
            result = conn.execute(text("""
                SELECT table_name FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = :table_name
            """), {"table_name": table_name})
            return result.fetchone() is not None
    except Exception as e:
        log.warning(f"Error checking if table {table_name} exists: {e}")
        return False

def check_index_exists(index_name):
    """Check if index exists using independent connection"""
    from sqlalchemy import text
    try:
        # Use engine.connect() instead of db.session to avoid polluting the main transaction
        with db.engine.connect() as conn:
            result = conn.execute(text("""
                SELECT indexname FROM pg_indexes 
                WHERE schemaname = 'public' AND indexname = :index_name
            """), {"index_name": index_name})
            return result.fetchone() is not None
    except Exception as e:
        log.warning(f"Error checking if index {index_name} exists: {e}")
        return False

def apply_migrations():
    """
    Apply all pending migrations
    
    üîí DATA PROTECTION: This function ONLY adds new tables/columns/indexes.
    It NEVER deletes user data. All existing FAQs, leads, messages, etc. are preserved.
    
    üîí CONCURRENCY PROTECTION: Uses PostgreSQL advisory lock to prevent multiple
    processes from running migrations simultaneously (prevents deadlocks).
    """
    checkpoint("Starting apply_migrations()")
    migrations_applied = []
    
    # üîí CONCURRENCY PROTECTION: Acquire PostgreSQL advisory lock
    # Lock ID: 1234567890 (arbitrary unique integer)
    # This ensures only ONE process runs migrations at a time
    checkpoint("Acquiring PostgreSQL advisory lock for migrations...")
    from sqlalchemy import text
    lock_acquired = False
    try:
        # Try to acquire lock (non-blocking)
        result = db.session.execute(text("SELECT pg_try_advisory_lock(1234567890)"))
        lock_acquired = result.scalar()
        
        if not lock_acquired:
            checkpoint("‚ö†Ô∏è Another process is running migrations - waiting...")
            # Block until lock is available
            db.session.execute(text("SELECT pg_advisory_lock(1234567890)"))
            lock_acquired = True
            checkpoint("‚úÖ Acquired migration lock after waiting")
        else:
            checkpoint("‚úÖ Acquired migration lock immediately")
    except Exception as e:
        checkpoint(f"‚ùå Failed to acquire migration lock: {e}")
        raise
    
    try:
        checkpoint("Checking if database is completely empty...")
        # Check if database is empty and create all tables if needed
        from sqlalchemy import text, inspect
        inspector = inspect(db.engine)
        existing_tables = inspector.get_table_names()
        checkpoint(f"Found {len(existing_tables)} existing tables: {existing_tables[:5]}...")
        
        if len(existing_tables) == 0:
            checkpoint("Database is empty - creating all tables from SQLAlchemy metadata")
            try:
                db.create_all()
                checkpoint("‚úÖ All tables created successfully from metadata")
                migrations_applied.append("create_all_tables_from_metadata")
            except Exception as e:
                checkpoint(f"‚ùå Failed to create tables: {e}")
                raise
        
        # üîí BUILD 111: TRIPLE LAYER DATA PROTECTION
        # Layer 1: Count FAQs BEFORE migrations
        # Layer 2: Run migrations inside TRY block
        # Layer 3: Count FAQs AFTER migrations and ROLLBACK if decreased
        checkpoint("Starting data protection layer 1 - counting existing data")
        faq_count_before = 0
        lead_count_before = 0
        msg_count_before = 0
        try:
            from sqlalchemy import text
            
            # üî• CRITICAL FIX: Check table existence BEFORE counting to prevent UndefinedTable exceptions
            if check_table_exists('faqs'):
                faq_count_before = db.session.execute(text("SELECT COUNT(*) FROM faqs")).scalar() or 0
                checkpoint(f"üîí LAYER 1 (BEFORE): {faq_count_before} FAQs exist")
            else:
                checkpoint(f"üîí LAYER 1 (BEFORE): faqs table does not exist yet")
                
            if check_table_exists('leads'):
                lead_count_before = db.session.execute(text("SELECT COUNT(*) FROM leads")).scalar() or 0
                checkpoint(f"üîí LAYER 1 (BEFORE): {lead_count_before} leads exist")
            else:
                checkpoint(f"üîí LAYER 1 (BEFORE): leads table does not exist yet")
                
            if check_table_exists('messages'):
                msg_count_before = db.session.execute(text("SELECT COUNT(*) FROM messages")).scalar() or 0
                checkpoint(f"üîí LAYER 1 (BEFORE): {msg_count_before} messages exist")
            else:
                checkpoint(f"üîí LAYER 1 (BEFORE): messages table does not exist yet")
        except Exception as e:
            # üî• CRITICAL FIX: ROLLBACK immediately to prevent InFailedSqlTransaction
            db.session.rollback()
            log.warning(f"Could not check data counts (database may be new): {e}")
            checkpoint(f"Could not check data counts (database may be new): {e}")
        
        # Migration 1: Add transcript column to CallLog
        if check_table_exists('call_log'):
            from sqlalchemy import text
            try:
                # üîí IDEMPOTENT: Use IF NOT EXISTS to prevent DuplicateColumn errors
                db.session.execute(text("ALTER TABLE call_log ADD COLUMN IF NOT EXISTS transcript TEXT"))
                migrations_applied.append("add_call_log_transcript")
                log.info("Applied migration: add_call_log_transcript")
            except Exception as e:
                # üî• CRITICAL FIX: ROLLBACK immediately to prevent InFailedSqlTransaction
                db.session.rollback()
                log.warning(f"Could not add transcript column (may already exist): {e}")
        
        # Migration 2: Create CallTurn table
        if not check_table_exists('call_turn'):
            from sqlalchemy import text
            db.session.execute(text("""
                CREATE TABLE call_turn (
                    id SERIAL PRIMARY KEY,
                    call_sid VARCHAR(64) NOT NULL,
                    business_id INTEGER NOT NULL,
                    started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    mode VARCHAR(10) DEFAULT 'stream',
                    t_audio_ms INTEGER,
                    t_nlp_ms INTEGER,
                    t_tts_ms INTEGER,
                    t_total_ms INTEGER,
                    error_code VARCHAR(50)
                )
            """))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_call_turn_sid ON call_turn(call_sid)"))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_call_turn_business_time ON call_turn(business_id, started_at)"))
            migrations_applied.append("create_call_turn_table")
            log.info("Applied migration: create_call_turn_table")
        
        # Migration 3: Add feature flags to Business table
        feature_flags = [
            'enable_calls_stream',
            'enable_recording_fallback', 
            'enable_payments_paypal',
            'enable_payments_tranzila'
        ]
        
        for flag in feature_flags:
            if check_table_exists('business') and not check_column_exists('business', flag):
                from sqlalchemy import text
                default_value = 'true' if flag.startswith('enable_calls') or flag.startswith('enable_recording') else 'false'
                db.session.execute(text(f"ALTER TABLE business ADD COLUMN {flag} BOOLEAN DEFAULT {default_value}"))
                migrations_applied.append(f"add_business_{flag}")
                log.info(f"Applied migration: add_business_{flag}")
        
        # Migration 4: Create threads table for unified messaging
        if not check_table_exists('threads'):
            from sqlalchemy import text
            db.session.execute(text("""
                CREATE TABLE threads (
                    id SERIAL PRIMARY KEY,
                    business_id INTEGER NOT NULL,
                    type VARCHAR(16) NOT NULL,
                    provider VARCHAR(16) NOT NULL,
                    peer_number VARCHAR(32) NOT NULL,
                    title VARCHAR(120),
                    last_message_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_threads_biz_last ON threads(business_id, last_message_at DESC)"))
            migrations_applied.append("create_threads_table")
            log.info("Applied migration: create_threads_table")
        
        # Migration 5: Create messages table for unified messaging
        if not check_table_exists('messages'):
            from sqlalchemy import text
            db.session.execute(text("""
                CREATE TABLE messages (
                    id SERIAL PRIMARY KEY,
                    thread_id INTEGER NOT NULL REFERENCES threads(id),
                    direction VARCHAR(4) NOT NULL,
                    message_type VARCHAR(16) NOT NULL,
                    content_text TEXT,
                    media_url TEXT,
                    provider_msg_id VARCHAR(64),
                    status VARCHAR(16) DEFAULT 'received',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_msgs_thread_time ON messages(thread_id, created_at)"))
            migrations_applied.append("create_messages_table")
            log.info("Applied migration: create_messages_table")
        
        # Migration 6: Add unique index for message deduplication
        if check_table_exists('messages') and not check_index_exists('uniq_msg_provider_id'):
            from sqlalchemy import text
            try:
                # First remove any existing duplicates (keep the earliest)
                db.session.execute(text("""
                    DELETE FROM messages 
                    WHERE id NOT IN (
                        SELECT MIN(id) 
                        FROM messages 
                        WHERE provider_msg_id IS NOT NULL AND provider_msg_id != ''
                        GROUP BY provider_msg_id
                    )
                    AND provider_msg_id IS NOT NULL AND provider_msg_id != ''
                """))
                
                # Create unique index on provider_msg_id (for non-null values)
                db.session.execute(text("""
                    CREATE UNIQUE INDEX uniq_msg_provider_id 
                    ON messages(provider_msg_id) 
                    WHERE provider_msg_id IS NOT NULL AND provider_msg_id != ''
                """))
                migrations_applied.append("add_unique_provider_msg_id")
                log.info("Applied migration: add_unique_provider_msg_id")
            except Exception as e:
                # üî• CRITICAL FIX: ROLLBACK immediately to prevent InFailedSqlTransaction
                db.session.rollback()
                log.warning(f"Could not create unique index (may already exist): {e}")
        
        # Migration 7: Create leads table for CRM system
        if not check_table_exists('leads'):
            from sqlalchemy import text
            db.session.execute(text("""
                CREATE TABLE leads (
                    id SERIAL PRIMARY KEY,
                    tenant_id INTEGER NOT NULL REFERENCES business(id),
                    first_name VARCHAR(255),
                    last_name VARCHAR(255),
                    phone_e164 VARCHAR(64),
                    email VARCHAR(255),
                    source VARCHAR(32) DEFAULT 'form',
                    external_id VARCHAR(128),
                    status VARCHAR(32) DEFAULT 'New',
                    owner_user_id INTEGER REFERENCES users(id),
                    tags JSONB,
                    notes TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    last_contact_at TIMESTAMP
                )
            """))
            
            # Create indexes for leads table
            indexes = [
                "CREATE INDEX IF NOT EXISTS idx_leads_tenant ON leads(tenant_id)",
                "CREATE INDEX IF NOT EXISTS idx_leads_status ON leads(status)",
                "CREATE INDEX IF NOT EXISTS idx_leads_source ON leads(source)",
                "CREATE INDEX IF NOT EXISTS idx_leads_phone ON leads(phone_e164)",
                "CREATE INDEX IF NOT EXISTS idx_leads_email ON leads(email)",
                "CREATE INDEX IF NOT EXISTS idx_leads_external_id ON leads(external_id)",
                "CREATE INDEX IF NOT EXISTS idx_leads_owner ON leads(owner_user_id)",
                "CREATE INDEX IF NOT EXISTS idx_leads_created ON leads(created_at)",
                "CREATE INDEX IF NOT EXISTS idx_leads_contact ON leads(last_contact_at)"
            ]
            
            for index_sql in indexes:
                db.session.execute(text(index_sql))
                
            migrations_applied.append("create_leads_table")
            log.info("Applied migration: create_leads_table")
        
        # Migration 8: Create lead_reminders table
        if not check_table_exists('lead_reminders'):
            from sqlalchemy import text
            db.session.execute(text("""
                CREATE TABLE lead_reminders (
                    id SERIAL PRIMARY KEY,
                    lead_id INTEGER NOT NULL REFERENCES leads(id),
                    due_at TIMESTAMP NOT NULL,
                    note TEXT,
                    channel VARCHAR(16) DEFAULT 'ui',
                    delivered_at TIMESTAMP,
                    completed_at TIMESTAMP,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    created_by INTEGER REFERENCES users(id)
                )
            """))
            
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_lead_reminders_lead ON lead_reminders(lead_id)"))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_lead_reminders_due ON lead_reminders(due_at)"))
            migrations_applied.append("create_lead_reminders_table")
            log.info("Applied migration: create_lead_reminders_table")
        
        # Migration 9: Create lead_activities table
        if not check_table_exists('lead_activities'):
            from sqlalchemy import text
            db.session.execute(text("""
                CREATE TABLE lead_activities (
                    id SERIAL PRIMARY KEY,
                    lead_id INTEGER NOT NULL REFERENCES leads(id),
                    type VARCHAR(32) NOT NULL,
                    payload JSONB,
                    at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    created_by INTEGER REFERENCES users(id)
                )
            """))
            
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_lead_activities_lead ON lead_activities(lead_id)"))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_lead_activities_type ON lead_activities(type)"))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_lead_activities_time ON lead_activities(at)"))
            migrations_applied.append("create_lead_activities_table")
            log.info("Applied migration: create_lead_activities_table")
        
        # Migration 10: Create lead_merge_candidates table
        if not check_table_exists('lead_merge_candidates'):
            from sqlalchemy import text
            db.session.execute(text("""
                CREATE TABLE lead_merge_candidates (
                    id SERIAL PRIMARY KEY,
                    lead_id INTEGER NOT NULL REFERENCES leads(id),
                    duplicate_lead_id INTEGER NOT NULL REFERENCES leads(id),
                    confidence_score FLOAT DEFAULT 0.0,
                    reason VARCHAR(64),
                    reviewed_at TIMESTAMP,
                    reviewed_by INTEGER REFERENCES users(id),
                    merged_at TIMESTAMP,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """))
            
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_merge_candidates_lead ON lead_merge_candidates(lead_id)"))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_merge_candidates_dup ON lead_merge_candidates(duplicate_lead_id)"))
            migrations_applied.append("create_lead_merge_candidates_table")
            log.info("Applied migration: create_lead_merge_candidates_table")
        
        # Migration 11: Add order_index column to leads table for Kanban support
        if check_table_exists('leads') and not check_column_exists('leads', 'order_index'):
            from sqlalchemy import text
            db.session.execute(text("ALTER TABLE leads ADD COLUMN order_index INTEGER DEFAULT 0"))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_leads_order_index ON leads(order_index)"))
            # Set default order for existing leads based on their ID
            db.session.execute(text("UPDATE leads SET order_index = id WHERE order_index = 0"))
            migrations_applied.append("add_leads_order_index")
            log.info("Applied migration: add_leads_order_index")
        
        # Migration 12: Add working_hours and voice_message columns to business table
        business_columns = [
            ('working_hours', 'VARCHAR(50)', "'08:00-18:00'"),
            ('voice_message', 'TEXT', 'NULL')
        ]
        
        for col_name, col_type, default_val in business_columns:
            if check_table_exists('business') and not check_column_exists('business', col_name):
                from sqlalchemy import text
                db.session.execute(text(f"ALTER TABLE business ADD COLUMN {col_name} {col_type} DEFAULT {default_val}"))
                migrations_applied.append(f"add_business_{col_name}")
                log.info(f"Applied migration: add_business_{col_name}")
        
        # Migration 15: Add unique constraint on call_log.call_sid to prevent duplicates
        if check_table_exists('call_log') and not check_index_exists('uniq_call_log_call_sid'):
            from sqlalchemy import text
            try:
                # First remove any existing duplicates (keep the earliest)
                db.session.execute(text("""
                    DELETE FROM call_log 
                    WHERE id NOT IN (
                        SELECT MIN(id) 
                        FROM call_log 
                        WHERE call_sid IS NOT NULL AND call_sid != ''
                        GROUP BY call_sid
                    )
                    AND call_sid IS NOT NULL AND call_sid != ''
                """))
                
                # Create unique index on call_sid
                db.session.execute(text("""
                    CREATE UNIQUE INDEX uniq_call_log_call_sid 
                    ON call_log(call_sid) 
                    WHERE call_sid IS NOT NULL AND call_sid != ''
                """))
                migrations_applied.append("add_unique_call_sid")
                log.info("Applied migration: add_unique_call_sid")
            except Exception as e:
                # üî• CRITICAL FIX: ROLLBACK immediately to prevent InFailedSqlTransaction
                db.session.rollback()
                log.warning(f"Could not create unique index on call_sid (may already exist): {e}")
        
        # Migration 13: Create business_settings table for AI prompt management
        if not check_table_exists('business_settings'):
            from sqlalchemy import text
            db.session.execute(text("""
                CREATE TABLE business_settings (
                    tenant_id INTEGER NOT NULL REFERENCES business(id) PRIMARY KEY,
                    ai_prompt TEXT,
                    model VARCHAR(50) DEFAULT 'gpt-4o-mini',
                    max_tokens INTEGER DEFAULT 150,
                    temperature FLOAT DEFAULT 0.7,
                    updated_by VARCHAR(255),
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """))
            migrations_applied.append("create_business_settings_table")
            log.info("Applied migration: create_business_settings_table")
        
        # Migration 14: Create prompt_revisions table for AI prompt versioning
        if not check_table_exists('prompt_revisions'):
            from sqlalchemy import text
            db.session.execute(text("""
                CREATE TABLE prompt_revisions (
                    id SERIAL PRIMARY KEY,
                    tenant_id INTEGER NOT NULL REFERENCES business(id),
                    version INTEGER NOT NULL,
                    prompt TEXT,
                    changed_by VARCHAR(255),
                    changed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """))
            
            # Create index for (tenant_id, version)
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_tenant_version ON prompt_revisions(tenant_id, version)"))
            migrations_applied.append("create_prompt_revisions_table")
            log.info("Applied migration: create_prompt_revisions_table")
        
        # Migration 16: Create business_contact_channels table for multi-tenant routing
        if not check_table_exists('business_contact_channels'):
            from sqlalchemy import text
            db.session.execute(text("""
                CREATE TABLE business_contact_channels (
                    id SERIAL PRIMARY KEY,
                    business_id INTEGER NOT NULL REFERENCES business(id),
                    channel_type VARCHAR(32) NOT NULL,
                    identifier VARCHAR(255) NOT NULL,
                    is_primary BOOLEAN DEFAULT false,
                    config_json TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """))
            
            # Create indexes
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_bcc_business ON business_contact_channels(business_id)"))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_bcc_channel ON business_contact_channels(channel_type)"))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_bcc_identifier ON business_contact_channels(identifier)"))
            
            # Unique constraint: one identifier per channel type
            db.session.execute(text("""
                CREATE UNIQUE INDEX IF NOT EXISTS uq_channel_identifier 
                ON business_contact_channels(channel_type, identifier)
            """))
            
            # Seed data: Add contact channels for existing businesses
            # For each business with a phone_number, create twilio_voice + whatsapp channels
            db.session.execute(text("""
                INSERT INTO business_contact_channels (business_id, channel_type, identifier, is_primary)
                SELECT 
                    id as business_id,
                    'twilio_voice' as channel_type,
                    phone_number as identifier,
                    true as is_primary
                FROM business
                WHERE phone_number IS NOT NULL AND phone_number != ''
                ON CONFLICT (channel_type, identifier) DO NOTHING
            """))
            
            # Add WhatsApp channels with business_X format
            db.session.execute(text("""
                INSERT INTO business_contact_channels (business_id, channel_type, identifier, is_primary)
                SELECT 
                    id as business_id,
                    'whatsapp' as channel_type,
                    'business_' || id as identifier,
                    true as is_primary
                FROM business
                ON CONFLICT (channel_type, identifier) DO NOTHING
            """))
            
            migrations_applied.append("create_business_contact_channels_table")
            log.info("Applied migration: create_business_contact_channels_table with seed data")
        
        # Migration 17: Add signature_data to contract table
        if check_table_exists('contract') and not check_column_exists('contract', 'signature_data'):
            from sqlalchemy import text
            db.session.execute(text("ALTER TABLE contract ADD COLUMN signature_data TEXT"))
            migrations_applied.append("add_contract_signature_data")
            log.info("Applied migration: add_contract_signature_data")
        
        # Migration 19: Add direction, duration, to_number to call_log table
        call_log_columns = [
            ('direction', 'VARCHAR(16)', "'inbound'"),
            ('duration', 'INTEGER', '0'),
            ('to_number', 'VARCHAR(64)', 'NULL')
        ]
        
        for col_name, col_type, default_val in call_log_columns:
            if check_table_exists('call_log') and not check_column_exists('call_log', col_name):
                from sqlalchemy import text
                db.session.execute(text(f"ALTER TABLE call_log ADD COLUMN {col_name} {col_type} DEFAULT {default_val}"))
                migrations_applied.append(f"add_call_log_{col_name}")
                log.info(f"Applied migration: add_call_log_{col_name}")
        
        # Migration 18: Fix Deal.customer_id foreign key (leads.id ‚Üí customer.id)
        if check_table_exists('deal'):
            from sqlalchemy import text
            try:
                # Check if the wrong constraint exists
                constraint_check = db.session.execute(text("""
                    SELECT constraint_name 
                    FROM information_schema.table_constraints 
                    WHERE table_name = 'deal' 
                    AND constraint_type = 'FOREIGN KEY'
                    AND constraint_name LIKE '%customer_id%'
                """)).fetchone()
                
                if constraint_check:
                    constraint_name = constraint_check[0]
                    # Drop old wrong foreign key (if it points to leads)
                    db.session.execute(text(f"ALTER TABLE deal DROP CONSTRAINT IF EXISTS {constraint_name}"))
                    log.info(f"Dropped old foreign key constraint: {constraint_name}")
                
                # Add correct foreign key pointing to customer.id with CASCADE
                db.session.execute(text("""
                    ALTER TABLE deal 
                    ADD CONSTRAINT deal_customer_id_fkey 
                    FOREIGN KEY (customer_id) 
                    REFERENCES customer(id) 
                    ON DELETE CASCADE
                """))
                migrations_applied.append("fix_deal_customer_fkey")
                log.info("Applied migration: fix_deal_customer_fkey - Now points to customer.id with CASCADE")
            except Exception as e:
                # üî• CRITICAL FIX: ROLLBACK immediately to prevent InFailedSqlTransaction
                db.session.rollback()
                log.warning(f"Could not fix deal foreign key (may already be correct): {e}")
        
        # Migration 19: Add Policy Engine fields to business_settings
        policy_fields = [
            ('slot_size_min', 'INTEGER', '60'),
            ('allow_24_7', 'BOOLEAN', 'FALSE'),
            ('opening_hours_json', 'JSON', 'NULL'),
            ('booking_window_days', 'INTEGER', '30'),
            ('min_notice_min', 'INTEGER', '0')
        ]
        
        for col_name, col_type, default_val in policy_fields:
            if check_table_exists('business_settings') and not check_column_exists('business_settings', col_name):
                from sqlalchemy import text
                db.session.execute(text(f"ALTER TABLE business_settings ADD COLUMN {col_name} {col_type} DEFAULT {default_val}"))
                migrations_applied.append(f"add_business_settings_{col_name}")
                log.info(f"‚úÖ Applied migration: add_business_settings_{col_name} - Policy Engine field")
        
        # Migration 20: Add require_phone_before_booking to business_settings
        if check_table_exists('business_settings') and not check_column_exists('business_settings', 'require_phone_before_booking'):
            from sqlalchemy import text
            db.session.execute(text("ALTER TABLE business_settings ADD COLUMN require_phone_before_booking BOOLEAN DEFAULT TRUE"))
            migrations_applied.append("add_business_settings_require_phone_before_booking")
            log.info("‚úÖ Applied migration 20: require_phone_before_booking - Phone required guard")
        
        # Migration 21: Create FAQs table for business-specific fast-path responses
        if not check_table_exists('faqs'):
            from sqlalchemy import text
            db.session.execute(text("""
                CREATE TABLE faqs (
                    id SERIAL PRIMARY KEY,
                    business_id INTEGER NOT NULL REFERENCES business(id) ON DELETE CASCADE,
                    question VARCHAR(500) NOT NULL,
                    answer TEXT NOT NULL,
                    is_active BOOLEAN DEFAULT TRUE,
                    order_index INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_business_active ON faqs(business_id, is_active)"))
            migrations_applied.append("create_faqs_table")
            log.info("‚úÖ Applied migration 21: create_faqs_table - Business-specific FAQs for fast-path")
        
        # Migration 22: Add FAQ Fast-Path fields (intent_key, patterns, channels, priority, lang)
        faq_fastpath_fields = [
            ('intent_key', 'VARCHAR(50)', None),  # Nullable, no default
            ('patterns_json', 'JSON', None),  # Nullable, no default
            ('channels', 'VARCHAR(20)', "'voice'"),
            ('priority', 'INTEGER', '0'),
            ('lang', 'VARCHAR(10)', "'he-IL'")
        ]
        
        for col_name, col_type, default_val in faq_fastpath_fields:
            if check_table_exists('faqs') and not check_column_exists('faqs', col_name):
                from sqlalchemy import text
                if default_val is None:
                    # Nullable column without default
                    db.session.execute(text(f"ALTER TABLE faqs ADD COLUMN {col_name} {col_type}"))
                else:
                    # Column with explicit default value
                    db.session.execute(text(f"ALTER TABLE faqs ADD COLUMN {col_name} {col_type} DEFAULT {default_val}"))
                migrations_applied.append(f"add_faqs_{col_name}")
                log.info(f"‚úÖ Applied migration 22: add_faqs_{col_name} - FAQ Fast-Path field")
        
        # Migration 23: Create CallSession table for appointment deduplication
        if not check_table_exists('call_session'):
            from sqlalchemy import text
            db.session.execute(text("""
                CREATE TABLE call_session (
                    id SERIAL PRIMARY KEY,
                    call_sid VARCHAR(64) UNIQUE NOT NULL,
                    business_id INTEGER NOT NULL,
                    lead_id INTEGER,
                    last_requested_slot VARCHAR(100),
                    last_confirmed_slot VARCHAR(100),
                    created_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP AT TIME ZONE 'UTC'),
                    updated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP AT TIME ZONE 'UTC')
                )
            """))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_call_session_sid ON call_session(call_sid)"))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_call_session_business ON call_session(business_id)"))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_call_session_lead ON call_session(lead_id)"))
            migrations_applied.append("create_call_session_table")
            log.info("‚úÖ Applied migration 23: create_call_session_table - Appointment deduplication")
        
        # Migration 24: Create WhatsAppConversationState table for AI toggle per conversation
        if not check_table_exists('whatsapp_conversation_state'):
            from sqlalchemy import text
            db.session.execute(text("""
                CREATE TABLE whatsapp_conversation_state (
                    id SERIAL PRIMARY KEY,
                    business_id INTEGER NOT NULL,
                    phone VARCHAR(64) NOT NULL,
                    ai_active BOOLEAN DEFAULT TRUE,
                    updated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP AT TIME ZONE 'UTC'),
                    updated_by INTEGER,
                    CONSTRAINT fk_business FOREIGN KEY (business_id) REFERENCES business(id),
                    CONSTRAINT fk_updated_by FOREIGN KEY (updated_by) REFERENCES users(id),
                    CONSTRAINT uq_business_phone_state UNIQUE (business_id, phone)
                )
            """))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_wa_conv_state_business ON whatsapp_conversation_state(business_id)"))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_wa_conv_state_phone ON whatsapp_conversation_state(phone)"))
            migrations_applied.append("create_whatsapp_conversation_state_table")
            log.info("‚úÖ Applied migration 24: create_whatsapp_conversation_state_table - AI toggle per conversation")
        
        # Migration 25: Add whatsapp_provider column to business table (Meta Cloud API support)
        if check_table_exists('business') and not check_column_exists('business', 'whatsapp_provider'):
            from sqlalchemy import text
            db.session.execute(text("ALTER TABLE business ADD COLUMN whatsapp_provider VARCHAR(32) DEFAULT 'baileys'"))
            migrations_applied.append("add_business_whatsapp_provider")
            log.info("‚úÖ Applied migration 25: add_business_whatsapp_provider - Meta Cloud API support")
        
        # Migration 26: Create WhatsAppConversation table for session tracking and auto-summary
        if not check_table_exists('whatsapp_conversation'):
            from sqlalchemy import text
            db.session.execute(text("""
                CREATE TABLE whatsapp_conversation (
                    id SERIAL PRIMARY KEY,
                    business_id INTEGER NOT NULL,
                    provider VARCHAR(32) DEFAULT 'baileys',
                    customer_wa_id VARCHAR(64) NOT NULL,
                    lead_id INTEGER,
                    started_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP AT TIME ZONE 'UTC'),
                    last_message_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP AT TIME ZONE 'UTC'),
                    last_customer_message_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP AT TIME ZONE 'UTC'),
                    is_open BOOLEAN DEFAULT TRUE,
                    summary_created BOOLEAN DEFAULT FALSE,
                    summary TEXT,
                    created_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP AT TIME ZONE 'UTC'),
                    updated_at TIMESTAMP DEFAULT (CURRENT_TIMESTAMP AT TIME ZONE 'UTC'),
                    CONSTRAINT fk_wa_conv_business FOREIGN KEY (business_id) REFERENCES business(id),
                    CONSTRAINT fk_wa_conv_lead FOREIGN KEY (lead_id) REFERENCES leads(id)
                )
            """))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_wa_conv_business_open ON whatsapp_conversation(business_id, is_open)"))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_wa_conv_customer ON whatsapp_conversation(business_id, customer_wa_id)"))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_wa_conv_last_msg ON whatsapp_conversation(last_message_at)"))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_wa_conv_last_cust_msg ON whatsapp_conversation(last_customer_message_at)"))
            migrations_applied.append("create_whatsapp_conversation_table")
            log.info("‚úÖ Applied migration 26: create_whatsapp_conversation_table - Session tracking + auto-summary")
        
        # Migration 27: Add whatsapp_last_summary fields to leads table
        if check_table_exists('leads') and not check_column_exists('leads', 'whatsapp_last_summary'):
            from sqlalchemy import text
            db.session.execute(text("ALTER TABLE leads ADD COLUMN whatsapp_last_summary TEXT"))
            db.session.execute(text("ALTER TABLE leads ADD COLUMN whatsapp_last_summary_at TIMESTAMP"))
            migrations_applied.append("add_leads_whatsapp_summary")
            log.info("‚úÖ Applied migration 27: add_leads_whatsapp_summary - WhatsApp session summary on leads")
        
        # Migration 28: BUILD 163 - Monday.com integration + Auto-hangup + Bot speaks first
        if check_table_exists('business_settings'):
            from sqlalchemy import text
            
            # Monday.com integration fields
            if not check_column_exists('business_settings', 'monday_webhook_url'):
                db.session.execute(text("ALTER TABLE business_settings ADD COLUMN monday_webhook_url VARCHAR(512)"))
                migrations_applied.append("add_monday_webhook_url")
                log.info("‚úÖ Applied migration 28a: add_monday_webhook_url")
            
            if not check_column_exists('business_settings', 'send_call_transcripts_to_monday'):
                db.session.execute(text("ALTER TABLE business_settings ADD COLUMN send_call_transcripts_to_monday BOOLEAN DEFAULT FALSE"))
                migrations_applied.append("add_send_call_transcripts_to_monday")
                log.info("‚úÖ Applied migration 28b: add_send_call_transcripts_to_monday")
            
            # Auto hang-up fields
            if not check_column_exists('business_settings', 'auto_end_after_lead_capture'):
                db.session.execute(text("ALTER TABLE business_settings ADD COLUMN auto_end_after_lead_capture BOOLEAN DEFAULT FALSE"))
                migrations_applied.append("add_auto_end_after_lead_capture")
                log.info("‚úÖ Applied migration 28c: add_auto_end_after_lead_capture")
            
            if not check_column_exists('business_settings', 'auto_end_on_goodbye'):
                db.session.execute(text("ALTER TABLE business_settings ADD COLUMN auto_end_on_goodbye BOOLEAN DEFAULT FALSE"))
                migrations_applied.append("add_auto_end_on_goodbye")
                log.info("‚úÖ Applied migration 28d: add_auto_end_on_goodbye")
            
            # Bot speaks first field
            if not check_column_exists('business_settings', 'bot_speaks_first'):
                db.session.execute(text("ALTER TABLE business_settings ADD COLUMN bot_speaks_first BOOLEAN DEFAULT FALSE"))
                migrations_applied.append("add_bot_speaks_first")
                log.info("‚úÖ Applied migration 28e: add_bot_speaks_first")
        
        # Migration 29: BUILD 182 - Outbound lead lists for bulk import
        if not check_table_exists('outbound_lead_lists'):
            from sqlalchemy import text
            db.session.execute(text("""
                CREATE TABLE outbound_lead_lists (
                    id SERIAL PRIMARY KEY,
                    tenant_id INTEGER NOT NULL REFERENCES business(id),
                    name VARCHAR(255) NOT NULL,
                    file_name VARCHAR(255),
                    total_leads INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS ix_outbound_lead_lists_tenant_id ON outbound_lead_lists(tenant_id)"))
            migrations_applied.append("create_outbound_lead_lists_table")
            log.info("‚úÖ Applied migration 29a: create_outbound_lead_lists_table - Bulk import for outbound calls")
        
        # Migration 29b: Add outbound_list_id to leads table
        if check_table_exists('leads') and not check_column_exists('leads', 'outbound_list_id'):
            from sqlalchemy import text
            db.session.execute(text("ALTER TABLE leads ADD COLUMN outbound_list_id INTEGER REFERENCES outbound_lead_lists(id)"))
            db.session.execute(text("CREATE INDEX IF NOT EXISTS ix_leads_outbound_list_id ON leads(outbound_list_id)"))
            migrations_applied.append("add_leads_outbound_list_id")
            log.info("‚úÖ Applied migration 29b: add_leads_outbound_list_id - Link leads to import lists")
        
        # Migration 30: BUILD 183 - Separate inbound/outbound webhook URLs
        if check_table_exists('business_settings'):
            from sqlalchemy import text
            
            if not check_column_exists('business_settings', 'inbound_webhook_url'):
                db.session.execute(text("ALTER TABLE business_settings ADD COLUMN inbound_webhook_url VARCHAR(512)"))
                migrations_applied.append("add_inbound_webhook_url")
                log.info("‚úÖ Applied migration 30a: add_inbound_webhook_url - Separate webhook for inbound calls")
            
            if not check_column_exists('business_settings', 'outbound_webhook_url'):
                db.session.execute(text("ALTER TABLE business_settings ADD COLUMN outbound_webhook_url VARCHAR(512)"))
                migrations_applied.append("add_outbound_webhook_url")
                log.info("‚úÖ Applied migration 30b: add_outbound_webhook_url - Separate webhook for outbound calls")
        
        # Migration 31: BUILD 186 - Calendar scheduling toggle for inbound calls
        if check_table_exists('business_settings'):
            from sqlalchemy import text
            
            if not check_column_exists('business_settings', 'enable_calendar_scheduling'):
                db.session.execute(text("ALTER TABLE business_settings ADD COLUMN enable_calendar_scheduling BOOLEAN DEFAULT TRUE"))
                migrations_applied.append("add_enable_calendar_scheduling")
                log.info("‚úÖ Applied migration 31: add_enable_calendar_scheduling - Toggle for AI appointment scheduling")
        
        # Migration 32: BUILD 204 - Dynamic STT Vocabulary for per-business transcription quality
        if check_table_exists('business_settings'):
            from sqlalchemy import text
            
            if not check_column_exists('business_settings', 'stt_vocabulary_json'):
                db.session.execute(text("ALTER TABLE business_settings ADD COLUMN stt_vocabulary_json JSON"))
                migrations_applied.append("add_stt_vocabulary_json")
                log.info("‚úÖ Applied migration 32a: add_stt_vocabulary_json - Per-business STT vocabulary")
            
            if not check_column_exists('business_settings', 'business_context'):
                db.session.execute(text("ALTER TABLE business_settings ADD COLUMN business_context VARCHAR(500)"))
                migrations_applied.append("add_business_context")
                log.info("‚úÖ Applied migration 32b: add_business_context - Business context for STT prompts")
        
        # Migration 33: BUILD 309 - SIMPLE_MODE settings for call flow control
        if check_table_exists('business_settings'):
            from sqlalchemy import text
            
            if not check_column_exists('business_settings', 'call_goal'):
                db.session.execute(text("ALTER TABLE business_settings ADD COLUMN call_goal VARCHAR(50) DEFAULT 'lead_only'"))
                migrations_applied.append("add_call_goal")
                log.info("‚úÖ Applied migration 33a: add_call_goal - Controls call objective (lead_only vs appointment)")
            
            if not check_column_exists('business_settings', 'confirm_before_hangup'):
                db.session.execute(text("ALTER TABLE business_settings ADD COLUMN confirm_before_hangup BOOLEAN DEFAULT TRUE"))
                migrations_applied.append("add_confirm_before_hangup")
                log.info("‚úÖ Applied migration 33b: add_confirm_before_hangup - Requires confirmation before disconnecting")
        
        # Migration 34: POST-CALL EXTRACTION - Full transcript + extracted fields for CallLog
        # üîí IDEMPOTENT: Uses PostgreSQL DO blocks to safely add columns
        if check_table_exists('call_log'):
            from sqlalchemy import text
            
            try:
                # Use single DO block for all call_log columns - more efficient
                db.session.execute(text("""
                    DO $$
                    BEGIN
                        -- Add final_transcript column
                        IF NOT EXISTS (
                            SELECT 1 FROM information_schema.columns
                            WHERE table_name = 'call_log' AND column_name = 'final_transcript'
                        ) THEN
                            ALTER TABLE call_log ADD COLUMN final_transcript TEXT;
                            RAISE NOTICE 'Added call_log.final_transcript';
                        END IF;
    
                        -- Add extracted_service column
                        IF NOT EXISTS (
                            SELECT 1 FROM information_schema.columns
                            WHERE table_name = 'call_log' AND column_name = 'extracted_service'
                        ) THEN
                            ALTER TABLE call_log ADD COLUMN extracted_service VARCHAR(255);
                            RAISE NOTICE 'Added call_log.extracted_service';
                        END IF;
    
                        -- Add extracted_city column
                        IF NOT EXISTS (
                            SELECT 1 FROM information_schema.columns
                            WHERE table_name = 'call_log' AND column_name = 'extracted_city'
                        ) THEN
                            ALTER TABLE call_log ADD COLUMN extracted_city VARCHAR(255);
                            RAISE NOTICE 'Added call_log.extracted_city';
                        END IF;
    
                        -- Add extraction_confidence column
                        IF NOT EXISTS (
                            SELECT 1 FROM information_schema.columns
                            WHERE table_name = 'call_log' AND column_name = 'extraction_confidence'
                        ) THEN
                            ALTER TABLE call_log ADD COLUMN extraction_confidence DOUBLE PRECISION;
                            RAISE NOTICE 'Added call_log.extraction_confidence';
                        END IF;
                    END;
                    $$;
                """))
                migrations_applied.append("add_call_log_extraction_fields")
                log.info("‚úÖ Applied migration 34: add_call_log_extraction_fields - POST-CALL EXTRACTION for CallLog")
            except Exception as e:
                log.error(f"‚ùå Migration 34 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 35: POST-CALL EXTRACTION - Service type and city fields for Lead
        # üîí IDEMPOTENT: Uses PostgreSQL DO blocks to safely add columns
        if check_table_exists('leads'):
            from sqlalchemy import text
            
            try:
                # Use single DO block for all leads columns - more efficient
                db.session.execute(text("""
                    DO $$
                    BEGIN
                        -- Add service_type column
                        IF NOT EXISTS (
                            SELECT 1 FROM information_schema.columns
                            WHERE table_name = 'leads' AND column_name = 'service_type'
                        ) THEN
                            ALTER TABLE leads ADD COLUMN service_type VARCHAR(255);
                            RAISE NOTICE 'Added leads.service_type';
                        END IF;
    
                        -- Add city column
                        IF NOT EXISTS (
                            SELECT 1 FROM information_schema.columns
                            WHERE table_name = 'leads' AND column_name = 'city'
                        ) THEN
                            ALTER TABLE leads ADD COLUMN city VARCHAR(255);
                            RAISE NOTICE 'Added leads.city';
                        END IF;
                    END;
                    $$;
                """))
                migrations_applied.append("add_leads_extraction_fields")
                log.info("‚úÖ Applied migration 35: add_leads_extraction_fields - POST-CALL EXTRACTION for Lead")
            except Exception as e:
                log.error(f"‚ùå Migration 35 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 36: BUILD 350 - Add last_call_direction to leads for inbound/outbound filtering
        # üîí IDEMPOTENT: Uses PostgreSQL DO block to safely add column + index + backfill
        if check_table_exists('leads'):
            from sqlalchemy import text
            
            try:
                # Use DO block to add column, index, and backfill in one transaction
                db.session.execute(text("""
                    DO $$
                    BEGIN
                        -- Add last_call_direction column if it doesn't exist
                        IF NOT EXISTS (
                            SELECT 1 FROM information_schema.columns
                            WHERE table_name = 'leads' AND column_name = 'last_call_direction'
                        ) THEN
                            ALTER TABLE leads ADD COLUMN last_call_direction VARCHAR(16);
                            RAISE NOTICE 'Added leads.last_call_direction';
                        END IF;
                    END;
                    $$;
                """))
                
                # Create index for performance (idempotent)
                db.session.execute(text("""
                    CREATE INDEX IF NOT EXISTS idx_leads_last_call_direction 
                    ON leads(last_call_direction)
                """))
                
                # Backfill last_call_direction from call_log table
                # üîí CRITICAL: Use FIRST call's direction (ASC), not latest (DESC)
                # This determines the lead's origin (inbound vs outbound)
                # ‚ö†Ô∏è PERFORMANCE: For very large datasets (>100K calls), this may take time
                # but it's a one-time operation and uses indexed columns (lead_id, created_at)
                checkpoint("Backfilling last_call_direction from call_log...")
                if check_table_exists('call_log'):
                    backfill_result = db.session.execute(text("""
                        WITH first_calls AS (
                            SELECT DISTINCT ON (cl.lead_id) 
                                cl.lead_id,
                                cl.direction,
                                cl.created_at
                            FROM call_log cl
                            WHERE cl.lead_id IS NOT NULL 
                              AND cl.direction IS NOT NULL
                              AND cl.direction IN ('inbound', 'outbound')
                            ORDER BY cl.lead_id, cl.created_at ASC
                        )
                        UPDATE leads l
                        SET last_call_direction = fc.direction
                        FROM first_calls fc
                        WHERE l.id = fc.lead_id
                          AND l.last_call_direction IS NULL
                    """))
                    rows_updated = backfill_result.rowcount
                    checkpoint(f"‚úÖ Backfilled last_call_direction for {rows_updated} leads (using FIRST call direction)")
                
                migrations_applied.append("add_leads_last_call_direction")
                log.info("‚úÖ Applied migration 36: add_leads_last_call_direction - Inbound/outbound filtering support")
            except Exception as e:
                log.error(f"‚ùå Migration 36 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 37: Lead Attachments - Production-ready file uploads for leads
        if not check_table_exists('lead_attachments'):
            checkpoint("Migration 37: Creating lead_attachments table for secure file storage")
            try:
                db.session.execute(text("""
                    CREATE TABLE lead_attachments (
                        id SERIAL PRIMARY KEY,
                        tenant_id INTEGER NOT NULL REFERENCES business(id),
                        lead_id INTEGER NOT NULL REFERENCES leads(id) ON DELETE CASCADE,
                        note_id INTEGER REFERENCES lead_notes(id) ON DELETE SET NULL,
                        filename VARCHAR(255) NOT NULL,
                        content_type VARCHAR(128) NOT NULL,
                        size_bytes INTEGER NOT NULL,
                        storage_key VARCHAR(512) NOT NULL,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        created_by INTEGER REFERENCES users(id)
                    )
                """))
                
                # Create indexes for performance
                db.session.execute(text("CREATE INDEX idx_lead_attachments_tenant_lead ON lead_attachments(tenant_id, lead_id)"))
                db.session.execute(text("CREATE INDEX idx_lead_attachments_lead_id ON lead_attachments(lead_id)"))
                db.session.execute(text("CREATE INDEX idx_lead_attachments_note_id ON lead_attachments(note_id)"))
                db.session.execute(text("CREATE INDEX idx_lead_attachments_created_at ON lead_attachments(created_at)"))
                
                migrations_applied.append('create_lead_attachments_table')
                log.info("‚úÖ Applied migration 37: create_lead_attachments_table - Secure file upload support")
            except Exception as e:
                log.error(f"‚ùå Migration 37 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 38: BUILD 342 - Add recording_sid to call_log for Twilio recording tracking
        # üîí CRITICAL FIX: This column is referenced in code but missing from DB
        if check_table_exists('call_log') and not check_column_exists('call_log', 'recording_sid'):
            checkpoint("Migration 38: Adding recording_sid column to call_log table")
            try:
                from sqlalchemy import text
                db.session.execute(text("ALTER TABLE call_log ADD COLUMN recording_sid VARCHAR(64)"))
                migrations_applied.append('add_call_log_recording_sid')
                log.info("‚úÖ Applied migration 38: add_call_log_recording_sid - Fix post-call pipeline crash")
            except Exception as e:
                log.error(f"‚ùå Migration 38 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 39: CRITICAL HOTFIX - Add missing columns to call_log for post-call pipeline
        # üîí IDEMPOTENT: These columns are referenced in code but missing from production DB
        # Fixes: psycopg2.errors.UndefinedColumn: column call_log.audio_bytes_len does not exist
        if check_table_exists('call_log'):
            checkpoint("Migration 39: Adding missing audio/transcript columns to call_log table")
            try:
                from sqlalchemy import text
                
                # Add audio_bytes_len column if missing
                if not check_column_exists('call_log', 'audio_bytes_len'):
                    db.session.execute(text("ALTER TABLE call_log ADD COLUMN audio_bytes_len BIGINT"))
                    migrations_applied.append('add_call_log_audio_bytes_len')
                    log.info("‚úÖ Applied migration 39a: add_call_log_audio_bytes_len")
                
                # Add audio_duration_sec column if missing
                if not check_column_exists('call_log', 'audio_duration_sec'):
                    db.session.execute(text("ALTER TABLE call_log ADD COLUMN audio_duration_sec DOUBLE PRECISION"))
                    migrations_applied.append('add_call_log_audio_duration_sec')
                    log.info("‚úÖ Applied migration 39b: add_call_log_audio_duration_sec")
                
                # Add transcript_source column if missing
                if not check_column_exists('call_log', 'transcript_source'):
                    db.session.execute(text("ALTER TABLE call_log ADD COLUMN transcript_source VARCHAR(32)"))
                    migrations_applied.append('add_call_log_transcript_source')
                    log.info("‚úÖ Applied migration 39c: add_call_log_transcript_source")
                
                checkpoint("‚úÖ Migration 39 completed - all missing columns added")
            except Exception as e:
                log.error(f"‚ùå Migration 39 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 40: Outbound Call Management - Bulk calling infrastructure
        # üîí CRITICAL: These tables are referenced in routes_outbound.py and tasks_recording.py
        # Creates: outbound_call_runs (campaigns) and outbound_call_jobs (individual calls)
        if not check_table_exists('outbound_call_runs'):
            checkpoint("Migration 40a: Creating outbound_call_runs table for bulk calling campaigns")
            try:
                from sqlalchemy import text
                db.session.execute(text("""
                    CREATE TABLE outbound_call_runs (
                        id SERIAL PRIMARY KEY,
                        business_id INTEGER NOT NULL REFERENCES business(id),
                        outbound_list_id INTEGER REFERENCES outbound_lead_lists(id),
                        concurrency INTEGER DEFAULT 3,
                        total_leads INTEGER DEFAULT 0,
                        queued_count INTEGER DEFAULT 0,
                        in_progress_count INTEGER DEFAULT 0,
                        completed_count INTEGER DEFAULT 0,
                        failed_count INTEGER DEFAULT 0,
                        status VARCHAR(32) DEFAULT 'running',
                        last_error TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        completed_at TIMESTAMP
                    )
                """))
                
                # Create indexes for performance
                db.session.execute(text("CREATE INDEX idx_outbound_call_runs_business_id ON outbound_call_runs(business_id)"))
                db.session.execute(text("CREATE INDEX idx_outbound_call_runs_status ON outbound_call_runs(status)"))
                db.session.execute(text("CREATE INDEX idx_outbound_call_runs_created_at ON outbound_call_runs(created_at)"))
                
                migrations_applied.append('create_outbound_call_runs_table')
                log.info("‚úÖ Applied migration 40a: create_outbound_call_runs_table - Bulk calling campaign tracking")
            except Exception as e:
                log.error(f"‚ùå Migration 40a failed: {e}")
                db.session.rollback()
                raise
        
        if not check_table_exists('outbound_call_jobs'):
            checkpoint("Migration 40b: Creating outbound_call_jobs table for individual call tracking")
            try:
                from sqlalchemy import text
                db.session.execute(text("""
                    CREATE TABLE outbound_call_jobs (
                        id SERIAL PRIMARY KEY,
                        run_id INTEGER NOT NULL REFERENCES outbound_call_runs(id),
                        lead_id INTEGER NOT NULL REFERENCES leads(id),
                        call_log_id INTEGER REFERENCES call_log(id),
                        status VARCHAR(32) DEFAULT 'queued',
                        error_message TEXT,
                        call_sid VARCHAR(64),
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        started_at TIMESTAMP,
                        completed_at TIMESTAMP
                    )
                """))
                
                # Create indexes for performance
                db.session.execute(text("CREATE INDEX idx_outbound_call_jobs_run_id ON outbound_call_jobs(run_id)"))
                db.session.execute(text("CREATE INDEX idx_outbound_call_jobs_lead_id ON outbound_call_jobs(lead_id)"))
                db.session.execute(text("CREATE INDEX idx_outbound_call_jobs_status ON outbound_call_jobs(status)"))
                db.session.execute(text("CREATE INDEX idx_outbound_call_jobs_call_sid ON outbound_call_jobs(call_sid)"))
                
                migrations_applied.append('create_outbound_call_jobs_table')
                log.info("‚úÖ Applied migration 40b: create_outbound_call_jobs_table - Individual call job tracking")
            except Exception as e:
                log.error(f"‚ùå Migration 40b failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 41: Add parent_call_sid and twilio_direction to call_log
        # üî• FIX: Prevents duplicate call logs and tracks original Twilio direction
        if not check_column_exists('call_log', 'parent_call_sid'):
            checkpoint("Migration 41a: Adding parent_call_sid to call_log for tracking parent/child call relationships")
            try:
                from sqlalchemy import text
                db.session.execute(text("""
                    ALTER TABLE call_log 
                    ADD COLUMN parent_call_sid VARCHAR(64)
                """))
                
                # Create index for performance
                db.session.execute(text("CREATE INDEX idx_call_log_parent_call_sid ON call_log(parent_call_sid)"))
                
                migrations_applied.append('add_parent_call_sid_to_call_log')
                log.info("‚úÖ Applied migration 41a: add_parent_call_sid_to_call_log - Track parent/child call legs")
            except Exception as e:
                log.error(f"‚ùå Migration 41a failed: {e}")
                db.session.rollback()
                raise
        
        if not check_column_exists('call_log', 'twilio_direction'):
            checkpoint("Migration 41b: Adding twilio_direction to call_log for storing original Twilio direction")
            try:
                from sqlalchemy import text
                db.session.execute(text("""
                    ALTER TABLE call_log 
                    ADD COLUMN twilio_direction VARCHAR(32)
                """))
                
                # Create index for performance
                db.session.execute(text("CREATE INDEX idx_call_log_twilio_direction ON call_log(twilio_direction)"))
                
                migrations_applied.append('add_twilio_direction_to_call_log')
                log.info("‚úÖ Applied migration 41b: add_twilio_direction_to_call_log - Store original Twilio direction values")
            except Exception as e:
                log.error(f"‚ùå Migration 41b failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 42: AI Topic Classification System
        checkpoint("Migration 42: AI Topic Classification System")
        try:
            # Create business_topics table
            if not check_table_exists('business_topics'):
                log.info("Creating business_topics table...")
                db.session.execute(text("""
                    CREATE TABLE business_topics (
                        id SERIAL PRIMARY KEY,
                        business_id INTEGER NOT NULL REFERENCES business(id),
                        name VARCHAR(255) NOT NULL,
                        synonyms JSONB,
                        embedding JSONB,
                        is_active BOOLEAN DEFAULT TRUE,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """))
                db.session.execute(text("CREATE INDEX idx_business_topic_active ON business_topics(business_id, is_active)"))
                migrations_applied.append('create_business_topics_table')
                log.info("‚úÖ Created business_topics table")
            
            # Create business_ai_settings table
            if not check_table_exists('business_ai_settings'):
                log.info("Creating business_ai_settings table...")
                db.session.execute(text("""
                    CREATE TABLE business_ai_settings (
                        business_id INTEGER PRIMARY KEY REFERENCES business(id),
                        embedding_enabled BOOLEAN DEFAULT FALSE,
                        embedding_threshold FLOAT DEFAULT 0.78,
                        embedding_top_k INTEGER DEFAULT 3,
                        auto_tag_leads BOOLEAN DEFAULT TRUE,
                        auto_tag_calls BOOLEAN DEFAULT TRUE,
                        auto_tag_whatsapp BOOLEAN DEFAULT FALSE,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """))
                migrations_applied.append('create_business_ai_settings_table')
                log.info("‚úÖ Created business_ai_settings table")
            
            # Add topic classification fields to call_log
            if check_table_exists('call_log'):
                if not check_column_exists('call_log', 'detected_topic_id'):
                    log.info("Adding topic classification fields to call_log...")
                    db.session.execute(text("""
                        ALTER TABLE call_log 
                        ADD COLUMN detected_topic_id INTEGER REFERENCES business_topics(id),
                        ADD COLUMN detected_topic_confidence FLOAT,
                        ADD COLUMN detected_topic_source VARCHAR(32) DEFAULT 'embedding'
                    """))
                    db.session.execute(text("CREATE INDEX idx_call_log_detected_topic ON call_log(detected_topic_id)"))
                    migrations_applied.append('add_topic_fields_to_call_log')
                    log.info("‚úÖ Added topic classification fields to call_log")
            
            # Add topic classification fields to leads
            if check_table_exists('leads'):
                if not check_column_exists('leads', 'detected_topic_id'):
                    log.info("Adding topic classification fields to leads...")
                    db.session.execute(text("""
                        ALTER TABLE leads 
                        ADD COLUMN detected_topic_id INTEGER REFERENCES business_topics(id),
                        ADD COLUMN detected_topic_confidence FLOAT,
                        ADD COLUMN detected_topic_source VARCHAR(32) DEFAULT 'embedding'
                    """))
                    db.session.execute(text("CREATE INDEX idx_leads_detected_topic ON leads(detected_topic_id)"))
                    migrations_applied.append('add_topic_fields_to_leads')
                    log.info("‚úÖ Added topic classification fields to leads")
            
            # Add topic classification fields to whatsapp_conversation
            if check_table_exists('whatsapp_conversation'):
                if not check_column_exists('whatsapp_conversation', 'detected_topic_id'):
                    log.info("Adding topic classification fields to whatsapp_conversation...")
                    db.session.execute(text("""
                        ALTER TABLE whatsapp_conversation 
                        ADD COLUMN detected_topic_id INTEGER REFERENCES business_topics(id),
                        ADD COLUMN detected_topic_confidence FLOAT,
                        ADD COLUMN detected_topic_source VARCHAR(32) DEFAULT 'embedding'
                    """))
                    db.session.execute(text("CREATE INDEX idx_wa_conv_detected_topic ON whatsapp_conversation(detected_topic_id)"))
                    migrations_applied.append('add_topic_fields_to_whatsapp_conversation')
                    log.info("‚úÖ Added topic classification fields to whatsapp_conversation")
            
            log.info("‚úÖ Applied migration 42: AI Topic Classification System")
        except Exception as e:
            log.error(f"‚ùå Migration 42 failed: {e}")
            db.session.rollback()
            raise
        
        # Migration 43: Service Canonicalization - Add canonical_service_type to BusinessTopic and service mapping settings
        checkpoint("Migration 43: Service Canonicalization and Topic-to-Service Mapping")
        try:
            # Add canonical_service_type to business_topics
            if check_table_exists('business_topics'):
                if not check_column_exists('business_topics', 'canonical_service_type'):
                    log.info("Adding canonical_service_type to business_topics...")
                    db.session.execute(text("""
                        ALTER TABLE business_topics 
                        ADD COLUMN canonical_service_type VARCHAR(255)
                    """))
                    migrations_applied.append('add_canonical_service_type_to_business_topics')
                    log.info("‚úÖ Added canonical_service_type to business_topics")
            
            # Add service mapping settings to business_ai_settings
            if check_table_exists('business_ai_settings'):
                if not check_column_exists('business_ai_settings', 'map_topic_to_service_type'):
                    log.info("Adding service mapping settings to business_ai_settings...")
                    db.session.execute(text("""
                        ALTER TABLE business_ai_settings 
                        ADD COLUMN map_topic_to_service_type BOOLEAN DEFAULT FALSE,
                        ADD COLUMN service_type_min_confidence FLOAT DEFAULT 0.75
                    """))
                    migrations_applied.append('add_service_mapping_settings_to_business_ai_settings')
                    log.info("‚úÖ Added service mapping settings to business_ai_settings")
            
            log.info("‚úÖ Applied migration 43: Service Canonicalization and Topic-to-Service Mapping")
        except Exception as e:
            log.error(f"‚ùå Migration 43 failed: {e}")
            db.session.rollback()
            raise
        
        # Migration 44: WhatsApp Broadcast System - Campaign management tables
        checkpoint("Migration 44: WhatsApp Broadcast System")
        try:
            # Create whatsapp_broadcasts table
            if not check_table_exists('whatsapp_broadcasts'):
                log.info("Creating whatsapp_broadcasts table...")
                db.session.execute(text("""
                    CREATE TABLE whatsapp_broadcasts (
                        id SERIAL PRIMARY KEY,
                        business_id INTEGER NOT NULL REFERENCES business(id),
                        name VARCHAR(255),
                        provider VARCHAR(32),
                        message_type VARCHAR(32),
                        template_id VARCHAR(255),
                        template_name VARCHAR(255),
                        message_text TEXT,
                        audience_filter JSON,
                        status VARCHAR(32) DEFAULT 'pending',
                        total_recipients INTEGER DEFAULT 0,
                        sent_count INTEGER DEFAULT 0,
                        failed_count INTEGER DEFAULT 0,
                        created_by INTEGER REFERENCES users(id),
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        started_at TIMESTAMP,
                        completed_at TIMESTAMP
                    )
                """))
                db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_whatsapp_broadcasts_business ON whatsapp_broadcasts(business_id)"))
                db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_whatsapp_broadcasts_status ON whatsapp_broadcasts(status)"))
                migrations_applied.append('create_whatsapp_broadcasts_table')
                log.info("‚úÖ Created whatsapp_broadcasts table")
            
            # Create whatsapp_broadcast_recipients table
            if not check_table_exists('whatsapp_broadcast_recipients'):
                log.info("Creating whatsapp_broadcast_recipients table...")
                db.session.execute(text("""
                    CREATE TABLE whatsapp_broadcast_recipients (
                        id SERIAL PRIMARY KEY,
                        broadcast_id INTEGER NOT NULL REFERENCES whatsapp_broadcasts(id),
                        business_id INTEGER NOT NULL REFERENCES business(id),
                        phone VARCHAR(64) NOT NULL,
                        lead_id INTEGER REFERENCES leads(id),
                        status VARCHAR(32) DEFAULT 'queued',
                        error_message TEXT,
                        message_id VARCHAR(255),
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        sent_at TIMESTAMP
                    )
                """))
                db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_whatsapp_broadcast_recipients_broadcast ON whatsapp_broadcast_recipients(broadcast_id)"))
                db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_whatsapp_broadcast_recipients_status ON whatsapp_broadcast_recipients(status)"))
                migrations_applied.append('create_whatsapp_broadcast_recipients_table')
                log.info("‚úÖ Created whatsapp_broadcast_recipients table")
            
            log.info("‚úÖ Applied migration 44: WhatsApp Broadcast System")
        except Exception as e:
            log.error(f"‚ùå Migration 44 failed: {e}")
            db.session.rollback()
            raise
        
        # Migration 45: Status Webhook - Add status_webhook_url to business_settings for lead status change notifications
        checkpoint("Migration 45: Status Webhook URL for lead status changes")
        if check_table_exists('business_settings') and not check_column_exists('business_settings', 'status_webhook_url'):
            try:
                from sqlalchemy import text
                db.session.execute(text("""
                    ALTER TABLE business_settings 
                    ADD COLUMN status_webhook_url VARCHAR(512) NULL
                """))
                migrations_applied.append('add_status_webhook_url')
                log.info("‚úÖ Added status_webhook_url column to business_settings")
            except Exception as e:
                log.error(f"‚ùå Migration 45 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 46: Bulk Call Deduplication - Add idempotency fields to outbound_call_jobs
        # Prevents duplicate calls from retry/concurrency/timeout scenarios
        checkpoint("Migration 46: Bulk Call Deduplication - Adding idempotency fields")
        
        # Add twilio_call_sid column for tracking initiated calls
        if check_table_exists('outbound_call_jobs') and not check_column_exists('outbound_call_jobs', 'twilio_call_sid'):
            try:
                from sqlalchemy import text
                db.session.execute(text("""
                    ALTER TABLE outbound_call_jobs 
                    ADD COLUMN twilio_call_sid VARCHAR(64) NULL
                """))
                # Create index for lookup performance
                db.session.execute(text("CREATE INDEX idx_outbound_call_jobs_twilio_sid ON outbound_call_jobs(twilio_call_sid)"))
                migrations_applied.append('add_twilio_call_sid_to_outbound_jobs')
                log.info("‚úÖ Added twilio_call_sid column to outbound_call_jobs for deduplication")
            except Exception as e:
                log.error(f"‚ùå Migration 46a failed: {e}")
                db.session.rollback()
                raise
        
        # Add dial_started_at column for tracking when dial attempt started
        if check_table_exists('outbound_call_jobs') and not check_column_exists('outbound_call_jobs', 'dial_started_at'):
            try:
                from sqlalchemy import text
                db.session.execute(text("""
                    ALTER TABLE outbound_call_jobs 
                    ADD COLUMN dial_started_at TIMESTAMP NULL
                """))
                migrations_applied.append('add_dial_started_at_to_outbound_jobs')
                log.info("‚úÖ Added dial_started_at column to outbound_call_jobs for tracking dial attempts")
            except Exception as e:
                log.error(f"‚ùå Migration 46b failed: {e}")
                db.session.rollback()
                raise
        
        # Add dial_lock_token column for atomic locking
        if check_table_exists('outbound_call_jobs') and not check_column_exists('outbound_call_jobs', 'dial_lock_token'):
            try:
                from sqlalchemy import text
                db.session.execute(text("""
                    ALTER TABLE outbound_call_jobs 
                    ADD COLUMN dial_lock_token VARCHAR(64) NULL
                """))
                # Create index for lock validation performance
                db.session.execute(text("CREATE INDEX idx_outbound_call_jobs_lock_token ON outbound_call_jobs(dial_lock_token)"))
                migrations_applied.append('add_dial_lock_token_to_outbound_jobs')
                log.info("‚úÖ Added dial_lock_token column to outbound_call_jobs for atomic locking")
            except Exception as e:
                log.error(f"‚ùå Migration 46c failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 46d: Add composite index for cleanup query performance
        if check_table_exists('outbound_call_jobs') and not check_index_exists('idx_outbound_call_jobs_status_twilio_sid'):
            checkpoint("Migration 46d: Adding composite index for cleanup query performance")
            try:
                from sqlalchemy import text
                # Composite index on (status, twilio_call_sid) for efficient cleanup queries
                db.session.execute(text("""
                    CREATE INDEX idx_outbound_call_jobs_status_twilio_sid 
                    ON outbound_call_jobs(status, twilio_call_sid)
                """))
                migrations_applied.append('add_composite_index_status_twilio_sid')
                log.info("‚úÖ Added composite index on (status, twilio_call_sid) for cleanup query performance")
            except Exception as e:
                log.error(f"‚ùå Migration 46d failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 47: WhatsApp Webhook Secret - Add webhook_secret column to business table
        # üîí IDEMPOTENT: Safe column addition for n8n integration security
        checkpoint("Migration 47: WhatsApp Webhook Secret for n8n integration")
        if check_table_exists('business') and not check_column_exists('business', 'webhook_secret'):
            try:
                from sqlalchemy import text
                # Add webhook_secret column with unique constraint
                db.session.execute(text("""
                    ALTER TABLE business 
                    ADD COLUMN webhook_secret VARCHAR(128) UNIQUE NULL
                """))
                migrations_applied.append('add_business_webhook_secret')
                log.info("‚úÖ Added webhook_secret column to business table for n8n webhook authentication")
            except Exception as e:
                log.error(f"‚ùå Migration 47 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 48: Add call_transcript column to appointments table
        # üîí IDEMPOTENT: Safe column addition for storing full conversation transcripts
        checkpoint("Migration 48: Add call_transcript to appointments")
        if check_table_exists('appointments') and not check_column_exists('appointments', 'call_transcript'):
            try:
                from sqlalchemy import text
                # Add call_transcript column to store full transcripts
                db.session.execute(text("""
                    ALTER TABLE appointments 
                    ADD COLUMN call_transcript TEXT
                """))
                migrations_applied.append('add_appointments_call_transcript')
                log.info("‚úÖ Added call_transcript column to appointments table for full conversation transcripts")
            except Exception as e:
                log.error(f"‚ùå Migration 48 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 49: Add idempotency_key column to whatsapp_broadcasts table
        # üîí IDEMPOTENT: Safe column addition for preventing duplicate broadcasts
        checkpoint("Migration 49: Add idempotency_key to whatsapp_broadcasts")
        if check_table_exists('whatsapp_broadcasts') and not check_column_exists('whatsapp_broadcasts', 'idempotency_key'):
            try:
                from sqlalchemy import text
                # Add idempotency_key column with index for duplicate prevention
                db.session.execute(text("""
                    ALTER TABLE whatsapp_broadcasts 
                    ADD COLUMN idempotency_key VARCHAR(64)
                """))
                # Create index for efficient lookup
                db.session.execute(text("""
                    CREATE INDEX IF NOT EXISTS idx_wa_broadcast_idempotency 
                    ON whatsapp_broadcasts(idempotency_key)
                """))
                migrations_applied.append('add_whatsapp_broadcasts_idempotency_key')
                log.info("‚úÖ Added idempotency_key column to whatsapp_broadcasts table for duplicate prevention")
            except Exception as e:
                log.error(f"‚ùå Migration 49 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 50: Add dynamic_summary and lead_id to appointments table
        # üîí CRITICAL FIX: These columns are referenced in code but missing from production DB
        # Fixes: psycopg2.errors.UndefinedColumn: column appointments.lead_id does not exist
        checkpoint("Migration 50: Adding dynamic_summary and lead_id to appointments")
        if check_table_exists('appointments'):
            try:
                from sqlalchemy import text
                
                # Add lead_id column if missing
                if not check_column_exists('appointments', 'lead_id'):
                    db.session.execute(text("""
                        ALTER TABLE appointments 
                        ADD COLUMN lead_id INTEGER REFERENCES leads(id) ON DELETE SET NULL
                    """))
                    # Create index for performance
                    db.session.execute(text("""
                        CREATE INDEX IF NOT EXISTS idx_appointments_lead_id 
                        ON appointments(lead_id)
                    """))
                    migrations_applied.append('add_appointments_lead_id')
                    log.info("‚úÖ Added lead_id column to appointments table")
                
                # Add dynamic_summary column if missing
                if not check_column_exists('appointments', 'dynamic_summary'):
                    db.session.execute(text("""
                        ALTER TABLE appointments 
                        ADD COLUMN dynamic_summary TEXT
                    """))
                    migrations_applied.append('add_appointments_dynamic_summary')
                    log.info("‚úÖ Added dynamic_summary column to appointments table")
                
                checkpoint("‚úÖ Migration 50 completed - appointments table updated")
            except Exception as e:
                log.error(f"‚ùå Migration 50 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 51: Add Twilio Cost Metrics columns to call_log table
        # üîí CRITICAL FIX: These columns are referenced in code but missing from production DB
        # Fixes: psycopg2.errors.UndefinedColumn: column call_log.recording_mode does not exist
        # This migration adds recording_mode and all related cost tracking fields
        checkpoint("Migration 51: Adding Twilio Cost Metrics columns to call_log")
        if check_table_exists('call_log'):
            try:
                from sqlalchemy import text
                
                # Add recording_mode column if missing
                if not check_column_exists('call_log', 'recording_mode'):
                    db.session.execute(text("""
                        ALTER TABLE call_log 
                        ADD COLUMN recording_mode VARCHAR(32)
                    """))
                    migrations_applied.append('add_call_log_recording_mode')
                    log.info("‚úÖ Added recording_mode column to call_log table")
                
                # Add stream_started_at column if missing
                if not check_column_exists('call_log', 'stream_started_at'):
                    db.session.execute(text("""
                        ALTER TABLE call_log 
                        ADD COLUMN stream_started_at TIMESTAMP
                    """))
                    migrations_applied.append('add_call_log_stream_started_at')
                    log.info("‚úÖ Added stream_started_at column to call_log table")
                
                # Add stream_ended_at column if missing
                if not check_column_exists('call_log', 'stream_ended_at'):
                    db.session.execute(text("""
                        ALTER TABLE call_log 
                        ADD COLUMN stream_ended_at TIMESTAMP
                    """))
                    migrations_applied.append('add_call_log_stream_ended_at')
                    log.info("‚úÖ Added stream_ended_at column to call_log table")
                
                # Add stream_duration_sec column if missing
                if not check_column_exists('call_log', 'stream_duration_sec'):
                    db.session.execute(text("""
                        ALTER TABLE call_log 
                        ADD COLUMN stream_duration_sec DOUBLE PRECISION
                    """))
                    migrations_applied.append('add_call_log_stream_duration_sec')
                    log.info("‚úÖ Added stream_duration_sec column to call_log table")
                
                # Add stream_connect_count column if missing
                if not check_column_exists('call_log', 'stream_connect_count'):
                    db.session.execute(text("""
                        ALTER TABLE call_log 
                        ADD COLUMN stream_connect_count INTEGER DEFAULT 0
                    """))
                    migrations_applied.append('add_call_log_stream_connect_count')
                    log.info("‚úÖ Added stream_connect_count column to call_log table")
                
                # Add webhook_11205_count column if missing
                if not check_column_exists('call_log', 'webhook_11205_count'):
                    db.session.execute(text("""
                        ALTER TABLE call_log 
                        ADD COLUMN webhook_11205_count INTEGER DEFAULT 0
                    """))
                    migrations_applied.append('add_call_log_webhook_11205_count')
                    log.info("‚úÖ Added webhook_11205_count column to call_log table")
                
                # Add webhook_retry_count column if missing
                if not check_column_exists('call_log', 'webhook_retry_count'):
                    db.session.execute(text("""
                        ALTER TABLE call_log 
                        ADD COLUMN webhook_retry_count INTEGER DEFAULT 0
                    """))
                    migrations_applied.append('add_call_log_webhook_retry_count')
                    log.info("‚úÖ Added webhook_retry_count column to call_log table")
                
                # Add recording_count column if missing
                if not check_column_exists('call_log', 'recording_count'):
                    db.session.execute(text("""
                        ALTER TABLE call_log 
                        ADD COLUMN recording_count INTEGER DEFAULT 0
                    """))
                    migrations_applied.append('add_call_log_recording_count')
                    log.info("‚úÖ Added recording_count column to call_log table")
                
                # Add estimated_cost_bucket column if missing
                if not check_column_exists('call_log', 'estimated_cost_bucket'):
                    db.session.execute(text("""
                        ALTER TABLE call_log 
                        ADD COLUMN estimated_cost_bucket VARCHAR(16)
                    """))
                    migrations_applied.append('add_call_log_estimated_cost_bucket')
                    log.info("‚úÖ Added estimated_cost_bucket column to call_log table")
                
                checkpoint("‚úÖ Migration 51 completed - call_log cost metrics columns added")
            except Exception as e:
                log.error(f"‚ùå Migration 51 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 52: Add customer_name to call_log and lead_name to outbound_call_jobs
        # üî• PURPOSE: Fix NAME_ANCHOR system SSOT - retrieve customer name from database
        # Priority order: CallLog.customer_name ‚Üí OutboundCallJob.lead_name ‚Üí Lead.full_name
        if not check_column_exists('call_log', 'customer_name') or not check_column_exists('outbound_call_jobs', 'lead_name'):
            checkpoint("Migration 52: Adding customer_name and lead_name for NAME_ANCHOR SSOT")
            try:
                # 1. Add customer_name to call_log
                if not check_column_exists('call_log', 'customer_name'):
                    checkpoint("  ‚Üí Adding customer_name to call_log...")
                    db.session.execute(text("""
                        ALTER TABLE call_log 
                        ADD COLUMN customer_name VARCHAR(255)
                    """))
                    checkpoint("  ‚úÖ call_log.customer_name added")
                else:
                    checkpoint("  ‚ÑπÔ∏è call_log.customer_name already exists")
                
                # 2. Add lead_name to outbound_call_jobs
                if not check_column_exists('outbound_call_jobs', 'lead_name'):
                    checkpoint("  ‚Üí Adding lead_name to outbound_call_jobs...")
                    db.session.execute(text("""
                        ALTER TABLE outbound_call_jobs 
                        ADD COLUMN lead_name VARCHAR(255)
                    """))
                    checkpoint("  ‚úÖ outbound_call_jobs.lead_name added")
                else:
                    checkpoint("  ‚ÑπÔ∏è outbound_call_jobs.lead_name already exists")
                
                migrations_applied.append('migration_52_name_anchor_ssot')
                checkpoint("‚úÖ Migration 52 completed - NAME_ANCHOR SSOT fields added")
            except Exception as e:
                log.error(f"‚ùå Migration 52 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 53: Add gender column to leads table
        # üî• PURPOSE: Fix missing gender column - prevents "column leads.gender does not exist" errors
        # This column is defined in Lead model but was never added to DB via migration
        if check_table_exists('leads') and not check_column_exists('leads', 'gender'):
            checkpoint("Migration 53: Adding gender column to leads table")
            try:
                checkpoint("  ‚Üí Adding gender to leads...")
                db.session.execute(text("""
                    ALTER TABLE leads 
                    ADD COLUMN gender VARCHAR(16)
                """))
                checkpoint("  ‚úÖ leads.gender added")
                migrations_applied.append('add_leads_gender_column')
                checkpoint("‚úÖ Migration 53 completed - leads.gender column added")
            except Exception as e:
                log.error(f"‚ùå Migration 53 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 54: Projects for Outbound Calls
        # üéØ PURPOSE: Enable grouping leads into projects with call tracking and statistics
        # Projects = Container for leads + call history + stats (only after calls start)
        if not check_table_exists('outbound_projects'):
            checkpoint("Migration 54: Creating outbound_projects table")
            try:
                checkpoint("  ‚Üí Creating outbound_projects table...")
                db.session.execute(text("""
                    CREATE TABLE outbound_projects (
                        id SERIAL PRIMARY KEY,
                        tenant_id INTEGER NOT NULL REFERENCES business(id) ON DELETE CASCADE,
                        name VARCHAR(255) NOT NULL,
                        description TEXT,
                        status VARCHAR(50) DEFAULT 'draft',
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        started_at TIMESTAMP,
                        completed_at TIMESTAMP,
                        created_by INTEGER REFERENCES users(id)
                    )
                """))
                db.session.execute(text("CREATE INDEX IF NOT EXISTS ix_outbound_projects_tenant_id ON outbound_projects(tenant_id)"))
                db.session.execute(text("CREATE INDEX IF NOT EXISTS ix_outbound_projects_status ON outbound_projects(status)"))
                checkpoint("  ‚úÖ outbound_projects table created")
                
                # Junction table for project-lead relationships
                checkpoint("  ‚Üí Creating project_leads junction table...")
                db.session.execute(text("""
                    CREATE TABLE project_leads (
                        id SERIAL PRIMARY KEY,
                        project_id INTEGER NOT NULL REFERENCES outbound_projects(id) ON DELETE CASCADE,
                        lead_id INTEGER NOT NULL REFERENCES leads(id) ON DELETE CASCADE,
                        added_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        call_attempts INTEGER DEFAULT 0,
                        last_call_at TIMESTAMP,
                        last_call_status VARCHAR(50),
                        total_call_duration INTEGER DEFAULT 0,
                        UNIQUE(project_id, lead_id)
                    )
                """))
                db.session.execute(text("CREATE INDEX IF NOT EXISTS ix_project_leads_project_id ON project_leads(project_id)"))
                db.session.execute(text("CREATE INDEX IF NOT EXISTS ix_project_leads_lead_id ON project_leads(lead_id)"))
                checkpoint("  ‚úÖ project_leads junction table created")
                
                migrations_applied.append('create_outbound_projects_tables')
                checkpoint("‚úÖ Migration 54 completed - Projects tables created")
            except Exception as e:
                log.error(f"‚ùå Migration 54 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 54b: Add project_id to call_log for project statistics
        if check_table_exists('call_log') and not check_column_exists('call_log', 'project_id'):
            checkpoint("Migration 54b: Adding project_id to call_log")
            try:
                checkpoint("  ‚Üí Adding project_id to call_log...")
                db.session.execute(text("ALTER TABLE call_log ADD COLUMN project_id INTEGER REFERENCES outbound_projects(id) ON DELETE SET NULL"))
                db.session.execute(text("CREATE INDEX IF NOT EXISTS ix_call_log_project_id ON call_log(project_id)"))
                checkpoint("  ‚úÖ call_log.project_id added")
                migrations_applied.append('add_call_log_project_id')
                checkpoint("‚úÖ Migration 54b completed - project tracking in calls")
            except Exception as e:
                log.error(f"‚ùå Migration 54b failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 54c: Add project_id to outbound_call_jobs for bulk operations
        if check_table_exists('outbound_call_jobs') and not check_column_exists('outbound_call_jobs', 'project_id'):
            checkpoint("Migration 54c: Adding project_id to outbound_call_jobs")
            try:
                checkpoint("  ‚Üí Adding project_id to outbound_call_jobs...")
                db.session.execute(text("ALTER TABLE outbound_call_jobs ADD COLUMN project_id INTEGER REFERENCES outbound_projects(id) ON DELETE SET NULL"))
                db.session.execute(text("CREATE INDEX IF NOT EXISTS ix_outbound_call_jobs_project_id ON outbound_call_jobs(project_id)"))
                checkpoint("  ‚úÖ outbound_call_jobs.project_id added")
                migrations_applied.append('add_outbound_call_jobs_project_id')
                checkpoint("‚úÖ Migration 54c completed - project tracking in bulk jobs")
            except Exception as e:
                log.error(f"‚ùå Migration 54c failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 55: Add delivered_at column to whatsapp_broadcast_recipients
        # üî• CRITICAL FIX: This column is defined in WhatsappBroadcastRecipient model but missing from DB
        # Fixes: psycopg2.errors.UndefinedColumn: column "delivered_at" of relation "whatsapp_broadcast_recipients" does not exist
        if check_table_exists('whatsapp_broadcast_recipients') and not check_column_exists('whatsapp_broadcast_recipients', 'delivered_at'):
            checkpoint("Migration 55: Adding delivered_at to whatsapp_broadcast_recipients")
            try:
                checkpoint("  ‚Üí Adding delivered_at to whatsapp_broadcast_recipients...")
                db.session.execute(text("""
                    ALTER TABLE whatsapp_broadcast_recipients 
                    ADD COLUMN delivered_at TIMESTAMP
                """))
                checkpoint("  ‚úÖ whatsapp_broadcast_recipients.delivered_at added")
                migrations_applied.append('add_whatsapp_broadcast_recipients_delivered_at')
                checkpoint("‚úÖ Migration 55 completed - WhatsApp broadcast delivery tracking column added")
            except Exception as e:
                log.error(f"‚ùå Migration 55 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 56: Add stopped_by and stopped_at columns to whatsapp_broadcasts
        # üî• CRITICAL FIX: These columns are defined in WhatsAppBroadcast model but missing from DB
        # Fixes: psycopg2.errors.UndefinedColumn: column "stopped_by" of relation "whatsapp_broadcasts" does not exist
        if check_table_exists('whatsapp_broadcasts'):
            checkpoint("Migration 56: Adding stopped_by and stopped_at to whatsapp_broadcasts")
            try:
                # Add stopped_by column if missing
                if not check_column_exists('whatsapp_broadcasts', 'stopped_by'):
                    checkpoint("  ‚Üí Adding stopped_by to whatsapp_broadcasts...")
                    db.session.execute(text("""
                        ALTER TABLE whatsapp_broadcasts 
                        ADD COLUMN stopped_by INTEGER REFERENCES users(id)
                    """))
                    checkpoint("  ‚úÖ whatsapp_broadcasts.stopped_by added")
                    migrations_applied.append('add_whatsapp_broadcasts_stopped_by')
                
                # Add stopped_at column if missing
                if not check_column_exists('whatsapp_broadcasts', 'stopped_at'):
                    checkpoint("  ‚Üí Adding stopped_at to whatsapp_broadcasts...")
                    db.session.execute(text("""
                        ALTER TABLE whatsapp_broadcasts 
                        ADD COLUMN stopped_at TIMESTAMP
                    """))
                    checkpoint("  ‚úÖ whatsapp_broadcasts.stopped_at added")
                    migrations_applied.append('add_whatsapp_broadcasts_stopped_at')
                
                checkpoint("‚úÖ Migration 56 completed - WhatsApp broadcast stop functionality columns added")
            except Exception as e:
                log.error(f"‚ùå Migration 56 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 57: Authentication & Session Management System
        # Add refresh tokens table and password reset fields to users
        checkpoint("Migration 57: Adding authentication and session management features")
        
        # 57a: Create refresh_tokens table
        if not check_table_exists('refresh_tokens'):
            checkpoint("  ‚Üí Creating refresh_tokens table...")
            try:
                db.session.execute(text("""
                    CREATE TABLE refresh_tokens (
                        id SERIAL PRIMARY KEY,
                        user_id INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,
                        tenant_id INTEGER REFERENCES business(id) ON DELETE CASCADE,
                        token_hash VARCHAR(255) NOT NULL UNIQUE,
                        user_agent_hash VARCHAR(255),
                        expires_at TIMESTAMP NOT NULL,
                        is_valid BOOLEAN DEFAULT TRUE,
                        remember_me BOOLEAN DEFAULT FALSE,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        last_used_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """))
                
                # Add indexes for performance
                db.session.execute(text("CREATE INDEX idx_refresh_tokens_user_id ON refresh_tokens(user_id)"))
                db.session.execute(text("CREATE INDEX idx_refresh_tokens_tenant_id ON refresh_tokens(tenant_id)"))
                db.session.execute(text("CREATE INDEX idx_refresh_tokens_token_hash ON refresh_tokens(token_hash)"))
                db.session.execute(text("CREATE INDEX idx_refresh_tokens_expires_at ON refresh_tokens(expires_at)"))
                db.session.execute(text("CREATE INDEX idx_refresh_tokens_is_valid ON refresh_tokens(is_valid)"))
                
                # Add last_activity_at column for per-session idle tracking
                if not check_column_exists('refresh_tokens', 'last_activity_at'):
                    db.session.execute(text("""
                        ALTER TABLE refresh_tokens 
                        ADD COLUMN last_activity_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    """))
                    # Create index for performance
                    db.session.execute(text("""
                        CREATE INDEX idx_refresh_tokens_last_activity 
                        ON refresh_tokens(last_activity_at)
                    """))
                    checkpoint("  ‚úÖ refresh_tokens.last_activity_at added")
                    migrations_applied.append('add_refresh_tokens_last_activity_at')
                
                checkpoint("  ‚úÖ refresh_tokens table created with all fields")
                migrations_applied.append('create_refresh_tokens_table')
            except Exception as e:
                log.error(f"‚ùå Migration 57a failed: {e}")
                db.session.rollback()
                raise
        
        # 57b: Add password reset fields to users table
        if check_table_exists('users'):
            checkpoint("  ‚Üí Adding password reset fields to users table...")
            try:
                # Add reset_token_hash column
                if not check_column_exists('users', 'reset_token_hash'):
                    db.session.execute(text("""
                        ALTER TABLE users 
                        ADD COLUMN reset_token_hash VARCHAR(255)
                    """))
                    checkpoint("  ‚úÖ users.reset_token_hash added")
                    migrations_applied.append('add_users_reset_token_hash')
                
                # Add reset_token_expiry column
                if not check_column_exists('users', 'reset_token_expiry'):
                    db.session.execute(text("""
                        ALTER TABLE users 
                        ADD COLUMN reset_token_expiry TIMESTAMP
                    """))
                    checkpoint("  ‚úÖ users.reset_token_expiry added")
                    migrations_applied.append('add_users_reset_token_expiry')
                
                # Add reset_token_used column
                if not check_column_exists('users', 'reset_token_used'):
                    db.session.execute(text("""
                        ALTER TABLE users 
                        ADD COLUMN reset_token_used BOOLEAN DEFAULT FALSE
                    """))
                    checkpoint("  ‚úÖ users.reset_token_used added")
                    migrations_applied.append('add_users_reset_token_used')
                
                # Add last_activity_at column for idle timeout tracking
                if not check_column_exists('users', 'last_activity_at'):
                    db.session.execute(text("""
                        ALTER TABLE users 
                        ADD COLUMN last_activity_at TIMESTAMP
                    """))
                    checkpoint("  ‚úÖ users.last_activity_at added")
                    migrations_applied.append('add_users_last_activity_at')
                
                checkpoint("  ‚úÖ Password reset and activity tracking fields added to users")
            except Exception as e:
                log.error(f"‚ùå Migration 57b failed: {e}")
                db.session.rollback()
                raise
        
        checkpoint("‚úÖ Migration 57 completed - Authentication system enhanced")
        
        # Migration 58: Add voice_id to business table for per-business voice selection
        # üîí CRITICAL FIX: This column is referenced in Business model but missing from DB
        # Fixes: psycopg2.errors.UndefinedColumn: column business.voice_id does not exist
        if check_table_exists('business') and not check_column_exists('business', 'voice_id'):
            checkpoint("Migration 58: Adding voice_id column to business table")
            try:
                from sqlalchemy import text
                # Add voice_id column with default value 'ash'
                # NOT NULL DEFAULT ensures all existing rows automatically get 'ash' value
                db.session.execute(text("""
                    ALTER TABLE business 
                    ADD COLUMN voice_id VARCHAR(32) NOT NULL DEFAULT 'ash'
                """))
                
                migrations_applied.append('add_business_voice_id')
                checkpoint("‚úÖ Applied migration 58: add_business_voice_id - Per-business voice selection")
            except Exception as e:
                log.error(f"‚ùå Migration 58 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 60: Email System - Add email_settings, email_messages, and email_templates tables
        # Production-grade email system with per-business configuration and complete logging
        checkpoint("Migration 60: Creating email system tables (email_settings, email_messages, email_templates)")
        
        # Migration 60a: Create email_settings table (per-business email configuration)
        if not check_table_exists('email_settings'):
            try:
                from sqlalchemy import text
                db.session.execute(text("""
                    CREATE TABLE email_settings (
                        id SERIAL PRIMARY KEY,
                        business_id INTEGER NOT NULL UNIQUE REFERENCES business(id) ON DELETE CASCADE,
                        provider VARCHAR(32) NOT NULL DEFAULT 'sendgrid',
                        from_email VARCHAR(255) NOT NULL,
                        from_name VARCHAR(255) NOT NULL,
                        reply_to VARCHAR(255),
                        reply_to_enabled BOOLEAN NOT NULL DEFAULT TRUE,
                        brand_logo_url TEXT,
                        brand_primary_color VARCHAR(20) DEFAULT '#2563EB',
                        default_greeting TEXT DEFAULT '◊©◊ú◊ï◊ù {{lead.first_name}},',
                        footer_html TEXT,
                        footer_text TEXT,
                        is_enabled BOOLEAN NOT NULL DEFAULT TRUE,
                        created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
                    )
                """))
                
                # Create index on business_id for fast lookups
                db.session.execute(text("""
                    CREATE UNIQUE INDEX idx_email_settings_business_id ON email_settings(business_id)
                """))
                
                migrations_applied.append('create_email_settings_table')
                checkpoint("  ‚úÖ email_settings table created with branding fields (logo, color, greeting, footer)")
            except Exception as e:
                log.error(f"‚ùå Migration 60a (email_settings) failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 60b: Create email_templates table (per-business email templates)
        # IMPORTANT: Must be created before email_messages (FK dependency)
        if not check_table_exists('email_templates'):
            try:
                from sqlalchemy import text
                db.session.execute(text("""
                    CREATE TABLE email_templates (
                        id SERIAL PRIMARY KEY,
                        business_id INTEGER NOT NULL REFERENCES business(id) ON DELETE CASCADE,
                        name VARCHAR(255) NOT NULL,
                        type VARCHAR(50) DEFAULT 'generic',
                        subject_template VARCHAR(500) NOT NULL,
                        html_template TEXT NOT NULL,
                        text_template TEXT,
                        created_by_user_id INTEGER REFERENCES users(id) ON DELETE SET NULL,
                        is_active BOOLEAN NOT NULL DEFAULT TRUE,
                        created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
                    )
                """))
                
                # Create index on business_id for fast lookups
                db.session.execute(text("""
                    CREATE INDEX idx_email_templates_business_id ON email_templates(business_id)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_email_templates_is_active ON email_templates(is_active)
                """))
                
                migrations_applied.append('create_email_templates_table')
                checkpoint("  ‚úÖ email_templates table created with indexes on business_id, is_active")
            except Exception as e:
                log.error(f"‚ùå Migration 60b (email_templates) failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 60c: Create email_messages table (complete email log)
        if not check_table_exists('email_messages'):
            try:
                from sqlalchemy import text
                db.session.execute(text("""
                    CREATE TABLE email_messages (
                        id SERIAL PRIMARY KEY,
                        business_id INTEGER NOT NULL REFERENCES business(id) ON DELETE CASCADE,
                        lead_id INTEGER REFERENCES leads(id) ON DELETE SET NULL,
                        created_by_user_id INTEGER REFERENCES users(id) ON DELETE SET NULL,
                        template_id INTEGER REFERENCES email_templates(id) ON DELETE SET NULL,
                        to_email VARCHAR(255) NOT NULL,
                        to_name VARCHAR(255),
                        subject VARCHAR(500) NOT NULL,
                        body_html TEXT NOT NULL,
                        body_text TEXT,
                        rendered_subject VARCHAR(500),
                        rendered_body_html TEXT,
                        rendered_body_text TEXT,
                        provider VARCHAR(32) NOT NULL DEFAULT 'sendgrid',
                        from_email VARCHAR(255),
                        from_name VARCHAR(255),
                        reply_to VARCHAR(255),
                        status VARCHAR(32) NOT NULL DEFAULT 'queued',
                        provider_message_id VARCHAR(255),
                        error TEXT,
                        meta JSONB,
                        sent_at TIMESTAMP,
                        created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
                    )
                """))
                
                # Create indexes for common queries
                db.session.execute(text("""
                    CREATE INDEX idx_email_messages_business_id ON email_messages(business_id)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_email_messages_lead_id ON email_messages(lead_id)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_email_messages_created_by ON email_messages(created_by_user_id)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_email_messages_status ON email_messages(status)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_email_messages_created_at ON email_messages(created_at DESC)
                """))
                
                migrations_applied.append('create_email_messages_table')
                checkpoint("  ‚úÖ email_messages table created with indexes on business_id, lead_id, status, created_at, template_id")
            except Exception as e:
                log.error(f"‚ùå Migration 60c (email_messages) failed: {e}")
                db.session.rollback()
                raise
        
        checkpoint("‚úÖ Migration 60 completed - Email system tables created")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # Migration 61: Clean up invalid voice_id values in businesses table
        # Only Realtime-supported voices are allowed
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        checkpoint("Migration 61: Cleaning up invalid voice_id values")
        
        try:
            # Check if voice_id column exists
            voice_id_exists = db.session.execute(text("""
                SELECT column_name 
                FROM information_schema.columns 
                WHERE table_name = 'businesses' 
                AND column_name = 'voice_id'
            """)).fetchone()
            
            if voice_id_exists:
                # Valid Realtime voices
                valid_voices = ['alloy', 'ash', 'ballad', 'coral', 'echo', 'sage', 'shimmer', 'verse', 'marin', 'cedar']
                default_voice = 'cedar'
                
                # Find businesses with invalid voices
                invalid_count_result = db.session.execute(text("""
                    SELECT COUNT(*) 
                    FROM businesses 
                    WHERE voice_id IS NULL 
                       OR voice_id NOT IN :valid_voices
                """), {"valid_voices": tuple(valid_voices)})
                
                invalid_count = invalid_count_result.scalar() or 0
                
                if invalid_count > 0:
                    checkpoint(f"  Found {invalid_count} businesses with invalid voice_id values")
                    
                    # Update invalid voices to default
                    db.session.execute(text("""
                        UPDATE businesses 
                        SET voice_id = :default_voice
                        WHERE voice_id IS NULL 
                           OR voice_id NOT IN :valid_voices
                    """), {
                        "default_voice": default_voice,
                        "valid_voices": tuple(valid_voices)
                    })
                    
                    checkpoint(f"  ‚úÖ Updated {invalid_count} businesses to voice_id='{default_voice}'")
                    migrations_applied.append('cleanup_invalid_voices')
                else:
                    checkpoint("  ‚úÖ No invalid voice_id values found")
            else:
                checkpoint("  ‚ÑπÔ∏è voice_id column does not exist - skipping")
        
        except Exception as e:
            log.error(f"‚ùå Migration 61 (cleanup_invalid_voices) failed: {e}")
            db.session.rollback()
            raise
        
        checkpoint("‚úÖ Migration 61 completed - Invalid voices cleaned up")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # Migration 62: Seed default email templates for all businesses
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        checkpoint("Migration 62: Seeding default email templates")
        
        try:
            # Check if email_templates table exists
            if check_table_exists('email_templates'):
                # Get all businesses that don't have templates yet
                businesses_result = db.session.execute(text("""
                    SELECT b.id, b.name
                    FROM business b
                    WHERE NOT EXISTS (
                        SELECT 1 FROM email_templates et 
                        WHERE et.business_id = b.id
                    )
                    AND b.is_active = TRUE
                """)).fetchall()
                
                businesses_count = len(businesses_result)
                
                if businesses_count > 0:
                    checkpoint(f"  Found {businesses_count} businesses without email templates")
                    
                    # Template 1: Default Welcome
                    template_1_subject = "◊©◊ú◊ï◊ù ◊û-{{business.name}}"
                    template_1_html = """
<!DOCTYPE html>
<html dir="rtl" lang="he">
<head>
    <meta charset="UTF-8">
    <style>
        body { font-family: Arial, sans-serif; direction: rtl; text-align: right; }
        .content { max-width: 600px; margin: 0 auto; padding: 20px; }
        .header { background-color: #2563EB; color: white; padding: 20px; border-radius: 8px 8px 0 0; }
        .body { background-color: #f9fafb; padding: 30px; }
        .footer { background-color: #f3f4f6; padding: 15px; text-align: center; font-size: 12px; color: #6b7280; border-radius: 0 0 8px 8px; }
        .button { display: inline-block; background-color: #2563EB; color: white; padding: 12px 24px; text-decoration: none; border-radius: 5px; margin: 20px 0; }
    </style>
</head>
<body>
    <div class="content">
        <div class="header">
            <h1>◊©◊ú◊ï◊ù {% if lead %}{{lead.first_name}}{% else %}◊©◊ù{% endif %}!</h1>
        </div>
        <div class="body">
            <p>◊ê◊†◊ó◊†◊ï ◊ë-{{business.name}} ◊©◊û◊ó◊ô◊ù ◊ú◊ô◊¶◊ï◊® ◊ê◊ô◊™◊ö ◊ß◊©◊®.</p>
            
            <p>◊ê◊†◊ï ◊û◊°◊§◊ß◊ô◊ù ◊©◊ô◊®◊ï◊™ ◊û◊ß◊¶◊ï◊¢◊ô ◊ï◊ê◊ô◊õ◊ï◊™◊ô ◊ú◊ú◊ß◊ï◊ó◊ï◊™◊ô◊†◊ï, ◊ï◊†◊©◊û◊ó ◊ú◊¢◊ñ◊ï◊® ◊í◊ù ◊ú◊ö.</p>
            
            <p>◊¶◊ï◊ï◊™ {{business.name}}</p>
        </div>
        {% if signature %}
        <div class="footer">
            {{signature}}
        </div>
        {% endif %}
    </div>
</body>
</html>
"""
                    template_1_text = "◊©◊ú◊ï◊ù {% if lead %}{{lead.first_name}}{% else %}◊©◊ù{% endif %}!\n\n◊ê◊†◊ó◊†◊ï ◊ë-{{business.name}} ◊©◊û◊ó◊ô◊ù ◊ú◊ô◊¶◊ï◊® ◊ê◊ô◊™◊ö ◊ß◊©◊®.\n\n◊¶◊ï◊ï◊™ {{business.name}}"
                    
                    # Template 2: Follow-up / Reminder
                    template_2_subject = "◊™◊ñ◊õ◊ï◊®◊™ - {{business.name}}"
                    template_2_html = """
<!DOCTYPE html>
<html dir="rtl" lang="he">
<head>
    <meta charset="UTF-8">
    <style>
        body { font-family: Arial, sans-serif; direction: rtl; text-align: right; }
        .content { max-width: 600px; margin: 0 auto; padding: 20px; background-color: #fffbeb; border: 2px solid #fbbf24; border-radius: 8px; }
        .icon { font-size: 48px; text-align: center; margin-bottom: 20px; }
    </style>
</head>
<body>
    <div class="content">
        <div class="icon">‚è∞</div>
        <h2>◊©◊ú◊ï◊ù {% if lead %}{{lead.first_name}}{% else %}◊©◊ù{% endif %},</h2>
        
        <p>◊®◊¶◊ô◊†◊ï ◊ú◊î◊ñ◊õ◊ô◊® ◊ú◊ö ◊©◊ê◊†◊ó◊†◊ï ◊õ◊ê◊ü ◊ë◊©◊ë◊ô◊ú◊ö!</p>
        
        <p>◊†◊©◊û◊ó ◊ú◊ß◊ë◊ï◊¢ ◊©◊ô◊ó◊î ◊ï◊ú◊ì◊ë◊® ◊¢◊ú ◊ê◊ô◊ö ◊†◊ï◊õ◊ú ◊ú◊¢◊ñ◊ï◊®.</p>
        
        <p>◊ë◊ë◊®◊õ◊î,<br>◊¶◊ï◊ï◊™ {{business.name}}</p>
        {% if signature %}
        <div style="margin-top: 20px; padding-top: 20px; border-top: 1px solid #d1d5db;">
            {{signature}}
        </div>
        {% endif %}
    </div>
</body>
</html>
"""
                    template_2_text = "◊©◊ú◊ï◊ù {% if lead %}{{lead.first_name}}{% else %}◊©◊ù{% endif %},\n\n◊®◊¶◊ô◊†◊ï ◊ú◊î◊ñ◊õ◊ô◊® ◊ú◊ö ◊©◊ê◊†◊ó◊†◊ï ◊õ◊ê◊ü ◊ë◊©◊ë◊ô◊ú◊ö!\n\n◊†◊©◊û◊ó ◊ú◊ß◊ë◊ï◊¢ ◊©◊ô◊ó◊î ◊ï◊ú◊ì◊ë◊® ◊¢◊ú ◊ê◊ô◊ö ◊†◊ï◊õ◊ú ◊ú◊¢◊ñ◊ï◊®.\n\n◊ë◊ë◊®◊õ◊î,\n◊¶◊ï◊ï◊™ {{business.name}}"
                    
                    # Template 3: Quick Follow-up
                    template_3_subject = "◊®◊ß ◊®◊¶◊ô◊™◊ô ◊ú◊ï◊ï◊ì◊ê - {{business.name}}"
                    template_3_html = """
<!DOCTYPE html>
<html dir="rtl" lang="he">
<head>
    <meta charset="UTF-8">
    <style>
        body { font-family: Arial, sans-serif; direction: rtl; text-align: right; }
        .content { max-width: 600px; margin: 0 auto; padding: 20px; }
        .simple { background-color: white; padding: 30px; border: 1px solid #e5e7eb; border-radius: 8px; }
    </style>
</head>
<body>
    <div class="content">
        <div class="simple">
            <p>◊î◊ô◊ô {% if lead %}{{lead.first_name}}{% else %}◊©◊ù{% endif %},</p>
            
            <p>◊®◊ß ◊®◊¶◊ô◊™◊ô ◊ú◊©◊ú◊ï◊ó ◊î◊ï◊ì◊¢◊î ◊û◊î◊ô◊®◊î ◊ï◊ú◊ï◊ï◊ì◊ê ◊©◊î◊õ◊ú ◊ë◊°◊ì◊®.</p>
            
            <p>◊ê◊ù ◊ô◊© ◊û◊©◊î◊ï ◊©◊ê◊†◊ô ◊ô◊õ◊ï◊ú ◊ú◊¢◊ñ◊ï◊® ◊ë◊ï, ◊ê◊†◊ô ◊õ◊ê◊ü!</p>
            
            <p>◊™◊ï◊ì◊î,<br>{{business.name}}</p>
            
            {% if signature %}
            <div style="margin-top: 20px; padding-top: 20px; border-top: 1px solid #e5e7eb; color: #6b7280; font-size: 14px;">
                {{signature}}
            </div>
            {% endif %}
        </div>
    </div>
</body>
</html>
"""
                    template_3_text = "◊î◊ô◊ô {% if lead %}{{lead.first_name}}{% else %}◊©◊ù{% endif %},\n\n◊®◊ß ◊®◊¶◊ô◊™◊ô ◊ú◊©◊ú◊ï◊ó ◊î◊ï◊ì◊¢◊î ◊û◊î◊ô◊®◊î ◊ï◊ú◊ï◊ï◊ì◊ê ◊©◊î◊õ◊ú ◊ë◊°◊ì◊®.\n\n◊ê◊ù ◊ô◊© ◊û◊©◊î◊ï ◊©◊ê◊†◊ô ◊ô◊õ◊ï◊ú ◊ú◊¢◊ñ◊ï◊® ◊ë◊ï, ◊ê◊†◊ô ◊õ◊ê◊ü!\n\n◊™◊ï◊ì◊î,\n{{business.name}}"
                    
                    # Insert templates for each business
                    templates_inserted = 0
                    for business_id, business_name in businesses_result:
                        try:
                            # Template 1
                            db.session.execute(text("""
                                INSERT INTO email_templates 
                                (business_id, name, type, subject_template, html_template, text_template, is_active, created_at, updated_at)
                                VALUES (:business_id, :name, :type, :subject_template, :html_template, :text_template, TRUE, NOW(), NOW())
                            """), {
                                "business_id": business_id,
                                "name": "◊ë◊®◊ô◊®◊™ ◊û◊ó◊ì◊ú - ◊ë◊®◊õ◊î",
                                "type": "welcome",
                                "subject_template": template_1_subject,
                                "html_template": template_1_html,
                                "text_template": template_1_text
                            })
                            
                            # Template 2
                            db.session.execute(text("""
                                INSERT INTO email_templates 
                                (business_id, name, type, subject_template, html_template, text_template, is_active, created_at, updated_at)
                                VALUES (:business_id, :name, :type, :subject_template, :html_template, :text_template, TRUE, NOW(), NOW())
                            """), {
                                "business_id": business_id,
                                "name": "◊™◊ñ◊õ◊ï◊®◊™ - ◊ß◊ë◊ô◊¢◊™ ◊©◊ô◊ó◊î",
                                "type": "followup",
                                "subject_template": template_2_subject,
                                "html_template": template_2_html,
                                "text_template": template_2_text
                            })
                            
                            # Template 3
                            db.session.execute(text("""
                                INSERT INTO email_templates 
                                (business_id, name, type, subject_template, html_template, text_template, is_active, created_at, updated_at)
                                VALUES (:business_id, :name, :type, :subject_template, :html_template, :text_template, TRUE, NOW(), NOW())
                            """), {
                                "business_id": business_id,
                                "name": "◊û◊¢◊ß◊ë - ◊î◊ï◊ì◊¢◊î ◊û◊î◊ô◊®◊î",
                                "type": "quick_followup",
                                "subject_template": template_3_subject,
                                "html_template": template_3_html,
                                "text_template": template_3_text
                            })
                            
                            templates_inserted += 3
                            checkpoint(f"  ‚úÖ Seeded 3 templates for business_id={business_id} ({business_name})")
                        
                        except Exception as e:
                            log.warning(f"  ‚ö†Ô∏è Failed to seed templates for business_id={business_id}: {e}")
                            # Continue with other businesses
                    
                    checkpoint(f"  ‚úÖ Seeded {templates_inserted} email templates across {businesses_count} businesses")
                    migrations_applied.append('seed_email_templates')
                else:
                    checkpoint("  ‚úÖ All businesses already have email templates")
            else:
                checkpoint("  ‚ÑπÔ∏è email_templates table does not exist - skipping")
        
        except Exception as e:
            log.error(f"‚ùå Migration 62 (seed_email_templates) failed: {e}")
            # Don't rollback - this is not critical, just log the error
            checkpoint(f"  ‚ö†Ô∏è Template seeding failed but continuing: {e}")
        
        checkpoint("‚úÖ Migration 62 completed - Email templates seeded")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # Migration 63: Add theme-based email settings fields
        # üé® PURPOSE: Enable luxury email themes with simple field editing (no HTML)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        checkpoint("Migration 63: Adding theme-based email settings fields")
        
        if check_table_exists('email_settings'):
            try:
                # Add theme_id column if missing
                if not check_column_exists('email_settings', 'theme_id'):
                    checkpoint("  ‚Üí Adding theme_id to email_settings...")
                    db.session.execute(text("""
                        ALTER TABLE email_settings 
                        ADD COLUMN theme_id VARCHAR(50) DEFAULT 'classic_blue'
                    """))
                    checkpoint("  ‚úÖ email_settings.theme_id added")
                    migrations_applied.append('add_email_settings_theme_id')
                
                # Add cta_default_text column if missing
                if not check_column_exists('email_settings', 'cta_default_text'):
                    checkpoint("  ‚Üí Adding cta_default_text to email_settings...")
                    db.session.execute(text("""
                        ALTER TABLE email_settings 
                        ADD COLUMN cta_default_text VARCHAR(200)
                    """))
                    checkpoint("  ‚úÖ email_settings.cta_default_text added")
                    migrations_applied.append('add_email_settings_cta_default_text')
                
                # Add cta_default_url column if missing
                if not check_column_exists('email_settings', 'cta_default_url'):
                    checkpoint("  ‚Üí Adding cta_default_url to email_settings...")
                    db.session.execute(text("""
                        ALTER TABLE email_settings 
                        ADD COLUMN cta_default_url VARCHAR(500)
                    """))
                    checkpoint("  ‚úÖ email_settings.cta_default_url added")
                    migrations_applied.append('add_email_settings_cta_default_url')
                
                checkpoint("‚úÖ Migration 63 completed - Theme-based email settings fields added")
            except Exception as e:
                log.error(f"‚ùå Migration 63 failed: {e}")
                db.session.rollback()
                raise
        else:
            checkpoint("  ‚ÑπÔ∏è email_settings table does not exist - skipping")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # Migration 64: Add company_id field to Business table
        # üè¢ PURPOSE: Store Israeli company registration number (◊ó.◊§) 
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        checkpoint("Migration 64: Adding company_id field to Business table")
        
        if check_table_exists('business'):
            try:
                # Add company_id column if missing
                if not check_column_exists('business', 'company_id'):
                    checkpoint("  ‚Üí Adding company_id to business table...")
                    db.session.execute(text("""
                        ALTER TABLE business 
                        ADD COLUMN company_id VARCHAR(50)
                    """))
                    checkpoint("  ‚úÖ business.company_id added")
                    migrations_applied.append('add_business_company_id')
                else:
                    checkpoint("  ‚úÖ business.company_id already exists")
                
                checkpoint("‚úÖ Migration 64 completed - company_id field added to Business")
            except Exception as e:
                log.error(f"‚ùå Migration 64 failed: {e}")
                db.session.rollback()
                raise
        else:
            checkpoint("  ‚ÑπÔ∏è business table does not exist - skipping")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # Migration 65: Push Subscriptions - Web Push notifications support
        # üîî PURPOSE: Enable push notifications to users' devices (PWA, future native apps)
        # Supports: webpush (now), fcm/apns (future)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        if not check_table_exists('push_subscriptions'):
            checkpoint("Migration 65: Creating push_subscriptions table for Web Push notifications")
            try:
                from sqlalchemy import text
                db.session.execute(text("""
                    CREATE TABLE push_subscriptions (
                        id SERIAL PRIMARY KEY,
                        business_id INTEGER NOT NULL REFERENCES business(id) ON DELETE CASCADE,
                        user_id INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,
                        channel VARCHAR(16) NOT NULL DEFAULT 'webpush',
                        endpoint TEXT NOT NULL,
                        p256dh TEXT,
                        auth TEXT,
                        device_info VARCHAR(512),
                        is_active BOOLEAN NOT NULL DEFAULT TRUE,
                        created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
                    )
                """))
                
                # Create indexes for efficient querying
                db.session.execute(text("""
                    CREATE INDEX idx_push_subscriptions_user_id ON push_subscriptions(user_id)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_push_subscriptions_business_id ON push_subscriptions(business_id)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_push_subscriptions_is_active ON push_subscriptions(is_active)
                """))
                # Unique constraint to prevent duplicate subscriptions
                db.session.execute(text("""
                    CREATE UNIQUE INDEX idx_push_subscriptions_user_endpoint ON push_subscriptions(user_id, endpoint)
                """))
                
                migrations_applied.append('create_push_subscriptions_table')
                checkpoint("‚úÖ Applied migration 65: create_push_subscriptions_table - Web Push notifications support")
            except Exception as e:
                log.error(f"‚ùå Migration 65 failed: {e}")
                db.session.rollback()
                raise
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # Migration 66: Reminder Push Log - Track sent reminder push notifications
        # üîî PURPOSE: Prevent duplicate reminder push notifications across workers
        # Uses DB-backed deduplication with unique constraint on (reminder_id, offset_minutes)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        if not check_table_exists('reminder_push_log'):
            checkpoint("Migration 66: Creating reminder_push_log table for reminder notification deduplication")
            try:
                from sqlalchemy import text
                db.session.execute(text("""
                    CREATE TABLE reminder_push_log (
                        id SERIAL PRIMARY KEY,
                        reminder_id INTEGER NOT NULL REFERENCES lead_reminders(id) ON DELETE CASCADE,
                        offset_minutes INTEGER NOT NULL,
                        sent_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
                    )
                """))
                
                # Create indexes for efficient querying
                db.session.execute(text("""
                    CREATE INDEX idx_reminder_push_log_reminder_id ON reminder_push_log(reminder_id)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_reminder_push_log_sent_at ON reminder_push_log(sent_at)
                """))
                # Unique constraint to prevent duplicate notifications
                db.session.execute(text("""
                    CREATE UNIQUE INDEX uq_reminder_push_log ON reminder_push_log(reminder_id, offset_minutes)
                """))
                
                migrations_applied.append('create_reminder_push_log_table')
                checkpoint("‚úÖ Applied migration 66: create_reminder_push_log_table - Reminder push notification deduplication")
            except Exception as e:
                log.error(f"‚ùå Migration 66 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 67: Email Text Templates - Quick text snippets for email body content
        # These are simple text templates (like quotes, greetings, pricing info) that can be used in emails
        checkpoint("Migration 67: Creating email_text_templates table for quick text snippets")
        if not check_table_exists('email_text_templates'):
            try:
                from sqlalchemy import text
                db.session.execute(text("""
                    CREATE TABLE email_text_templates (
                        id SERIAL PRIMARY KEY,
                        business_id INTEGER NOT NULL REFERENCES business(id) ON DELETE CASCADE,
                        name VARCHAR(255) NOT NULL,
                        category VARCHAR(100) DEFAULT 'general',
                        subject_line VARCHAR(500),
                        body_text TEXT NOT NULL,
                        created_by_user_id INTEGER REFERENCES users(id) ON DELETE SET NULL,
                        is_active BOOLEAN NOT NULL DEFAULT TRUE,
                        created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
                    )
                """))
                
                # Create indexes for fast lookups
                db.session.execute(text("""
                    CREATE INDEX idx_email_text_templates_business_id ON email_text_templates(business_id)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_email_text_templates_category ON email_text_templates(category)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_email_text_templates_is_active ON email_text_templates(is_active)
                """))
                
                migrations_applied.append('create_email_text_templates_table')
                checkpoint("‚úÖ Applied migration 67: create_email_text_templates_table - Email text snippets for quick content")
            except Exception as e:
                log.error(f"‚ùå Migration 67 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 68: WhatsApp Manual Templates - Custom text templates for broadcasts
        checkpoint("Migration 68: Creating whatsapp_manual_templates table for custom broadcast templates")
        if not check_table_exists('whatsapp_manual_templates'):
            try:
                from sqlalchemy import text
                db.session.execute(text("""
                    CREATE TABLE whatsapp_manual_templates (
                        id SERIAL PRIMARY KEY,
                        business_id INTEGER NOT NULL REFERENCES business(id) ON DELETE CASCADE,
                        name VARCHAR(255) NOT NULL,
                        message_text TEXT NOT NULL,
                        created_by_user_id INTEGER REFERENCES users(id) ON DELETE SET NULL,
                        is_active BOOLEAN NOT NULL DEFAULT TRUE,
                        created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
                    )
                """))
                
                # Create indexes for fast lookups
                db.session.execute(text("""
                    CREATE INDEX idx_whatsapp_manual_templates_business_id ON whatsapp_manual_templates(business_id)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_whatsapp_manual_templates_is_active ON whatsapp_manual_templates(is_active)
                """))
                
                migrations_applied.append('create_whatsapp_manual_templates_table')
                checkpoint("‚úÖ Applied migration 68: create_whatsapp_manual_templates_table - WhatsApp custom templates")
            except Exception as e:
                log.error(f"‚ùå Migration 68 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 69: ISO 27001 Security Events Table - Audit and incident tracking
        # Required for ISO 27001 compliance (A.12.4, A.16) and audit readiness
        checkpoint("Migration 69: Creating security_events table for ISO 27001 compliance")
        if not check_table_exists('security_events'):
            try:
                from sqlalchemy import text
                db.session.execute(text("""
                    CREATE TABLE security_events (
                        id SERIAL PRIMARY KEY,
                        business_id INTEGER REFERENCES business(id),
                        event_type VARCHAR(64) NOT NULL,
                        severity VARCHAR(16) NOT NULL DEFAULT 'low' CHECK (severity IN ('critical', 'high', 'medium', 'low')),
                        description TEXT NOT NULL,
                        impact TEXT,
                        response TEXT,
                        lessons_learned TEXT,
                        status VARCHAR(32) DEFAULT 'open' CHECK (status IN ('open', 'investigating', 'mitigated', 'resolved', 'closed')),
                        user_id INTEGER REFERENCES users(id),
                        user_email VARCHAR(255),
                        ip_address VARCHAR(64),
                        user_agent VARCHAR(512),
                        resource_type VARCHAR(64),
                        resource_id VARCHAR(64),
                        endpoint VARCHAR(255),
                        method VARCHAR(16),
                        event_metadata JSONB,
                        assigned_to_user_id INTEGER REFERENCES users(id),
                        created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
                        resolved_at TIMESTAMP,
                        updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
                    )
                """))
                
                # Create indexes for efficient querying
                db.session.execute(text("""
                    CREATE INDEX idx_security_events_business_id ON security_events(business_id)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_security_events_event_type ON security_events(event_type)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_security_events_severity ON security_events(severity)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_security_events_status ON security_events(status)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_security_events_created_at ON security_events(created_at)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_security_events_business_severity ON security_events(business_id, severity)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_security_events_status_created ON security_events(status, created_at)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_security_events_type_created ON security_events(event_type, created_at)
                """))
                
                migrations_applied.append('create_security_events_table')
                checkpoint("‚úÖ Applied migration 69: create_security_events_table - ISO 27001 security audit compliance")
            except Exception as e:
                log.error(f"‚ùå Migration 69 failed: {e}")
                db.session.rollback()
                raise
        
        # Migration 70: Rename metadata to event_metadata in security_events (SQLAlchemy reserved name fix)
        checkpoint("Migration 70: Checking if security_events.metadata needs to be renamed to event_metadata")
        if check_table_exists('security_events') and check_column_exists('security_events', 'metadata'):
            try:
                from sqlalchemy import text
                checkpoint("Migration 70: Renaming security_events.metadata to event_metadata (SQLAlchemy reserved name)")
                db.session.execute(text("""
                    ALTER TABLE security_events RENAME COLUMN metadata TO event_metadata
                """))
                migrations_applied.append('rename_security_events_metadata_to_event_metadata')
                checkpoint("‚úÖ Applied migration 70: rename_security_events_metadata_to_event_metadata")
            except Exception as e:
                log.error(f"‚ùå Migration 70 failed: {e}")
                db.session.rollback()
                raise
        elif check_table_exists('security_events'):
            checkpoint("Migration 70: Column security_events.metadata does not exist (already event_metadata or new table) - skipping")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # Migration 71: Page-level permissions for businesses (enabled_pages)
        # üîê PURPOSE: Implement full page access control system
        # Adds enabled_pages JSONB column to business table
        # Sets default to ALL pages for existing businesses (backward compatibility)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        checkpoint("Migration 71: Adding enabled_pages column to business table")
        if check_table_exists('business') and not check_column_exists('business', 'enabled_pages'):
            try:
                from sqlalchemy import text
                from server.security.page_registry import DEFAULT_ENABLED_PAGES
                import json
                
                checkpoint("  ‚Üí Adding enabled_pages column...")
                # Add column with default empty list
                db.session.execute(text("""
                    ALTER TABLE business 
                    ADD COLUMN enabled_pages JSON NOT NULL DEFAULT '[]'
                """))
                checkpoint("  ‚úÖ enabled_pages column added")
                
                # Set all existing businesses to have all pages enabled (backward compatibility)
                default_pages_json = json.dumps(DEFAULT_ENABLED_PAGES)
                checkpoint(f"  ‚Üí Setting default pages for existing businesses: {len(DEFAULT_ENABLED_PAGES)} pages")
                
                # Update only rows that don't have pages set yet (NULL or empty array)
                # üî• FIX: Use JSONB cast and proper comparison to avoid "operator does not exist: json = json" error
                result = db.session.execute(text("""
                    UPDATE business 
                    SET enabled_pages = :pages
                    WHERE enabled_pages IS NULL 
                       OR CAST(enabled_pages AS TEXT) = '[]'
                       OR json_array_length(CAST(enabled_pages AS json)) = 0
                """), {"pages": default_pages_json})
                
                updated_count = result.rowcount
                checkpoint(f"  ‚úÖ Updated {updated_count} existing businesses with all pages enabled")
                
                migrations_applied.append('add_business_enabled_pages')
                checkpoint("‚úÖ Applied migration 71: add_business_enabled_pages - Page-level permissions system")
            except Exception as e:
                log.error(f"‚ùå Migration 71 failed: {e}")
                db.session.rollback()
                raise
        elif check_table_exists('business'):
            checkpoint("Migration 71: enabled_pages column already exists - skipping")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # Migration 72: CRM Context-Aware Support - Add note_type, call_id, structured_data to lead_notes
        # üéØ PURPOSE: Enable AI to read/write CRM context and create call summary notes
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        checkpoint("Migration 72: CRM Context-Aware Support - Adding fields to lead_notes")
        
        if check_table_exists('lead_notes'):
            try:
                # Add note_type column if missing
                if not check_column_exists('lead_notes', 'note_type'):
                    checkpoint("  ‚Üí Adding note_type to lead_notes...")
                    db.session.execute(text("""
                        ALTER TABLE lead_notes 
                        ADD COLUMN note_type VARCHAR(32) DEFAULT 'manual'
                    """))
                    db.session.execute(text("""
                        CREATE INDEX IF NOT EXISTS idx_lead_notes_type 
                        ON lead_notes(lead_id, note_type)
                    """))
                    checkpoint("  ‚úÖ lead_notes.note_type added")
                    migrations_applied.append('add_lead_notes_note_type')
                
                # Add call_id column if missing
                if not check_column_exists('lead_notes', 'call_id'):
                    checkpoint("  ‚Üí Adding call_id to lead_notes...")
                    db.session.execute(text("""
                        ALTER TABLE lead_notes 
                        ADD COLUMN call_id INTEGER REFERENCES call_log(id)
                    """))
                    db.session.execute(text("""
                        CREATE INDEX IF NOT EXISTS idx_lead_notes_call_id 
                        ON lead_notes(call_id)
                    """))
                    checkpoint("  ‚úÖ lead_notes.call_id added")
                    migrations_applied.append('add_lead_notes_call_id')
                
                # Add structured_data column if missing
                if not check_column_exists('lead_notes', 'structured_data'):
                    checkpoint("  ‚Üí Adding structured_data to lead_notes...")
                    db.session.execute(text("""
                        ALTER TABLE lead_notes 
                        ADD COLUMN structured_data JSON
                    """))
                    checkpoint("  ‚úÖ lead_notes.structured_data added")
                    migrations_applied.append('add_lead_notes_structured_data')
                
                checkpoint("‚úÖ Migration 72 completed - CRM Context-Aware Support fields added to lead_notes")
            except Exception as e:
                log.error(f"‚ùå Migration 72 failed: {e}")
                db.session.rollback()
                raise
        else:
            checkpoint("  ‚ÑπÔ∏è lead_notes table does not exist - skipping")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # Migration 73: CRM Context-Aware Support - Add enable_customer_service to business_settings
        # üéØ PURPOSE: Toggle per-business customer service mode
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        checkpoint("Migration 73: CRM Context-Aware Support - Adding enable_customer_service to business_settings")
        
        if check_table_exists('business_settings'):
            try:
                if not check_column_exists('business_settings', 'enable_customer_service'):
                    checkpoint("  ‚Üí Adding enable_customer_service to business_settings...")
                    db.session.execute(text("""
                        ALTER TABLE business_settings 
                        ADD COLUMN enable_customer_service BOOLEAN DEFAULT FALSE
                    """))
                    checkpoint("  ‚úÖ business_settings.enable_customer_service added")
                    migrations_applied.append('add_business_settings_enable_customer_service')
                else:
                    checkpoint("  ‚úÖ business_settings.enable_customer_service already exists")
                
                checkpoint("‚úÖ Migration 73 completed - Customer service toggle added")
            except Exception as e:
                log.error(f"‚ùå Migration 73 failed: {e}")
                db.session.rollback()
                raise
        else:
            checkpoint("  ‚ÑπÔ∏è business_settings table does not exist - skipping")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # Migration 74: Email Text Templates Enhancement - Add button_text, button_link, footer_text
        # üéØ PURPOSE: Allow full email template customization including CTA button and footer
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        checkpoint("Migration 74: Email Text Templates - Adding button and footer fields")
        
        if check_table_exists('email_text_templates'):
            try:
                # Add button_text column if missing
                if not check_column_exists('email_text_templates', 'button_text'):
                    checkpoint("  ‚Üí Adding button_text to email_text_templates...")
                    db.session.execute(text("""
                        ALTER TABLE email_text_templates 
                        ADD COLUMN button_text VARCHAR(255)
                    """))
                    checkpoint("  ‚úÖ email_text_templates.button_text added")
                    migrations_applied.append('add_email_text_templates_button_text')
                
                # Add button_link column if missing
                if not check_column_exists('email_text_templates', 'button_link'):
                    checkpoint("  ‚Üí Adding button_link to email_text_templates...")
                    db.session.execute(text("""
                        ALTER TABLE email_text_templates 
                        ADD COLUMN button_link VARCHAR(512)
                    """))
                    checkpoint("  ‚úÖ email_text_templates.button_link added")
                    migrations_applied.append('add_email_text_templates_button_link')
                
                # Add footer_text column if missing
                if not check_column_exists('email_text_templates', 'footer_text'):
                    checkpoint("  ‚Üí Adding footer_text to email_text_templates...")
                    db.session.execute(text("""
                        ALTER TABLE email_text_templates 
                        ADD COLUMN footer_text TEXT
                    """))
                    checkpoint("  ‚úÖ email_text_templates.footer_text added")
                    migrations_applied.append('add_email_text_templates_footer_text')
                
                checkpoint("‚úÖ Migration 74 completed - Email text template fields added")
            except Exception as e:
                log.error(f"‚ùå Migration 74 failed: {e}")
                db.session.rollback()
                raise
        else:
            checkpoint("  ‚ÑπÔ∏è email_text_templates table does not exist - skipping")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # Migration 75: Separate Customer Service AI Notes from Free Notes
        # üéØ PURPOSE: Fix overlap between AI customer service notes and free notes
        # Problem: Manual notes in AI tab used note_type='manual', causing them to appear in both tabs
        # Solution: Introduce new note_type='customer_service_ai' for AI customer service context
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        checkpoint("Migration 75: Separating Customer Service AI notes from Free Notes")
        
        if check_table_exists('lead_notes'):
            try:
                from sqlalchemy import text
                
                # Step 1: Update existing manual notes without attachments to be customer_service_ai
                # These are the notes that were added in the AI Customer Service tab
                # We identify them as manual notes with no attachments and no created_by user
                # (created_by=NULL typically means AI-created or system-created)
                checkpoint("  ‚Üí Migrating existing AI customer service notes...")
                
                # First, check if attachments column exists and what type it is
                column_type_query = text("""
                    SELECT data_type, udt_name
                    FROM information_schema.columns
                    WHERE table_name = 'lead_notes' AND column_name = 'attachments'
                """)
                column_info = db.session.execute(column_type_query).fetchone()
                
                # Build the query based on column type
                if column_info:
                    data_type = column_info[0].lower()
                    udt_name = column_info[1].lower() if len(column_info) > 1 else ''
                    checkpoint(f"  Column attachments type: {data_type} ({udt_name})")
                    
                    # Determine the right comparison based on column type
                    if 'jsonb' in data_type or udt_name == 'jsonb':
                        # JSONB column - use jsonb operators
                        attachments_condition = "(attachments IS NULL OR attachments = '[]'::jsonb OR jsonb_array_length(attachments) = 0)"
                    elif 'json' in data_type or udt_name == 'json':
                        # JSON column - cast and compare
                        attachments_condition = "(attachments IS NULL OR CAST(attachments AS TEXT) = '[]' OR json_array_length(attachments) = 0)"
                    else:
                        # TEXT column - use trim and cast
                        attachments_condition = "(attachments IS NULL OR TRIM(attachments) = '' OR TRIM(attachments) = '[]' OR (attachments ~ '^\\[\\s*\\]$'))"
                    
                    checkpoint(f"  Using condition: {attachments_condition}")
                else:
                    checkpoint("  ‚ö†Ô∏è attachments column not found, skipping attachment check")
                    attachments_condition = "TRUE"
                
                # Count notes that will be migrated
                count_query = text(f"""
                    SELECT COUNT(*) FROM lead_notes
                    WHERE note_type = 'manual'
                      AND {attachments_condition}
                      AND created_by IS NULL
                """)
                notes_to_migrate = db.session.execute(count_query).scalar() or 0
                checkpoint(f"  Found {notes_to_migrate} manual notes without attachments and without user (AI/system notes)")
                
                if notes_to_migrate > 0:
                    # Update note_type for these notes
                    # Note: We keep created_by=NULL to preserve that these were AI/system generated
                    update_query = text(f"""
                        UPDATE lead_notes 
                        SET note_type = 'customer_service_ai'
                        WHERE note_type = 'manual'
                          AND {attachments_condition}
                          AND created_by IS NULL
                    """)
                    db.session.execute(update_query)
                    checkpoint(f"  ‚úÖ Migrated {notes_to_migrate} notes to customer_service_ai type")
                else:
                    checkpoint("  ‚úÖ No notes to migrate")
                
                # Step 2: Add index for faster filtering by note_type
                if not check_index_exists('idx_lead_notes_type_tenant'):
                    checkpoint("  ‚Üí Creating index on note_type and tenant_id...")
                    db.session.execute(text("""
                        CREATE INDEX idx_lead_notes_type_tenant 
                        ON lead_notes(tenant_id, note_type, created_at DESC)
                    """))
                    checkpoint("  ‚úÖ Index created for efficient note filtering")
                
                migrations_applied.append('separate_customer_service_ai_notes')
                checkpoint("‚úÖ Migration 75 completed - Customer Service AI notes now separate from Free Notes")
                
                # Log summary
                checkpoint("""
                  üìã Migration 75 Summary:
                  - Created new note_type 'customer_service_ai' for AI customer service context
                  - Migrated existing manual notes (without attachments, without user) to new type
                  - Added index for efficient filtering
                  - AI will now only see: call_summary, system, and customer_service_ai notes
                  - Free Notes tab will only show: manual notes (with or without attachments)
                """)
                
            except Exception as e:
                log.error(f"‚ùå Migration 75 failed: {e}")
                db.session.rollback()
                raise
        else:
            checkpoint("  ‚ÑπÔ∏è lead_notes table does not exist - skipping")
        
        # Migration 76: Create attachments table for unified file management
        if not check_table_exists('attachments'):
            checkpoint("üîß Running Migration 76: Create attachments table for unified file management")
            try:
                from sqlalchemy import text
                
                # Create attachments table
                db.session.execute(text("""
                    CREATE TABLE attachments (
                        id SERIAL PRIMARY KEY,
                        business_id INTEGER NOT NULL REFERENCES business(id) ON DELETE CASCADE,
                        uploaded_by INTEGER REFERENCES users(id) ON DELETE SET NULL,
                        filename_original VARCHAR(255) NOT NULL,
                        mime_type VARCHAR(100) NOT NULL,
                        file_size INTEGER NOT NULL,
                        storage_path VARCHAR(512) NOT NULL,
                        public_url VARCHAR(512),
                        channel_compatibility JSON DEFAULT '{"email": true, "whatsapp": true, "broadcast": true}'::json,
                        metadata JSON,
                        is_deleted BOOLEAN DEFAULT FALSE,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        deleted_at TIMESTAMP,
                        deleted_by INTEGER REFERENCES users(id) ON DELETE SET NULL
                    )
                """))
                checkpoint("  ‚úÖ attachments table created")
                
                # Add indexes for performance
                db.session.execute(text("""
                    CREATE INDEX idx_attachments_business 
                    ON attachments(business_id, created_at DESC) 
                    WHERE is_deleted = FALSE
                """))
                checkpoint("  ‚úÖ Index created: idx_attachments_business")
                
                db.session.execute(text("""
                    CREATE INDEX idx_attachments_uploader 
                    ON attachments(uploaded_by, created_at DESC)
                """))
                checkpoint("  ‚úÖ Index created: idx_attachments_uploader")
                
                # Create storage directory structure
                import os
                storage_root = os.path.join(os.getcwd(), 'storage', 'attachments')
                os.makedirs(storage_root, exist_ok=True)
                checkpoint(f"  ‚úÖ Storage directory created: {storage_root}")
                
                migrations_applied.append('create_attachments_table')
                checkpoint("‚úÖ Migration 76 completed - Unified attachments system ready")
                
            except Exception as e:
                log.error(f"‚ùå Migration 76 failed: {e}")
                db.session.rollback()
                raise
        else:
            checkpoint("  ‚ÑπÔ∏è attachments table already exists - skipping")
        
        # Migration 77: Upgrade contracts system - reuse attachments for R2 storage
        if not check_table_exists('contract_files'):
            checkpoint("üîß Running Migration 77: Upgrade contracts system with attachment integration")
            
            try:
                # Add missing columns to existing contract table if it exists
                if check_table_exists('contract'):
                    checkpoint("  ‚Üí Upgrading existing contract table...")
                    
                    # Add lead_id if missing
                    if not check_column_exists('contract', 'lead_id'):
                        db.session.execute(text("""
                            ALTER TABLE contract 
                            ADD COLUMN lead_id INTEGER REFERENCES leads(id)
                        """))
                        db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_contract_lead ON contract(lead_id)"))
                        checkpoint("    ‚úÖ Added lead_id column")
                    
                    # Add title if missing
                    if not check_column_exists('contract', 'title'):
                        db.session.execute(text("""
                            ALTER TABLE contract 
                            ADD COLUMN title VARCHAR(255)
                        """))
                        checkpoint("    ‚úÖ Added title column")
                    
                    # Update status column to use new enum values with CHECK constraint
                    if check_column_exists('contract', 'status'):
                        # Drop old constraint if exists and add new one
                        db.session.execute(text("""
                            ALTER TABLE contract DROP CONSTRAINT IF EXISTS contract_status_check
                        """))
                        db.session.execute(text("""
                            ALTER TABLE contract 
                            ADD CONSTRAINT contract_status_check 
                            CHECK (status IN ('draft', 'sent', 'signed', 'cancelled'))
                        """))
                        checkpoint("    ‚úÖ Updated status CHECK constraint")
                    
                    # Add signer fields if missing
                    for col in ['signer_name', 'signer_phone', 'signer_email']:
                        if not check_column_exists('contract', col):
                            db.session.execute(text(f"""
                                ALTER TABLE contract 
                                ADD COLUMN {col} VARCHAR(255)
                            """))
                    checkpoint("    ‚úÖ Added signer fields")
                    
                    # Add created_by if missing
                    if not check_column_exists('contract', 'created_by'):
                        db.session.execute(text("""
                            ALTER TABLE contract 
                            ADD COLUMN created_by INTEGER REFERENCES users(id)
                        """))
                    checkpoint("    ‚úÖ Added created_by field")
                    
                    # Add updated_at if missing
                    if not check_column_exists('contract', 'updated_at'):
                        db.session.execute(text("""
                            ALTER TABLE contract 
                            ADD COLUMN updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                        """))
                    checkpoint("    ‚úÖ Added updated_at field")
                    
                    # Ensure indexes
                    db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_contract_business_created ON contract(business_id, created_at DESC)"))
                    db.session.execute(text("CREATE INDEX IF NOT EXISTS idx_contract_business_status ON contract(business_id, status)"))
                    checkpoint("    ‚úÖ Created performance indexes")
                
                # Create contract_files table - links contracts to attachments
                checkpoint("  ‚Üí Creating contract_files table (attachment-based)...")
                db.session.execute(text("""
                    CREATE TABLE contract_files (
                        id SERIAL PRIMARY KEY,
                        business_id INTEGER NOT NULL REFERENCES business(id),
                        contract_id INTEGER NOT NULL REFERENCES contract(id) ON DELETE CASCADE,
                        attachment_id INTEGER NOT NULL REFERENCES attachments(id) ON DELETE CASCADE,
                        purpose VARCHAR(32) NOT NULL CHECK (purpose IN ('original', 'signed', 'extra_doc', 'template')),
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        created_by INTEGER REFERENCES users(id),
                        deleted_at TIMESTAMP
                    )
                """))
                
                # Create indexes for contract_files
                db.session.execute(text("CREATE INDEX idx_contract_files_contract ON contract_files(contract_id, created_at DESC)"))
                db.session.execute(text("CREATE INDEX idx_contract_files_business ON contract_files(business_id)"))
                db.session.execute(text("CREATE INDEX idx_contract_files_attachment ON contract_files(attachment_id)"))
                checkpoint("    ‚úÖ contract_files table created (attachment-based)")
                
                # Create contract_sign_tokens table - DB-based tokens (NOT JWT)
                checkpoint("  ‚Üí Creating contract_sign_tokens table...")
                db.session.execute(text("""
                    CREATE TABLE contract_sign_tokens (
                        id SERIAL PRIMARY KEY,
                        business_id INTEGER NOT NULL REFERENCES business(id),
                        contract_id INTEGER NOT NULL REFERENCES contract(id) ON DELETE CASCADE,
                        token_hash VARCHAR(64) NOT NULL UNIQUE,
                        scope VARCHAR(32) NOT NULL DEFAULT 'sign',
                        expires_at TIMESTAMP NOT NULL,
                        used_at TIMESTAMP,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        created_by INTEGER REFERENCES users(id)
                    )
                """))
                
                # Create indexes for contract_sign_tokens
                db.session.execute(text("CREATE INDEX idx_contract_tokens_hash ON contract_sign_tokens(token_hash)"))
                db.session.execute(text("CREATE INDEX idx_contract_tokens_contract ON contract_sign_tokens(contract_id)"))
                db.session.execute(text("CREATE INDEX idx_contract_tokens_expires ON contract_sign_tokens(expires_at)"))
                checkpoint("    ‚úÖ contract_sign_tokens table created (secure DB-based tokens)")
                
                # Create contract_sign_events table (Audit Trail)
                checkpoint("  ‚Üí Creating contract_sign_events table...")
                db.session.execute(text("""
                    CREATE TABLE contract_sign_events (
                        id SERIAL PRIMARY KEY,
                        business_id INTEGER NOT NULL REFERENCES business(id),
                        contract_id INTEGER NOT NULL REFERENCES contract(id) ON DELETE CASCADE,
                        event_type VARCHAR(32) NOT NULL CHECK (event_type IN (
                            'created', 'file_uploaded', 'sent_for_signature', 
                            'viewed', 'signed_completed', 'cancelled'
                        )),
                        metadata JSONB,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        created_by INTEGER REFERENCES users(id)
                    )
                """))
                
                # Create indexes for contract_sign_events
                db.session.execute(text("CREATE INDEX idx_contract_events_contract ON contract_sign_events(contract_id, created_at)"))
                db.session.execute(text("CREATE INDEX idx_contract_events_business ON contract_sign_events(business_id)"))
                checkpoint("    ‚úÖ contract_sign_events table created")
                
                migrations_applied.append('upgrade_contracts_system_attachment_based')
                checkpoint("‚úÖ Migration 77 completed - Contracts system with attachment integration")
                checkpoint("  üìã Summary:")
                checkpoint("     ‚Ä¢ contract_files ‚Üí attachment_id (reuses R2 storage)")
                checkpoint("     ‚Ä¢ contract_sign_tokens ‚Üí DB-based (NOT JWT)")
                checkpoint("     ‚Ä¢ contract_sign_events ‚Üí full audit trail")
                
            except Exception as e:
                log.error(f"‚ùå Migration 77 failed: {e}")
                db.session.rollback()
                raise
        else:
            checkpoint("  ‚ÑπÔ∏è contract_files table already exists - skipping")
        
        # Migration 78: Rename metadata to event_metadata in contract_sign_events (SQLAlchemy reserved word fix)
        if check_table_exists('contract_sign_events') and check_column_exists('contract_sign_events', 'metadata'):
            checkpoint("üîß Running Migration 78: Rename metadata to event_metadata in contract_sign_events")
            
            try:
                # Rename the column from metadata to event_metadata
                db.session.execute(text("""
                    ALTER TABLE contract_sign_events 
                    RENAME COLUMN metadata TO event_metadata
                """))
                
                migrations_applied.append('rename_contract_sign_events_metadata')
                checkpoint("‚úÖ Migration 78 completed - Renamed metadata to event_metadata in contract_sign_events")
                checkpoint("  üìã Reason: 'metadata' is a reserved attribute in SQLAlchemy Declarative API")
                
            except Exception as e:
                log.error(f"‚ùå Migration 78 failed: {e}")
                db.session.rollback()
                raise
        else:
            if check_table_exists('contract_sign_events'):
                if check_column_exists('contract_sign_events', 'event_metadata'):
                    checkpoint("  ‚ÑπÔ∏è event_metadata column already exists - skipping")
                else:
                    checkpoint("  ‚ÑπÔ∏è metadata column not found (may have been migrated already) - skipping")
            else:
                checkpoint("  ‚ÑπÔ∏è contract_sign_events table does not exist - skipping")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # Migration 79: Add attachments column to email_messages table
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        if check_table_exists('email_messages') and not check_column_exists('email_messages', 'attachments'):
            checkpoint("üîß Running Migration 79: Add attachments column to email_messages")
            
            try:
                # Add attachments column as JSON array to store attachment IDs
                db.session.execute(text("""
                    ALTER TABLE email_messages 
                    ADD COLUMN attachments JSON DEFAULT '[]'
                """))
                
                migrations_applied.append('add_email_messages_attachments')
                checkpoint("‚úÖ Migration 79 completed - Added attachments column to email_messages")
                checkpoint("  üìã Purpose: Store attachment IDs for email attachments support")
                
            except Exception as e:
                log.error(f"‚ùå Migration 79 failed: {e}")
                db.session.rollback()
                raise
        else:
            if check_table_exists('email_messages'):
                if check_column_exists('email_messages', 'attachments'):
                    checkpoint("  ‚ÑπÔ∏è attachments column already exists - skipping")
                else:
                    checkpoint("  ‚ÑπÔ∏è email_messages table not found - skipping")
            else:
                checkpoint("  ‚ÑπÔ∏è email_messages table does not exist - skipping")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # Migration 80: Add 'file_downloaded' to contract_sign_events event_type CHECK constraint
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        if check_table_exists('contract_sign_events'):
            checkpoint("üîß Running Migration 80: Add 'file_downloaded' to contract_sign_events event types")
            
            try:
                # Check if constraint exists by querying check_constraints
                result = db.session.execute(text("""
                    SELECT constraint_name, check_clause
                    FROM information_schema.check_constraints 
                    WHERE constraint_name LIKE '%event_type%'
                    AND constraint_schema = 'public'
                """))
                constraint_row = result.fetchone()
                
                if constraint_row:
                    constraint_name = constraint_row[0]
                    check_clause = constraint_row[1] if len(constraint_row) > 1 else ''
                    
                    # Check if 'file_downloaded' is already in the constraint
                    if 'file_downloaded' in check_clause:
                        checkpoint("  ‚ÑπÔ∏è 'file_downloaded' already in event_type constraint - skipping")
                    else:
                        # Drop old constraint and add new one with 'file_downloaded'
                        db.session.execute(text(f"""
                            ALTER TABLE contract_sign_events 
                            DROP CONSTRAINT IF EXISTS {constraint_name}
                        """))
                        
                        db.session.execute(text("""
                            ALTER TABLE contract_sign_events 
                            ADD CONSTRAINT contract_sign_events_event_type_check 
                            CHECK (event_type IN (
                                'created', 'file_uploaded', 'sent_for_signature', 
                                'viewed', 'signed_completed', 'cancelled', 'file_downloaded'
                            ))
                        """))
                        
                        migrations_applied.append('add_file_downloaded_event_type')
                        checkpoint("‚úÖ Migration 80 completed - Added 'file_downloaded' to allowed event types")
                        checkpoint("  üìã Purpose: Allow logging of file download events in contract audit trail")
                else:
                    checkpoint("  ‚ÑπÔ∏è Event type constraint not found - table may not have constraint yet")
                
            except Exception as e:
                log.error(f"‚ùå Migration 80 failed: {e}")
                db.session.rollback()
                raise
        else:
            checkpoint("  ‚ÑπÔ∏è contract_sign_events table does not exist - skipping")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # Migration 81: Assets Library (◊û◊ê◊í◊®) - Create asset_items and asset_item_media tables
        # üéØ PURPOSE: Add Assets Library feature for managing items with images
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        checkpoint("Migration 81: Assets Library - Creating asset_items and asset_item_media tables")
        
        if not check_table_exists('asset_items'):
            try:
                checkpoint("  ‚Üí Creating asset_items table...")
                db.session.execute(text("""
                    CREATE TABLE asset_items (
                        id SERIAL PRIMARY KEY,
                        business_id INTEGER NOT NULL REFERENCES business(id) ON DELETE CASCADE,
                        title VARCHAR(160) NOT NULL,
                        description TEXT,
                        tags JSON DEFAULT '[]',
                        category VARCHAR(64),
                        status VARCHAR(16) NOT NULL DEFAULT 'active' CHECK (status IN ('active', 'archived')),
                        custom_fields JSON,
                        created_by INTEGER REFERENCES users(id) ON DELETE SET NULL,
                        updated_by INTEGER REFERENCES users(id) ON DELETE SET NULL,
                        created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
                    )
                """))
                
                # Create indexes for efficient querying
                db.session.execute(text("""
                    CREATE INDEX idx_asset_items_business_updated ON asset_items(business_id, updated_at DESC)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_asset_items_business_status_category ON asset_items(business_id, status, category)
                """))
                
                checkpoint("  ‚úÖ asset_items table created")
                migrations_applied.append('create_asset_items_table')
            except Exception as e:
                log.error(f"‚ùå Migration 81 (asset_items) failed: {e}")
                db.session.rollback()
                raise
        else:
            checkpoint("  ‚ÑπÔ∏è asset_items table already exists - skipping")
        
        if not check_table_exists('asset_item_media'):
            try:
                checkpoint("  ‚Üí Creating asset_item_media table...")
                db.session.execute(text("""
                    CREATE TABLE asset_item_media (
                        id SERIAL PRIMARY KEY,
                        business_id INTEGER NOT NULL REFERENCES business(id) ON DELETE CASCADE,
                        asset_item_id INTEGER NOT NULL REFERENCES asset_items(id) ON DELETE CASCADE,
                        attachment_id INTEGER NOT NULL REFERENCES attachments(id) ON DELETE CASCADE,
                        role VARCHAR(32) NOT NULL DEFAULT 'gallery' CHECK (role IN ('cover', 'gallery', 'floorplan', 'other')),
                        sort_order INTEGER DEFAULT 0,
                        created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
                    )
                """))
                
                # Create indexes for efficient querying
                db.session.execute(text("""
                    CREATE INDEX idx_asset_item_media_item ON asset_item_media(asset_item_id)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_asset_item_media_sort ON asset_item_media(asset_item_id, sort_order)
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_asset_item_media_attachment ON asset_item_media(attachment_id)
                """))
                
                checkpoint("  ‚úÖ asset_item_media table created")
                migrations_applied.append('create_asset_item_media_table')
            except Exception as e:
                log.error(f"‚ùå Migration 81 (asset_item_media) failed: {e}")
                db.session.rollback()
                raise
        else:
            checkpoint("  ‚ÑπÔ∏è asset_item_media table already exists - skipping")
        
        # üî• CRITICAL: Enable 'assets' page for all businesses
        # This ensures the Assets Library appears in sidebar for all businesses
        if check_table_exists('business') and check_column_exists('business', 'enabled_pages'):
            try:
                checkpoint("  ‚Üí Enabling 'assets' page for all businesses...")
                
                # Add 'assets' to enabled_pages for businesses that don't have it yet
                # Using JSONB || operator for performance
                result = db.session.execute(text("""
                    UPDATE business
                    SET enabled_pages = enabled_pages::jsonb || '["assets"]'::jsonb
                    WHERE enabled_pages IS NOT NULL
                      AND NOT (enabled_pages::jsonb ? 'assets')
                """))
                updated_count = result.rowcount
                
                if updated_count > 0:
                    checkpoint(f"  ‚úÖ Enabled 'assets' page for {updated_count} businesses")
                else:
                    checkpoint("  ‚ÑπÔ∏è All businesses already have 'assets' page enabled")
                
                # For businesses with NULL or empty enabled_pages, set default pages including assets
                result2 = db.session.execute(text("""
                    UPDATE business
                    SET enabled_pages = '["dashboard","crm_leads","crm_customers","calls_inbound","calls_outbound","whatsapp_inbox","whatsapp_broadcast","emails","calendar","statistics","invoices","contracts","assets","settings","users"]'::jsonb
                    WHERE enabled_pages IS NULL
                       OR enabled_pages::text = '[]'
                       OR jsonb_array_length(enabled_pages::jsonb) = 0
                """))
                updated_count2 = result2.rowcount
                
                if updated_count2 > 0:
                    checkpoint(f"  ‚úÖ Set default pages (including assets) for {updated_count2} businesses with empty pages")
                
                migrations_applied.append('enable_assets_page_for_businesses')
                checkpoint("‚úÖ Migration 81 completed - Assets Library tables created and page enabled")
            except Exception as e:
                log.error(f"‚ùå Failed to enable assets page for businesses: {e}")
                # Don't fail the entire migration if this fails
                checkpoint("‚ö†Ô∏è Assets tables created but page enablement may need manual fix")
        else:
            checkpoint("‚úÖ Migration 81 completed - Assets Library tables created")
        
        # Migration 82: Gmail Receipts System - Create gmail_connections and receipts tables
        checkpoint("Migration 82: Gmail Receipts System")
        
        # Create gmail_connections table
        if not check_table_exists('gmail_connections'):
            try:
                checkpoint("  ‚Üí Creating gmail_connections table...")
                db.session.execute(text("""
                    CREATE TABLE gmail_connections (
                        id SERIAL PRIMARY KEY,
                        business_id INTEGER NOT NULL REFERENCES business(id) ON DELETE CASCADE,
                        email_address VARCHAR(255) NOT NULL,
                        google_sub VARCHAR(255),
                        refresh_token_encrypted TEXT NOT NULL,
                        status VARCHAR(32) NOT NULL DEFAULT 'connected',
                        error_message TEXT,
                        last_sync_at TIMESTAMP,
                        last_history_id VARCHAR(64),
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        CONSTRAINT uq_gmail_connection_business UNIQUE (business_id),
                        CONSTRAINT chk_gmail_connection_status CHECK (status IN ('connected', 'disconnected', 'error'))
                    )
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_gmail_connections_business ON gmail_connections(business_id)
                """))
                checkpoint("  ‚úÖ gmail_connections table created")
                migrations_applied.append('create_gmail_connections_table')
            except Exception as e:
                log.error(f"‚ùå Migration 82 (gmail_connections) failed: {e}")
                db.session.rollback()
                raise
        else:
            checkpoint("  ‚ÑπÔ∏è gmail_connections table already exists - skipping")
        
        # Create receipts table
        if not check_table_exists('receipts'):
            try:
                checkpoint("  ‚Üí Creating receipts table...")
                db.session.execute(text("""
                    CREATE TABLE receipts (
                        id SERIAL PRIMARY KEY,
                        business_id INTEGER NOT NULL REFERENCES business(id) ON DELETE CASCADE,
                        source VARCHAR(32) NOT NULL DEFAULT 'gmail',
                        gmail_message_id VARCHAR(255),
                        gmail_thread_id VARCHAR(255),
                        from_email VARCHAR(255),
                        subject VARCHAR(500),
                        received_at TIMESTAMP,
                        vendor_name VARCHAR(255),
                        amount NUMERIC(12, 2),
                        currency VARCHAR(3) NOT NULL DEFAULT 'ILS',
                        invoice_number VARCHAR(100),
                        invoice_date DATE,
                        confidence INTEGER,
                        raw_extraction_json JSONB,
                        status VARCHAR(32) NOT NULL DEFAULT 'pending_review',
                        reviewed_by INTEGER REFERENCES users(id) ON DELETE SET NULL,
                        reviewed_at TIMESTAMP,
                        attachment_id INTEGER REFERENCES attachments(id) ON DELETE SET NULL,
                        is_deleted BOOLEAN DEFAULT FALSE,
                        deleted_at TIMESTAMP,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        CONSTRAINT chk_receipt_status CHECK (status IN ('pending_review', 'approved', 'rejected', 'not_receipt')),
                        CONSTRAINT chk_receipt_source CHECK (source IN ('gmail', 'manual', 'upload'))
                    )
                """))
                # Use partial unique index to allow NULL gmail_message_id (for manual uploads)
                db.session.execute(text("""
                    CREATE UNIQUE INDEX uq_receipt_business_gmail_message 
                    ON receipts(business_id, gmail_message_id) 
                    WHERE gmail_message_id IS NOT NULL
                """))
                db.session.execute(text("""
                    CREATE INDEX idx_receipts_business ON receipts(business_id);
                    CREATE INDEX idx_receipts_business_received ON receipts(business_id, received_at);
                    CREATE INDEX idx_receipts_business_status ON receipts(business_id, status);
                    CREATE INDEX idx_receipts_gmail_message_id ON receipts(gmail_message_id);
                    CREATE INDEX idx_receipts_attachment ON receipts(attachment_id);
                    CREATE INDEX idx_receipts_is_deleted ON receipts(is_deleted)
                """))
                checkpoint("  ‚úÖ receipts table created")
                migrations_applied.append('create_receipts_table')
            except Exception as e:
                log.error(f"‚ùå Migration 82 (receipts) failed: {e}")
                db.session.rollback()
                raise
        else:
            checkpoint("  ‚ÑπÔ∏è receipts table already exists - skipping")
        
        checkpoint("‚úÖ Migration 82 completed - Gmail Receipts System tables created")
        # ============================================================================
        # Migration 83: Assets AI Toggle - Add assets_use_ai to BusinessSettings
        # ============================================================================
        # Adds assets_use_ai boolean column to business_settings table
        # Controls whether AI can access assets tools during conversations
        # Default: true (enabled for backward compatibility)
        checkpoint("Migration 83: Adding assets_use_ai column to business_settings table")
        if check_table_exists('business_settings') and not check_column_exists('business_settings', 'assets_use_ai'):
            try:
                checkpoint("  ‚Üí Adding assets_use_ai column...")
                db.session.execute(text("""
                    ALTER TABLE business_settings
                    ADD COLUMN assets_use_ai BOOLEAN NOT NULL DEFAULT TRUE
                """))
                checkpoint("  ‚úÖ assets_use_ai column added (default: TRUE)")
                migrations_applied.append('add_assets_use_ai_column')
                checkpoint("‚úÖ Applied migration 83: add_assets_use_ai_column - AI tools toggle for assets")
            except Exception as e:
                log.error(f"‚ùå Migration 83 (assets_use_ai) failed: {e}")
                db.session.rollback()
                raise
        else:
            if not check_table_exists('business_settings'):
                checkpoint("Migration 83: business_settings table doesn't exist - skipping")
            else:
                checkpoint("Migration 83: assets_use_ai column already exists - skipping")
        
        # ============================================================================
        # Migration 84: Gmail Receipts Enhanced - Purpose-Based File Separation
        # ============================================================================
        # Adds complete file separation system with purpose and origin tracking
        # - purpose: Categorizes files (email_attachment, whatsapp_media, receipt_source, etc.)
        # - origin_module: Tracks which system created the file
        # - Email content fields for HTML‚ÜíPNG preview generation
        # - Sync tracking table for long-running Gmail syncs
        # Security: Prevents contract/receipt files from appearing in email/whatsapp pickers
        checkpoint("Migration 84: Gmail Receipts Enhanced - purpose-based file separation")
        
        # 84a: Add purpose field to attachments
        if check_table_exists('attachments'):
            if not check_column_exists('attachments', 'purpose'):
                checkpoint("Migration 84a: Adding purpose to attachments")
                from sqlalchemy import text
                try:
                    db.session.execute(text("""
                        ALTER TABLE attachments 
                        ADD COLUMN purpose VARCHAR(50) NOT NULL DEFAULT 'general_upload'
                    """))
                    db.session.commit()  # Commit immediately to persist the column
                    
                    # Add index for efficient filtering
                    if not check_index_exists('idx_attachments_purpose'):
                        db.session.execute(text("""
                            CREATE INDEX idx_attachments_purpose 
                            ON attachments(business_id, purpose, created_at)
                        """))
                        db.session.commit()  # Commit index creation
                    
                    migrations_applied.append("add_purpose_to_attachments")
                    checkpoint("‚úÖ Migration 84a complete: purpose added with index")
                except Exception as e:
                    db.session.rollback()
                    checkpoint(f"‚ö†Ô∏è Migration 84a failed: {e}")
                    log.error(f"Migration 84a error details: {e}", exc_info=True)
            else:
                checkpoint("Migration 84a: purpose column already exists - skipping")
        
        # 84b: Add origin_module field to attachments
        if check_table_exists('attachments'):
            if not check_column_exists('attachments', 'origin_module'):
                checkpoint("Migration 84b: Adding origin_module to attachments")
                from sqlalchemy import text
                try:
                    db.session.execute(text("""
                        ALTER TABLE attachments 
                        ADD COLUMN origin_module VARCHAR(50)
                    """))
                    db.session.commit()  # Commit immediately to persist the column
                    
                    # Add index for efficient filtering
                    if not check_index_exists('idx_attachments_origin'):
                        db.session.execute(text("""
                            CREATE INDEX idx_attachments_origin 
                            ON attachments(business_id, origin_module)
                        """))
                        db.session.commit()  # Commit index creation
                    
                    migrations_applied.append("add_origin_module_to_attachments")
                    checkpoint("‚úÖ Migration 84b complete: origin_module added with index")
                except Exception as e:
                    db.session.rollback()
                    checkpoint(f"‚ö†Ô∏è Migration 84b failed: {e}")
                    log.error(f"Migration 84b error details: {e}", exc_info=True)
            else:
                checkpoint("Migration 84b: origin_module column already exists - skipping")
        
        # 84c: Add email content fields to receipts
        if check_table_exists('receipts'):
            checkpoint("Migration 84c: Adding email content fields to receipts")
            from sqlalchemy import text
            try:
                fields_added = []
                
                # Add email_subject
                if not check_column_exists('receipts', 'email_subject'):
                    db.session.execute(text("""
                        ALTER TABLE receipts 
                        ADD COLUMN email_subject VARCHAR(500)
                    """))
                    # Copy from existing subject field if available
                    db.session.execute(text("""
                        UPDATE receipts 
                        SET email_subject = subject 
                        WHERE subject IS NOT NULL
                    """))
                    fields_added.append('email_subject')
                
                # Add email_from
                if not check_column_exists('receipts', 'email_from'):
                    db.session.execute(text("""
                        ALTER TABLE receipts 
                        ADD COLUMN email_from VARCHAR(255)
                    """))
                    # Copy from existing from_email field
                    db.session.execute(text("""
                        UPDATE receipts 
                        SET email_from = from_email 
                        WHERE from_email IS NOT NULL
                    """))
                    fields_added.append('email_from')
                
                # Add email_date
                if not check_column_exists('receipts', 'email_date'):
                    db.session.execute(text("""
                        ALTER TABLE receipts 
                        ADD COLUMN email_date TIMESTAMP
                    """))
                    # Copy from existing received_at field
                    db.session.execute(text("""
                        UPDATE receipts 
                        SET email_date = received_at 
                        WHERE received_at IS NOT NULL
                    """))
                    fields_added.append('email_date')
                
                # Add email_html_snippet
                if not check_column_exists('receipts', 'email_html_snippet'):
                    db.session.execute(text("""
                        ALTER TABLE receipts 
                        ADD COLUMN email_html_snippet TEXT
                    """))
                    fields_added.append('email_html_snippet')
                
                if fields_added:
                    migrations_applied.append("add_email_fields_to_receipts")
                    checkpoint(f"‚úÖ Migration 84c complete: {', '.join(fields_added)} added")
                else:
                    checkpoint("Migration 84c: All email fields already exist")
            except Exception as e:
                db.session.rollback()
                checkpoint(f"‚ö†Ô∏è Migration 84c failed: {e}")
        
        # 84d: Add preview_attachment_id to receipts
        if check_table_exists('receipts') and not check_column_exists('receipts', 'preview_attachment_id'):
            checkpoint("Migration 84d: Adding preview_attachment_id to receipts")
            from sqlalchemy import text
            try:
                db.session.execute(text("""
                    ALTER TABLE receipts 
                    ADD COLUMN preview_attachment_id INTEGER 
                    REFERENCES attachments(id) ON DELETE SET NULL
                """))
                
                if not check_index_exists('idx_receipts_preview_attachment'):
                    db.session.execute(text("""
                        CREATE INDEX idx_receipts_preview_attachment 
                        ON receipts(preview_attachment_id)
                    """))
                
                migrations_applied.append("add_preview_attachment_id_to_receipts")
                checkpoint("‚úÖ Migration 84d complete: preview_attachment_id added")
            except Exception as e:
                db.session.rollback()
                checkpoint(f"‚ö†Ô∏è Migration 84d failed: {e}")
        
        # 84e: Create receipt_sync_runs table
        if not check_table_exists('receipt_sync_runs'):
            checkpoint("Migration 84e: Creating receipt_sync_runs table")
            from sqlalchemy import text
            try:
                db.session.execute(text("""
                    CREATE TABLE receipt_sync_runs (
                        id SERIAL PRIMARY KEY,
                        business_id INTEGER NOT NULL REFERENCES business(id) ON DELETE CASCADE,
                        mode VARCHAR(20) NOT NULL DEFAULT 'incremental',
                        status VARCHAR(20) NOT NULL DEFAULT 'running',
                        started_at TIMESTAMP NOT NULL DEFAULT NOW(),
                        finished_at TIMESTAMP,
                        pages_scanned INTEGER DEFAULT 0,
                        messages_scanned INTEGER DEFAULT 0,
                        candidate_receipts INTEGER DEFAULT 0,
                        saved_receipts INTEGER DEFAULT 0,
                        preview_generated_count INTEGER DEFAULT 0,
                        errors_count INTEGER DEFAULT 0,
                        last_page_token VARCHAR(255),
                        last_internal_date VARCHAR(50),
                        error_message TEXT,
                        created_at TIMESTAMP DEFAULT NOW(),
                        updated_at TIMESTAMP DEFAULT NOW()
                    )
                """))
                
                db.session.execute(text("""
                    CREATE INDEX idx_receipt_sync_runs_business 
                    ON receipt_sync_runs(business_id, started_at DESC)
                """))
                
                db.session.execute(text("""
                    CREATE INDEX idx_receipt_sync_runs_status 
                    ON receipt_sync_runs(status, started_at DESC)
                """))
                
                migrations_applied.append("create_receipt_sync_runs_table")
                checkpoint("‚úÖ Migration 84e complete: receipt_sync_runs table created")
            except Exception as e:
                db.session.rollback()
                checkpoint(f"‚ö†Ô∏è Migration 84e failed: {e}")
        
        # 84f: Backfill existing attachments with purpose and origin
        if check_table_exists('attachments') and check_column_exists('attachments', 'purpose'):
            checkpoint("Migration 84f: Backfilling attachments with purpose/origin")
            from sqlalchemy import text
            try:
                # Mark receipt attachments
                result = db.session.execute(text("""
                    UPDATE attachments a
                    SET 
                        purpose = 'receipt_source',
                        origin_module = 'receipts'
                    WHERE EXISTS (
                        SELECT 1 FROM receipts r 
                        WHERE r.attachment_id = a.id
                    ) AND a.purpose = 'general_upload'
                """))
                receipt_count = result.rowcount
                
                # Mark contract attachments (if contract_files table exists)
                contract_count = 0
                if check_table_exists('contract_files'):
                    result = db.session.execute(text("""
                        UPDATE attachments a
                        SET 
                            purpose = CASE 
                                WHEN cf.purpose = 'signed' THEN 'contract_signed'
                                ELSE 'contract_original'
                            END,
                            origin_module = 'contracts'
                        FROM contract_files cf
                        WHERE cf.attachment_id = a.id
                        AND a.purpose = 'general_upload'
                    """))
                    contract_count = result.rowcount
                
                # Set origin_module for remaining general uploads
                db.session.execute(text("""
                    UPDATE attachments
                    SET origin_module = 'uploads'
                    WHERE purpose = 'general_upload' AND origin_module IS NULL
                """))
                
                migrations_applied.append("backfill_attachment_purpose_origin")
                checkpoint(f"‚úÖ Migration 84f complete: Backfilled {receipt_count} receipts, {contract_count} contracts")
            except Exception as e:
                db.session.rollback()
                checkpoint(f"‚ö†Ô∏è Migration 84f failed: {e}")
        
        checkpoint("‚úÖ Migration 84: Gmail Receipts Enhanced - Complete!")
        checkpoint("   üîí Security: Files now separated by purpose - contracts/receipts won't appear in email/whatsapp")
        
        checkpoint("Committing migrations to database...")
        if migrations_applied:
            db.session.commit()
            checkpoint(f"‚úÖ Applied {len(migrations_applied)} migrations: {', '.join(migrations_applied[:3])}...")
        else:
            checkpoint("No migrations needed - database is up to date")
        
        # üîí DATA PROTECTION CHECK: Verify data counts AFTER migrations - CRITICAL!
        # If FAQs or leads are deleted, ROLLBACK and FAIL the migration
        checkpoint("Starting data protection layer 3 - verifying no data loss")
        try:
            from sqlalchemy import text
            data_loss_detected = False
            
            if check_table_exists('faqs'):
                faq_count_after = db.session.execute(text("SELECT COUNT(*) FROM faqs")).scalar() or 0
                faq_delta = faq_count_after - faq_count_before
                if faq_delta < 0:
                    checkpoint(f"‚ùå DATA LOSS DETECTED: {abs(faq_delta)} FAQs were DELETED during migrations!")
                    data_loss_detected = True
                else:
                    checkpoint(f"‚úÖ DATA PROTECTION (AFTER): {faq_count_after} FAQs preserved (delta: +{faq_delta})")
            
            if check_table_exists('leads'):
                lead_count_after = db.session.execute(text("SELECT COUNT(*) FROM leads")).scalar() or 0
                lead_delta = lead_count_after - lead_count_before
                if lead_delta < 0:
                    checkpoint(f"‚ùå DATA LOSS DETECTED: {abs(lead_delta)} leads were DELETED during migrations!")
                    data_loss_detected = True
                else:
                    checkpoint(f"‚úÖ DATA PROTECTION (AFTER): {lead_count_after} leads preserved (delta: +{lead_delta})")
            
            # üõë ENFORCE DATA PROTECTION: Rollback and fail if FAQs or leads were deleted
            if data_loss_detected:
                db.session.rollback()
                error_msg = "‚ùå MIGRATION FAILED: Data loss detected. Rolling back changes."
                checkpoint(error_msg)
                raise Exception("Data protection violation: FAQs or leads were deleted during migration")
            
            # Messages can decrease (deduplication is expected and documented)
            if check_table_exists('messages'):
                msg_count_after = db.session.execute(text("SELECT COUNT(*) FROM messages")).scalar() or 0
                msg_delta = msg_count_after - msg_count_before
                if msg_delta < 0:
                    checkpoint(f"‚ö†Ô∏è Messages decreased by {abs(msg_delta)} (deduplication cleanup - expected)")
                else:
                    checkpoint(f"‚úÖ DATA PROTECTION (AFTER): {msg_count_after} messages (delta: +{msg_delta})")
        except Exception as e:
            if "Data protection violation" in str(e):
                raise  # Re-raise data protection violations
            
            # üî• CRITICAL FIX: ROLLBACK immediately to prevent InFailedSqlTransaction
            db.session.rollback()
            checkpoint(f"Could not verify data counts after migrations: {e}")
    
        checkpoint("‚úÖ Migration completed successfully!")
    
    # üîí CONCURRENCY PROTECTION: Release PostgreSQL advisory lock
    finally:
        if lock_acquired:
            try:
                db.session.execute(text("SELECT pg_advisory_unlock(1234567890)"))
                checkpoint("‚úÖ Released migration lock")
            except Exception as e:
                checkpoint(f"‚ö†Ô∏è Failed to release migration lock: {e}")
    
    return migrations_applied


if __name__ == '__main__':
    """
    Standalone execution: python -m server.db_migrate
    
    Runs migrations without eventlet or background workers.
    """
    import sys
    
    # Set migration mode
    import os
    os.environ['MIGRATION_MODE'] = '1'
    os.environ['ASYNC_LOG_QUEUE'] = '0'
    
    checkpoint("=" * 80)
    checkpoint("DATABASE MIGRATION RUNNER - Standalone Mode")
    checkpoint("=" * 80)
    
    # Validate DATABASE_URL
    database_url = os.getenv('DATABASE_URL')
    if not database_url:
        checkpoint("‚ùå DATABASE_URL environment variable is not set!")
        sys.exit(1)
    
    checkpoint(f"Database: {database_url.split('@')[0] if '@' in database_url else 'sqlite'}@***")
    
    try:
        # Create minimal app and run migrations
        checkpoint("Creating minimal Flask app context...")
        from server.app_factory import create_minimal_app
        app = create_minimal_app()
        
        checkpoint("Running migrations within app context...")
        with app.app_context():
            migrations = apply_migrations()
        
        checkpoint("=" * 80)
        checkpoint(f"‚úÖ SUCCESS - Applied {len(migrations)} migrations")
        checkpoint("=" * 80)
        sys.exit(0)
        
    except Exception as e:
        checkpoint("=" * 80)
        checkpoint(f"‚ùå MIGRATION FAILED: {e}")
        checkpoint("=" * 80)
        import traceback
        traceback.print_exc(file=sys.stderr)
        sys.exit(1)