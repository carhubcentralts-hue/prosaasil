import json
import logging
import os
import tempfile
from uuid import uuid4
from openai import OpenAI
from gtts import gTTS
from datetime import datetime

logger = logging.getLogger(__name__)

class AIService:
    def __init__(self):
        api_key = os.environ.get("OPENAI_API_KEY")
        if api_key:
            self.client = OpenAI(api_key=api_key)
            self.api_available = True
        else:
            self.client = None
            self.api_available = False
            logger.warning("OpenAI API key not found - using fallback responses")
        
        # The newest OpenAI model is "gpt-4o" which was released May 13, 2024.
        # Do not change this unless explicitly requested by the user
        self.model = "gpt-4o"
    
    def generate_response(self, user_input, business, conversation_history, caller_info):
        """Generate AI response for Hebrew conversation with enhanced fallback"""
        try:
            logger.info(f"ğŸ§  Generating AI response for: '{user_input}'")
            
            # CRITICAL: Check message limit first (6 messages max)
            if len(conversation_history) >= 6:
                logger.warning("Message limit reached - transferring to human agent")
                return {
                    'message': '× ×¨××” ×©××ª× ×–×§×•×§×™× ×œ×¢×–×¨×” ××¢××™×§×” ×™×•×ª×¨. ××¢×‘×™×¨ ××ª×›× ×œ× ×¦×™×’ ×”×× ×•×©×™ ×©×œ× ×• ×©×™×•×›×œ ×œ×¡×™×™×¢ ×‘×¦×•×¨×” ××•×ª×××ª.',
                    'continue_conversation': False,
                    'structured_data': None,
                    'transfer_to_agent': True
                }
            
            # Check for transfer to human based on unclear responses
            if self._should_transfer_to_human(conversation_history):
                logger.info("Transferring to human due to unclear conversation pattern")
                return {
                    'message': '×× ×™ ×¨×•×¦×” ×œ×•×•×“× ×©×ª×§×‘×œ×• ××ª ×”×©×™×¨×•×ª ×”×˜×•×‘ ×‘×™×•×ª×¨. ××—×‘×¨ ××ª×›× ×œ× ×¦×™×’ ×”×× ×•×©×™ ×©×œ× ×•.',
                    'continue_conversation': False,
                    'structured_data': None,
                    'transfer_to_agent': True
                }
            
            # Handle case where business is None
            if not business:
                logger.error("Business object is None")
                return {
                    'message': '××¦×˜×¢×¨, ×™×© ×‘×¢×™×” ×–×× ×™×ª ×‘××¢×¨×›×ª. ×× × × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨.',
                    'continue_conversation': False,
                    'structured_data': None
                }
            
            # Safely get business attributes
            business_name = getattr(business, 'name', '×”×¢×¡×§')
            business_type = getattr(business, 'business_type', '×¢×¡×§')
            system_prompt_text = getattr(business, 'system_prompt', '×©×™×¨×•×ª ××§×¦×•×¢×™')
            
            # Check API availability and test connection
            if not self._test_api_connection():
                return self._fallback_response_hebrew(user_input, business)
            
            # Build conversation context
            context = self._build_conversation_context(conversation_history)
            
            # Create comprehensive system prompt for Hebrew conversation
            system_prompt = f"""
××ª×” ×¢×•×–×¨ AI ××ª×§×“× ×‘×¨××” ×”×’×‘×•×”×” ×‘×™×•×ª×¨ ×¢×‘×•×¨ {business_name} ({business_type}).
××ª×” ××•××—×” ×‘×©×™×¨×•×ª ×œ×§×•×—×•×ª ×™×•×§×¨×ª×™ ×‘×¢×‘×¨×™×ª ×¢× ×™×›×•×œ×•×ª ××ª×§×“××•×ª.

××™×“×¢ ×¢×œ ×”×¢×¡×§:
{system_prompt_text}

ğŸ¯ ×”××•××—×™×•×ª ×©×œ×š:
1. ×”×‘× ×” ××•×©×œ××ª ×©×œ ×›×•×•× ×•×ª ×œ×§×•×— ×‘×¢×‘×¨×™×ª (intent recognition)
2. ×™×™×¢×•×¥ ××§×¦×•×¢×™ ×‘×ª×¤×¨×™×˜ ×¢× ×”××œ×¦×•×ª ××™×©×™×•×ª
3. ×”×–×× ×ª ×ª×•×¨×™× ××“×•×™×§×ª ×¢× ××™×©×•×¨ ××™×™×“×™
4. ×˜×™×¤×•×œ ×‘×‘×§×©×•×ª ××™×•×—×“×•×ª, ××œ×¨×’×™×•×ª ×•×¦×¨×›×™× ××™×•×—×“×™×
5. ××™×“×¢ ××“×•×™×§ ×¢×œ ××—×™×¨×™×, ×©×¢×•×ª ×•××™×§×•×
6. ×¢×–×¨×” ×‘××¨×’×•×Ÿ ××™×¨×•×¢×™× ×•×—×’×™×’×•×ª ×¤×¨×˜×™×•×ª

âš¡ ×›×œ×œ×™ ×¢×‘×•×“×” ××—××™×¨×™×:
- ×¢× ×” ×ª××™×“ ×‘×¢×‘×¨×™×ª ××•×©×œ××ª ×•××§×¦×•×¢×™×ª (ZERO ×× ×’×œ×™×ª!)
- ×”×™×” ×™×¢×™×œ, ××“×•×™×§ ×•××•×¢×™×œ ×‘-50-80 ××™×œ×™× ×‘×œ×‘×“
- ×ª××™×“ ×”×¦×™×¢ ×¤×ª×¨×•× ×•×ª ×™×¦×™×¨×ª×™×™× ×•×©×™×¨×•×ª VIP
- ×œ×ª×•×¨×™×: ×ª××¨×™×š ××œ× + ×©×¢×” + ××¡×¤×¨ ×¡×•×¢×“×™× + ×©× ××œ×
- ×× ×œ× ×™×•×“×¢ - ×”×¢×‘×¨ ×œ×¦×•×•×ª ×”××§×¦×•×¢×™ ×©×œ× ×•
- ×–×”×” ×¨×’×©×•×ª ×”×œ×§×•×— ×•×”×ª×× ××ª ×”×˜×•×Ÿ ×‘×”×ª××

×”×©×‘ ×¨×§ ×‘×¤×•×¨××˜ JSON ×‘×“×™×•×§ ×›×š:
{{
    "message": "×”×ª×’×•×‘×” ×©×œ×š ×‘×¢×‘×¨×™×ª ×œ×œ×§×•×—",
    "continue_conversation": true/false,
    "structured_data": {{}} ××• null
}}

×¢×‘×•×¨ ×‘×§×©×•×ª ×ª×•×¨, structured_data:
{{
    "type": "appointment", 
    "customer_name": "×©×",
    "customer_phone": "×˜×œ×¤×•×Ÿ", 
    "requested_date": "×ª××¨×™×š",
    "requested_service": "×©×™×¨×•×ª"
}}
"""
            
            # Build messages for GPT
            messages = [
                {"role": "system", "content": system_prompt}
            ]
            
            # Add conversation history for context
            for turn in conversation_history:
                role = "user" if turn.speaker == "user" else "assistant"
                messages.append({"role": role, "content": turn.message})
            
            # ×‘×“×™×§×ª ×”×’×‘×œ×ª ×”×•×“×¢×•×ª - ××¢×§×‘ ××—×¨ ×©×™×—×•×ª ××¨×•×›×•×ª
            message_count = len(conversation_history)
            if message_count >= 6:
                return {
                    "message": "×× ×™ ××¢×‘×™×¨ ××•×ª×š ×œ× ×¦×™×’ ×× ×•×©×™ ×©×™×•×›×œ ×œ×¢×–×•×¨ ×œ×š ×˜×•×‘ ×™×•×ª×¨. ×‘×”×§×“× ××™×©×”×• ×™×—×–×•×¨ ××œ×™×š.",
                    "continue_conversation": False,
                    "transfer_to_human": True,
                    "reason": "conversation_too_long"
                }

            # Add current user input
            messages.append({"role": "user", "content": user_input})
            
            # Call OpenAI API with explicit timeout
            print(f"ğŸ¤– GPT-4o generating response for: {user_input[:50]}...")
            print(f"â° [GPT] Starting with 10s timeout...")
            
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    response_format={"type": "json_object"},
                    max_tokens=500,
                    temperature=0.7,
                    timeout=10  # 10 second timeout as requested
                )
                print(f"âœ… [GPT] Response generated successfully")
            except Exception as gpt_error:
                print(f"âŒ [GPT] API call failed: {gpt_error}")
                logger.error(f"GPT-4o timeout or error: {gpt_error}")
                return {
                    'message': '××¦×˜×¢×¨×™×, ×™×© ×œ× ×• ×‘×¢×™×” ×˜×›× ×™×ª ×§×˜× ×”. ×× × × ×¡×• ×©×•×‘ ×‘×¢×•×“ ×¨×’×¢.',
                    'source': 'gpt_timeout',
                    'status': 'error',
                    'error': str(gpt_error)
                }
            
            # Parse response
            content = response.choices[0].message.content
            if content:
                try:
                    ai_response = json.loads(content)
                except json.JSONDecodeError:
                    # Fallback if response is not JSON
                    ai_response = {
                        'message': content,
                        'continue_conversation': True,
                        'structured_data': None
                    }
            else:
                raise ValueError("Empty response from OpenAI")
            
            # Add required log per instructions
            message = ai_response.get('message', '××¦×˜×¢×¨, ×œ× ×”×¦×œ×—×ª×™ ×œ×”×‘×™×Ÿ ××ª ×”×‘×§×©×”')
            print(f"ğŸ¤– GPT response: {ai_response}")
            logger.info(f"AI Response: {ai_response}")
            
            # CRITICAL FIX: Enhanced goodbye detection for proper conversation ending
            should_continue = ai_response.get('continue_conversation', True)
            
            # Additional goodbye detection based on user input - ××•×¨×—×‘
            goodbye_indicators = [
                '×ª×•×“×”', '×‘×™×™', '×œ×”×ª×¨××•×ª', '×–×”×•', '×–×” ×”×›×œ', '×¡×™×™××ª×™', 
                '×©×œ×•×', '× ×¢×™×', '×˜×•×‘', '×›×‘×¨ ×œ× ×¦×¨×™×š', '××™×Ÿ ×œ×™ ×™×•×ª×¨',
                '×©×™×”×™×” ×‘×”×¦×œ×—×”', '× ×¢×™× ×”×™×”', '×¢×“ ×”×¤×¢× ×”×‘××”',
                '×ª×•×“×” ×¨×‘×”', '×‘×¡×“×¨ ×‘×™×™', '× ×ª×¨××”', '×™××œ×œ×” ×‘×™×™',
                '×¢×“ ×›××Ÿ', '×× ×™ × ×’××¨', '×¡×œ×××”', '×—×‘×œ ×¢×œ ×”×–××Ÿ',
                '×× ×™ ×¡×•×’×¨', '××¡×¤×™×§', '×× ×™ ××’××•×¨', '× ×’××¨ ×œ×™'
            ]
            
            # Check user input for goodbye
            if any(word in user_input.lower() for word in goodbye_indicators):
                should_continue = False
                print(f"ğŸ›‘ GOODBYE detected in user input: '{user_input}'")
            
            # Check AI response for goodbye
            if any(phrase in message.lower() for phrase in ['×™×•× ×˜×•×‘', '×ª×•×“×” ×¨×‘×”', '× ×¢×™× ×œ×¤×’×•×©', '×©×™×”×™×” ×‘×”×¦×œ×—×”']):
                should_continue = False
                print(f"ğŸ›‘ GOODBYE detected in AI response: '{message}'")
            
            return {
                'message': message,
                'continue_conversation': should_continue,
                'structured_data': ai_response.get('structured_data')
            }
            
        except Exception as e:
            logger.error(f"Error generating AI response: {str(e)}")
            return self._fallback_response_hebrew(user_input, business)
    
    def _test_api_connection(self):
        """Test OpenAI API connection"""
        if not self.client or not self.api_available:
            return False
        
        try:
            # Quick test to verify API key works
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "test"}],
                max_tokens=1
            )
            return True
        except Exception as e:
            logger.error(f"OpenAI API test failed: {e}")
            self.api_available = False
            return False
    
    def _fallback_response_hebrew(self, user_input, business):
        """Generate fallback response when OpenAI is not available"""
        user_lower = user_input.lower()
        
        # Get business details safely
        business_name = getattr(business, 'name', business.get('name', '×”××¡×¢×“×”') if isinstance(business, dict) else '×”××¡×¢×“×”')
        business_type = getattr(business, 'business_type', business.get('business_type', 'restaurant') if isinstance(business, dict) else 'restaurant')
        
        # Debug logging
        logger.info(f"Processing input: '{user_input}' for business: {business_name} ({business_type})")
        
        # INTELLIGENT Hebrew responses based on keywords and business context
        if any(word in user_lower for word in ['×ª×•×¨', '×¤×’×™×©×”', '×”×–×× ×”', '×œ×§×‘×•×¢', '×œ×–××Ÿ', '×©×•×œ×—×Ÿ']):
            if business_type == '××¡×¢×“×”' or business_type == 'restaurant':
                message = f"×‘×”×—×œ×˜! ××©××— ×œ×¢×–×•×¨ ×œ×›× ×œ×§×‘×•×¢ ×©×•×œ×—×Ÿ ×‘{business_name}. ×‘××™×–×” ×ª××¨×™×š ×•×©×¢×” ×ª×¨×¦×•? ×›××” ×× ×©×™×?"
            else:
                message = f"××©××— ×œ×¢×–×•×¨ ×œ×›× ×œ×§×‘×•×¢ ×ª×•×¨ ×‘{business_name}. ××” ×”×©× ×©×œ×›× ×•××ª×™ ××ª××™× ×œ×›×?"
                
        elif any(word in user_lower for word in ['×©×¢×•×ª', '×¤×ª×•×—', '×–××™× ×•×ª', '××ª×™', '×–××Ÿ']):
            if business_type == '××¡×¢×“×”' or business_type == 'restaurant':
                message = f"{business_name} ×¤×ª×•×— ×›×œ ×™×•× ×‘×™×Ÿ ×”×©×¢×•×ª 12:00-23:00. ×”×× ×ª×¨×¦×• ×œ×§×‘×•×¢ ×©×•×œ×—×Ÿ?"
            else:
                message = f"{business_name} ×¤×•×¢×œ ×œ×¤×™ ×©×¢×•×ª ×”×¢×‘×•×“×”. ××™×–×” ×–××Ÿ ××ª××™× ×œ×›× ×œ×§×‘×•×¢?"
                
        elif any(word in user_lower for word in ['××—×™×¨', '×¢×œ×•×ª', '×›××”', '××—×™×¨×•×Ÿ']):
            if business_type == '××¡×¢×“×”' or business_type == 'restaurant':
                message = "×”××—×™×¨×™× ×©×œ× ×• ×ª×—×¨×•×ª×™×™× ×××•×“! ×™×© ×œ× ×• ×ª×¤×¨×™×˜ ××’×•×•×Ÿ ×¢× ×× ×•×ª ×‘×©×¨, ×“×’×™× ×•×¦××—×•× ×™×•×ª. ××” ×”×˜×¢× ×©×œ×›×?"
            else:
                message = "×”××—×™×¨×™× ×©×œ× ×• ×”×•×’× ×™× ×•×™×“×™×“×•×ª×™×™×. ×ª×•×›×œ×• ×œ×§×‘×œ ×¤×¨×˜×™× ××“×•×™×§×™× ×›×©× ×ª×× ×¤×’×™×©×”."
                
        elif any(word in user_lower for word in ['×ª×¤×¨×™×˜', '×× ×•×ª', '××•×›×œ', '××” ×™×©', '×¦××—×•× ×™', '×‘×©×¨', '×× ×”', '×“×’×™×', '×¤×™×¦×”', '×¤×™×¦×•×ª']):
            logger.info(f"Detected menu question - business_type: {business_type}")
            if business_type == '××¡×¢×“×”' or business_type == 'restaurant':
                message = f"×”×ª×¤×¨×™×˜ ×©×œ {business_name} ××’×•×•×Ÿ ×•××¢×•×œ×”! ×™×© ×œ× ×• ×× ×•×ª ×‘×©×¨, ×“×’×™×, ×¤×™×¦×•×ª ×•××‘×—×¨ ×× ×•×ª ×¦××—×•× ×™×•×ª. ××” ×”×˜×¢× ×©×œ×›×?"
            else:
                message = f"× ×©××— ×œ×¡×¤×¨ ×œ×›× ×¢×œ ×›×œ ×”×©×™×¨×•×ª×™× ×‘{business_name}. ×ª×•×›×œ×• ×œ×¤×¨×˜ ××” ××ª× ××—×¤×©×™×?"
                
        elif any(word in user_lower for word in ['×©×œ×•×', '×”×™×™', '×˜×•×‘', '×‘×•×§×¨', '×¢×¨×‘']):
            if business_type == 'restaurant':
                message = f"×©×œ×•× ×•×‘×¨×•×›×™× ×”×‘××™× ×œ{business_name}! ×”×’×¢×ª× ×œ××¡×¢×“×” ×”××•×‘×™×œ×”. ××™×š ××•×›×œ ×œ×¢×–×•×¨ ×œ×›× ×”×™×•×?"
            else:
                message = f"×©×œ×•× ×•×‘×¨×•×›×™× ×”×‘××™× ×œ{business_name}! ××™×š ××•×›×œ ×œ×¢×–×•×¨ ×œ×›×?"
                
        elif any(word in user_lower for word in ['×ª×•×“×”', '×‘×¡×“×¨', '×œ×”×ª×¨××•×ª', '×©×œ×•×']):
            message = f"×ª×•×“×” ×¨×‘×” ×©×¤× ×™×ª× ×œ{business_name}! × ×©××— ×œ×¨××•×ª ××ª×›× ××¦×œ× ×•. ×™×•× × ×”×“×¨!"
            
        else:
            # Smart generic response based on business type
            if business_type == 'restaurant':
                message = f"×©×œ×•×! ×–×” {business_name} - ×”××¡×¢×“×” ×©×œ×›× ×œ×—×•×•×™×” ×§×•×œ×™× ×¨×™×ª ××¢×•×œ×”. ×ª×•×›×œ×• ×œ×§×‘×•×¢ ×©×•×œ×—×Ÿ, ×œ×©××•×œ ×¢×œ ×”×ª×¤×¨×™×˜ ××• ×›×œ ×“×‘×¨ ××—×¨!"
            else:
                message = f"×©×œ×•×! ××ª× ××“×‘×¨×™× ×¢× {business_name}. ××™×š ××•×›×œ ×œ×¢×–×•×¨ ×œ×›×? ×ª×•×›×œ×• ×œ×¤×¨×˜ ××ª ×”×‘×§×©×” ×©×œ×›×."
        
        return {
            "message": message,
            "continue_conversation": True,
            "structured_data": None
        }
    
    def process_hebrew_conversation(self, user_text, business_id, call_sid):
        """Process Hebrew conversation - the function that was missing!"""
        try:
            from models import Business, ConversationTurn
            
            # Get business
            business = Business.query.get(business_id) if business_id else Business.query.first()
            if not business:
                return {"message": "××¦×˜×¢×¨, ×™×© ×‘×¢×™×” ×‘××¢×¨×›×ª."}
            
            # Get conversation history
            conversation_history = ConversationTurn.query.filter_by(call_sid=call_sid).all()
            
            # Generate response using existing method
            response = self.generate_response(user_text, business, conversation_history, {})
            
            # Save conversation turn to database
            try:
                from app import db
                # Save user message
                user_turn = ConversationTurn(
                    call_sid=call_sid,
                    speaker='user',
                    message=user_text,
                    confidence_score=1.0
                )
                db.session.add(user_turn)
                
                # Save AI response
                ai_turn = ConversationTurn(
                    call_sid=call_sid,
                    speaker='ai',
                    message=response.get('message', ''),
                    confidence_score=1.0
                )
                db.session.add(ai_turn)
                db.session.commit()
                
                logger.info(f"âœ… Saved conversation turn for call {call_sid}")
            except Exception as db_error:
                logger.error(f"âŒ Failed to save conversation: {db_error}")
            
            return response
            
        except Exception as e:
            logger.error(f"âŒ Error in process_hebrew_conversation: {e}")
            return {"message": "××¦×˜×¢×¨, ×™×© ×‘×¢×™×” ×˜×›× ×™×ª. ××™×š ××•×›×œ ×œ×¢×–×•×¨?"}
    
    def generate_whatsapp_response(self, business_id, customer_message, conversation_history=None):
        """Generate WhatsApp AI response"""
        try:
            from models import Business
            business = Business.query.get(business_id) if business_id else Business.query.first()
            if not business:
                return {"response": "×©×œ×•×! ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?"}
            
            response = self.generate_response(customer_message, business, conversation_history or [], {})
            return {
                "response": response.get("message", "×©×œ×•×! ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?"),
                "continue": response.get("continue_conversation", True)
            }
        except Exception as e:
            logger.error(f"Error in generate_whatsapp_response: {e}")
            return {"response": "×©×œ×•×! ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?"}
    
    def process_structured_data(self, call_log_id, structured_data):
        """Process structured data from AI response (appointments, etc.)"""
        try:
            if structured_data and structured_data.get('type') == 'appointment':
                # Create appointment request
                appointment = AppointmentRequest(
                    call_log_id=call_log_id,
                    customer_name=structured_data.get('customer_name'),
                    customer_phone=structured_data.get('customer_phone'),
                    requested_service=structured_data.get('requested_service'),
                    status='pending'
                )
                
                # Parse requested date if provided
                if structured_data.get('requested_date'):
                    try:
                        appointment.requested_date = datetime.fromisoformat(
                            structured_data['requested_date']
                        )
                    except ValueError:
                        logger.warning(f"Invalid date format: {structured_data['requested_date']}")
                
                db.session.add(appointment)
                logger.info(f"Created appointment request for call {call_log_id}")
                
        except Exception as e:
            logger.error(f"Error processing structured data: {str(e)}")
    
    def _build_conversation_context(self, conversation_history):
        """Build conversation context from history"""
        context = []
        for turn in conversation_history[-10:]:  # Last 10 turns
            speaker = "×œ×§×•×—" if turn.speaker == "user" else "×¢×•×–×¨"
            context.append(f"{speaker}: {turn.message}")
        
        return "\n".join(context)
    
    def transcribe_hebrew_audio(self, audio_path):
        """Convert Hebrew audio to text using OpenAI Whisper"""
        if not self.api_available:
            logger.warning("OpenAI API not available for transcription")
            return ""
        
        try:
            with open(audio_path, "rb") as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="he"  # Hebrew language
                )
                hebrew_text = transcript.text
                logger.info(f"ğŸ¤ Transcribed Hebrew: {hebrew_text}")
                return hebrew_text
        except Exception as e:
            logger.error(f"âŒ Error in transcription: {e}")
            return ""
    
    def synthesize_hebrew_speech(self, text):
        """×™×¦×™×¨×ª ×ª×’×•×‘×” ×¢×‘×¨×™×ª ×™×©×™×¨×” - NO AUDIO FILES"""
        try:
            logger.info(f"ğŸ”Š Returning direct Hebrew text instead of audio: {text}")
            return text  # Return text directly instead of audio file
                
        except Exception as e:
            logger.error(f"âŒ Error in Hebrew TTS: {e}")
            return text
            
    def _is_request_clear(self, user_input):
        """×‘×“×™×§×” ×”×× ×”×‘×§×©×” ×‘×¨×•×¨×” ×•××•×‘× ×ª"""
        if not user_input or len(user_input.strip()) < 2:
            return False
            
        # ×‘×“×™×§×ª ××™×œ×™× ××•×‘× ×•×ª ×‘×¢×‘×¨×™×ª
        clear_words = [
            '×ª×•×¨', '×”×–×× ×”', '×©×œ×•×', '××™×“×¢', '×©×¢×•×ª', '×¤×ª×•×—', '×¡×’×•×¨',
            '××—×™×¨', '×¢×œ×•×ª', '×›××”', '××™×š', '××”', '××™×¤×”', '××ª×™',
            '×¨×•×¦×”', '×¦×¨×™×š', '××¤×©×¨', '×™×›×•×œ', '×‘×‘×§×©×”', '×ª×•×“×”'
        ]
        
        # ×‘×“×™×§×” ×× ×™×© ×œ×¤×—×•×ª ××™×œ×” ××—×ª ××•×‘× ×ª
        return any(word in user_input.lower() for word in clear_words)
        
    def _should_transfer_to_human(self, user_input, conversation_history):
        """×‘×“×™×§×” ×”×× ×¦×¨×™×š ×œ×”×¢×‘×™×¨ ×œ×¦×•×•×ª ×××™×ª×™"""
        transfer_triggers = [
            '×¨×•×¦×” ×œ×“×‘×¨ ×¢× ××“×', '××“× ×××™×ª×™', '×× ×”×œ', '×ª×œ×•× ×”',
            '×œ× ××‘×™×Ÿ', '×œ× ×¢×•×–×¨', '×‘×¢×™×”', '×›×•×¢×¡', '×–×” ×œ× ×¢×•×‘×“'
        ]
        
        # ×× ×™×© 3+ ×¡×™×‘×•×‘×™ ×©×™×—×” ×œ×œ× ×¤×ª×¨×•×Ÿ
        if len(conversation_history) >= 6:
            return True
            
        # ×× ×™×© ×‘×™×˜×•×™×™ ×ª×¡×›×•×œ
        return any(trigger in user_input.lower() for trigger in transfer_triggers)
