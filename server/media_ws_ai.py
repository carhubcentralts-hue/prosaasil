"""
WebSocket Media Stream Handler - AI Mode with Hebrew TTS
ADVANCED VERSION WITH TURN-TAKING, BARGE-IN, AND LOOP PREVENTION
"""
import os, json, time, base64, audioop, math, threading, queue, random, zlib
# Using Flask-Sock for WebSocket handling  
from simple_websocket import ConnectionClosed
from server.stream_state import stream_registry

SR = 8000
# ğŸ¯ ×¤×¨××˜×¨×™× ××•×ª×××™× ×œ×©×™×—×” ××”×™×¨×” ×•×—×œ×§×”!
MIN_UTT_SEC = float(os.getenv("MIN_UTT_SEC", "0.8"))        # ×–××Ÿ ××™× ×™××œ×™ ×œ×ª××œ×•×œ ××™×›×•×ª×™
MAX_UTT_SEC = float(os.getenv("MAX_UTT_SEC", "3.5"))        # ××•× ×¢ ××•× ×•×œ×•×’×™× ××¨×•×›×™×
VAD_RMS = int(os.getenv("VAD_RMS", "90"))                   # ×¤×—×•×ª ×¨×’×™×© - ××•× ×¢ ×—×™×ª×•×›×™×
BARGE_IN = os.getenv("BARGE_IN", "true").lower() == "true"
VAD_HANGOVER_MS = int(os.getenv("VAD_HANGOVER_MS", "200"))  # ×™×•×ª×¨ ×¡×‘×œ× ×•×ª
RESP_MIN_DELAY_MS = int(os.getenv("RESP_MIN_DELAY_MS", "50")) # ×ª×’×•×‘×” ××”×™×¨×”!
RESP_MAX_DELAY_MS = int(os.getenv("RESP_MAX_DELAY_MS", "100")) # ×œ×œ× ×”×©×”×™×•×ª ××™×•×ª×¨×•×ª
REPLY_REFRACTORY_MS = int(os.getenv("REPLY_REFRACTORY_MS", "400")) # ×§×™×¨×•×¨ ×§×¦×¨ ×™×•×ª×¨
BARGE_IN_VOICE_FRAMES = int(os.getenv("BARGE_IN_VOICE_FRAMES","15"))  # 300ms ×œ×¤× ×™ ×”×¤×¨×¢×”
THINKING_HINT_MS = int(os.getenv("THINKING_HINT_MS", "0"))       # ×‘×œ×™ "×‘×•×“×§×ª" - ×™×©×™×¨×•×ª ×œ×¢×‘×•×“×”!
THINKING_TEXT_HE = os.getenv("THINKING_TEXT_HE", "")   # ××™×Ÿ ×”×•×“×¢×ª ×—×©×™×‘×”
DEDUP_WINDOW_SEC = int(os.getenv("DEDUP_WINDOW_SEC", "8"))        # ×—×œ×•×Ÿ ×§×¦×¨ ×™×•×ª×¨
LLM_NATURAL_STYLE = True  # ×ª×’×•×‘×•×ª ×˜×‘×¢×™×•×ª ×œ×¤×™ ×”×©×™×—×”

# ××›×•× ×ª ××¦×‘×™×
STATE_LISTEN = "LISTENING"
STATE_THINK  = "THINKING"
STATE_SPEAK  = "SPEAKING"

class MediaStreamHandler:
    def __init__(self, ws):
        self.ws = ws
        self.mode = "AI"  # ×ª××™×“ ×‘××¦×‘ AI
        
        # ğŸ”§ ×ª××™××•×ª WebSocket - EventLet vs RFC6455 ×¢× ×˜×™×¤×•×œ ×©×’×™××•×ª
        if hasattr(ws, 'send'):
            self._ws_send_method = ws.send
        else:
            # ×× ××™×Ÿ send, × ×¡×” send_text ××• ×›×œ ×©×™×˜×” ××—×¨×ª
            self._ws_send_method = getattr(ws, 'send_text', lambda x: print(f"âŒ No send method: {x}"))
        
        # ğŸ›¡ï¸ Safe WebSocket send wrapper
        def _safe_ws_send(data):
            try:
                self._ws_send_method(data)
            except Exception as e:
                print(f"âŒ WebSocket send error (recovered): {e}")
                # Don't re-raise - keep connection alive
        
        self._ws_send = _safe_ws_send
        self.stream_sid = None
        self.call_sid = None  # PATCH 3: For watchdog connection
        self.rx = 0
        self.tx = 0
        
        # ğŸ¯ ×¤×ª×¨×•×Ÿ ×¤×©×•×˜ ×•×™×¢×™×œ ×œ× ×™×”×•×œ ×ª×•×¨×•×ª
        self.buf = bytearray()
        self.last_rx = None
        self.speaking = False           # ×”×× ×”×‘×•×˜ ××“×‘×¨ ×›×¨×’×¢
        self.processing = False         # ×”×× ××¢×‘×“ ××‘×¢ ×›×¨×’×¢
        self.conversation_id = 0        # ××•× ×” ×©×™×—×•×ª ×œ×× ×™×¢×ª ×›×¤×™×œ×•×™×•×ª
        self.last_processing_id = -1    # ××–×”×” ×”×¢×™×‘×•×“ ×”××—×¨×•×Ÿ
        self.response_timeout = None    # ×–××Ÿ ×ª×’×•×‘×” ××§×¡×™××œ×™
        
        # ×“×”-×“×•×¤×œ×™×§×¦×™×” ××ª×§×“××ª ×¢× hash
        self.last_user_hash = None
        self.last_user_hash_ts = 0.0
        self.last_reply_hash = None
        self.introduced = False
        self.response_history = []       # ×”×™×¡×˜×•×¨×™×™×ª ×ª×’×•×‘×•×ª
        self.last_tts_end_ts = 0.0
        self.voice_in_row = 0
        self.greeting_sent = False
        self.state = STATE_LISTEN        # ××¦×‘ × ×•×›×—×™
        
        # âœ… ×ª×™×§×•×Ÿ ×§×¨×™×˜×™: ××¢×§×‘ × ×¤×¨×“ ××—×¨ ×§×•×œ ×•×©×§×˜
        self.last_voice_ts = 0.0         # ×–××Ÿ ×”×§×•×œ ×”××—×¨×•×Ÿ - ×œ×—×™×©×•×‘ ×“×××” ×××™×ª×™
        self.noise_floor = 35.0          # ×¨××ª ×¨×¢×© ×‘×¡×™×¡×™×ª
        self.vad_threshold = 35.0        # ×¡×£ VAD ×“×™× ××™
        self.is_calibrated = False       # ×”×× ×›×•×™×œ×¨× ×• ××ª ×¨××ª ×”×¨×¢×©
        self.calibration_frames = 0      # ××•× ×” ×¤×¨×™×™××™× ×œ×›×™×•×œ
        self.mark_pending = False        # ×”×× ×××ª×™× ×™× ×œ×¡×™××•×Ÿ TTS
        self.mark_sent_ts = 0.0          # ×–××Ÿ ×©×œ×™×—×ª ×¡×™××•×Ÿ
        
        # ×”×’× ×•×ª Watchdog
        self.processing_start_ts = 0.0   # ×ª×—×™×œ×ª ×¢×™×‘×•×“
        self.speaking_start_ts = 0.0     # ×ª×—×™×œ×ª ×“×™×‘×•×¨
        
        # âœ… WebSocket Keepalive ×œ×× ×™×¢×ª × ×¤×™×œ×•×ª ××—×¨×™ 5 ×“×§×•×ª
        self.last_keepalive_ts = 0.0     # ×–××Ÿ keepalive ××—×¨×•×Ÿ
        self.keepalive_interval = 18.0   # ×©×œ×— ×›×œ 18 ×©× ×™×•×ª
        self.heartbeat_counter = 0       # ××•× ×” heartbeat
        
        # TX Queue for smooth audio transmission
        self.tx_q = queue.Queue(maxsize=4096)
        self.tx_running = False
        self.tx_thread = threading.Thread(target=self._tx_loop, daemon=True)
        
        print("ğŸ¯ AI CONVERSATION STARTED")

    def run(self):
        # Media stream handler initialized")
        
        # CRITICAL FIX: Ensure json import is available
        import json
        
        # Write debug to MULTIPLE LOCATIONS for guaranteed persistence
        timestamp = int(time.time())
        debug_files = [
            f"/tmp/ws_handler_debug_{timestamp}.txt",
            f"/tmp/websocket_debug.txt",
            f"/tmp/handler_called.txt",
            f"/home/runner/workspace/handler_debug.txt",
            f"/tmp/HANDLER_WORKS_{timestamp}.txt"
        ]
        
        success_count = 0
        for debug_file in debug_files:
            try:
                with open(debug_file, "w") as f:
                    f.write(f"HANDLER_START: {self.stream_sid} at {time.time()}\n")
                    f.write(f"WEBSOCKET_HANDLER_DEFINITELY_WORKS!\n")
                    f.write(f"CONNECTION_SUCCESSFUL: {timestamp}\n")
                    f.flush()
                success_count += 1
                print(f"âœ… Debug written to {debug_file}", flush=True)
            except Exception as e:
                print(f"âŒ Failed to write {debug_file}: {e}", flush=True)
        
        print(f"âœ… Debug files written: {success_count}/{len(debug_files)}", flush=True)
        
        # PATCH 4: Advanced logging counters
        self.rx_frames = 0
        self.tx_frames = 0
        
        print(f"WS_START sid={self.stream_sid} mode=AI call_sid={self.call_sid}")
        print(f"ğŸ¯ CONVERSATION READY (VAD threshold: {VAD_RMS})")
        
        try:
            while True:
                # COMPATIBILITY: Handle both EventLet and Flask-Sock WebSocket APIs
                raw = None
                try:
                    # Simplified WebSocket handling - no spam logs
                    ws_type = str(type(self.ws))
                    
                    # RFC6455WebSocket-specific handling (EventLet)
                    if 'RFC6455WebSocket' in ws_type:
                        # EventLet RFC6455WebSocket uses wait() method
                        raw = self.ws.wait()
                        # ×¨×§ ×¡×¤×™×¨×” ×‘×œ×™ spam
                        self.rx_frames += 1
                    else:
                        # Standard WebSocket APIs
                        if hasattr(self.ws, 'receive'):
                            raw = self.ws.receive()
                        elif hasattr(self.ws, 'recv'):
                            raw = self.ws.recv()
                        elif hasattr(self.ws, 'read_message'):
                            raw = self.ws.read_message()
                        elif hasattr(self.ws, 'receive_data'):
                            raw = self.ws.receive_data()
                        elif hasattr(self.ws, 'read'):
                            raw = self.ws.read()
                        else:
                            print(f"âš ï¸ Unknown WebSocket type: {type(self.ws)}, available methods: {[m for m in dir(self.ws) if not m.startswith('_')]}", flush=True)
                            raise Exception(f"No compatible receive method found for {type(self.ws)}")
                        
                    if raw is None or raw == '':
                        print("ğŸ“ WebSocket connection closed normally", flush=True)
                        break
                        
                    # Handle both string and bytes
                    if isinstance(raw, bytes):
                        raw = raw.decode('utf-8')
                        
                    evt = json.loads(raw)
                    et = evt.get("event")
                    
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ Invalid JSON received: {str(raw)[:100] if raw else 'None'}... Error: {e}", flush=True)
                    continue
                except Exception as e:
                    print(f"âš ï¸ WebSocket receive error: {e}", flush=True)
                    import traceback
                    traceback.print_exc()
                    # Try to continue, might be temporary - don't crash the connection
                    continue

                if et == "start":
                    # ×ª××™×›×” ×‘×©× ×™ ×¤×•×¨××˜×™×: Twilio ×××™×ª×™ ×•×‘×“×™×§×•×ª
                    if "start" in evt:
                        # Twilio format: {"event": "start", "start": {"streamSid": "...", "callSid": "..."}}
                        self.stream_sid = evt["start"]["streamSid"]
                        self.call_sid = (
                            evt["start"].get("callSid")
                            or (evt["start"].get("customParameters") or {}).get("CallSid")
                            or (evt["start"].get("customParameters") or {}).get("call_sid")
                        )
                    else:
                        # Direct format: {"event": "start", "streamSid": "...", "callSid": "..."}
                        self.stream_sid = evt.get("streamSid")
                        self.call_sid = evt.get("callSid")
                    self.last_rx_ts = time.time()
                    self.last_keepalive_ts = time.time()  # âœ… ×”×ª×—×œ keepalive
                    print(f"ğŸ¯ WS_START sid={self.stream_sid} call_sid={self.call_sid} mode={self.mode}")
                    if self.call_sid:
                        stream_registry.mark_start(self.call_sid)
                    
                    # âœ… ×‘×¨×›×” ××™×™×“×™×ª - ×‘×œ×™ ×”×©×”×™×”!
                    if not self.tx_running:
                        self.tx_running = True
                        self.tx_thread.start()
                    
                    if not self.greeting_sent:
                        print("ğŸ¯ SENDING IMMEDIATE GREETING!")
                        greet = "×©×œ×•×, ×œ××” ××§×¡×™××•×¡ × ×“×œ×Ÿ. ××™×–×” ××–×•×¨ ××¢× ×™×™×Ÿ ××•×ª×š?"
                        self._speak_simple(greet)
                        self.greeting_sent = True
                    continue

                if et == "media":
                    self.rx += 1
                    b64 = evt["media"]["payload"]
                    mulaw = base64.b64decode(b64)
                    pcm16 = audioop.ulaw2lin(mulaw, 2)
                    self.last_rx_ts = time.time()
                    if self.call_sid:
                        stream_registry.touch_media(self.call_sid)
                    
                    # ××“×“ ×“×™×‘×•×¨/×©×§×˜ (VAD) - ×–×™×”×•×™ ×§×•×œ ×—×–×§ ×‘×œ×‘×“
                    rms = audioop.rms(pcm16, 2)
                    
                    # ğŸ“Š VAD ×“×™× ××™ ××©×•×¤×¨ ×¢× ×§×œ×™×‘×¨×¦×™×” ××¨×•×›×” ×™×•×ª×¨ ×•×”×™×¡×˜×¨×–×™×¡
                    if not self.is_calibrated and self.calibration_frames < 40:
                        # ×§×œ×™×‘×¨×¦×™×” ××¨×•×›×” ×™×•×ª×¨: 300-500ms = 15-25 frames, × ×©×ª××© ×‘-40 ×œ×”×™×•×ª ×‘×˜×•×—×™×
                        self.noise_floor = (self.noise_floor * self.calibration_frames + rms) / (self.calibration_frames + 1)
                        self.calibration_frames += 1
                        if self.calibration_frames >= 60:
                            # âœ… VAD ×¨×’×™×© ×”×¨×‘×” ×™×•×ª×¨ - threshold × ××•×š ×™×•×ª×¨
                            self.vad_threshold = max(35, self.noise_floor * 2.2 + 8)
                            self.is_calibrated = True
                            print(f"ğŸ›ï¸ VAD CALIBRATED (threshold: {self.vad_threshold:.1f})")
                            
                            # ×”×™×¡×˜×¨×–×™×¡ ×œ×× ×™×¢×ª ×¨×™×¦×•×“
                            if not hasattr(self, 'vad_hysteresis_count'):
                                self.vad_hysteresis_count = 0
                            if not hasattr(self, 'last_vad_state'):
                                self.last_vad_state = False
                    
                    # ğŸ“Š ×–×™×”×•×™ ×§×•×œ ××©×•×¤×¨ ×¢× ×”×™×¡×˜×¨×–×™×¡ ×•-Zero-Crossing Rate
                    if self.is_calibrated:
                        # ×—×™×©×•×‘ Zero-Crossing Rate ×œ××“×™×“×ª ×“×™×‘×•×¨ ×¨×š
                        import numpy as np
                        try:
                            pcm_np = np.frombuffer(pcm16, dtype=np.int16)
                            zero_crossings = np.sum(np.diff(np.sign(pcm_np)) != 0) / len(pcm_np) if len(pcm_np) > 0 else 0
                        except:
                            zero_crossings = 0
                        
                        # VAD ×‘×¡×™×¡×™
                        basic_voice = rms > self.vad_threshold
                        
                        # VAD ××©×•×¤×¨ ×¢× Zero-Crossing Rate
                        zcr_voice = zero_crossings > 0.05  # ×“×™×‘×•×¨ ×¨×š ×¢× ×”×¨×‘×” ××¢×‘×¨×™ ××¤×¡
                        enhanced_voice = basic_voice or (zcr_voice and rms > self.vad_threshold * 0.6)
                        
                        # ×”×™×¡×˜×¨×–×™×¡: 100ms = 5 frames ×œ×× ×™×¢×ª ×¨×™×¦×•×“
                        if enhanced_voice != self.last_vad_state:
                            self.vad_hysteresis_count += 1
                            if self.vad_hysteresis_count >= 5:  # 100ms ×”×™×¡×˜×¨×–×™×¡ ×—×–×§ ×™×•×ª×¨
                                is_strong_voice = enhanced_voice
                                self.last_vad_state = enhanced_voice
                                self.vad_hysteresis_count = 0
                            else:
                                is_strong_voice = self.last_vad_state  # ×”×©××¨ ××¦×‘ ×§×•×“×
                        else:
                            is_strong_voice = enhanced_voice
                            self.vad_hysteresis_count = 0
                    else:
                        # ×œ×¤× ×™ ×§×œ×™×‘×¨×¦×™×” - VAD ×¤×©×•×˜
                        is_strong_voice = rms > 60
                    
                    # âœ… ×ª×™×§×•×Ÿ ×§×¨×™×˜×™: ×¢×“×›×Ÿ last_voice_ts ×¨×§ ×›×©×™×© ×§×•×œ ×××™×ª×™
                    current_time = time.time()
                    if is_strong_voice:
                        self.last_voice_ts = current_time
                    
                    # ×—×™×©×•×‘ ×“×××” ×××™×ª×™ - ×××– ×”×§×•×œ ×”××—×¨×•×Ÿ! 
                    # ×× ××™×Ÿ ×§×•×œ ×‘×›×œ×œ, ×“×××” = 0 (×›×“×™ ×©×œ× × ×ª×§×¢)
                    silence_time = (current_time - self.last_voice_ts) if self.last_voice_ts > 0 else 0
                    
                    # âœ… ×œ×•×’×™× × ×§×™×™× - ×¨×§ ××™×¨×•×¢×™× ×—×©×•×‘×™× (×œ× ×›×œ frame)  
                    
                    # ×¡×¤×™×¨×ª ×¤×¨×™×™××™× ×¨×¦×•×¤×™× ×©×œ ×§×•×œ ×—×–×§ ×‘×œ×‘×“
                    if is_strong_voice:
                        self.voice_in_row += 1
                    else:
                        self.voice_in_row = max(0, self.voice_in_row - 2)  # ×§×™×–×•×– ××”×™×¨ ×œ×¨×¢×©×™×

                    # âš¡ BARGE-IN ××©×•×¤×¨: ×¢×¦×™×¨×ª TTS ××™×™×“×™×ª ×¢× ×—×œ×•×Ÿ ×—×¡×“ ×œ×¤×™ ×”×”× ×—×™×•×ª
                    if self.speaking and BARGE_IN:
                        # âœ… ×—×œ×•×Ÿ ×—×¡×“ ×œ×¤×™ ×”×”× ×—×™×•×ª: 200ms ××—×¨×™ ×ª×—×™×œ×ª TTS
                        grace_period = 0.2  # 200ms ×—×œ×•×Ÿ ×—×¡×“ ××“×•×™×§
                        time_since_tts_start = current_time - self.speaking_start_ts
                        
                        if time_since_tts_start < grace_period:
                            # ×‘×ª×•×š ×—×œ×•×Ÿ ×”×—×¡×“ - ×”×ª×¢×œ× ×-barge-in
                            continue
                        
                        # ×¡×£ ×‘××¨×’-××™×Ÿ ××“×•×™×§: noise_floor*2.2+10 (×œ× ×¨×¢×© ×¨×’×™×œ)
                        barge_in_threshold = max(50, self.noise_floor * 2.2 + 10) if self.is_calibrated else 80
                        is_barge_in_voice = rms > barge_in_threshold
                        
                        if is_barge_in_voice:
                            self.voice_in_row += 1
                            # 180-220ms ×©×œ ×§×•×œ ×¨×¦×™×£ = 9-11 frames (×œ×¤×™ ×”×”× ×—×™×•×ª)
                            if self.voice_in_row >= 10:  # 200ms ×©×œ ×§×•×œ ×¨×¦×™×£ ×œ×¤× ×™ ×”×¤×¨×¢×”
                                print(f"âš¡ BARGE-IN DETECTED (after {time_since_tts_start*1000:.0f}ms)")
                                
                                # âœ… ××“×™×“×ª Interrupt Halt Time
                                interrupt_start = time.time()
                                
                                # âœ… ×¢×¦×™×¨×ª TTS ××™×™×“×™×ª - ×œ× ×¢×•×“ ×¤×¨×™×™××™×!
                                self.speaking = False
                                self._interrupt_speaking()
                                
                                # âœ… ××“×™×“×ª ×–××Ÿ ×¢×¦×™×¨×”
                                halt_time = (time.time() - interrupt_start) * 1000
                                print(f"ğŸ“Š INTERRUPT_HALT: {halt_time:.1f}ms (target: â‰¤200ms)")
                                
                                # âœ… ××¢×‘×¨ ××™×™×“×™ ×œ-LISTENING
                                self.state = STATE_LISTEN
                                self.processing = False
                                
                                # âœ… × ×™×§×•×™ ×‘××¤×¨ ×•×¤×ª×™×—×” ×—×“×©×” ×œ×ª××œ×•×œ
                                self.buf.clear()
                                self.last_voice_ts = current_time  # ×”×ª×—×œ ××“×™×“×ª ×©×§×˜ ××—×“×©
                                self.voice_in_row = 0
                                
                                print("ğŸ¤ BARGE-IN -> LISTENING (user can speak now)")
                                
                                # ×©×œ×— clear ×œ×˜×•×•×™×œ×™×• ×›×“×™ ×œ× ×§×•×ª ××•×“×™×• ×ª×§×•×¢
                                try:
                                    self.tx_q.put_nowait({"type": "clear"})
                                except:
                                    pass
                                continue
                        else:
                            # ×× ××™×Ÿ ×§×•×œ ×—×–×§ ××¡×¤×™×§ - ×§×–×– ××ª ×”×¡×¤×™×¨×”
                            self.voice_in_row = max(0, self.voice_in_row - 1)
                    else:
                        self.voice_in_row = 0  # ××¤×¡ ×¡×¤×™×¨×” ×× ×œ× ×‘××¦×‘ speaking
                    
                    # ×× ×”××¢×¨×›×ª ××“×‘×¨×ª ×•××™×Ÿ ×”×¤×¨×¢×” - × ×§×” ×§×œ×˜
                    if self.speaking:
                        self.buf.clear()
                        continue
                    
                    # âœ… ××™×¡×•×£ ××•×“×™×• ×¢× ×–×™×”×•×™ ×“×××” ×ª×§×™×Ÿ
                    if not self.processing and self.state == STATE_LISTEN:
                        # ×—×œ×•×Ÿ ×¨×¤×¨×§×˜×•×¨×™ ××—×¨×™ TTS
                        if (current_time - self.last_tts_end_ts) < (REPLY_REFRACTORY_MS/1000.0):
                            continue
                        
                        # ××¡×•×£ ××•×“×™×• ×¨×§ ×›×©×™×© ×§×•×œ ××• ×›×©×™×© ×›×‘×¨ ×“×‘×¨ ××” ×‘×‘××¤×¨
                        if is_strong_voice or len(self.buf) > 0:
                            self.buf.extend(pcm16)
                            dur = len(self.buf) / (2 * SR)
                            
                            # âœ… ×–×™×”×•×™ ×¡×•×£ ××‘×¢ ×œ×¤×™ ×”×”× ×—×™×•×ª - 350-500ms ×©×§×˜
                            min_silence = 0.35 if dur > 1.5 else 0.5  # 350-500ms ×œ×¤×™ ×”×”× ×—×™×•×ª
                            silent = silence_time >= min_silence  
                            too_long = dur >= MAX_UTT_SEC
                            min_duration = 0.8  # ××™× ×™××•× ×œ×ª××œ×•×œ ××™×›×•×ª×™
                            
                            # âœ… EOU ××™×›×•×ª×™: ×‘××¤×¨ ××¡×¤×™×§ ×’×“×•×œ ×œ×ª××œ×•×œ ××©××¢×•×ª×™
                            buffer_big_enough = len(self.buf) > 12800  # ×œ×¤×—×•×ª 0.8s ×©×œ ××•×“×™×• ××™×›×•×ª×™
                            
                            # ×¡×•×£ ××‘×¢: ×“×××” ××¡×¤×§×ª OR ×–××Ÿ ×™×•×ª×¨ ××“×™ OR ×‘××¤×¨ ×’×“×•×œ ×¢× ×©×§×˜
                            if ((silent and buffer_big_enough) or too_long) and dur >= min_duration:
                                print(f"ğŸ¤ END OF UTTERANCE: {dur:.1f}s audio, conversation #{self.conversation_id}")
                                
                                # âœ… ××“×™×“×ª Turn Latency - ×”×ª×—×œ×ª ××“×™×“×”
                                self.eou_timestamp = time.time()
                                
                                # ××¢×‘×¨ ×œ×¢×™×‘×•×“
                                self.processing = True
                                self.processing_start_ts = current_time
                                self.state = STATE_THINK
                                current_id = self.conversation_id
                                self.conversation_id += 1
                                
                                # ×¢×™×‘×•×“ ×‘×× ×•×ª×§
                                utt_pcm = bytes(self.buf)
                                self.buf.clear()
                                self.last_voice_ts = 0  # ××¤×¡ ×œ×¡×™×‘×•×‘ ×”×‘×
                                
                                print(f"ğŸ§  STATE -> PROCESSING | len={len(utt_pcm)} | silence_ms={silence_time*1000:.0f}")
                                
                                try:
                                    self._process_utterance_safe(utt_pcm, current_id)
                                except Exception as proc_err:
                                    print(f"âŒ Audio processing failed for conversation #{current_id}: {proc_err}")
                                    import traceback
                                    traceback.print_exc()
                                    # Continue without crashing WebSocket
                                finally:
                                    self.processing = False
                                    if self.state == STATE_THINK:
                                        self.state = STATE_LISTEN
                                    print(f"âœ… Processing complete for conversation #{current_id}")
                    
                    # âœ… WebSocket Keepalive - ××•× ×¢ × ×¤×™×œ×•×ª ××—×¨×™ 5 ×“×§×•×ª
                    if current_time - self.last_keepalive_ts > self.keepalive_interval:
                        self.last_keepalive_ts = current_time
                        self.heartbeat_counter += 1
                        
                        # ×©×œ×— heartbeat mark event
                        try:
                            heartbeat_msg = {
                                "event": "mark",
                                "streamSid": self.stream_sid,
                                "mark": {"name": f"heartbeat_{self.heartbeat_counter}"}
                            }
                            self._ws_send(json.dumps(heartbeat_msg))
                            print(f"ğŸ’“ WS_KEEPALIVE #{self.heartbeat_counter} (prevents 5min timeout)")
                        except Exception as e:
                            print(f"âš ï¸ Keepalive failed: {e}")
                    
                    # âœ… Watchdog: ×•×•×“× ×©×œ× ×ª×§×•×¢×™× ×‘××¦×‘ + EOU ×›×¤×•×™×”
                    if self.processing and (current_time - self.processing_start_ts) > 2.5:
                        print("âš ï¸ PROCESSING TIMEOUT - forcing reset")
                        self.processing = False
                        self.state = STATE_LISTEN
                        self.buf.clear()
                    
                    if self.speaking and (current_time - self.speaking_start_ts) > 6.0:
                        print("âš ï¸ SPEAKING TIMEOUT - forcing reset")  
                        self.speaking = False
                        self.state = STATE_LISTEN
                    
                    # âœ… EOU ×—×™×¨×•×: ××›×¨×™×— ×¢×™×‘×•×“ ×× ×”×‘××¤×¨ ×’×“×•×œ ××“×™
                    if (not self.processing and self.state == STATE_LISTEN and 
                        len(self.buf) > 32000 and  # 2.0s ×©×œ ××•×“×™×• (×¡×‘×™×¨!)
                        silence_time > 0.2):      # 200ms ×©×§×˜ (×¡×‘×™×¨!)
                        print(f"ğŸš¨ EMERGENCY EOU: {len(self.buf)/(2*SR):.1f}s audio, silence={silence_time:.2f}s")
                        # ×›×¤×” EOU
                        self.processing = True
                        self.processing_start_ts = current_time
                        self.state = STATE_THINK
                        current_id = self.conversation_id
                        self.conversation_id += 1
                        
                        utt_pcm = bytes(self.buf)
                        self.buf.clear()
                        self.last_voice_ts = 0
                        
                        print(f"ğŸ§  EMERGENCY STATE -> PROCESSING | len={len(utt_pcm)} | silence_ms={silence_time*1000:.0f}")
                        
                        try:
                            self._process_utterance_safe(utt_pcm, current_id)
                        except Exception as proc_err:
                            print(f"âŒ Emergency audio processing failed for conversation #{current_id}: {proc_err}")
                            import traceback
                            traceback.print_exc()
                            # Continue without crashing WebSocket
                        finally:
                            self.processing = False
                            if self.state == STATE_THINK:
                                self.state = STATE_LISTEN
                            print(f"âœ… Emergency processing complete for conversation #{current_id}")
                    
                    continue

                if et == "mark":
                    # âœ… ×¡×™××•×Ÿ TTS ×”×•×©×œ× - ×—×–×•×¨ ×œ×”××–× ×”
                    mark_name = evt.get("mark", {}).get("name", "")
                    if mark_name == "assistant_tts_end":
                        print("ğŸ¯ TTS_MARK_ACK: assistant_tts_end -> LISTENING")
                        self.speaking = False
                        self.state = STATE_LISTEN
                        self.mark_pending = False
                        self.last_tts_end_ts = time.time()
                        # ××™×¤×•×¡ ×—×©×•×‘ ×œ××¢×¨×›×ª VAD
                        self.last_voice_ts = 0
                        self.voice_in_row = 0
                        print("ğŸ¤ STATE -> LISTENING | buffer_reset")
                    elif mark_name.startswith("heartbeat_"):
                        # ××™×©×•×¨ keepalive - ×”×ª×¢×œ×
                        pass
                    continue

                if et == "stop":
                    print(f"WS_STOP sid={self.stream_sid} rx={self.rx} tx={self.tx}")
                    # Send close frame properly
                    try:
                        if hasattr(self.ws, 'close'):
                            self.ws.close()
                    except:
                        pass
                    break

        except ConnectionClosed as e:
            print(f"ğŸ“ WS_CLOSED sid={self.stream_sid} rx={self.rx} tx={self.tx} reason=ConnectionClosed")
            # âœ… × ×™×¡×™×•×Ÿ ×”×ª××•×©×©×•×ª ×× ×”×©×™×—×” ×¢×“×™×™×Ÿ ×¤×¢×™×œ×”
            if self.call_sid:
                print(f"ğŸ”„ WS connection lost for active call {self.call_sid} - recovery might be possible via Twilio REST API")
        except Exception as e:
            print(f"âŒ WS_ERROR sid={self.stream_sid}: {type(e).__name__}: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # Clean up TX thread
            if hasattr(self, 'tx_thread') and self.tx_thread.is_alive():
                self.tx_running = False
                try:
                    self.tx_thread.join(timeout=1.0)
                except:
                    pass
            try: 
                self.ws.close()
            except: 
                pass
            # Mark as ended
            if hasattr(self, 'call_sid') and self.call_sid:
                stream_registry.clear(self.call_sid)
        
        # Final cleanup
        print(f"WS_DONE sid={self.stream_sid} rx={self.rx} tx={self.tx}")

    def _interrupt_speaking(self):
        """×¢×¦×™×¨×” ××™×™×“×™×ª ×©×œ ×“×™×‘×•×¨ ×”×‘×•×˜ (BARGE-IN ××©×•×¤×¨)"""
        if not self.speaking:
            return
            
        print("ğŸš¨ BARGE-IN: interrupt")
        self.speaking = False
        
        # × ×§×” ××ª ×ª×•×¨ ×”×©×™×“×•×¨
        try:
            while not self.tx_q.empty():
                self.tx_q.get_nowait()
        except:
            pass
            
        # ×©×œ×— CLEAR ×œ×˜×•×•×™×œ×™×•
        try:
            self.tx_q.put_nowait({"type": "clear"})
        except:
            pass
        
        print("âœ… Bot is now silent - user can speak")

    # ğŸ¯ ×¢×™×‘×•×“ ××‘×¢ ×¤×©×•×˜ ×•×‘×™×˜×•×— (×œ×œ× ×›×¤×™×œ×•×™×•×ª)
    def _process_utterance_safe(self, pcm16_8k: bytes, conversation_id: int):
        """×¢×™×‘×•×“ ××‘×¢ ×¢× ×”×’× ×” ×›×¤×•×œ×” ××¤× ×™ ×œ×•×œ××•×ª"""
        # ×•×•×“× ×©×œ× ××¢×‘×“×™× ××ª ××•×ª×• ID ×¤×¢××™×™×
        if conversation_id <= self.last_processing_id:
            print(f"ğŸš« DUPLICATE processing ID {conversation_id} (last: {self.last_processing_id}) - SKIP")
            return
        
        self.last_processing_id = conversation_id
        
        # ×•×•×“× ×©×”××¢×¨×›×ª ×œ× ××“×‘×¨×ª ×›×¨×’×¢
        if self.speaking:
            print("ğŸš« Still speaking - cannot process new utterance")
            return
            
        print(f"ğŸ¤ SAFE PROCESSING: conversation #{conversation_id}")
        self.state = STATE_THINK  # ××¢×‘×¨ ×œ××¦×‘ ×—×©×™×‘×”
        
        text = ""  # initialize to avoid unbound variable
        try:
            # PATCH 6: Safe ASR - never leaves empty
            try:
                text = self._hebrew_stt(pcm16_8k) or ""
                print(f"ğŸ¤ USER: {text}")
            
            # âœ… ××“×™×“×ª ASR Latency
            if hasattr(self, 'eou_timestamp'):
                asr_latency = time.time() - self.eou_timestamp
                print(f"ğŸ“Š ASR_LATENCY: {asr_latency:.3f}s (target: <0.7s)")
            
            except Exception as e:
                print(f"âŒ STT ERROR: {e}")
                text = ""
            
            if not text.strip():
                text = "××¤×©×¨ ×œ×—×–×•×¨ ×¢×œ ×–×” ×‘××©×¤×˜ ×§×¦×¨?"
            # STT result processed")
            
            # PATCH 6: Anti-duplication on user text (14s window) - WITH DEBUG
            uh = zlib.crc32(text.strip().encode("utf-8"))
            if (self.last_user_hash == uh and 
                (time.time() - self.last_user_hash_ts) <= DEDUP_WINDOW_SEC):
                print("ğŸš« DUPLICATE USER INPUT (ignored)")
                self.processing = False
                self.state = STATE_LISTEN
                return
            self.last_user_hash, self.last_user_hash_ts = uh, time.time()
            # Processing new user input")
            
            # 3. AI Response - Ğ‘Ğ•Ğ— micro-ack! ×ª×Ÿ ×œ×” ×œ×—×©×•×‘ ×‘×©×§×˜
            ai_processing_start = time.time()
            
            # âœ… ×”×©×ª××© ×‘×¤×•× ×§×¦×™×” ×”××ª×§×“××ª ×¢× ××ª××—×” ×•×”×××’×¨ ×”×›×•×œ×œ!
            reply = self._ai_response(text)
            
            # PATCH 6: Anti-duplication bot reply - WITH DEBUG
            rh = zlib.crc32(reply.strip().encode("utf-8"))
            if self.last_reply_hash == rh:
                print("ğŸš« DUPLICATE BOT REPLY (using alternative)")
                # ×ª×©×•×‘×•×ª ×—×œ×•×¤×™×•×ª ××•×¢×™×œ×•×ª ×‘××§×•× ×’× ×¨×™×•×ª
                alternatives = [
                    "××™×–×” ××–×•×¨ ×‘×ª×œ ××‘×™×‘ ××¢× ×™×™×Ÿ ××•×ª×š? ×™×© ×œ×™ ××¡×¤×¨ ××¤×©×¨×•×™×•×ª ××¦×•×™× ×•×ª.",
                    "×‘×•××• × ××¦× ×œ×š ××©×”×• ××ª××™×. ××™×–×” ×ª×§×¦×™×‘ ×™×© ×œ×š ×‘×—×©×‘×•×Ÿ?",
                    "×™×© ×œ×™ ×“×™×¨×•×ª ×™×¤×•×ª ×‘××¨×›×–. ××” ×—×©×•×‘ ×œ×š ×™×•×ª×¨ - ×’×•×“×œ ××• ××™×§×•×?"
                ]
                import random
                reply = random.choice(alternatives)
                rh = zlib.crc32(reply.encode("utf-8"))
                # Using alternative response")
            self.last_reply_hash = rh
            print(f"ğŸ¤– BOT: {reply}")
            
            # âœ… ××“×™×“×ª AI Processing Time
            ai_processing_time = time.time() - ai_processing_start
            print(f"ğŸ“Š AI_PROCESSING: {ai_processing_time:.3f}s")
            
            # 5. ×”×•×¡×£ ×œ×”×™×¡×˜×•×¨×™×”
            self.response_history.append({
                'id': conversation_id,
                'user': text,
                'bot': reply,
                'time': time.time()
            })
            
            # PATCH 6: Always speak something
            self._speak_simple(reply)
            
            # âœ… CRITICAL: ×—×–×•×¨ ×œ××¦×‘ ×”××–× ×” ××—×¨×™ ×›×œ ×ª×’×•×‘×”!
            self.state = STATE_LISTEN
            print(f"âœ… RETURNED TO LISTEN STATE after conversation #{conversation_id}")
            
        except Exception as e:
            print(f"âŒ CRITICAL Processing error: {e}")
            print(f"   Text was: '{text}' ({len(text)} chars)")
            # âœ… ×ª×™×§×•×Ÿ ×§×¨×™×˜×™: ×“×‘×§ ×œ×˜×¨××¡×‘×§ ×•××œ ×ª×§×¨×™×¡
            import traceback
            traceback.print_exc()
            # âœ… ×ª×’×•×‘×ª ×—×™×¨×•× ××¤×•×¨×˜×ª ×•××•×¢×™×œ×”
            try:
                self.state = STATE_SPEAK
                emergency_response = "××¦×˜×¢×¨×ª, ×œ× ×©××¢×ª×™ ×˜×•×‘ ×‘×’×œ×œ ×”×—×™×‘×•×¨. ×× ×™ ××ª××—×” ×××§×¡×™××•×¡ × ×“×œ\"×Ÿ ×•×™×© ×œ×™ ×“×™×¨×•×ª ××“×”×™××•×ª ×‘××¨×›×–. ×‘×•××• × ×ª×—×™×œ ××—×“×© - ××™×–×” ×¡×•×’ × ×›×¡ ××ª×” ××—×¤×© ×•×‘××™×–×” ××–×•×¨?"
                self._speak_with_breath(emergency_response)
                self.state = STATE_LISTEN
                print(f"âœ… RETURNED TO LISTEN STATE after error in conversation #{conversation_id}")
            except Exception as emergency_err:
                print(f"âŒ EMERGENCY RESPONSE FAILED: {emergency_err}")
                self.state = STATE_LISTEN
                # âœ… ×—×–×•×¨ ×œ××¦×‘ ×”××–× ×” ×‘×›×œ ××§×¨×”


    # âœ… ×“×™×‘×•×¨ ××ª×§×“× ×¢× ×¡×™××•× ×™× ×œ×˜×•×•×™×œ×™×•
    def _speak_simple(self, text: str):
        """TTS ×¢× ××¢×§×‘ ××¦×‘×™× ×•×¡×™××•× ×™×"""
        if not text:
            return
            
        if self.speaking:
            print("ğŸš« Already speaking - cannot start new speech")
            return
            
        self.speaking = True
        self.speaking_start_ts = time.time()
        self.state = STATE_SPEAK
        print(f"ğŸ”Š TTS_START: '{text}'")
        
        # âœ… ××“×™×“×ª Turn Latency (×-EOU ×¢×“ TTS)
        if hasattr(self, 'eou_timestamp'):
            turn_latency = time.time() - self.eou_timestamp
            print(f"ğŸ“Š TURN_LATENCY: {turn_latency:.3f}s (target: <1.2s)")
            delattr(self, 'eou_timestamp')  # × ×§×” ×œ××“×™×“×” ×”×‘××”
        
        try:
            # ×”××ª× ×” ×§×¦×¨×” ×œ×ª×—×•×©×ª ×˜×‘×¢×™×•×ª
            time.sleep(random.uniform(0.2, 0.4))
                
            # ×§×™×¦×•×¨ ×˜×§×¡×˜ ××¨×•×š
            if len(text) > 150:
                text = text[:150].rsplit(' ', 1)[0] + '.'
                print(f"ğŸ”ª TTS_SHORTENED: {text}")
            
            tts_audio = self._hebrew_tts(text)
            if tts_audio and len(tts_audio) > 1000:
                print(f"ğŸ”Š TTS SUCCESS: {len(tts_audio)} bytes")
                self._send_pcm16_as_mulaw_frames_with_mark(tts_audio)
            else:
                print("ğŸ”Š TTS FAILED - sending beep")
                self._send_beep(800)
                self._finalize_speaking()
        except Exception as e:
            print(f"ğŸ”Š TTS ERROR: {e} - sending beep")
            self._send_beep(800)
            self._finalize_speaking()
    
    def _finalize_speaking(self):
        """×¡×™×•× ×“×™×‘×•×¨ ×¢× ×—×–×¨×” ×œ×”××–× ×”"""
        self.speaking = False
        self.last_tts_end_ts = time.time()
        self.state = STATE_LISTEN
        self.last_voice_ts = 0  # ××™×¤×•×¡ ×œ××¢×¨×›×ª VAD
        self.voice_in_row = 0
        print("ğŸ¤ SPEAKING_END -> LISTEN STATE | buffer_reset")

    def _send_pcm16_as_mulaw_frames_with_mark(self, pcm16_8k: bytes):
        """×©×œ×™×—×ª ××•×“×™×• ×¢× ×¡×™××•×Ÿ ×œ×˜×•×•×™×œ×™×• ×•×‘×¨×’-××™×Ÿ"""
        if not self.stream_sid or not pcm16_8k:
            self._finalize_speaking()
            return
            
        # CLEAR ×œ×¤× ×™ ×©×œ×™×—×”
        self._ws_send(json.dumps({"event":"clear","streamSid":self.stream_sid}))
        
        mulaw = audioop.lin2ulaw(pcm16_8k, 2)
        FR = 160  # 20ms @ 8kHz
        frames_sent = 0
        total_frames = len(mulaw) // FR
        
        print(f"ğŸ”Š TTS_FRAMES: {total_frames} frames ({total_frames * 20}ms)")
        
        for i in range(0, len(mulaw), FR):
            # ×‘×“×™×§×ª ×‘×¨×’-××™×Ÿ
            if not self.speaking:
                print(f"ğŸš¨ BARGE-IN! Stopped at frame {frames_sent}/{total_frames}")
                self._ws_send(json.dumps({"event":"clear","streamSid":self.stream_sid}))
                self._finalize_speaking()
                return
                
            # ×©×œ×— ×¤×¨×™×™×
            frame = mulaw[i:i+FR].ljust(FR, b'\x00')
            payload = base64.b64encode(frame).decode()
            media_msg = json.dumps({
                "event": "media",
                "streamSid": self.stream_sid,
                "media": {"payload": payload}
            })
            self._ws_send(media_msg)
            frames_sent += 1
            
            # Yield ×œeventlet
            if frames_sent % 5 == 0:  # ×›×œ 100ms
                time.sleep(0)  # yield
        
        # ×”×•×¡×£ 200ms ×©×§×˜ ×‘×¡×•×£
        silence_frames = 10  # 200ms @ 20ms per frame  
        silence_mulaw = b'\x00' * FR
        for _ in range(silence_frames):
            if not self.speaking:
                break
            payload = base64.b64encode(silence_mulaw).decode()
            media_msg = json.dumps({
                "event": "media", 
                "streamSid": self.stream_sid,
                "media": {"payload": payload}
            })
            self._ws_send(media_msg)
            time.sleep(0)  # yield
        
        # ×©×œ×— ×¡×™××•×Ÿ ×œ×˜×•×•×™×œ×™×•
        self.mark_pending = True
        self.mark_sent_ts = time.time()
        mark_msg = json.dumps({
            "event": "mark",
            "streamSid": self.stream_sid,
            "mark": {"name": "assistant_tts_end"}
        })
        self._ws_send(mark_msg)
        print("ğŸ¯ TTS_MARK_SENT: assistant_tts_end")
        
        # Timeout fallback ×× ×”×¡×™××•×Ÿ ×œ× ×™×—×–×•×¨
        def mark_timeout():
            time.sleep(0.15)  # 150ms timeout
            if self.mark_pending and (time.time() - self.mark_sent_ts) > 0.14:
                print("âš ï¸ TTS_MARK_TIMEOUT -> LISTENING") 
                self._finalize_speaking()
        
        import threading
        threading.Thread(target=mark_timeout, daemon=True).start()

    def _send_pcm16_as_mulaw_frames(self, pcm16_8k: bytes):
        """×©×œ×™×—×ª ××•×“×™×• ×¢× ×™×›×•×œ×ª ×¢×¦×™×¨×” ×‘×××¦×¢ (BARGE-IN) - ×’×¨×¡×” ×™×©× ×”"""
        if not self.stream_sid or not pcm16_8k:
            return
            
        # CLEAR ×œ×¤× ×™ ×©×œ×™×—×”
        self._ws_send(json.dumps({"event":"clear","streamSid":self.stream_sid}))
        
        mulaw = audioop.lin2ulaw(pcm16_8k, 2)
        FR = 160  # 20ms @ 8kHz
        frames_sent = 0
        total_frames = len(mulaw) // FR
        
        print(f"ğŸ”Š Starting audio transmission: {total_frames} frames ({total_frames * 20}ms)")
        
        for i in range(0, len(mulaw), FR):
            # ğŸš¨ ×‘×“×™×§×” ×§×¨×™×˜×™×ª: ×”×× ×¢×“×™×™×Ÿ ×¦×¨×™×š ×œ×“×‘×¨?
            if not self.speaking:
                print(f"ğŸš¨ BARGE-IN detected! Stopped at frame {frames_sent}/{total_frames}")
                # ×©×œ×— CLEAR × ×•×¡×£ ×œ××§×¨×” ×”×¦×•×¨×š
                self._ws_send(json.dumps({"event":"clear","streamSid":self.stream_sid}))
                break
                
            chunk = mulaw[i:i+FR]
            if len(chunk) < FR:
                # ×”×’×¢× ×• ×œ×¡×•×£ - ×–×” ×ª×§×™×Ÿ
                break
                
            payload = base64.b64encode(chunk).decode("ascii")
            try:
                self._ws_send(json.dumps({
                    "event": "media",
                    "streamSid": self.stream_sid,
                    "media": {"payload": payload}
                }))
                self.tx += 1
                frames_sent += 1
                
                # ×œ×•×’×™× ××ª×§×“××™× ×›×œ 50 ×¤×¨×™×™××™ ×©×™×“×•×¨ + PATCH 10
                if self.tx % 50 == 0:
                    elapsed = time.time() - self.last_tts_end_ts
                    print(f"WS_TX sid={self.stream_sid} tx={self.tx} frames_sent={frames_sent}/{total_frames} elapsed={elapsed:.1f}s")
            except Exception as e:
                print(f"âŒ Error sending frame {frames_sent}: {e}")
                break
        
        if self.speaking:
            print(f"âœ… Complete audio sent: {frames_sent}/{total_frames} frames")
        else:
            print(f"âš ï¸ Audio interrupted: {frames_sent}/{total_frames} frames sent")

    def _send_beep(self, ms: int):
        """×¦×¤×¦×•×£ ×¤×©×•×˜"""
        samples = int(SR * ms / 1000)
        amp = 9000
        out = bytearray()
        for n in range(samples):
            val = int(amp * math.sin(2*math.pi*440*n/SR))
            out.extend(val.to_bytes(2, "little", signed=True))
        self._send_pcm16_as_mulaw_frames(bytes(out))
    
    def _beep_pcm16_8k(self, ms: int) -> bytes:
        """×™×¦×™×¨×ª ×¦×¤×¦×•×£ PCM16 8kHz"""
        samples = int(SR * ms / 1000)
        amp = 9000
        out = bytearray()
        for n in range(samples):
            val = int(amp * math.sin(2*math.pi*440*n/SR))
            out.extend(val.to_bytes(2, "little", signed=True))
        return bytes(out)
    
    def _process_audio_for_stt(self, pcm16_8k: bytes) -> bytes:
        """ğŸµ ×¢×™×‘×•×“ ××•×“×™×• ××™×›×•×ª×™ ×œ×¤× ×™ STT: AGC, ×¤×™×œ×˜×¨×™×, resample ×œ-16kHz"""
        try:
            import numpy as np
            from scipy import signal
            
            # ×”××¨ ×œ-numpy array
            audio_int16 = np.frombuffer(pcm16_8k, dtype=np.int16)
            audio_float = audio_int16.astype(np.float32) / 32768.0  # normalize to [-1, 1]
            
            # âœ… 1. DC-offset removal
            audio_float = audio_float - float(np.mean(audio_float))
            
            # âœ… 2. High-pass filter (100Hz) - ××˜××˜× ×–××–×•×
            sos_hp = signal.butter(4, 100, btype='high', fs=8000, output='sos')
            audio_float = np.array(signal.sosfilt(sos_hp, audio_float), dtype=np.float32)
            
            # âœ… 3. Low-pass filter (3.6kHz) - ×˜×œ×¤×•× ×™ ×¨×’×™×œ  
            sos_lp = signal.butter(4, 3600, btype='low', fs=8000, output='sos')
            audio_float = np.array(signal.sosfilt(sos_lp, audio_float), dtype=np.float32)
            
            # âœ… 4. AGC ×¢×“×™×Ÿ - × ×¨××•×œ ×œ×˜×•×•×— ××˜×¨×” (-20dBFS â‰ˆ 0.1)
            rms_squared = np.mean(audio_float * audio_float)
            rms = float(np.sqrt(rms_squared))
            if rms > 0.001:  # ×× ×™×© ××•×“×™×• ×××™×ª×™
                target_rms = 0.1  # -20dBFS
                gain = min(target_rms / rms, 3.0)  # ××’×‘×™×œ ×’×™×™×Ÿ ×œ-3x
                audio_float = np.array(audio_float * gain, dtype=np.float32)
            
            # âœ… 5. Clipping protection
            audio_float = np.clip(audio_float, -0.95, 0.95)
            
            # âœ… 6. Resample 8kHz â†’ 16kHz (Whisper ×¢×•×‘×“ ×˜×•×‘ ×™×•×ª×¨ ×‘-16k)
            audio_16k = signal.resample(audio_float, len(audio_float) * 2)
            
            # ×”××¨ ×—×–×¨×” ×œ-int16
            audio_16k_int16 = np.array(audio_16k * 32767, dtype=np.int16)
            
            return audio_16k_int16.tobytes()
            
        except Exception as e:
            print(f"âš ï¸ Audio processing failed, using simple resample: {e}")
            # Fallback: resample ×¤×©×•×˜ ×œ-16kHz
            try:
                import numpy as np
                from scipy import signal
                audio_int16 = np.frombuffer(pcm16_8k, dtype=np.int16)
                audio_float = audio_int16.astype(np.float32) / 32768.0
                audio_16k = signal.resample(audio_float, len(audio_float) * 2)
                audio_16k_int16 = np.array(audio_16k * 32767, dtype=np.int16)
                return audio_16k_int16.tobytes()
            except Exception as e2:
                print(f"âš ï¸ Even simple resample failed: {e2}")
                # Ultimate fallback: duplicate samples (crude but works)
                return pcm16_8k + pcm16_8k  # Double the data for "16kHz"

    def _hebrew_stt(self, pcm16_8k: bytes) -> str:
        """Hebrew STT using Google STT Streaming with speech contexts (×œ×¤×™ ×”×”× ×—×™×•×ª)"""
        try:
            print(f"ğŸ¤ STT_START: Processing {len(pcm16_8k)} bytes with Google STT Streaming Hebrew")
            
            from server.services.lazy_services import get_stt_client
            from google.cloud import speech
            
            client = get_stt_client()
            if not client:
                print("âŒ Google STT client not available - fallback to Whisper")
                return self._whisper_fallback(pcm16_8k)
            
            # âœ… Google STT Streaming Configuration ×œ×¤×™ ×”×”× ×—×™×•×ª
            recognition_config = speech.RecognitionConfig(
                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=8000,  # âœ… ×”×©××¨ 8kHz ×œ×˜×œ×¤×•× ×™×”
                language_code="he-IL",   # ×¢×‘×¨×™×ª ×™×©×¨××œ×™×ª
                use_enhanced=True,       # ××•×“×œ ××©×•×¤×¨
                enable_automatic_punctuation=True,
                speech_contexts=[        # âœ… Speech contexts ×œ×¢×‘×¨×™×ª ×œ×¤×™ ×”×”× ×—×™×•×ª
                    speech.SpeechContext(phrases=[
                        "××§×¡×™××•×¡ × ×“×œ×Ÿ", "×œ××”", "×©×™ ×“×™×¨×•×ª ×•××©×¨×“×™×",
                        "×ª×œ ××‘×™×‘", "×¨××ª ×’×Ÿ", "×¨××œ×”", "×œ×•×“", "×‘×™×ª ×©××©", 
                        "××•×“×™×¢×™×Ÿ", "×¤×ª×— ×ª×§×•×•×”", "×¨×—×•×‘×•×ª", "×”×¨×¦×œ×™×”",
                        "×“×™×¨×”", "×—×“×¨×™×", "×©×›×™×¨×•×ª", "×§× ×™×”", "××©×›× ×ª×",
                        "×ª×§×¦×™×‘", "×©×§×œ", "××œ×£", "××™×œ×™×•×Ÿ", "× ×“×œ×Ÿ"
                    ])
                ]
            )
            
            # Single request recognition (×œ× streaming ×œ××‘×¢ ×§×¦×¨)
            audio = speech.RecognitionAudio(content=pcm16_8k)
            
            # âœ… ×¢× timeout ×§×¦×¨ ×œ×ª×’×•×‘×” ××”×™×¨×”
            response = client.recognize(
                config=recognition_config,
                audio=audio,
                timeout=3.0  # 3 ×©× ×™×•×ª ××§×¡
            )
            
            if response.results and response.results[0].alternatives:
                hebrew_text = response.results[0].alternatives[0].transcript.strip()
                confidence = response.results[0].alternatives[0].confidence
                print(f"âœ… GOOGLE_STT_SUCCESS: '{hebrew_text}' (confidence: {confidence:.2f})")
                return hebrew_text
            else:
                print("âŒ Google STT returned no results - fallback to Whisper")
                return self._whisper_fallback(pcm16_8k)
                
        except Exception as e:
            print(f"âŒ GOOGLE_STT_ERROR: {e} - fallback to Whisper")
            return self._whisper_fallback(pcm16_8k)
    
    def _whisper_fallback(self, pcm16_8k: bytes) -> str:
        """Whisper fallback for Google STT failures"""
        try:
            print(f"ğŸ”„ WHISPER_FALLBACK: Processing {len(pcm16_8k)} bytes")
            
            from server.services.lazy_services import get_openai_client
            client = get_openai_client()
            if not client:
                print("âŒ OpenAI client not available")
                return ""
            
            # Resample to 16kHz for Whisper
            pcm16_16k = audioop.ratecv(pcm16_8k, 2, 1, 8000, 16000, None)[0]
            
            # Save as temporary WAV file
            import tempfile, wave
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_wav:
                with wave.open(temp_wav.name, 'wb') as wav_file:
                    wav_file.setnchannels(1)
                    wav_file.setsampwidth(2)
                    wav_file.setframerate(16000)
                    wav_file.writeframes(pcm16_16k)
                
                with open(temp_wav.name, 'rb') as audio_file:
                    transcription = client.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio_file,
                        language="he",
                        response_format="text", 
                        temperature=0.2
                    )
                
                hebrew_text = transcription.strip() if transcription else ""
                print(f"âœ… WHISPER_FALLBACK_SUCCESS: '{hebrew_text}'")
                
                # Clean up
                import os
                os.unlink(temp_wav.name)
                return hebrew_text
                
        except Exception as e:
            print(f"âŒ WHISPER_FALLBACK_ERROR: {e}")
            return ""
    
    def _ai_response(self, hebrew_text: str) -> str:
        """Generate NATURAL Hebrew AI response - exactly what the conversation needs!"""
        try:
            from server.services.lazy_services import get_openai_client
            client = get_openai_client()
            if not client:
                print("âŒ OpenAI client not available for AI response")
                return "××¦×˜×¢×¨, ×™×© ×‘×¢×™×” ×˜×›× ×™×ª."
            
            # ğŸ¯ ×”×™×¡×˜×•×¨×™×” ×©×œ ×©×™×—×•×ª ×œ×× ×™×¢×ª ×—×–×¨×•×ª
            if not hasattr(self, 'conversation_history'):
                self.conversation_history = []
            
            # ğŸš« ×× ×¢ ×œ×•×œ××•×ª - ×‘×“×•×§ ×× ×–×” ××•×ª×” ×©××œ×” ××• ×ª×’×•×‘×” ×–×”×” ×××•×—×¨×ª
            if len(self.conversation_history) >= 2:
                last_two = self.conversation_history[-2:]
                # ×‘×“×•×§ ×× 2 ×”×ª×’×•×‘×•×ª ×”××—×¨×•× ×•×ª ×©×œ× ×• ×–×”×•×ª
                if (last_two[0]['bot'] == last_two[1]['bot'] and 
                    last_two[0]['bot'].count("×“×™×–× ×’×•×£") > 0):
                    print(f"ğŸš« BOT LOOP DETECTED - same response repeated!")
                    return "××™×–×” ××–×•×¨ ××¢× ×™×™×Ÿ ××•×ª×š ×™×•×ª×¨?"
                    
                # ×‘×“×•×§ ×× ×”××©×ª××© ×—×•×–×¨ ×¢×œ ××•×ª×” ×©××œ×”
                if last_two[-1]['user'].strip() == hebrew_text.strip():
                    print(f"ğŸš« USER LOOP DETECTED: Same input repeated")
                    return "×‘×•××™ × × ×¡×” ××©×”×• ××—×¨ - ××™×–×” ×ª×§×¦×™×‘ ×™×© ×œ×š?"
                    
            # ğŸ“œ ×”×§×©×¨ ××”×™×¡×˜×•×¨×™×” (×œ×”×‘× ×” ×˜×•×‘×” ×™×•×ª×¨)
            history_context = ""
            if self.conversation_history:
                recent = self.conversation_history[-2:]  # 2 ××—×¨×•× ×™×
                history_context = "×”×§×©×¨ ×©×™×—×”: "
                for turn in recent:
                    history_context += f"×œ×§×•×— ×××¨: '{turn['user'][:40]}' ×¢× ×™× ×•: '{turn['bot'][:40]}' | "
            
            # ğŸ¯ ×–×™×”×•×™ ××–×•×¨ ××”×‘×§×©×”
            requested_area = self._detect_area(hebrew_text)
            
            # âœ… ×‘×“×™×§×ª ××™×“×¢ ×©× ××¡×£ ×œ×ª×™××•× ×¤×’×™×©×”
            lead_info = self._analyze_lead_completeness()
            
            # âœ… ×¤×¨×•××¤×˜ ×¡×•×›× ×ª × ×“×œ×Ÿ ××§×¦×•×¢×™×ª ×œ×¤×™ ×”×”× ×—×™×•×ª ×”×—×“×©×•×ª
            smart_prompt = f"""××ª ×¡×•×›× ×ª × ×“×œ×Ÿ ×˜×œ×¤×•× ×™×ª ×©×œ AgentLocator. ×”××˜×¨×”: ×œ××¡×•×£ ×‘××”×™×¨×•×ª ×¤×¨×˜×™ ×œ×™×“: ××–×•×¨/×©×›×•× ×”, ×¡×•×’ × ×›×¡, ×ª×§×¦×™×‘, ×˜×•×•×— ×›× ×™×¡×”/×–××Ÿ, ×©× + ×˜×œ×¤×•×Ÿ/×•×•××˜×¡××¤.

×›×œ ×ª×©×•×‘×” ×©×œ×š: 1â€“2 ××©×¤×˜×™× ×§×¦×¨×™× ×××•×“ (+/âˆ’ 15 ××™×œ×™×) ×•×ª××™×“ ×©××œ×” ××—×ª ×‘×¡×•×£.
×× ×œ× ×©××¢×ª/×œ× ×‘×˜×•×—×” â€“ ×ª×’×™×“×™ "×œ× ×‘×˜×•×— ×©×©××¢×ª×™ × ×›×•×Ÿ, ××¤×©×¨ ×œ×—×–×•×¨ ×¢×œ ×–×”?" (××œ ×ª××¦×™××™).
××™×Ÿ ×œ×”×¦×™×¢ × ×›×¡×™× ×¡×¤×¦×™×¤×™×™× ×‘×œ×™ × ×ª×•× ×™×; ××™×Ÿ ×”××¦××•×ª.
×›×©×œ×§×•×— ×§×•×˜×¢ ××•×ª×š â€“ ×¢×¦×¨×™ ××™×“ ×•×ª×‘×§×©×™ ××× ×• ×œ×”××©×™×š.
×›×©×—×¡×¨ ××™×“×¢ â€“ ×©××œ×ª ×”×‘×”×¨×” ×××•×§×“×ª ××—×ª.
×›×©×”×¡×œ×•×˜×™× ××œ××™× â€“ ×”×¦×¢×™ ×ª×™××•× ×¤×’×™×©×” (×©×™×—×ª ×•×™×“××•/×˜×œ×¤×•×Ÿ), ×”×¦×™×¢×™ 2â€“3 ×—×œ×•× ×•×ª ×–××Ÿ ×§×¦×¨×™×, ×‘×§×©×™ ××™×©×•×¨ ×•×©×œ×—×™ ×¡×™×›×•× ×§×¦×¨.

×›×œ×œ×™ × ×™×¡×•×—:
- ××™×Ÿ ×©×ª×™ ×©××œ×•×ª ×‘××•×ª×” ×ª×©×•×‘×”
- ××™×Ÿ "× ××•×"; ××©×¤×˜×™× ×§×¦×¨×™×
- ×‘×¡×•×£ ×›×œ ×ª×©×•×‘×”â€”×¡×™××Ÿ ×©××œ×” ××—×“
- ×× ×™×© ×¨×¢×©/×œ× ×‘×˜×•×—â€”×‘×§×©×ª ×—×–×¨×” ×‘××§×•× ×œ× ×—×©

×“×•×’×××•×ª:
×“×•×’××” 1 - ×œ×§×•×— ×©×§×˜/×œ× ×‘×¨×•×¨:
×œ×§×•×—: [×¨×¢×©/×œ× ×‘×¨×•×¨]
×¡×•×›× ×ª: "×œ× ×‘×˜×•×— ×©×©××¢×ª×™ × ×›×•×Ÿ, ××¤×©×¨ ×œ×—×–×•×¨ ×¢×œ ×–×”?"

×“×•×’××” 2 - ×§×™×˜×•×¢ ×‘×××¦×¢:
×œ×§×•×—: [×§×•×˜×¢ ×‘×××¦×¢ ×”×“×™×‘×•×¨]
×¡×•×›× ×ª: "××¤×©×¨ ×œ×”××©×™×š?"

×“×•×’××” 3 - ×ª×™××•× ×¤×’×™×©×”:
×œ×§×•×—: "×™×© ×œ×™ ××–×•×¨ ×•×ª×§×¦×™×‘"
×¡×•×›× ×ª: "××¢×•×œ×”! ×‘×•××• × ×§×‘×¢ ×¤×’×™×©×”. ××ª×™ × ×•×— ×œ×š - ×”×™×•× 18:00 ××• ××—×¨ 10:30?"

××–×•×¨ ××–×•×”×”: {requested_area if requested_area else '×œ× ×™×“×•×¢'}
××™×“×¢ × ××¡×£: {lead_info['summary']}
×”×™×¡×˜×•×¨×™×”: {history_context}

{lead_info['meeting_prompt']}

×”×œ×§×•×— ××•××¨: "{hebrew_text}"
×ª×’×•×‘×” (××§×¡×™××•× 15 ××™×œ×™× + ×©××œ×” ××—×ª):"""

            # âœ… GPT-4o MINI ××”×™×¨ ×™×•×ª×¨ ×œ×©×™×—×” ×—×™×”!
            try:
                response = client.chat.completions.create(
                    model="gpt-4o-mini",      # ××”×™×¨ ×™×•×ª×¨ ×GPT-4
                    messages=[
                        {"role": "system", "content": smart_prompt},
                        {"role": "user", "content": hebrew_text}
                    ],
                    max_tokens=60,            # âœ… ××’×‘×™×œ ×œ-15 ××™×œ×™× (+/- ×›××”) ×œ×¤×™ ×”×”× ×—×™×•×ª
                    temperature=0.3,          # âœ… ×¤×—×•×ª creative = ×¢×§×‘×™×ª ×™×•×ª×¨
                    timeout=6.0               # ××§×¡ 6 ×©× ×™×•×ª
                )
            except Exception as e:
                print(f"â° AI timeout/error ({e}) - extending timeout and retrying once")
                # âœ… × ×™×¡×™×•×Ÿ ×©× ×™ ×¢× timeout ×™×•×ª×¨ ××¨×•×š
                try:
                    response = client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[
                            {"role": "system", "content": smart_prompt},
                            {"role": "user", "content": hebrew_text}
                        ],
                        max_tokens=60,            # âœ… ××’×‘×™×œ ×œ-15 ××™×œ×™× (+/- ×›××”) ×œ×¤×™ ×”×”× ×—×™×•×ª
                        temperature=0.3,          # âœ… ×¤×—×•×ª creative = ×¢×§×‘×™×ª ×™×•×ª×¨
                        timeout=12.0  # × ×™×¡×™×•×Ÿ ×©× ×™ ×¢× timeout ×›×¤×•×œ
                    )
                    content = response.choices[0].message.content
                    if content and content.strip():
                        return content.strip()
                except Exception as e2:
                    print(f"â° Second AI attempt failed ({e2}) - using intelligent emergency response")
                # âœ… ×ª×’×•×‘×ª ×—×™×¨×•× ×—×›××” ×¢×œ ×‘×¡×™×¡ ×”××–×•×¨ ×©×–×•×”×”
                if requested_area:
                    return f"×¡×œ×™×—×” ×¢×œ ×”×”×©×”×™×”! ××™×–×” ×¡×•×’ ×“×™×¨×” ××ª×” ××—×¤×© ×‘{requested_area}? ×™×© ×œ×™ ×›××” ××¤×©×¨×•×™×•×ª ××¢× ×™×™× ×•×ª."
                else:
                    return "×¡×œ×™×—×” ×¢×œ ×”×”×©×”×™×” ×”×˜×›× ×™×ª! ××™×–×” ××–×•×¨ ××¢× ×™×™×Ÿ ××•×ª×š - ××¨×›×–, ××¨×›×–-×“×¨×•× ××• ××–×•×¨ ×™×¨×•×©×œ×™×?"
            
            content = response.choices[0].message.content
            if content and content.strip():
                ai_answer = content.strip()
                
                # âœ… ××›×™×¤×ª ×’×‘×•×œ 15 ××™×œ×™× ×œ×¤×™ ×”×”× ×—×™×•×ª ×”×—×“×©×•×ª
                words = ai_answer.split()
                if len(words) > 18:  # ××§×¡ 18 ××™×œ×™× (15 + buffer ×§×˜×Ÿ ×œ×©××œ×”)
                    # ×§×¦×¨ ×œ-15 ××™×œ×™× + ×©××œ×” ××—×ª
                    truncated = ' '.join(words[:15])
                    if '?' not in truncated:
                        truncated += " ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?"
                    ai_answer = truncated
                    print(f"ğŸ”ª WORD_LIMIT: {len(words)} â†’ {len(ai_answer.split())} words")
                
                # âœ… ×× ×¢ ×¨×§ ×ª×’×•×‘×•×ª ×’× ×¨×™×•×ª - ××œ ×ª×—×¡×•× ×“×™×¨×•×ª ×¡×¤×¦×™×¤×™×•×ª!
                if (ai_answer.count("×ª×•×“×” ×¨×‘×”") > 1 or "×©××—×ª×™ ×œ×¢×–×•×¨" in ai_answer or 
                    "×ª××™×“ ×¤×” ×œ×¢×–×•×¨" in ai_answer or len(ai_answer.strip()) < 15):
                    # ×ª×—×œ×™×£ ×‘×©××œ×” ××¢× ×™×™× ×ª ×¨×§ ×× ×”×ª×’×•×‘×” ×’× ×¨×™×ª
                    ai_answer = "××™×–×” ××–×•×¨ ××¢× ×™×™×Ÿ ××•×ª×š ×™×•×ª×¨? ×™×© ×œ×™ ××¤×©×¨×•×™×•×ª ××¦×•×™× ×•×ª ×‘××¨×›×–."
                    print(f"ğŸš« BLOCKED ONLY GENERIC RESPONSES: Using engaging question instead")
                
                print(f"ğŸ¤– AI SUCCESS: {ai_answer}")
                
                # ğŸ’¾ ×”×•×¡×£ ×œh×™×¡×˜×•×¨×™×” ×œ×× ×™×¢×ª ×—×–×¨×•×ª
                self.conversation_history.append({
                    'user': hebrew_text.strip(),
                    'bot': ai_answer,
                    'time': time.time()
                })
                
                # ğŸ§¹ × ×§×” ×”×™×¡×˜×•×¨×™×” ×™×©× ×” (×¨×§ 10 ××—×¨×•× ×™×)
                if len(self.conversation_history) > 10:
                    self.conversation_history = self.conversation_history[-10:]
                    
                return ai_answer
            else:
                print("AI returned empty response - should not happen with good prompt")
                # âœ… ×ª×’×•×‘×ª ×—×™×¨×•× ×—×›××” ×¨×§ ×× ×‘×××ª ××™×Ÿ ×ª×•×›×Ÿ
                if requested_area:
                    return f"××™×–×” ×¡×•×’ ×“×™×¨×” ××ª×” ××—×¤×© ×‘{requested_area}? ×™×© ×œ×™ ×›××” ××¤×©×¨×•×™×•×ª ××¢× ×™×™× ×•×ª."
                else:
                    return "××™×–×” ××–×•×¨ ××¢× ×™×™×Ÿ ××•×ª×š? ×™×© ×œ×™ ×“×™×¨×•×ª ×‘××¨×›×– ×”××¨×¥, ××¨×›×–-×“×¨×•× ×•××–×•×¨ ×™×¨×•×©×œ×™×."
            
        except Exception as e:
            print(f"AI_ERROR: {e} - Using intelligent emergency response")
            # âœ… ×ª×’×•×‘×ª ×—×™×¨×•× ×—×›××” ×¢×œ ×‘×¡×™×¡ ×–×™×”×•×™ ×”××–×•×¨
            print(f"ğŸš¨ CRITICAL AI_ERROR for: '{hebrew_text}' - detected area: {requested_area}")
            
            # ×ª×’×•×‘×ª ×—×™×¨×•× ×‘×”×ª×× ×œ××–×•×¨ ×©×–×•×”×”
            if requested_area:
                return f"××¦×˜×¢×¨×ª ×œ×”×©×”×™×”! ××™×–×” ×¡×•×’ ×“×™×¨×” ××ª×” ××—×¤×© ×‘{requested_area}? ×™×© ×œ×™ ×›××” ××¤×©×¨×•×™×•×ª."
            elif "×ª×•×“×”" in hebrew_text or "×‘×™×™" in hebrew_text:
                return "×ª×•×“×” ×¨×‘×”! ×× ×™ ×›××Ÿ ×œ×›×œ ×©××œ×”."
            elif any(word in hebrew_text for word in ["×©×œ×•×", "×”×™×™", "×”×œ×•"]):
                return "×©×œ×•×! ××™×–×” ××–×•×¨ ××¢× ×™×™×Ÿ ××•×ª×š? ×™×© ×œ×™ ×“×™×¨×•×ª ×‘××¨×›×–, ××¨×›×–-×“×¨×•× ×•××–×•×¨ ×™×¨×•×©×œ×™×."
            else:
                return "××™×–×” ××–×•×¨ ××¢× ×™×™×Ÿ ××•×ª×š? ×™×© ×œ×™ ×“×™×¨×•×ª ×‘××¨×›×– ×”××¨×¥, ××¨×›×–-×“×¨×•× ×•××–×•×¨ ×™×¨×•×©×œ×™×."
    
    def _hebrew_tts(self, text: str) -> bytes | None:
        """Hebrew Text-to-Speech using Google Cloud TTS with Wavenet voice"""
        try:
            print(f"ğŸ”Š TTS_START: Generating Hebrew TTS with Google Wavenet for '{text[:50]}...' (length: {len(text)} chars)")
            from server.services.lazy_services import get_tts_client
            from google.cloud import texttospeech
            
            client = get_tts_client()
            if not client:
                print("âŒ Google TTS client not available")
                return None
            
            synthesis_input = texttospeech.SynthesisInput(text=text)
            voice = texttospeech.VoiceSelectionParams(
                language_code="he-IL",
                name="he-IL-Wavenet-A"  # âœ… Wavenet - ×”×§×•×œ ×”×˜×•×‘ ×‘×™×•×ª×¨ ×œ×¢×‘×¨×™×ª
            )
            audio_config = texttospeech.AudioConfig(
                audio_encoding=texttospeech.AudioEncoding.LINEAR16,
                sample_rate_hertz=8000,
                speaking_rate=1.1,   # ××”×™×¨ ×™×•×ª×¨
                pitch=0.0,           # ×˜×•×Ÿ ×˜×‘×¢×™
                effects_profile_id=["telephony-class-application"]  # ××•×¤×˜×™××™×–×¦×™×” ×œ×˜×œ×¤×•×Ÿ
            )
            
            response = client.synthesize_speech(
                input=synthesis_input,
                voice=voice,
                audio_config=audio_config
            )
            
            print(f"âœ… TTS_SUCCESS: Generated {len(response.audio_content)} bytes of Wavenet audio ({len(response.audio_content)/16000:.1f}s estimated)")
            return response.audio_content
            
        except Exception as e:
            print(f"âŒ TTS_CRITICAL_ERROR: {e}")
            print(f"   Text was: '{text}'")
            print(f"   Check Google Cloud credentials!")
            # âœ… ×ª×™×§×•×Ÿ ×§×¨×™×˜×™: ××œ ×ª×§×¨×™×¡ - ×”××©×š ×œ×¢×‘×•×“
            import traceback
            traceback.print_exc()
            return None
    
    def _tx_loop(self):
        """TX Queue loop for smooth audio transmission"""
        while self.tx_running:
            try:
                item = self.tx_q.get(timeout=0.5)
            except queue.Empty:
                continue
            
            if item.get("type") == "end":
                break
            if item.get("type") == "clear" and self.stream_sid:
                self._ws_send(json.dumps({"event": "clear", "streamSid": self.stream_sid}))
                continue
            if item.get("type") == "media":
                self._ws_send(json.dumps({
                    "event": "media", 
                    "streamSid": self.stream_sid,
                    "media": {"payload": item["payload"]}
                }))
                continue
            if item.get("type") == "mark":
                self._ws_send(json.dumps({
                    "event": "mark", 
                    "streamSid": self.stream_sid,
                    "mark": {"name": item.get("name", "mark")}
                }))
    
    def _speak_with_breath(self, text: str):
        """×“×™×‘×•×¨ ×¢× × ×©×™××” ×× ×•×©×™×ª ×•-TX Queue - ×ª××™×“ ××©×“×¨ ××©×”×•"""
        if not text:
            return
            
        self.speaking = True
        self.state = STATE_SPEAK
        self.speaking_start_ts = time.time()  # âœ… ×—×œ×•×Ÿ ×—×¡×“ - ×–××Ÿ ×ª×—×™×œ×ª TTS
        
        try:
            # × ×©×™××” ×× ×•×©×™×ª (220-360ms)
            breath_delay = random.uniform(RESP_MIN_DELAY_MS/1000.0, RESP_MAX_DELAY_MS/1000.0)
            time.sleep(breath_delay)
            
            # clear + ×©×™×“×•×¨
            if self.stream_sid:
                self.tx_q.put_nowait({"type": "clear"})
            
            # × ×¡×” TTS ×××™×ª×™
            pcm = None
            try:
                pcm = self._hebrew_tts(text)
            except Exception as e:
                print("TTS_ERR:", e)
                
            if not pcm or len(pcm) < 400:
                print("ğŸ”Š TTS FAILED - sending beep")
                pcm = self._beep_pcm16_8k(300)  # ×¦×¤×¦×•×£ 300ms
            else:
                print(f"ğŸ”Š TTS SUCCESS: {len(pcm)} bytes")
            
            # ×©×œ×— ××ª ×”××•×“×™×•
            if pcm:
                self._send_pcm16_as_mulaw_frames(pcm)
            time.sleep(breath_delay)
            print(f"ğŸ’¨ HUMAN BREATH: {breath_delay*1000:.0f}ms")
            
            # TTS
            pcm = None
            try:
                pcm = self._hebrew_tts(text)
            except Exception as e:
                print(f"TTS_ERR: {e}")
            
            if not pcm or len(pcm) < 400:
                # ××•×“×™×• ×—×™×¨×•× - ×¦×¤×¦×•×£
                pcm = self._beep_pcm16_8k_v2(300)
            
            # ×©×œ×— ×“×¨×š TX Queue
            if self.stream_sid:
                self.tx_q.put_nowait({"type": "clear"})
            
            # ×”××¨ ×œ-Âµ-law ×•×©×œ×— ×‘-20ms chunks
            mulaw = audioop.lin2ulaw(pcm, 2)
            FR = 160  # 20ms @ 8kHz
            
            for i in range(0, len(mulaw), FR):
                if not self.speaking:  # ×× × ×¤×¡×§ ×‘×××¦×¢
                    break
                    
                chunk = mulaw[i:i+FR]
                if len(chunk) < FR:
                    break
                    
                b64 = base64.b64encode(chunk).decode("ascii")
                self.tx_q.put_nowait({"type": "media", "payload": b64})
                self.tx += 1
            
            # ×¡×™×•×
            self.tx_q.put_nowait({"type": "mark", "name": "tts_done"})
            
        finally:
            self.speaking = False
            self.last_tts_end_ts = time.time()
            self.state = STATE_LISTEN
    
    def _beep_pcm16_8k_v2(self, ms: int) -> bytes:
        """×™×¦×™×¨×ª ×¦×¤×¦×•×£ PCM16 8kHz"""
        samples = int(SR * ms / 1000)
        amp = 9000
        out = bytearray()
        
        for n in range(samples):
            val = int(amp * math.sin(2 * math.pi * 440 * n / SR))
            out.extend(val.to_bytes(2, "little", signed=True))
            
        return bytes(out)
    
    def _detect_area(self, text: str) -> str:
        """×–×™×”×•×™ ××–×•×¨ ××”×˜×§×¡×˜ ×©×œ ×”×œ×§×•×—"""
        text = text.lower()
        
        # ××¨×›×– ×”××¨×¥
        if any(word in text for word in ["×ª×œ ××‘×™×‘", "×“×™×–× ×’×•×£", "×¤×œ×•×¨× ×˜×™×Ÿ", "× ×•×•×” ×¦×“×§"]):
            return "×ª×œ ××‘×™×‘"
        elif any(word in text for word in ["×¨××ª ×’×Ÿ", "×’×‘×¢×ª×™×™×", "×”×‘×•×¨×¡×”"]):
            return "×¨××ª ×’×Ÿ/×’×‘×¢×ª×™×™×"
        elif any(word in text for word in ["×”×¨×¦×œ×™×”", "×¤×™×ª×•×—"]):
            return "×”×¨×¦×œ×™×”"
            
        # ××¨×›×– ×•×“×¨×•×
        elif any(word in text for word in ["×¨××œ×”"]):
            return "×¨××œ×”"
        elif any(word in text for word in ["×œ×•×“"]):
            return "×œ×•×“"
        elif any(word in text for word in ["×¤×ª×— ×ª×§×•×•×”", "×¤×ª×— ×ª×§×•×”"]):
            return "×¤×ª×— ×ª×§×•×•×”"
        elif any(word in text for word in ["××•×“×™×¢×™×Ÿ"]):
            return "××•×“×™×¢×™×Ÿ"
        elif any(word in text for word in ["×¨×—×•×‘×•×ª"]):
            return "×¨×—×•×‘×•×ª"
            
        # ××–×•×¨ ×™×¨×•×©×œ×™×
        elif any(word in text for word in ["×‘×™×ª ×©××©"]):
            return "×‘×™×ª ×©××©"
        elif any(word in text for word in ["××¢×œ×” ××“×•××™×"]):
            return "××¢×œ×” ××“×•××™×"
        elif any(word in text for word in ["×™×¨×•×©×œ×™×"]):
            return "×™×¨×•×©×œ×™×"
            
        return None
    
    def _analyze_lead_completeness(self) -> dict:
        """âœ… × ×™×ª×•×— ×”×©×œ××ª ××™×“×¢ ×œ×™×“ ×œ×ª×™××•× ×¤×’×™×©×”"""
        collected_info = {
            'area': False,
            'property_type': False, 
            'budget': False,
            'timing': False,
            'contact': False
        }
        
        meeting_ready = False
        
        # ×‘×“×•×§ ×”×™×¡×˜×•×¨×™×” ×œ××™×¡×•×£ ××™×“×¢
        if hasattr(self, 'conversation_history') and self.conversation_history:
            full_conversation = ' '.join([turn['user'] + ' ' + turn['bot'] for turn in self.conversation_history])
            
            # ×–×™×”×•×™ ××–×•×¨
            if any(area in full_conversation for area in ['×ª×œ ××‘×™×‘', '×¨××ª ×’×Ÿ', '×¨××œ×”', '×œ×•×“', '×‘×™×ª ×©××©', '××•×“×™×¢×™×Ÿ', '×¤×ª×— ×ª×§×•×•×”', '×¨×—×•×‘×•×ª', '×”×¨×¦×œ×™×”', '×™×¨×•×©×œ×™×']):
                collected_info['area'] = True
            
            # ×–×™×”×•×™ ×¡×•×’ × ×›×¡
            if any(prop_type in full_conversation for prop_type in ['×“×™×¨×”', '×—×“×¨×™×', '2 ×—×“×¨×™×', '3 ×—×“×¨×™×', '4 ×—×“×¨×™×', '××©×¨×“', '×“×•×¤×œ×§×¡']):
                collected_info['property_type'] = True
            
            # ×–×™×”×•×™ ×ª×§×¦×™×‘
            if any(budget_word in full_conversation for budget_word in ['×©×§×œ', '××œ×£', '×ª×§×¦×™×‘', 'â‚ª', '××œ×¤×™×', '××™×œ×™×•×Ÿ']):
                collected_info['budget'] = True
            
            # ×–×™×”×•×™ ×–××Ÿ ×›× ×™×¡×”
            if any(timing in full_conversation for timing in ['××™×™×“×™', '×“×—×•×£', '×—×•×“×©', '×©×‘×•×¢×™×™×', '×‘×§×¨×•×‘', '×¢×›×©×™×•']):
                collected_info['timing'] = True
            
            # ×–×™×”×•×™ ×¤×¨×˜×™ ×§×©×¨
            if any(contact in full_conversation for contact in ['×˜×œ×¤×•×Ÿ', '×•×•××˜×¡××¤', '× ×™×™×“', '××¡×¤×¨', '×¤×¨×˜×™×']):
                collected_info['contact'] = True
        
        # ×¡×¤×™×¨×ª ××™×“×¢ ×©× ××¡×£
        completed_fields = sum(collected_info.values())
        
        # ×ª×™××•× ×¤×’×™×©×” ×× ×™×© ×œ×¤×—×•×ª 3 ×©×“×•×ª
        meeting_ready = completed_fields >= 3
        
        # ×™×¦×™×¨×ª ×¡×™×›×•×
        summary_parts = []
        if collected_info['area']: summary_parts.append('××–×•×¨')
        if collected_info['property_type']: summary_parts.append('×¡×•×’ × ×›×¡')
        if collected_info['budget']: summary_parts.append('×ª×§×¦×™×‘')
        if collected_info['timing']: summary_parts.append('×–××Ÿ')
        if collected_info['contact']: summary_parts.append('×§×©×¨')
        
        summary = f"{len(summary_parts)}/5 ×©×“×•×ª: {', '.join(summary_parts) if summary_parts else '××™×Ÿ'}"
        
        # ×”×•×“×¢×” ×œ×ª×™××•× ×¤×’×™×©×”
        meeting_prompt = ""
        if meeting_ready:
            import datetime
            now = datetime.datetime.now()
            today_evening = f"×”×™×•× {now.hour + 2}:00"
            tomorrow_morning = f"××—×¨ {9 + (now.hour % 3)}:30"
            
            meeting_prompt = f"""
×–××Ÿ ×œ×ª×™××•× ×¤×’×™×©×”! ×™×© ××¡×¤×™×§ ××™×“×¢ ({completed_fields}/5 ×©×“×•×ª).
×”×¦×¢ 2-3 ×—×œ×•× ×•×ª ×–××Ÿ: {today_evening}, {tomorrow_morning}, ××• ×¢×•×“ ××¤×©×¨×•×ª ×§×¦×¨×”.
×‘×§×© ××™×©×•×¨ ×•×©×œ×— ×¡×™×›×•× ×§×¦×¨."""
        else:
            missing = 3 - completed_fields
            meeting_prompt = f"×¦×¨×™×š ×¢×•×“ {missing} ×©×“×•×ª ××™×“×¢ ×œ×¤× ×™ ×ª×™××•× ×¤×’×™×©×”."
        
        return {
            'collected': collected_info,
            'completed_count': completed_fields,
            'meeting_ready': meeting_ready,
            'summary': summary,
            'meeting_prompt': meeting_prompt
        }