"""
WebSocket Media Stream Handler - AI Mode with Hebrew TTS
ADVANCED VERSION WITH TURN-TAKING, BARGE-IN, AND LOOP PREVENTION
"""
import os, json, time, base64, audioop, math, threading, queue, random, zlib, asyncio
import builtins
from server.services.mulaw_fast import mulaw_to_pcm16_fast

# âš¡ PHASE 1: DEBUG mode - ×—×•× ×§ ×›×œ print ×‘-hot path
DEBUG = os.getenv("DEBUG", "0") == "1"
_orig_print = builtins.print

def _dprint(*args, **kwargs):
    """Print only when DEBUG=1 (gating for hot path)"""
    if DEBUG:
        _orig_print(*args, **kwargs)

def force_print(*args, **kwargs):
    """Always print (for critical errors only)"""
    _orig_print(*args, **kwargs)

# ×—×•× ×§×™× ×›×œ print ×‘××•×“×•×œ ×”×–×” ×›×©-DEBUG=0
builtins.print = _dprint

# âš¡ PHASE 1 Task 4: ×˜×œ××˜×¨×™×” - 4 ××“×“×™× ×‘×›×œ TURN
import logging
_now_ms = lambda: int(time.time() * 1000)

def emit_turn_metrics(first_partial, final_ms, tts_ready, total, barge_in=False, eou_reason="unknown"):
    """
    âš¡ PHASE 1: Emit turn latency metrics (non-blocking, uses async logger)
    
    Critical metrics for performance monitoring:
    - STT_FIRST_PARTIAL_MS: Time to first partial from STT
    - STT_FINAL_MS: Time to final/EOU
    - TTS_READY_MS: Time until TTS audio is ready
    - TOTAL_LATENCY_MS: Time until first audio frame sent
    """
    payload = {
        "STT_FIRST_PARTIAL_MS": first_partial,
        "STT_FINAL_MS": final_ms,
        "TTS_READY_MS": tts_ready,
        "TOTAL_LATENCY_MS": total,
        "BARGE_IN_HIT": barge_in,
        "EOU_REASON": eou_reason
    }
    logging.getLogger("turn").info(json.dumps(payload, ensure_ascii=False))

# âš¡ STREAMING STT: ×“×™×¤×•×œ×˜ ××•×¤×¢×œ ×‘×§×•×“, ×›×“×™ ×©×œ× × ×™×¤×•×œ ×œ×¡×™× ×’×œ-×¨×™×§×•×•×¡×˜ ×× ENV ×œ× × ×˜×¢×Ÿ
USE_STREAMING_STT = True
if os.getenv("ENABLE_STREAMING_STT", "").lower() in ("false", "0", "no"):
    USE_STREAMING_STT = False

# âœ… CRITICAL: App Singleton - create ONCE for entire process lifecycle
# This prevents Flask app recreation per-call which caused 5-6s delays and 503 errors
_flask_app_singleton = None
_flask_app_lock = threading.Lock()

def _get_flask_app():
    """Get or create Flask app singleton - prevents app recreation per-call"""
    global _flask_app_singleton
    if _flask_app_singleton is None:
        with _flask_app_lock:
            if _flask_app_singleton is None:  # Double-check after acquiring lock
                from server.app_factory import create_app
                _flask_app_singleton = create_app()
                force_print("âœ… Flask app singleton created for media handlers")
    return _flask_app_singleton

# âš¡ BUILD 116: ××•×¤×˜×™××™×–×¦×™×•×ª ×œ×–××Ÿ ×ª×’×•×‘×” <2s
print("="*80)
print("âš¡ BUILD 116 - SUB-2S RESPONSE OPTIMIZATION + PHASE 1")
print("="*80)
print(f"[BOOT] DEBUG = {DEBUG}")
print(f"[BOOT] USE_STREAMING_STT = {USE_STREAMING_STT}")
print(f"[BOOT] GOOGLE_CLOUD_REGION = {os.getenv('GOOGLE_CLOUD_REGION', 'europe-west1')}")
print(f"[BOOT] GCP_STT_MODEL = {os.getenv('GCP_STT_MODEL', 'phone_call')} (ENHANCED=True enforced)")
print(f"[BOOT] GCP_STT_LANGUAGE = {os.getenv('GCP_STT_LANGUAGE', 'he-IL')}")
print(f"[BOOT] STT_BATCH_MS = {os.getenv('STT_BATCH_MS', '40')}")
print(f"[BOOT] STT_PARTIAL_DEBOUNCE_MS = {os.getenv('STT_PARTIAL_DEBOUNCE_MS', '90')}")
print(f"[BOOT] VAD_HANGOVER_MS = {os.getenv('VAD_HANGOVER_MS', '180')}")
print(f"[BOOT] UTTERANCE_TIMEOUT = 320ms (aggressive for sub-2s response)")
print("="*80)

if USE_STREAMING_STT:
    print("ğŸš€ STT MODE: Real-time Streaming (Session-per-call)")
else:
    print("âš ï¸  WARNING: STT MODE is Single-request (SLOW!) - Set ENABLE_STREAMING_STT=true")
    print("ğŸ“ STT MODE: Single-request (fast Î¼-law + optimized Google STT)")

# âš¡ THREAD-SAFE SESSION REGISTRY for multi-call support
# Each call_sid has its own session + dispatcher state
_sessions_registry = {}  # call_sid -> {"session": StreamingSTTSession, "utterance": {...}, "tenant": str, "ts": float}
_registry_lock = threading.RLock()
MAX_CONCURRENT_CALLS = int(os.getenv("MAX_CONCURRENT_CALLS", "50"))

def _register_session(call_sid: str, session, tenant_id=None):
    """Register a new STT session for a call (thread-safe)"""
    with _registry_lock:
        if len(_sessions_registry) >= MAX_CONCURRENT_CALLS:
            raise RuntimeError(f"Over capacity: {len(_sessions_registry)}/{MAX_CONCURRENT_CALLS} calls")
        _sessions_registry[call_sid] = {
            "session": session,
            "utterance": {
                "id": None, 
                "partial_cb": None, 
                "final_buf": None,
                "final_received": None,  # âš¡ NEW: Event for waiting on final
                "last_partial": ""  # âš¡ NEW: Backup partial text
            },
            "tenant": tenant_id,
            "ts": time.time()
        }
        if DEBUG: print(f"âœ… [REGISTRY] Registered session for call {call_sid[:8]}... (tenant: {tenant_id}, total: {len(_sessions_registry)})")

def _get_session(call_sid: str):
    """Get STT session for a call (thread-safe)"""
    with _registry_lock:
        item = _sessions_registry.get(call_sid)
        return item["session"] if item else None

def _get_utterance_state(call_sid: str):
    """Get utterance state for a call (thread-safe)"""
    with _registry_lock:
        item = _sessions_registry.get(call_sid)
        return item["utterance"] if item else None

def _close_session(call_sid: str):
    """Close and remove STT session for a call (thread-safe)"""
    with _registry_lock:
        item = _sessions_registry.pop(call_sid, None)
    
    if item:
        try:
            item["session"].close()
            if DEBUG: print(f"âœ… [REGISTRY] Closed session for call {call_sid[:8]}... (remaining: {len(_sessions_registry)})")
        except Exception as e:
            if DEBUG: print(f"âš ï¸ [REGISTRY] Error closing session for {call_sid[:8]}...: {e}")

def _create_dispatcher_callbacks(call_sid: str):
    """Create partial/final callbacks that route to the correct call's utterance"""
    def on_partial(text: str):
        utt = _get_utterance_state(call_sid)
        if utt:
            # âš¡ BUILD 112: Save last partial as backup and log it
            with _registry_lock:
                utt["last_partial"] = text
            if DEBUG: print(f"ğŸŸ¡ [PARTIAL] '{text}' saved for {call_sid[:8]}... (utterance: {utt.get('id', '???')})")
            
            # âš¡ BUILD 114: Early Finalization - if partial is strong enough, trigger final AND continue
            # This saves 400-600ms by triggering final event early
            if text and len(text) > 15 and text.rstrip().endswith(('.', '?', '!')):
                if DEBUG: print(f"âš¡ [EARLY_FINALIZE] Strong partial detected: '{text}' â†’ triggering final event")
                # Trigger final event (but continue to call partial callback)
                final_event = utt.get("final_received")
                if final_event:
                    final_event.set()
            
            # Call the utterance's partial callback
            cb = utt.get("partial_cb")
            if cb:
                try:
                    cb(text)
                except Exception as e:
                    print(f"âš ï¸ Partial callback error for {call_sid[:8]}...: {e}")
    
    def on_final(text: str):
        utt = _get_utterance_state(call_sid)
        if utt:
            buf = utt.get("final_buf")
            if buf is not None:
                buf.append(text)
                if DEBUG: print(f"âœ… [FINAL] '{text}' received for {call_sid[:8]}... (utterance: {utt.get('id', '???')})")
                
                # âš¡ Signal that final has arrived!
                final_event = utt.get("final_received")
                if final_event:
                    final_event.set()
                    if DEBUG: print(f"ğŸ“¢ [FINAL_EVENT] Set for {call_sid[:8]}...")
    
    return on_partial, on_final

def _cleanup_stale_sessions():
    """Cleanup sessions that haven't received audio for >2 minutes (edge case protection)"""
    STALE_TIMEOUT = 120  # 2 minutes
    current_time = time.time()
    
    with _registry_lock:
        stale_call_sids = [
            call_sid for call_sid, item in _sessions_registry.items()
            if current_time - item["ts"] > STALE_TIMEOUT
        ]
    
    for call_sid in stale_call_sids:
        if DEBUG: print(f"ğŸ§¹ [REAPER] Cleaning stale session: {call_sid[:8]}... (inactive for >{STALE_TIMEOUT}s)")
        _close_session(call_sid)

# Start session reaper thread
def _start_session_reaper():
    """Background thread that cleans up stale sessions every 60s"""
    def reaper_loop():
        while True:
            time.sleep(60)  # Check every 60 seconds
            try:
                _cleanup_stale_sessions()
            except Exception as e:
                print(f"âš ï¸ [REAPER] Error during cleanup: {e}")
    
    reaper_thread = threading.Thread(target=reaper_loop, daemon=True, name="SessionReaper")
    reaper_thread.start()
    print("ğŸ§¹ [REAPER] Session cleanup thread started")

# Start reaper on module load (only if streaming enabled)
if USE_STREAMING_STT:
    _start_session_reaper()

# Override print to always flush (CRITICAL for logs visibility)
_original_print = builtins.print
def print(*args, **kwargs):
    kwargs.setdefault('flush', True)
    _original_print(*args, **kwargs)
builtins.print = print

# WebSocket ConnectionClosed exception (works with both Flask-Sock and Starlette)
class ConnectionClosed(Exception):
    """WebSocket connection closed"""
    pass

from server.stream_state import stream_registry

SR = 8000
# âš¡ BUILD 114: VAD OPTIMIZED FOR SPEED (Streaming STT enabled, â‰¤2s latency target)
MIN_UTT_SEC = float(os.getenv("MIN_UTT_SEC", "0.6"))        # âš¡ 0.6s - ×××¤×©×¨ ×ª×’×•×‘×•×ª ×§×¦×¨×•×ª ×›××• "×›×Ÿ"
MAX_UTT_SEC = float(os.getenv("MAX_UTT_SEC", "12.0"))       # âœ… 12.0s - ×–××Ÿ ××¡×¤×™×§ ×œ×ª×™××•×¨ × ×›×¡×™× ××¤×•×¨×˜
VAD_RMS = int(os.getenv("VAD_RMS", "65"))                   # âœ… ×¤×—×•×ª ×¨×’×™×© ×œ×¨×¢×©×™× - ××¤×—×™×ª ×§×˜×™×¢×•×ª ×©×’×•×™×•×ª
BARGE_IN = os.getenv("BARGE_IN", "true").lower() == "true"
VAD_HANGOVER_MS = int(os.getenv("VAD_HANGOVER_MS", "180"))  # âš¡ BUILD 116: 180ms - aggressive for sub-2s response
RESP_MIN_DELAY_MS = int(os.getenv("RESP_MIN_DELAY_MS", "50")) # âš¡ SPEED: 50ms ×‘××§×•× 80ms - ×ª×’×•×‘×” ××”×™×¨×”
RESP_MAX_DELAY_MS = int(os.getenv("RESP_MAX_DELAY_MS", "120")) # âš¡ SPEED: 120ms ×‘××§×•× 200ms - ×¤×—×•×ª ×”××ª× ×”
REPLY_REFRACTORY_MS = int(os.getenv("REPLY_REFRACTORY_MS", "1100")) # âš¡ BUILD 107: 1100ms - ×§×™×¨×•×¨ ××”×™×¨ ×™×•×ª×¨
BARGE_IN_VOICE_FRAMES = int(os.getenv("BARGE_IN_VOICE_FRAMES","40"))  # âœ… 40 frames = â‰ˆ800ms ×§×•×œ ×¨×¦×™×£ × ×“×¨×© ×œ×§×˜×™×¢×”
THINKING_HINT_MS = int(os.getenv("THINKING_HINT_MS", "0"))       # ×‘×œ×™ "×‘×•×“×§×ª" - ×™×©×™×¨×•×ª ×œ×¢×‘×•×“×”!
THINKING_TEXT_HE = os.getenv("THINKING_TEXT_HE", "")   # ××™×Ÿ ×”×•×“×¢×ª ×—×©×™×‘×”
DEDUP_WINDOW_SEC = int(os.getenv("DEDUP_WINDOW_SEC", "8"))        # ×—×œ×•×Ÿ ×§×¦×¨ ×™×•×ª×¨
LLM_NATURAL_STYLE = True  # ×ª×’×•×‘×•×ª ×˜×‘×¢×™×•×ª ×œ×¤×™ ×”×©×™×—×”

# ××›×•× ×ª ××¦×‘×™×
STATE_LISTEN = "LISTENING"
STATE_THINK  = "THINKING"
STATE_SPEAK  = "SPEAKING"

class MediaStreamHandler:
    def __init__(self, ws):
        self.ws = ws
        self.mode = "AI"  # ×ª××™×“ ×‘××¦×‘ AI
        
        # ğŸ”§ ×ª××™××•×ª WebSocket - EventLet vs RFC6455 ×¢× ×˜×™×¤×•×œ ×©×’×™××•×ª
        if hasattr(ws, 'send'):
            self._ws_send_method = ws.send
        else:
            # ×× ××™×Ÿ send, × ×¡×” send_text ××• ×›×œ ×©×™×˜×” ××—×¨×ª
            self._ws_send_method = getattr(ws, 'send_text', lambda x: print(f"âŒ No send method: {x}"))
        
        # ğŸ›¡ï¸ Safe WebSocket send wrapper with connection health
        self.ws_connection_failed = False
        self.failed_send_count = 0
        
        def _safe_ws_send(data):
            if self.ws_connection_failed:
                return False  # Don't spam when connection is dead
                
            try:
                self._ws_send_method(data)
                self.failed_send_count = 0  # Reset on success
                return True
            except Exception as e:
                self.failed_send_count += 1
                if self.failed_send_count <= 3:  # Only log first 3 errors
                    print(f"âŒ WebSocket send error #{self.failed_send_count}: {e}")
                
                if self.failed_send_count >= 10:  # Increased threshold - After 10 failures, mark as dead
                    self.ws_connection_failed = True
                    print(f"ğŸš¨ WebSocket connection marked as FAILED after {self.failed_send_count} attempts")
                
                return False
        
        self._ws_send = _safe_ws_send
        self.stream_sid = None
        self.call_sid = None  # PATCH 3: For watchdog connection
        self.rx = 0
        self.tx = 0
        
        # ğŸ¯ ×¤×ª×¨×•×Ÿ ×¤×©×•×˜ ×•×™×¢×™×œ ×œ× ×™×”×•×œ ×ª×•×¨×•×ª
        self.buf = bytearray()
        self.last_rx = None
        self.speaking = False           # ×”×× ×”×‘×•×˜ ××“×‘×¨ ×›×¨×’×¢
        self.processing = False         # ×”×× ××¢×‘×“ ××‘×¢ ×›×¨×’×¢
        self.conversation_id = 0        # ××•× ×” ×©×™×—×•×ª ×œ×× ×™×¢×ª ×›×¤×™×œ×•×™×•×ª
        self.last_processing_id = -1    # ××–×”×” ×”×¢×™×‘×•×“ ×”××—×¨×•×Ÿ
        self.response_timeout = None    # ×–××Ÿ ×ª×’×•×‘×” ××§×¡×™××œ×™
        
        # ×“×”-×“×•×¤×œ×™×§×¦×™×” ××ª×§×“××ª ×¢× hash
        self.last_user_hash = None
        self.last_user_hash_ts = 0.0
        self.last_reply_hash = None
        self.introduced = False
        self.response_history = []       # ×”×™×¡×˜×•×¨×™×™×ª ×ª×’×•×‘×•×ª
        self.last_tts_end_ts = 0.0
        self.voice_in_row = 0
        self.greeting_sent = False
        self.state = STATE_LISTEN        # ××¦×‘ × ×•×›×—×™
        
        # âœ… ×ª×™×§×•×Ÿ ×§×¨×™×˜×™: ××¢×§×‘ × ×¤×¨×“ ××—×¨ ×§×•×œ ×•×©×§×˜
        self.last_voice_ts = 0.0         # ×–××Ÿ ×”×§×•×œ ×”××—×¨×•×Ÿ - ×œ×—×™×©×•×‘ ×“×××” ×××™×ª×™
        self.noise_floor = 35.0          # ×¨××ª ×¨×¢×© ×‘×¡×™×¡×™×ª
        self.vad_threshold = 35.0        # ×¡×£ VAD ×“×™× ××™
        self.is_calibrated = False       # ×”×× ×›×•×™×œ×¨× ×• ××ª ×¨××ª ×”×¨×¢×©
        self.calibration_frames = 0      # ××•× ×” ×¤×¨×™×™××™× ×œ×›×™×•×œ
        self.mark_pending = False        # ×”×× ×××ª×™× ×™× ×œ×¡×™××•×Ÿ TTS
        self.mark_sent_ts = 0.0          # ×–××Ÿ ×©×œ×™×—×ª ×¡×™××•×Ÿ
        
        # ×”×’× ×•×ª Watchdog
        self.processing_start_ts = 0.0   # ×ª×—×™×œ×ª ×¢×™×‘×•×“
        self.speaking_start_ts = 0.0     # ×ª×—×™×œ×ª ×“×™×‘×•×¨
        
        # âš¡ BUILD 109: Smart barge-in - disable for long responses
        self.long_response = False       # ×”×× ×”×ª×©×•×‘×” ××¨×•×›×” (>20 ××™×œ×™×)
        
        # âœ… BUILD 117: WebSocket Keepalive with more frequent pings
        self.last_keepalive_ts = 0.0     # ×–××Ÿ keepalive ××—×¨×•×Ÿ
        self.keepalive_interval = 10.0   # âœ… ×©×œ×— ×›×œ 10 ×©× ×™×•×ª (was 18s) - prevents timeouts
        self.heartbeat_counter = 0       # ××•× ×” heartbeat
        
        # âš¡ BUILD 116: Enhanced telemetry - track every stage
        self.t0_connected = 0.0          # [T0] WebSocket connected
        self.t1_greeting_start = 0.0     # [T1] Greeting started
        self.t2_greeting_end = 0.0       # [T2] Greeting last frame sent
        self.s1_stream_opened = 0.0      # [S1] STT stream opened
        self.s2_first_partial = 0.0      # [S2] First partial received
        self.s3_final = 0.0              # [S3] Final text received
        self.a1_ai_start = 0.0           # [A1] AI processing started
        self.a2_ai_done = 0.0            # [A2] AI response ready
        self.v1_tts_start = 0.0          # [V1] TTS synthesis started
        self.v2_tts_done = 0.0           # [V2] TTS synthesis completed
        self.tx_first_frame = 0.0        # [TX] First reply frame sent
        
        # TX Queue for smooth audio transmission
        # âš¡ BUILD 115.1: Reduced to 120 frames (~2.4s buffer) to prevent lag
        self.tx_q = queue.Queue(maxsize=120)
        self.tx_running = False
        self.tx_thread = threading.Thread(target=self._tx_loop, daemon=True)
        self._last_overflow_log = 0.0  # For throttled logging
        
        print("ğŸ¯ AI CONVERSATION STARTED")
        
        # ×××¤×™×™× ×™× ×œ×–×™×”×•×™ ×¢×¡×§
        self.business_id = None  # âœ… ×™×–×•×”×” ×“×™× ××™×ª ×œ×¤×™ to_number
        self.phone_number = None
        
        # âš¡ DTMF phone collection (digits gathered from keypad)
        self.dtmf_buffer = ""  # Accumulated digits from phone keypad
        self.waiting_for_dtmf = False  # Are we waiting for phone input?
        self.dtmf_purpose = None  # What are we collecting? 'phone', etc.
        
        # ×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×” ×œ××¢×§×‘ ××—×¨ ×”×§×©×¨
        self.conversation_history = []  # ×¨×©×™××” ×©×œ ×”×•×“×¢×•×ª {'user': str, 'bot': str}
        self.turn_count = 0  # âš¡ Phase 2C: Track turns for first-turn optimization
        
        # âœ… CRITICAL: Track background threads for proper cleanup
        self.background_threads = []
        
        # âš¡ BUILD 115: Async executor for non-blocking fallback STT
        from concurrent.futures import ThreadPoolExecutor
        self.loop = None  # Will be set when needed
        self.exec = ThreadPoolExecutor(max_workers=1)  # Per-call executor
        self.events_q = None  # Will be created if async mode is used
        
        # âš¡ STREAMING STT: Will be initialized after business identification (in "start" event)

    def _init_streaming_stt(self):
        """
        âš¡ BUILD 114: Initialize streaming STT with retry mechanism
        3 attempts before falling back to single-request mode
        """
        if not USE_STREAMING_STT or not self.call_sid:
            return
        
        from server.services.gcp_stt_stream import StreamingSTTSession
        
        # âš¡ RETRY MECHANISM: 3 attempts before fallback
        for attempt in range(3):
            try:
                # Create dispatcher callbacks for this specific call
                on_partial, on_final = _create_dispatcher_callbacks(self.call_sid)
                
                # Create session
                session = StreamingSTTSession(
                    on_partial=on_partial,
                    on_final=on_final
                )
                
                # Register in thread-safe registry
                _register_session(self.call_sid, session, tenant_id=self.business_id)
                
                self.s1_stream_opened = time.time()  # âš¡ [S1] STT stream opened
                if DEBUG: print(f"âœ… [S1={self.s1_stream_opened:.3f}] Streaming session started for call {self.call_sid[:8]}... (business: {self.business_id}, attempt: {attempt+1}, Î”={(self.s1_stream_opened - self.t0_connected)*1000:.0f}ms from T0)")
                return  # Success!
                
            except RuntimeError as e:
                if DEBUG: print(f"ğŸš¨ [STT] Over capacity (attempt {attempt+1}/3): {e}")
                if attempt < 2:
                    time.sleep(0.2)  # Brief delay before retry
                    continue
                # Don't crash - will use fallback STT
                return
                
            except Exception as e:
                if DEBUG: print(f"âš ï¸ [STT] Streaming start failed (attempt {attempt+1}/3): {e}", flush=True)
                if attempt < 2:
                    time.sleep(0.2)  # Brief delay before retry
                    continue
                if DEBUG:
                    import traceback
                    traceback.print_exc()
                return
        
        # If we get here, all 3 attempts failed
        if DEBUG: print(f"âŒ [STT] All streaming attempts failed for call {self.call_sid[:8]} â†’ using fallback single request", flush=True)
    
    def _close_streaming_stt(self):
        """Close streaming STT session at end of call"""
        if self.call_sid:
            _close_session(self.call_sid)
    
    def _utterance_begin(self, partial_cb=None):
        """
        Mark start of new utterance.
        Switches dispatcher target to new utterance buffer.
        """
        import uuid
        import threading
        
        if not self.call_sid:
            return
        
        utt_state = _get_utterance_state(self.call_sid)
        if utt_state is not None:
            with _registry_lock:
                utt_state["id"] = uuid.uuid4().hex[:8]
                utt_state["partial_cb"] = partial_cb
                utt_state["final_buf"] = []
                utt_state["final_received"] = threading.Event()  # âš¡ NEW: wait for final
                utt_state["last_partial"] = ""  # âš¡ NEW: save last partial as backup
            
            if DEBUG: print(f"ğŸ¤ [{self.call_sid[:8]}] Utterance {utt_state['id']} BEGIN")
    
    def _utterance_end(self, timeout=0.850):
        """
        Mark end of utterance.
        âš¡ BUILD 118: Increased timeout to 850ms - streaming STT needs time for final results
        """
        if not self.call_sid:
            print("âš ï¸ _utterance_end: No call_sid")
            return ""
        
        utt_state = _get_utterance_state(self.call_sid)
        if utt_state is None:
            print(f"âš ï¸ _utterance_end: No utterance state for call {self.call_sid[:8]}")
            return ""
        
        utt_id = utt_state.get("id", "???")
        print(f"ğŸ¤ [{self.call_sid[:8]}] _utterance_end: Collecting results for utterance {utt_id} (timeout={timeout}s)")
        
        # âš¡ BUILD 118: Wait 850ms for streaming results - allows time for final transcription
        # Streaming STT enabled by default â†’ fast partial results
        wait_start = time.time()
        wait_duration = 0.0
        final_event = utt_state.get("final_received")
        if final_event:
            got_final = final_event.wait(timeout=timeout)  # 850ms wait for streaming
            wait_duration = time.time() - wait_start
            if got_final:
                print(f"âœ… [{self.call_sid[:8]}] Got final event in {wait_duration:.3f}s")
            else:
                print(f"âš ï¸ [{self.call_sid[:8]}] Timeout after {wait_duration:.3f}s - using fallback")  
        
        # Collect text - prioritize partial over finals
        with _registry_lock:
            # âš¡ PRIMARY: Use last partial (this is what we actually get!)
            last_partial = utt_state.get("last_partial", "")
            
            # FALLBACK: Check finals buffer (rarely populated)
            finals = utt_state.get("final_buf") or []
            finals_text = " ".join(finals).strip()
            
            # Use partial if available, otherwise finals
            if last_partial:
                text = last_partial
                print(f"âœ… [{self.call_sid[:8]}] Using partial: '{text[:50]}...' ({len(text)} chars)")
            elif finals_text:
                text = finals_text
                print(f"âœ… [{self.call_sid[:8]}] Using final: '{text[:50]}...' ({len(text)} chars)")
            else:
                text = ""
                print(f"âš ï¸ [{self.call_sid[:8]}] No text available - returning empty")
            
            # Reset dispatcher
            utt_state["id"] = None
            utt_state["partial_cb"] = None
            utt_state["final_buf"] = None
            utt_state["final_received"] = None
            utt_state["last_partial"] = ""
        
        # âš¡ BUILD 114: Detailed latency logging
        print(f"ğŸ [{self.call_sid[:8]}] Utterance {utt_id} COMPLETE: returning '{text[:30] if text else '(empty)'}'")
        print(f"[LATENCY] final_wait={wait_duration:.2f}s, utterance_total={time.time() - wait_start:.2f}s")
        
        return text

    def run(self):
        # Media stream handler initialized")
        
        # CRITICAL FIX: Ensure json import is available
        import json
        
        # Write debug to MULTIPLE LOCATIONS for guaranteed persistence
        timestamp = int(time.time())
        debug_files = [
            f"/tmp/ws_handler_debug_{timestamp}.txt",
            f"/tmp/websocket_debug.txt",
            f"/tmp/handler_called.txt",
            f"/home/runner/workspace/handler_debug.txt",
            f"/tmp/HANDLER_WORKS_{timestamp}.txt"
        ]
        
        success_count = 0
        for debug_file in debug_files:
            try:
                with open(debug_file, "w") as f:
                    f.write(f"HANDLER_START: {self.stream_sid} at {time.time()}\n")
                    f.write(f"WEBSOCKET_HANDLER_DEFINITELY_WORKS!\n")
                    f.write(f"CONNECTION_SUCCESSFUL: {timestamp}\n")
                    f.flush()
                success_count += 1
                print(f"âœ… Debug written to {debug_file}", flush=True)
            except Exception as e:
                print(f"âŒ Failed to write {debug_file}: {e}", flush=True)
        
        print(f"âœ… Debug files written: {success_count}/{len(debug_files)}", flush=True)
        
        # PATCH 4: Advanced logging counters
        self.rx_frames = 0
        self.tx_frames = 0
        
        print(f"WS_START sid={self.stream_sid} mode=AI call_sid={self.call_sid}")
        print(f"ğŸ¯ CONVERSATION READY (VAD threshold: {VAD_RMS})")
        
        try:
            while True:
                # COMPATIBILITY: Handle both EventLet and Flask-Sock WebSocket APIs
                raw = None
                try:
                    # Simplified WebSocket handling - no spam logs
                    ws_type = str(type(self.ws))
                    
                    # RFC6455WebSocket-specific handling (EventLet)
                    if 'RFC6455WebSocket' in ws_type:
                        # EventLet RFC6455WebSocket uses wait() method
                        raw = self.ws.wait()
                        # ×¨×§ ×¡×¤×™×¨×” ×‘×œ×™ spam
                        self.rx_frames += 1
                    else:
                        # Standard WebSocket APIs
                        if hasattr(self.ws, 'receive'):
                            raw = self.ws.receive()
                        elif hasattr(self.ws, 'recv'):
                            raw = self.ws.recv()
                        elif hasattr(self.ws, 'read_message'):
                            raw = self.ws.read_message()
                        elif hasattr(self.ws, 'receive_data'):
                            raw = self.ws.receive_data()
                        elif hasattr(self.ws, 'read'):
                            raw = self.ws.read()
                        else:
                            print(f"âš ï¸ Unknown WebSocket type: {type(self.ws)}, available methods: {[m for m in dir(self.ws) if not m.startswith('_')]}", flush=True)
                            raise Exception(f"No compatible receive method found for {type(self.ws)}")
                        
                    if raw is None or raw == '':
                        print("ğŸ“ WebSocket connection closed normally", flush=True)
                        break
                        
                    # Handle both string and bytes
                    if isinstance(raw, bytes):
                        raw = raw.decode('utf-8')
                        
                    evt = json.loads(raw)
                    et = evt.get("event")
                    
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ Invalid JSON received: {str(raw)[:100] if raw else 'None'}... Error: {e}", flush=True)
                    continue
                except Exception as e:
                    print(f"âš ï¸ WebSocket receive error: {e}", flush=True)
                    import traceback
                    traceback.print_exc()
                    # Try to continue, might be temporary - don't crash the connection
                    continue

                if et == "start":
                    # ×ª××™×›×” ×‘×©× ×™ ×¤×•×¨××˜×™×: Twilio ×××™×ª×™ ×•×‘×“×™×§×•×ª
                    if "start" in evt:
                        # Twilio format: {"event": "start", "start": {"streamSid": "...", "callSid": "..."}}
                        self.stream_sid = evt["start"]["streamSid"]
                        self.call_sid = (
                            evt["start"].get("callSid")
                            or (evt["start"].get("customParameters") or {}).get("CallSid")
                            or (evt["start"].get("customParameters") or {}).get("call_sid")
                        )
                        
                        # âœ… ×–×™×”×•×™ ××¡×¤×¨×™ ×˜×œ×¤×•×Ÿ ×-customParameters
                        custom_params = evt["start"].get("customParameters", {})
                        self.phone_number = (
                            custom_params.get("From") or
                            custom_params.get("CallFrom") or  
                            custom_params.get("from") or
                            custom_params.get("phone_number")
                        )
                        # âœ… CRITICAL FIX: ×©××™×¨×ª to_number ×œ××–×”×” ×¢×¡×§
                        self.to_number = (
                            evt["start"].get("to") or  # âœ… Twilio sends 'to' at start level
                            custom_params.get("To") or
                            custom_params.get("Called") or
                            custom_params.get("to") or
                            custom_params.get("called")
                        )
                        
                        # ğŸ” DEBUG: Log phone numbers from customParameters
                        print(f"\nğŸ“ START EVENT (customParameters path):")
                        print(f"   customParams.From: {custom_params.get('From')}")
                        print(f"   customParams.CallFrom: {custom_params.get('CallFrom')}")
                        print(f"   âœ… self.phone_number set to: '{self.phone_number}'")
                        print(f"   âœ… self.to_number set to: '{self.to_number}'")
                    else:
                        # Direct format: {"event": "start", "streamSid": "...", "callSid": "..."}
                        self.stream_sid = evt.get("streamSid")
                        self.call_sid = evt.get("callSid")
                        self.phone_number = evt.get("from") or evt.get("phone_number")
                        self.to_number = evt.get("to") or evt.get("called")
                        
                        # ğŸ” DEBUG: Log phone number on start
                        print(f"\nğŸ“ START EVENT - Phone numbers:")
                        print(f"   from field: {evt.get('from')}")
                        print(f"   phone_number field: {evt.get('phone_number')}")
                        print(f"   âœ… self.phone_number set to: '{self.phone_number}'")
                        
                    self.last_rx_ts = time.time()
                    self.last_keepalive_ts = time.time()  # âœ… ×”×ª×—×œ keepalive
                    self.t0_connected = time.time()  # âš¡ [T0] WebSocket connected
                    print(f"ğŸ¯ [T0={time.time():.3f}] WS_START sid={self.stream_sid} call_sid={self.call_sid} from={self.phone_number} to={getattr(self, 'to_number', 'N/A')} mode={self.mode}")
                    if self.call_sid:
                        stream_registry.mark_start(self.call_sid)
                    
                    # âš¡ OPTIMIZED: ×–×™×”×•×™ ×¢×¡×§ + ×‘×¨×›×” ×‘×©××™×œ×ª×” ××—×ª!
                    try:
                        app = _get_flask_app()  # âœ… Use singleton
                        with app.app_context():
                            business_id, greet = self._identify_business_and_get_greeting()
                        print(f"âš¡ FAST: business_id={business_id}, greeting loaded in single query!")
                    except Exception as e:
                        print(f"âŒ CRITICAL ERROR in business identification: {e}")
                        import traceback
                        traceback.print_exc()
                        self.business_id = 1
                        greet = "×©×œ×•×! ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?"
                    
                    # âš¡ STREAMING STT: Initialize NOW (after business_id is known)
                    self._init_streaming_stt()
                    
                    # âœ… ×™×¦×™×¨×ª call_log ××™×“ ×‘×”×ª×—×œ×ª ×©×™×—×” (××—×¨×™ ×–×™×”×•×™ ×¢×¡×§!)
                    try:
                        if self.call_sid and not hasattr(self, '_call_log_created'):
                            self._create_call_log_on_start()
                            self._call_log_created = True
                    except Exception as e:
                        print(f"âš ï¸ Call log creation failed (non-critical): {e}")
                    
                    # âœ… ×‘×¨×›×” ××™×™×“×™×ª - ×‘×œ×™ ×”×©×”×™×”!
                    if not self.tx_running:
                        self.tx_running = True
                        self.tx_thread.start()
                    
                    if not self.greeting_sent:
                        self.t1_greeting_start = time.time()  # âš¡ [T1] Greeting start
                        print(f"ğŸ¯ [T1={self.t1_greeting_start:.3f}] SENDING IMMEDIATE GREETING! (Î”={(self.t1_greeting_start - self.t0_connected)*1000:.0f}ms from T0)")
                        try:
                            self._speak_greeting(greet)  # âœ… ×¤×•× ×§×¦×™×” ××™×•×—×“×ª ×œ×‘×¨×›×” ×œ×œ× sleep!
                            self.t2_greeting_end = time.time()  # âš¡ [T2] Greeting end
                            print(f"ğŸ¯ [T2={self.t2_greeting_end:.3f}] GREETING_COMPLETE! (Duration={(self.t2_greeting_end - self.t1_greeting_start)*1000:.0f}ms)")
                            self.greeting_sent = True
                        except Exception as e:
                            print(f"âŒ CRITICAL ERROR sending greeting: {e}")
                            import traceback
                            traceback.print_exc()
                    continue

                if et == "media":
                    self.rx += 1
                    b64 = evt["media"]["payload"]
                    mulaw = base64.b64decode(b64)
                    # âš¡ SPEED: Fast Î¼-law decode using lookup table (~10-20x faster)
                    pcm16 = mulaw_to_pcm16_fast(mulaw)
                    self.last_rx_ts = time.time()
                    if self.call_sid:
                        stream_registry.touch_media(self.call_sid)
                    
                    # âš¡ STREAMING STT: Feed audio to session (continuous streaming)
                    if self.call_sid and pcm16:
                        session = _get_session(self.call_sid)
                        if session:
                            session.push_audio(pcm16)
                            # Update session timestamp to prevent cleanup
                            with _registry_lock:
                                item = _sessions_registry.get(self.call_sid)
                                if item:
                                    item["ts"] = time.time()
                        elif USE_STREAMING_STT:
                            # âš ï¸ Session should exist but doesn't!
                            if not hasattr(self, '_session_warning_logged'):
                                print(f"âš ï¸ [STT] No streaming session for {self.call_sid[:8]} - using fallback")
                                self._session_warning_logged = True
                    
                    # ××“×“ ×“×™×‘×•×¨/×©×§×˜ (VAD) - ×–×™×”×•×™ ×§×•×œ ×—×–×§ ×‘×œ×‘×“
                    rms = audioop.rms(pcm16, 2)
                    
                    # ğŸ“Š VAD ×“×™× ××™ ××©×•×¤×¨ ×¢× ×§×œ×™×‘×¨×¦×™×” ××¨×•×›×” ×™×•×ª×¨ ×•×”×™×¡×˜×¨×–×™×¡
                    if not self.is_calibrated and self.calibration_frames < 40:
                        # ×§×œ×™×‘×¨×¦×™×” ××¨×•×›×” ×™×•×ª×¨: 300-500ms = 15-25 frames, × ×©×ª××© ×‘-40 ×œ×”×™×•×ª ×‘×˜×•×—×™×
                        self.noise_floor = (self.noise_floor * self.calibration_frames + rms) / (self.calibration_frames + 1)
                        self.calibration_frames += 1
                        if self.calibration_frames >= 60:
                            # âœ… HEBREW-OPTIMIZED: Balanced threshold for Hebrew speech
                            self.vad_threshold = max(150, self.noise_floor * 5.0 + 100)  # ××•×ª×× ×œ×¢×‘×¨×™×ª - ×××–×™×Ÿ ×¢×“ ×”×¡×•×£
                            self.is_calibrated = True
                            print(f"ğŸ›ï¸ VAD CALIBRATED for HEBREW (threshold: {self.vad_threshold:.1f})")
                            
                            # ×”×™×¡×˜×¨×–×™×¡ ×œ×× ×™×¢×ª ×¨×™×¦×•×“
                            if not hasattr(self, 'vad_hysteresis_count'):
                                self.vad_hysteresis_count = 0
                            if not hasattr(self, 'last_vad_state'):
                                self.last_vad_state = False
                    
                    # ğŸ“Š ×–×™×”×•×™ ×§×•×œ ××©×•×¤×¨ ×¢× ×”×™×¡×˜×¨×–×™×¡ ×•-Zero-Crossing Rate
                    if self.is_calibrated:
                        # ×—×™×©×•×‘ Zero-Crossing Rate ×œ××“×™×“×ª ×“×™×‘×•×¨ ×¨×š
                        zero_crossings = 0
                        try:
                            import numpy as np
                            pcm_np = np.frombuffer(pcm16, dtype=np.int16)
                            zero_crossings = np.sum(np.diff(np.sign(pcm_np)) != 0) / len(pcm_np) if len(pcm_np) > 0 else 0
                        except ImportError:
                            # numpy ×œ× ××•×ª×§×Ÿ - × ×©×ª××© ×‘VAD ×‘×¡×™×¡×™ ×‘×œ×‘×“
                            zero_crossings = 0
                        except:
                            zero_crossings = 0
                        
                        # VAD ×‘×¡×™×¡×™
                        basic_voice = rms > self.vad_threshold
                        
                        # VAD ××©×•×¤×¨ ×¢× Zero-Crossing Rate
                        zcr_voice = zero_crossings > 0.05  # ×“×™×‘×•×¨ ×¨×š ×¢× ×”×¨×‘×” ××¢×‘×¨×™ ××¤×¡
                        enhanced_voice = basic_voice or (zcr_voice and rms > self.vad_threshold * 0.6)
                        
                        # ×”×™×¡×˜×¨×–×™×¡: 100ms = 5 frames ×œ×× ×™×¢×ª ×¨×™×¦×•×“
                        if enhanced_voice != self.last_vad_state:
                            self.vad_hysteresis_count += 1
                            if self.vad_hysteresis_count >= 5:  # 100ms ×”×™×¡×˜×¨×–×™×¡ ×—×–×§ ×™×•×ª×¨
                                is_strong_voice = enhanced_voice
                                self.last_vad_state = enhanced_voice
                                self.vad_hysteresis_count = 0
                            else:
                                is_strong_voice = self.last_vad_state  # ×”×©××¨ ××¦×‘ ×§×•×“×
                        else:
                            is_strong_voice = enhanced_voice
                            self.vad_hysteresis_count = 0
                    else:
                        # ×œ×¤× ×™ ×§×œ×™×‘×¨×¦×™×” - VAD ×—×–×§ ×™×•×ª×¨ ×œ×¢×‘×¨×™×ª
                        is_strong_voice = rms > 300  # Even higher for Hebrew speech
                    
                    # âœ… FIXED: Update last_voice_ts only with VERY strong voice
                    current_time = time.time()
                    # âœ… EXTRA CHECK: Only if RMS is significantly above threshold
                    if is_strong_voice and rms > (getattr(self, 'vad_threshold', 200) * 1.2):
                        self.last_voice_ts = current_time
                        # Debug only strong voice detection (max once per 3 seconds)
                        if not hasattr(self, 'last_debug_ts') or (current_time - self.last_debug_ts) > 3.0:
                            print(f"ğŸ™ï¸ REAL_VOICE: rms={rms}, threshold={getattr(self, 'vad_threshold', 'uncalibrated')}")
                            self.last_debug_ts = current_time
                    
                    # ×—×™×©×•×‘ ×“×××” ×××™×ª×™ - ×××– ×”×§×•×œ ×”××—×¨×•×Ÿ! 
                    # ×× ××™×Ÿ ×§×•×œ ×‘×›×œ×œ, ×“×××” = 0 (×›×“×™ ×©×œ× × ×ª×§×¢)
                    silence_time = (current_time - self.last_voice_ts) if self.last_voice_ts > 0 else 0
                    
                    # âœ… ×œ×•×’×™× × ×§×™×™× - ×¨×§ ××™×¨×•×¢×™× ×—×©×•×‘×™× (×œ× ×›×œ frame)  
                    
                    # ×¡×¤×™×¨×ª ×¤×¨×™×™××™× ×¨×¦×•×¤×™× ×©×œ ×§×•×œ ×—×–×§ ×‘×œ×‘×“
                    if is_strong_voice:
                        self.voice_in_row += 1
                    else:
                        self.voice_in_row = max(0, self.voice_in_row - 2)  # ×§×™×–×•×– ××”×™×¨ ×œ×¨×¢×©×™×

                    # âš¡ BUILD 109: SMART BARGE-IN - Disable for long responses, enable for short ones
                    # âš¡ BUILD 121: DISABLE barge-in when waiting for DTMF input!
                    if self.speaking and BARGE_IN and not self.waiting_for_dtmf:
                        # ğŸ§  SMART: If response is long (>20 words), DISABLE barge-in completely!
                        if self.long_response:
                            # ğŸ”’ Long response - let it finish! No interruptions allowed
                            continue
                        
                        # ğŸ”“ Short response - allow barge-in with grace period
                        grace_period = 2.5  # âœ… BUILD 117: 2.5 ×©× ×™×•×ª ×œ×× ×•×¢ ×§×˜×™×¢×•×ª
                        time_since_tts_start = current_time - self.speaking_start_ts
                        
                        if time_since_tts_start < grace_period:
                            # Inside grace period - NO barge-in allowed
                            continue
                        
                        # âœ… BUILD 117: ULTRA-HIGH threshold to prevent false interrupts
                        barge_in_threshold = max(1500, self.noise_floor * 18.0 + 600) if self.is_calibrated else 1800
                        is_barge_in_voice = rms > barge_in_threshold
                        
                        if is_barge_in_voice:
                            self.voice_in_row += 1
                            # âœ… BUILD 117: Require 2000ms continuous LOUD voice - very strict!
                            if self.voice_in_row >= 100:  # 2000ms ×§×•×œ ×¨×¦×™×£ ×—×–×§ - ×××© ×××© ×‘×˜×•×—!
                                print(f"âš¡ BARGE-IN DETECTED (after {time_since_tts_start*1000:.0f}ms)")
                                
                                # âœ… ××“×™×“×ª Interrupt Halt Time
                                interrupt_start = time.time()
                                
                                # âœ… FIXED: ×¨×§ ×‘×¦×¢ interrupt, ×”×•× ×™×˜×¤×œ ×‘×›×œ ×”××¦×‘×™×
                                self._interrupt_speaking()
                                
                                # âœ… ××“×™×“×ª ×–××Ÿ ×¢×¦×™×¨×”
                                halt_time = (time.time() - interrupt_start) * 1000
                                print(f"ğŸ“Š INTERRUPT_HALT: {halt_time:.1f}ms (target: â‰¤200ms)")
                                
                                # âœ… ××¢×‘×¨ ××™×™×“×™ ×œ-LISTENING
                                self.state = STATE_LISTEN
                                self.processing = False
                                
                                # âœ… × ×™×§×•×™ ×‘××¤×¨ ×•×¤×ª×™×—×” ×—×“×©×” ×œ×ª××œ×•×œ
                                self.buf.clear()
                                self.last_voice_ts = current_time  # ×”×ª×—×œ ××“×™×“×ª ×©×§×˜ ××—×“×©
                                self.voice_in_row = 0
                                
                                print("ğŸ¤ BARGE-IN -> LISTENING (user can speak now)")
                                
                                # ×©×œ×— clear ×œ×˜×•×•×™×œ×™×• ×›×“×™ ×œ× ×§×•×ª ××•×“×™×• ×ª×§×•×¢ (×× ×”×—×™×‘×•×¨ ×ª×§×™×Ÿ)
                                if not self.ws_connection_failed:
                                    try:
                                        self._tx_enqueue({"type": "clear"})
                                    except:
                                        pass
                                else:
                                    print("ğŸ’” SKIPPING barge-in clear - WebSocket connection failed")
                                continue
                        else:
                            # ×× ××™×Ÿ ×§×•×œ ×—×–×§ ××¡×¤×™×§ - ×§×–×– ××ª ×”×¡×¤×™×¨×”
                            self.voice_in_row = max(0, self.voice_in_row - 1)
                    else:
                        self.voice_in_row = 0  # ××¤×¡ ×¡×¤×™×¨×” ×× ×œ× ×‘××¦×‘ speaking
                    
                    # ×× ×”××¢×¨×›×ª ××“×‘×¨×ª ×•××™×Ÿ ×”×¤×¨×¢×” - × ×§×” ×§×œ×˜
                    if self.speaking:
                        self.buf.clear()
                        continue
                    
                    # âœ… ××™×¡×•×£ ××•×“×™×• ×¢× ×–×™×”×•×™ ×“×××” ×ª×§×™×Ÿ
                    if not self.processing and self.state == STATE_LISTEN:
                        # ×—×œ×•×Ÿ ×¨×¤×¨×§×˜×•×¨×™ ××—×¨×™ TTS
                        if (current_time - self.last_tts_end_ts) < (REPLY_REFRACTORY_MS/1000.0):
                            continue
                        
                        # ××¡×•×£ ××•×“×™×• ×¨×§ ×›×©×™×© ×§×•×œ ××• ×›×©×™×© ×›×‘×¨ ×“×‘×¨ ××” ×‘×‘××¤×¨
                        if is_strong_voice or len(self.buf) > 0:
                            # âš¡ STREAMING STT: Mark start of new utterance (once) + save partial text
                            if len(self.buf) == 0 and is_strong_voice:
                                # Callback to save partial text for early EOU detection
                                def save_partial(text):
                                    self.last_partial_text = text
                                    print(f"ğŸ”Š PARTIAL: '{text}'")
                                
                                self.last_partial_text = ""  # Reset
                                self._utterance_begin(partial_cb=save_partial)
                            
                            self.buf.extend(pcm16)
                            dur = len(self.buf) / (2 * SR)
                            
                            # âš¡ BUILD 107: ULTRA-LOW LATENCY - 0.5s silence for FAST responses
                            # ×ª×’×•×‘×•×ª ×§×¦×¨×•×ª: min_silence ×§×¦×¨ ×××•×“ (0.5s) âš¡âš¡âš¡
                            # ××©×¤×˜×™× ××¨×•×›×™×: min_silence ×§×¦×¨ (1.8s ×‘××§×•× 3.0s)
                            if dur < 2.0:
                                min_silence = 0.5  # âš¡ ×ª×’×•×‘×” ×§×¦×¨×” - ×¡×•×¤×¨ ××”×¨! (×—×¦×™ ×©× ×™×”!)
                            else:
                                min_silence = 1.8  # âš¡ ××©×¤×˜ ××¨×•×š - ××”×™×¨ (×‘××§×•× 3.0s)
                            
                            silent = silence_time >= min_silence  
                            too_long = dur >= MAX_UTT_SEC
                            min_duration = 0.6  # âš¡ BUILD 107: ××™× ×™××•× ×§×¦×¨ ×™×•×ª×¨ - 0.6s ×‘××§×•× 0.7s
                            
                            # âš¡ BUILD 107: ×‘××¤×¨ ×§×˜×Ÿ ×™×•×ª×¨ = ×ª×’×•×‘×” ××”×™×¨×” ×™×•×ª×¨!
                            buffer_big_enough = len(self.buf) > 8000  # âš¡ 0.5s ×‘××§×•× 0.8s - ×—×•×¡×š 300ms!
                            
                            # âš¡âš¡âš¡ BUILD 107: EARLY EOU - ××¢× ×” ××•×§×“× ×¢×œ partial ×—×–×§!
                            # ×× ×™×© partial ×—×–×§ (12+ ×ª×•×•×™× ×•×¡×™×•× ×‘××©×¤×˜) + 0.35s ×“×××” - ×§×¤×™×¦×” ××™×“!
                            last_partial = getattr(self, "last_partial_text", "")
                            high_conf_partial = (len(last_partial) >= 12) and any(last_partial.endswith(p) for p in (".", "?", "!", "â€¦", ":", ";"))
                            early_silence = silence_time >= 0.35  # ×“×××” ×§×¦×¨×¦×¨×”
                            
                            if high_conf_partial and early_silence and dur >= 0.5:
                                print(f"âš¡âš¡âš¡ EARLY EOU on strong partial: '{last_partial}' ({dur:.1f}s, {silence_time:.2f}s silence)")
                                # ×§×¤×™×¦×” ××™×™×“×™×ª ×œ×¢×™×‘×•×“!
                                silent = True
                                buffer_big_enough = True
                            
                            # ×¡×•×£ ××‘×¢: ×“×××” ××¡×¤×§×ª OR ×–××Ÿ ×™×•×ª×¨ ××“×™ OR ×‘××¤×¨ ×’×“×•×œ ×¢× ×©×§×˜
                            if ((silent and buffer_big_enough) or too_long) and dur >= min_duration:
                                print(f"ğŸ¤ END OF UTTERANCE: {dur:.1f}s audio, conversation #{self.conversation_id}")
                                
                                # âœ… ××“×™×“×ª Turn Latency - ×”×ª×—×œ×ª ××“×™×“×”
                                self.eou_timestamp = time.time()
                                
                                # ××¢×‘×¨ ×œ×¢×™×‘×•×“
                                self.processing = True
                                self.processing_start_ts = current_time
                                self.state = STATE_THINK
                                current_id = self.conversation_id
                                self.conversation_id += 1
                                
                                # ×¢×™×‘×•×“ ×‘×× ×•×ª×§
                                utt_pcm = bytes(self.buf)
                                self.buf.clear()
                                self.last_voice_ts = 0  # ××¤×¡ ×œ×¡×™×‘×•×‘ ×”×‘×
                                
                                print(f"ğŸ§  STATE -> PROCESSING | len={len(utt_pcm)} | silence_ms={silence_time*1000:.0f}")
                                
                                try:
                                    self._process_utterance_safe(utt_pcm, current_id)
                                except Exception as proc_err:
                                    print(f"âŒ Audio processing failed for conversation #{current_id}: {proc_err}")
                                    import traceback
                                    traceback.print_exc()
                                    # Continue without crashing WebSocket
                                finally:
                                    self.processing = False
                                    if self.state == STATE_THINK:
                                        self.state = STATE_LISTEN
                                    print(f"âœ… Processing complete for conversation #{current_id}")
                    
                    # âœ… WebSocket Keepalive - ××•× ×¢ × ×¤×™×œ×•×ª ××—×¨×™ 5 ×“×§×•×ª
                    if current_time - self.last_keepalive_ts > self.keepalive_interval:
                        self.last_keepalive_ts = current_time
                        self.heartbeat_counter += 1
                        
                        # ×©×œ×— heartbeat mark event ×× ×”×—×™×‘×•×¨ ×ª×§×™×Ÿ
                        if not self.ws_connection_failed:
                            try:
                                heartbeat_msg = {
                                    "event": "mark",
                                    "streamSid": self.stream_sid,
                                    "mark": {"name": f"heartbeat_{self.heartbeat_counter}"}
                                }
                                success = self._ws_send(json.dumps(heartbeat_msg))
                                if success:
                                    print(f"ğŸ’“ WS_KEEPALIVE #{self.heartbeat_counter} (prevents 5min timeout)")
                            except Exception as e:
                                print(f"âš ï¸ Keepalive failed: {e}")
                        else:
                            print(f"ğŸ’” SKIPPING keepalive - WebSocket connection failed")
                    
                    # âœ… Watchdog: ×•×•×“× ×©×œ× ×ª×§×•×¢×™× ×‘××¦×‘ + EOU ×›×¤×•×™×”
                    if self.processing and (current_time - self.processing_start_ts) > 2.5:
                        print("âš ï¸ PROCESSING TIMEOUT - forcing reset")
                        self.processing = False
                        self.state = STATE_LISTEN
                        self.buf.clear()
                    
                    # âœ… LONGER speaking timeout to prevent cutoff mid-sentence
                    if self.speaking and (current_time - self.speaking_start_ts) > 15.0:
                        print("âš ï¸ SPEAKING TIMEOUT - forcing reset after 15s")  
                        self.speaking = False
                        self.state = STATE_LISTEN
                    
                    # âœ… EOU ×—×™×¨×•×: ××›×¨×™×— ×¢×™×‘×•×“ ×× ×”×‘××¤×¨ ×’×“×•×œ ××“×™
                    if (not self.processing and self.state == STATE_LISTEN and 
                        len(self.buf) > 96000 and  # âœ… FIX: 6.0s ×©×œ ××•×“×™×• (×œ× ×§×•×˜×¢ ××©×¤×˜×™× ××¨×•×›×™×!)
                        silence_time > 2.0):      # âœ… FIX: 2.0s ×©×§×˜ ×œ×—×™×¨×•× - ×©×§×˜ ×××™×ª×™!
                        print(f"ğŸš¨ EMERGENCY EOU: {len(self.buf)/(2*SR):.1f}s audio, silence={silence_time:.2f}s")
                        # ×›×¤×” EOU
                        self.processing = True
                        self.processing_start_ts = current_time
                        self.state = STATE_THINK
                        current_id = self.conversation_id
                        self.conversation_id += 1
                        
                        utt_pcm = bytes(self.buf)
                        self.buf.clear()
                        self.last_voice_ts = 0
                        
                        print(f"ğŸ§  EMERGENCY STATE -> PROCESSING | len={len(utt_pcm)} | silence_ms={silence_time*1000:.0f}")
                        
                        try:
                            self._process_utterance_safe(utt_pcm, current_id)
                        except Exception as proc_err:
                            print(f"âŒ Emergency audio processing failed for conversation #{current_id}: {proc_err}")
                            import traceback
                            traceback.print_exc()
                            # Continue without crashing WebSocket
                        finally:
                            self.processing = False
                            if self.state == STATE_THINK:
                                self.state = STATE_LISTEN
                            print(f"âœ… Emergency processing complete for conversation #{current_id}")
                    
                    continue
                
                if et == "dtmf":
                    # âš¡ BUILD 121: DTMF digit collection for phone number input
                    digit = evt.get("dtmf", {}).get("digit", "")
                    print(f"ğŸ“ DTMF pressed: {digit} (buffer={self.dtmf_buffer})")
                    
                    if digit == "#":
                        # End of input - process collected digits
                        if self.dtmf_buffer and len(self.dtmf_buffer) >= 9:
                            phone_number = self.dtmf_buffer
                            print(f"âœ… DTMF phone collected: {phone_number}")
                            
                            # Clear buffer
                            self.dtmf_buffer = ""
                            self.waiting_for_dtmf = False
                            
                            # Inject as if customer said the number
                            hebrew_text = f"×”××¡×¤×¨ ×©×œ×™ ×”×•× {phone_number}"
                            print(f"ğŸ¯ DTMF -> AI: '{hebrew_text}'")
                            
                            # Process as normal utterance (trigger AI response)
                            try:
                                self._process_dtmf_phone(phone_number)
                            except Exception as e:
                                print(f"âŒ DTMF processing failed: {e}")
                                import traceback
                                traceback.print_exc()
                        else:
                            print(f"âš ï¸ DTMF input too short: {self.dtmf_buffer} (need 9+ digits)")
                            # Don't speak - just reset and let user retry
                        
                        # Reset buffer anyway
                        self.dtmf_buffer = ""
                        self.waiting_for_dtmf = False
                        
                    elif digit == "*":
                        # Clear/restart input
                        print(f"ğŸ”„ DTMF cleared (was: {self.dtmf_buffer})")
                        self.dtmf_buffer = ""
                        # Don't speak - just clear buffer
                        
                    elif digit.isdigit():
                        # Append digit
                        self.dtmf_buffer += digit
                        print(f"ğŸ“ DTMF buffer: {self.dtmf_buffer}")
                    
                    continue

                if et == "mark":
                    # âœ… ×¡×™××•×Ÿ TTS ×”×•×©×œ× - ×—×–×•×¨ ×œ×”××–× ×”
                    mark_name = evt.get("mark", {}).get("name", "")
                    if mark_name == "assistant_tts_end":
                        print("ğŸ¯ TTS_MARK_ACK: assistant_tts_end -> LISTENING")
                        self.speaking = False
                        self.state = STATE_LISTEN
                        self.mark_pending = False
                        self.last_tts_end_ts = time.time()
                        # ××™×¤×•×¡ ×—×©×•×‘ ×œ××¢×¨×›×ª VAD
                        self.last_voice_ts = 0
                        self.voice_in_row = 0
                        print("ğŸ¤ STATE -> LISTENING | buffer_reset")
                    elif mark_name.startswith("heartbeat_"):
                        # ××™×©×•×¨ keepalive - ×”×ª×¢×œ×
                        pass
                    continue

                if et == "stop":
                    print(f"WS_STOP sid={self.stream_sid} rx={self.rx} tx={self.tx}")
                    # âœ… CRITICAL: ×¡×™×›×•× ×©×™×—×” ×‘×¡×™×•×
                    self._finalize_call_on_stop()
                    # Send close frame properly
                    try:
                        if hasattr(self.ws, 'close'):
                            self.ws.close()
                    except:
                        pass
                    break

        except ConnectionClosed as e:
            print(f"ğŸ“ WS_CLOSED sid={self.stream_sid} rx={self.rx} tx={self.tx} reason=ConnectionClosed")
            # âœ… × ×™×¡×™×•×Ÿ ×”×ª××•×©×©×•×ª ×× ×”×©×™×—×” ×¢×“×™×™×Ÿ ×¤×¢×™×œ×”
            if self.call_sid:
                print(f"ğŸ”„ WS connection lost for active call {self.call_sid} - recovery might be possible via Twilio REST API")
        except Exception as e:
            print(f"âŒ WS_ERROR sid={self.stream_sid}: {type(e).__name__}: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # âš¡ STREAMING STT: Close session at end of call
            self._close_streaming_stt()
            
            # Clean up TX thread
            if hasattr(self, 'tx_thread') and self.tx_thread.is_alive():
                self.tx_running = False
                try:
                    self.tx_thread.join(timeout=1.0)
                except:
                    pass
            
            # âœ… CRITICAL: Wait for all background threads to complete
            # This prevents crashes when threads access DB after WebSocket closes
            if hasattr(self, 'background_threads') and self.background_threads:
                print(f"ğŸ§¹ Waiting for {len(self.background_threads)} background threads...")
                for i, thread in enumerate(self.background_threads):
                    if thread.is_alive():
                        try:
                            thread.join(timeout=3.0)  # Max 3 seconds per thread
                            if thread.is_alive():
                                print(f"âš ï¸ Background thread {i} still running after timeout")
                            else:
                                print(f"âœ… Background thread {i} completed")
                        except Exception as e:
                            print(f"âŒ Error joining thread {i}: {e}")
                print(f"âœ… All background threads cleanup complete")
            
            try: 
                self.ws.close()
            except: 
                pass
            # Mark as ended
            if hasattr(self, 'call_sid') and self.call_sid:
                stream_registry.clear(self.call_sid)
        
        # Final cleanup
        print(f"WS_DONE sid={self.stream_sid} rx={self.rx} tx={self.tx}")

    def _interrupt_speaking(self):
        """âœ… FIXED: ×¢×¦×™×¨×” ××™×™×“×™×ª ×©×œ ×“×™×‘×•×¨ ×”×‘×•×˜ - ×¡×“×¨ ×¤×¢×•×œ×•×ª × ×›×•×Ÿ"""
        print("ğŸš¨ INTERRUPT_START: Beginning full interrupt sequence")
        
        # âœ… STEP 1: ×©×œ×— clear ×œ×˜×•×•×™×œ×™×• ×¨××©×•×Ÿ
        if not self.ws_connection_failed:
            try:
                self._tx_enqueue({"type": "clear"})
                print("âœ… CLEAR_SENT: Twilio clear command sent")
            except Exception as e:
                print(f"âš ï¸ CLEAR_FAILED: {e}")
        
        # âœ… STEP 2: × ×§×” ××ª ×ª×•×¨ ×”×©×™×“×•×¨ ××—×¨ clear
        try:
            cleared_count = 0
            while not self.tx_q.empty():
                self.tx_q.get_nowait()
                cleared_count += 1
            if cleared_count > 0:
                print(f"âœ… TX_QUEUE_CLEARED: Removed {cleared_count} pending audio frames")
        except Exception as e:
            print(f"âš ï¸ TX_CLEAR_FAILED: {e}")
        
        # âœ… STEP 3: ×¢×“×›×Ÿ ××¦×‘×™×
        self.state = STATE_LISTEN
        self.mark_pending = False
        self.last_voice_ts = 0
        self.voice_in_row = 0
        self.processing = False
        
        # âœ… STEP 4: ×¨×§ ×‘×¡×•×£ - ×¢×“×›×Ÿ speaking=False
        self.speaking = False
        
        print("âœ… INTERRUPT_COMPLETE: Full interrupt sequence finished - ready to listen")

    # ğŸ¯ ×¢×™×‘×•×“ ××‘×¢ ×¤×©×•×˜ ×•×‘×™×˜×•×— (×œ×œ× ×›×¤×™×œ×•×™×•×ª)
    def _process_utterance_safe(self, pcm16_8k: bytes, conversation_id: int):
        """×¢×™×‘×•×“ ××‘×¢ ×¢× ×”×’× ×” ×›×¤×•×œ×” ××¤× ×™ ×œ×•×œ××•×ª"""
        # ×•×•×“× ×©×œ× ××¢×‘×“×™× ××ª ××•×ª×• ID ×¤×¢××™×™×
        if conversation_id <= self.last_processing_id:
            print(f"ğŸš« DUPLICATE processing ID {conversation_id} (last: {self.last_processing_id}) - SKIP")
            return
        
        self.last_processing_id = conversation_id
        
        # ×•×•×“× ×©×”××¢×¨×›×ª ×œ× ××“×‘×¨×ª ×›×¨×’×¢
        if self.speaking:
            print("ğŸš« Still speaking - cannot process new utterance")
            return
            
        print(f"ğŸ¤ SAFE PROCESSING: conversation #{conversation_id}")
        self.state = STATE_THINK  # ××¢×‘×¨ ×œ××¦×‘ ×—×©×™×‘×”
        
        text = ""  # initialize to avoid unbound variable
        try:
            # PATCH 6: Safe ASR - never leaves empty
            try:
                # âš¡ PHASE 2: Use smart wrapper (streaming or single-request)
                text = self._hebrew_stt_wrapper(pcm16_8k) or ""
                print(f"ğŸ¤ USER: {text}")
                
                # âœ… ××“×™×“×ª ASR Latency
                if hasattr(self, 'eou_timestamp'):
                    asr_latency = time.time() - self.eou_timestamp
                    self.last_stt_time = asr_latency  # âš¡ CRITICAL: Save for TOTAL_LATENCY calculation
                    print(f"ğŸ“Š ASR_LATENCY: {asr_latency:.3f}s (target: <0.7s)")
                    
            except Exception as e:
                print(f"âŒ STT ERROR: {e}")
                text = ""
            
            # âœ… SMART HANDLING: ×›×©×œ× ××‘×™×Ÿ - ×‘×©×§×˜ ××• "×œ× ×”×‘× ×ª×™" ××—×¨×™ ×›××” × ×™×¡×™×•× ×•×ª
            if not text.strip():
                # ×¡×¤×™×¨×ª ×›×™×©×œ×•× ×•×ª ×¨×¦×•×¤×™×
                if not hasattr(self, 'consecutive_empty_stt'):
                    self.consecutive_empty_stt = 0
                self.consecutive_empty_stt += 1
                
                # ×× 2 ×›×™×©×œ×•× ×•×ª ×‘×¨×¦×£ - ×ª×’×™×“ "×œ× ×”×‘× ×ª×™"
                if self.consecutive_empty_stt >= 2:
                    print("ğŸš« MULTIPLE_EMPTY_STT: Saying 'didn't understand'")
                    self.consecutive_empty_stt = 0  # ××™×¤×•×¡
                    try:
                        self._speak_simple("×œ× ×”×‘× ×ª×™, ××¤×©×¨ ×œ×—×–×•×¨?")
                    except:
                        pass
                else:
                    print("ğŸš« NO_SPEECH_DETECTED: Staying silent (attempt 1)")
                
                self.state = STATE_LISTEN
                self.processing = False
                return
            # âœ… ××™×¤×•×¡ ××•× ×” ×›×™×©×œ×•× ×•×ª - STT ×”×¦×œ×™×—!
            if hasattr(self, 'consecutive_empty_stt'):
                self.consecutive_empty_stt = 0
            
            # âš¡ BUILD 117: REMOVED SHORT_UNCOMMON_WORD filter - trust Google STT!
            # If STT returned text, it's real speech. Don't reject valid words like "×©×•×•×“×™"
            # Only reject if it's EXTREMELY short (1-2 chars) which is likely noise
            if len(text.strip()) <= 2:
                print(f"ğŸš« VERY_SHORT_TEXT: '{text}' (â‰¤2 chars) - likely noise")
                self.state = STATE_LISTEN
                self.processing = False
                return
            
            # PATCH 6: Anti-duplication on user text (14s window) - WITH DEBUG
            uh = zlib.crc32(text.strip().encode("utf-8"))
            if (self.last_user_hash == uh and 
                (time.time() - self.last_user_hash_ts) <= DEDUP_WINDOW_SEC):
                print("ğŸš« DUPLICATE USER INPUT (ignored)")
                self.processing = False
                self.state = STATE_LISTEN
                return
            self.last_user_hash, self.last_user_hash_ts = uh, time.time()
            # Processing new user input")
            
            # 3. AI Response - Ğ‘Ğ•Ğ— micro-ack! ×ª×Ÿ ×œ×” ×œ×—×©×•×‘ ×‘×©×§×˜
            ai_processing_start = time.time()
            
            # âœ… ×”×©×ª××© ×‘×¤×•× ×§×¦×™×” ×”××ª×§×“××ª ×¢× ××ª××—×” ×•×”×××’×¨ ×”×›×•×œ×œ!
            reply = self._ai_response(text)
            
            # âœ… FIXED: ×× AI ×”×—×–×™×¨ None (××™×Ÿ ×˜×§×¡×˜ ×××™×ª×™) - ××œ ×ª×’×™×‘!
            if reply is None:
                print("ğŸš« AI_RETURNED_NONE: No response needed - returning to listen mode")
                self.processing = False
                self.state = STATE_LISTEN
                return
            
            # âœ… ×× ×™×¢×ª ×›×¤×™×œ×•×™×•×ª ××©×•×¤×¨×ª - ×‘×“×™×§×ª 8 ×ª×©×•×‘×•×ª ××—×¨×•× ×•×ª (×¤×—×•×ª ×¨×’×™×©)
            if not hasattr(self, 'recent_replies'):
                self.recent_replies = []
            
            # âœ… FIXED: ×× ×™×¢×ª ×›×¤×™×œ×•×™×•×ª ×—×›××” - ×¨×§ ×›×¤×™×œ×•×™×•×ª ××¨×•×‘×•×ª ×××©
            reply_trimmed = reply.strip() if reply else ""
            exact_duplicates = [r for r in self.recent_replies if r == reply_trimmed]
            if len(exact_duplicates) >= 3:  # âœ… FIXED: ×¨×§ ××—×¨×™ 3 ×›×¤×™×œ×•×™×•×ª ××“×•×™×§×•×ª
                print("ğŸš« EXACT DUPLICATE detected (3+ times) - adding variation")
                if "×ª×•×“×”" in text.lower():
                    reply = "×‘×©××—×”! ×™×© ×œ×™ ×¢×•×“ ××¤×©×¨×•×™×•×ª ×× ××ª×” ××¢×•× ×™×™×Ÿ."
                else:
                    reply = reply + " ××• ××¤×©×¨ ×¢×•×“ ×¤×¨×˜×™×?"
                reply_trimmed = reply.strip()
                
            # ×¢×“×›×Ÿ ×”×™×¡×˜×•×¨×™×” - ×©××•×¨ ×¨×§ 8 ××—×¨×•× ×•×ª
            if reply_trimmed:  # âœ… ×¨×§ ×× ×™×© ×ª×©×•×‘×” ×××™×ª×™×ª
                self.recent_replies.append(reply_trimmed)
            if len(self.recent_replies) > 8:
                self.recent_replies = self.recent_replies[-8:]
            
            # âœ… FIXED: ×¨×§ ×× ×™×© ×ª×©×•×‘×” ×××™×ª×™×ª - ×“×¤×¡, ×©××•×¨ ×•×“×‘×¨
            if reply and reply.strip():
                print(f"ğŸ¤– BOT: {reply}")
                
                # âœ… ××“×™×“×ª AI Processing Time
                ai_processing_time = time.time() - ai_processing_start
                print(f"ğŸ“Š AI_PROCESSING: {ai_processing_time:.3f}s")
                
                # 5. ×”×•×¡×£ ×œ×”×™×¡×˜×•×¨×™×” (×©× ×™ ××‘× ×™× - ×¡× ×›×¨×•×Ÿ)
                self.response_history.append({
                    'id': conversation_id,
                    'user': text,
                    'bot': reply,
                    'time': time.time()
                })
                
                # âœ… CRITICAL FIX: ×¡× ×›×¨×•×Ÿ conversation_history ×œ×–×™×›×¨×•×Ÿ AI
                self.conversation_history.append({
                    'user': text,
                    'bot': reply
                })
                
                # âœ… ×©××™×¨×ª ×ª×•×¨ ×©×™×—×” ×‘××¡×“ × ×ª×•× ×™× ×œ×–×™×›×¨×•×Ÿ ×§×‘×•×¢
                self._save_conversation_turn(text, reply)
                
                # âœ¨ 6. Customer Intelligence - ×–×™×”×•×™/×™×¦×™×¨×ª ×œ×§×•×— ×•×œ×™×“ ×—×›×
                self._process_customer_intelligence(text, reply)
                
                # 6. ×“×‘×¨ ×¨×§ ×× ×™×© ××” ×œ×•××¨
                self._speak_simple(reply)
            else:
                print("ğŸš« NO_VALID_RESPONSE: AI returned empty/None - staying silent")
                # ×œ× ×“×•×¤×¡×™×, ×œ× ×©×•××¨×™× ×‘×”×™×¡×˜×•×¨×™×”, ×œ× ××“×‘×¨×™×
            
            # âœ… CRITICAL: ×—×–×•×¨ ×œ××¦×‘ ×”××–× ×” ××—×¨×™ ×›×œ ×ª×’×•×‘×”!
            self.state = STATE_LISTEN
            print(f"âœ… RETURNED TO LISTEN STATE after conversation #{conversation_id}")
            
        except Exception as e:
            print(f"âŒ CRITICAL Processing error: {e}")
            print(f"   Text was: '{text}' ({len(text)} chars)")
            # âœ… ×ª×™×§×•×Ÿ ×§×¨×™×˜×™: ×“×‘×§ ×œ×˜×¨××¡×‘×§ ×•××œ ×ª×§×¨×™×¡
            import traceback
            traceback.print_exc()
            # âœ… ×ª×’×•×‘×ª ×—×™×¨×•× ××¤×•×¨×˜×ª ×•××•×¢×™×œ×”
            try:
                self.state = STATE_SPEAK
                emergency_response = "××¦×˜×¢×¨×ª, ×œ× ×©××¢×ª×™ ×˜×•×‘ ×‘×’×œ×œ ×”×—×™×‘×•×¨. ×‘×•××• × ×ª×—×™×œ ××—×“×© - ××™×–×” ×¡×•×’ × ×›×¡ ××ª×” ××—×¤×© ×•×‘××™×–×” ××–×•×¨?"
                self._speak_with_breath(emergency_response)
                self.state = STATE_LISTEN
                print(f"âœ… RETURNED TO LISTEN STATE after error in conversation #{conversation_id}")
            except Exception as emergency_err:
                print(f"âŒ EMERGENCY RESPONSE FAILED: {emergency_err}")
                self.state = STATE_LISTEN
                # âœ… ×—×–×•×¨ ×œ××¦×‘ ×”××–× ×” ×‘×›×œ ××§×¨×”


    # âœ… ×“×™×‘×•×¨ ××ª×§×“× ×¢× ×¡×™××•× ×™× ×œ×˜×•×•×™×œ×™×•
    def _speak_greeting(self, text: str):
        """âš¡ TTS ××”×™×¨ ×œ×‘×¨×›×” - ×œ×œ× sleep!"""
        if not text:
            return
        
        # âš¡ BUILD 117: Stricter barge-in to prevent interruptions
        word_count = len(text.split())
        self.long_response = word_count > 12  # âœ… LOWERED: 12 words = ~2 sentences, disable barge-in
        if self.long_response:
            print(f"ğŸ”’ LONG_RESPONSE ({word_count} words) - BARGE-IN DISABLED")
        else:
            print(f"ğŸ”“ SHORT_RESPONSE ({word_count} words) - BARGE-IN ENABLED")
            
        self.speaking = True
        self.speaking_start_ts = time.time()
        self.state = STATE_SPEAK
        print(f"ğŸ”Š GREETING_TTS_START: '{text}'")
        
        try:
            # âš¡ ×‘×œ×™ sleep - ×‘×¨×›×” ××™×™×“×™×ª!
            tts_audio = self._hebrew_tts(text)
            if tts_audio and len(tts_audio) > 1000:
                print(f"âœ… GREETING_TTS_SUCCESS: {len(tts_audio)} bytes")
                self._send_pcm16_as_mulaw_frames_with_mark(tts_audio)
            else:
                print("âŒ GREETING_TTS_FAILED - sending beep")
                self._send_beep(800)
                self._finalize_speaking()
        except Exception as e:
            print(f"âŒ GREETING_TTS_ERROR: {e}")
            import traceback
            traceback.print_exc()
            try:
                self._send_beep(800)
            except:
                pass
            self._finalize_speaking()
    
    def _speak_simple(self, text: str):
        """TTS ×¢× ××¢×§×‘ ××¦×‘×™× ×•×¡×™××•× ×™×"""
        if not text:
            return
            
        if self.speaking:
            print("ğŸš« Already speaking - stopping current and starting new")
            try:
                # âœ… FIXED: ×‘×¦×¢ interrupt ××œ× ×œ×¤× ×™ ×”×ª×—×œ×ª TTS ×—×“×©
                self._interrupt_speaking()
                time.sleep(0.05)  # ×”××ª× ×” ×§×¦×¨×”
            except Exception as e:
                print(f"âš ï¸ Interrupt error (non-critical): {e}")
        
        # âš¡ BUILD 117: Stricter barge-in to prevent interruptions
        word_count = len(text.split())
        self.long_response = word_count > 12  # âœ… LOWERED: 12 words = ~2 sentences, disable barge-in
        if self.long_response:
            print(f"ğŸ”’ LONG_RESPONSE ({word_count} words) - BARGE-IN DISABLED")
        else:
            print(f"ğŸ”“ SHORT_RESPONSE ({word_count} words) - BARGE-IN ENABLED")
            
        self.speaking = True
        self.speaking_start_ts = time.time()
        self.state = STATE_SPEAK
        print(f"ğŸ”Š TTS_START: '{text}'")
        
        # âš¡ BUILD 107: Save EOU timestamp for total latency calculation
        eou_saved = getattr(self, 'eou_timestamp', None)
        
        try:
            # âš¡ ULTRA-SPEED: No delay before TTS - immediately start speaking
            # time.sleep removed for minimum latency
                
            # ×§×™×¦×•×¨ ×˜×§×¡×˜ ××¨×•×š
            if len(text) > 150:
                text = text[:150].rsplit(' ', 1)[0] + '.'
                print(f"ğŸ”ª TTS_SHORTENED: {text}")
            
            # â±ï¸ TTS timing instrumentation
            tts_start = time.time()
            tts_audio = self._hebrew_tts(text)
            tts_generation_time = time.time() - tts_start
            print(f"ğŸ“Š TTS_GENERATION: {tts_generation_time:.3f}s (target: <0.5s)")
            
            if tts_audio and len(tts_audio) > 1000:
                print(f"ğŸ”Š TTS SUCCESS: {len(tts_audio)} bytes")
                send_start = time.time()
                self._send_pcm16_as_mulaw_frames_with_mark(tts_audio)
                send_time = time.time() - send_start
                print(f"ğŸ“Š TTS_SEND: {send_time:.3f}s (audio transmission)")
                
                # âš¡ BUILD 114: Detailed latency breakdown (EOUâ†’first audio sent)
                if eou_saved:
                    turn_latency = send_start - eou_saved
                    total_latency = time.time() - eou_saved
                    stt_time = getattr(self, 'last_stt_time', 0.0)
                    ai_time = getattr(self, 'last_ai_time', 0.0)
                    
                    print(f"ğŸ“Š TURN_LATENCY: {turn_latency:.3f}s (EOUâ†’TTS start, target: <1.2s)")
                    print(f"ğŸ“Š ğŸ¯ TOTAL_LATENCY: {total_latency:.3f}s (EOUâ†’Audio sent, target: <2.0s)")
                    print(f"[LATENCY] stt={stt_time:.2f}s, ai={ai_time:.2f}s, tts={tts_generation_time:.2f}s, total={total_latency:.2f}s")
                    
                    # × ×§×” ×œ××“×™×“×” ×”×‘××”
                    if hasattr(self, 'eou_timestamp'):
                        delattr(self, 'eou_timestamp')
            else:
                print("ğŸ”Š TTS FAILED - sending beep")
                self._send_beep(800)
                self._finalize_speaking()
        except Exception as e:
            print(f"âŒ TTS_ERROR: {e}")
            import traceback
            traceback.print_exc()
            try:
                self._send_beep(800)
            except:
                pass
            self._finalize_speaking()
    
    def _tx_enqueue(self, item):
        """
        âš¡ BUILD 115.1: Enqueue with drop-oldest policy
        If queue is full, drop oldest frame and insert new one (Real-time > past)
        """
        try:
            self.tx_q.put_nowait(item)
        except queue.Full:
            # Drop oldest frame
            try:
                _ = self.tx_q.get_nowait()
            except queue.Empty:
                pass
            # Try again
            try:
                self.tx_q.put_nowait(item)
            except queue.Full:
                # Throttled logging - max once per 2 seconds
                now = time.monotonic()
                if now - self._last_overflow_log > 2.0:
                    print("âš ï¸ tx_q full (drop oldest)", flush=True)
                    self._last_overflow_log = now
    
    def _finalize_speaking(self):
        """×¡×™×•× ×“×™×‘×•×¨ ×¢× ×—×–×¨×” ×œ×”××–× ×”"""
        self.speaking = False
        self.long_response = False  # âš¡ BUILD 109: Reset flag
        self.last_tts_end_ts = time.time()
        self.state = STATE_LISTEN
        self.last_voice_ts = 0  # ××™×¤×•×¡ ×œ××¢×¨×›×ª VAD
        self.voice_in_row = 0
        print("ğŸ¤ SPEAKING_END -> LISTEN STATE | buffer_reset")

    def _send_pcm16_as_mulaw_frames_with_mark(self, pcm16_8k: bytes):
        """×©×œ×™×—×ª ××•×“×™×• ×¢× ×¡×™××•×Ÿ ×œ×˜×•×•×™×œ×™×• ×•×‘×¨×’-××™×Ÿ"""
        if not self.stream_sid or not pcm16_8k:
            self._finalize_speaking()
            return
            
        # CLEAR ×œ×¤× ×™ ×©×œ×™×—×”
        self._ws_send(json.dumps({"event":"clear","streamSid":self.stream_sid}))
        
        mulaw = audioop.lin2ulaw(pcm16_8k, 2)
        FR = 160  # 20ms @ 8kHz
        frames_sent = 0
        total_frames = len(mulaw) // FR
        
        print(f"ğŸ”Š TTS_FRAMES: {total_frames} frames ({total_frames * 20}ms)")
        
        for i in range(0, len(mulaw), FR):
            # ×‘×“×™×§×ª ×‘×¨×’-××™×Ÿ
            if not self.speaking:
                print(f"ğŸš¨ BARGE-IN! Stopped at frame {frames_sent}/{total_frames}")
                self._ws_send(json.dumps({"event":"clear","streamSid":self.stream_sid}))
                self._finalize_speaking()
                return
                
            # ×©×œ×— ×¤×¨×™×™×
            frame = mulaw[i:i+FR].ljust(FR, b'\x00')
            payload = base64.b64encode(frame).decode()
            media_msg = json.dumps({
                "event": "media",
                "streamSid": self.stream_sid,
                "media": {"payload": payload}
            })
            self._ws_send(media_msg)
            frames_sent += 1
            
            # Yield ×œeventlet
            if frames_sent % 5 == 0:  # ×›×œ 100ms
                time.sleep(0)  # yield
        
        # ×”×•×¡×£ 200ms ×©×§×˜ ×‘×¡×•×£
        silence_frames = 10  # 200ms @ 20ms per frame  
        silence_mulaw = b'\x00' * FR
        for _ in range(silence_frames):
            if not self.speaking:
                break
            payload = base64.b64encode(silence_mulaw).decode()
            media_msg = json.dumps({
                "event": "media", 
                "streamSid": self.stream_sid,
                "media": {"payload": payload}
            })
            self._ws_send(media_msg)
            time.sleep(0)  # yield
        
        # ×©×œ×— ×¡×™××•×Ÿ ×œ×˜×•×•×™×œ×™×•
        self.mark_pending = True
        self.mark_sent_ts = time.time()
        mark_msg = json.dumps({
            "event": "mark",
            "streamSid": self.stream_sid,
            "mark": {"name": "assistant_tts_end"}
        })
        self._ws_send(mark_msg)
        print("ğŸ¯ TTS_MARK_SENT: assistant_tts_end")
        
        # âœ… BUILD 100.4 FIX: ×¡×™×™× ×“×™×‘×•×¨ ××™×“ ×•×—×–×•×¨ ×œ×”××–× ×”!
        # ×”×‘×¢×™×”: ×”××¢×¨×›×ª × ×©××¨×” ×‘-STATE_SPEAK ××—×¨×™ ×‘×¨×›×” ×•×œ× ×—×–×¨×” ×œ×”××–× ×”
        self._finalize_speaking()
        print("âœ… GREETING_COMPLETE -> LISTEN STATE")

    def _send_pcm16_as_mulaw_frames(self, pcm16_8k: bytes):
        """×©×œ×™×—×ª ××•×“×™×• ×¢× ×™×›×•×œ×ª ×¢×¦×™×¨×” ×‘×××¦×¢ (BARGE-IN) - ×’×¨×¡×” ×™×©× ×”"""
        if not self.stream_sid or not pcm16_8k:
            return
            
        # CLEAR ×œ×¤× ×™ ×©×œ×™×—×”
        self._ws_send(json.dumps({"event":"clear","streamSid":self.stream_sid}))
        
        mulaw = audioop.lin2ulaw(pcm16_8k, 2)
        FR = 160  # 20ms @ 8kHz
        frames_sent = 0
        total_frames = len(mulaw) // FR
        
        # âš¡ Removed flooding log
        
        for i in range(0, len(mulaw), FR):
            # ğŸš¨ ×‘×“×™×§×” ×§×¨×™×˜×™×ª: ×”×× ×¢×“×™×™×Ÿ ×¦×¨×™×š ×œ×“×‘×¨?
            if not self.speaking:
                print(f"ğŸš¨ BARGE-IN detected! Stopped at frame {frames_sent}/{total_frames}")
                # ×©×œ×— CLEAR × ×•×¡×£ ×œ××§×¨×” ×”×¦×•×¨×š
                self._ws_send(json.dumps({"event":"clear","streamSid":self.stream_sid}))
                break
                
            chunk = mulaw[i:i+FR]
            if len(chunk) < FR:
                # ×”×’×¢× ×• ×œ×¡×•×£ - ×–×” ×ª×§×™×Ÿ
                break
                
            payload = base64.b64encode(chunk).decode("ascii")
            try:
                self._ws_send(json.dumps({
                    "event": "media",
                    "streamSid": self.stream_sid,
                    "media": {"payload": payload}
                }))
                self.tx += 1
                frames_sent += 1
                
                # âš¡ Removed flooding logs - only log errors
            except Exception as e:
                print(f"âŒ Error sending frame {frames_sent}: {e}")
                break
        
        # âš¡ Only log interruptions (barge-in), not normal completions
        if not self.speaking:
            print(f"âš ï¸ Audio interrupted: {frames_sent}/{total_frames} frames sent")

    def _send_beep(self, ms: int):
        """×¦×¤×¦×•×£ ×¤×©×•×˜"""
        samples = int(SR * ms / 1000)
        amp = 9000
        out = bytearray()
        for n in range(samples):
            val = int(amp * math.sin(2*math.pi*440*n/SR))
            out.extend(val.to_bytes(2, "little", signed=True))
        self._send_pcm16_as_mulaw_frames(bytes(out))
    
    def _beep_pcm16_8k(self, ms: int) -> bytes:
        """×™×¦×™×¨×ª ×¦×¤×¦×•×£ PCM16 8kHz"""
        samples = int(SR * ms / 1000)
        amp = 9000
        out = bytearray()
        for n in range(samples):
            val = int(amp * math.sin(2*math.pi*440*n/SR))
            out.extend(val.to_bytes(2, "little", signed=True))
        return bytes(out)
    
    def _process_audio_for_stt(self, pcm16_8k: bytes) -> bytes:
        """ğŸµ ×¢×™×‘×•×“ ××•×“×™×• ××™×›×•×ª×™ ×œ×¤× ×™ STT: AGC, ×¤×™×œ×˜×¨×™×, resample ×œ-16kHz"""
        try:
            import numpy as np
            from scipy import signal
        except ImportError:
            # numpy/scipy ×œ× ××•×ª×§× ×™× - ×”×—×–×¨ ×›××• ×©×–×”
            print("âš ï¸ numpy/scipy not available - using raw audio")
            return pcm16_8k
        
        try:
            
            # ×”××¨ ×œ-numpy array
            audio_int16 = np.frombuffer(pcm16_8k, dtype=np.int16)
            audio_float = audio_int16.astype(np.float32) / 32768.0  # normalize to [-1, 1]
            
            # âœ… 1. DC-offset removal
            audio_float = audio_float - float(np.mean(audio_float))
            
            # âœ… 2. High-pass filter (100Hz) - ××˜××˜× ×–××–×•×
            sos_hp = signal.butter(4, 100, btype='high', fs=8000, output='sos')
            audio_float = np.array(signal.sosfilt(sos_hp, audio_float), dtype=np.float32)
            
            # âœ… 3. Low-pass filter (3.6kHz) - ×˜×œ×¤×•× ×™ ×¨×’×™×œ  
            sos_lp = signal.butter(4, 3600, btype='low', fs=8000, output='sos')
            audio_float = np.array(signal.sosfilt(sos_lp, audio_float), dtype=np.float32)
            
            # âœ… 4. AGC ×¢×“×™×Ÿ - × ×¨××•×œ ×œ×˜×•×•×— ××˜×¨×” (-20dBFS â‰ˆ 0.1)
            rms_squared = np.mean(audio_float * audio_float)
            rms = float(np.sqrt(rms_squared))
            if rms > 0.001:  # ×× ×™×© ××•×“×™×• ×××™×ª×™
                target_rms = 0.1  # -20dBFS
                gain = min(target_rms / rms, 3.0)  # ××’×‘×™×œ ×’×™×™×Ÿ ×œ-3x
                audio_float = np.array(audio_float * gain, dtype=np.float32)
            
            # âœ… 5. Clipping protection
            audio_float = np.clip(audio_float, -0.95, 0.95)
            
            # âœ… 6. Resample 8kHz â†’ 16kHz (Whisper ×¢×•×‘×“ ×˜×•×‘ ×™×•×ª×¨ ×‘-16k)
            audio_16k = signal.resample(audio_float, len(audio_float) * 2)
            
            # ×”××¨ ×—×–×¨×” ×œ-int16
            audio_16k_int16 = np.array(audio_16k * 32767, dtype=np.int16)
            
            return audio_16k_int16.tobytes()
            
        except ImportError:
            print(f"âš ï¸ numpy/scipy not available - using raw audio")
            return pcm16_8k
        except Exception as e:
            print(f"âš ï¸ Audio processing failed, using raw audio: {e}")
            # Fallback: ×”×—×–×¨ ××•×“×™×• ×›××• ×©×–×”
            try:
                import numpy as np
                from scipy import signal
                audio_int16 = np.frombuffer(pcm16_8k, dtype=np.int16)
                audio_float = audio_int16.astype(np.float32) / 32768.0
                audio_16k = signal.resample(audio_float, len(audio_float) * 2)
                audio_16k_int16 = np.array(audio_16k * 32767, dtype=np.int16)
                return audio_16k_int16.tobytes()
            except Exception as e2:
                print(f"âš ï¸ Even simple resample failed: {e2}")
                # Ultimate fallback: duplicate samples (crude but works)
                return pcm16_8k + pcm16_8k  # Double the data for "16kHz"

    async def _stt_fallback_async(self, audio_data: bytes) -> str:
        """
        âš¡ BUILD 115: Async wrapper for fallback STT
        Runs _hebrew_stt in thread pool without blocking the event loop
        """
        try:
            loop = asyncio.get_running_loop()
            return await loop.run_in_executor(self.exec, self._hebrew_stt, audio_data)
        except Exception as e:
            print(f"âŒ [STT_FALLBACK_ASYNC] Failed: {e}", flush=True)
            return ""
    
    def _stt_fallback_nonblocking(self, audio_data: bytes) -> None:
        """
        âš¡ BUILD 115: Non-blocking wrapper for fallback STT (sync â†’ async)
        Submits work to thread pool and returns immediately.
        Result is delivered via callback to avoid blocking.
        """
        # Submit to thread pool
        fut = self.exec.submit(self._hebrew_stt, audio_data)
        
        # When done, deliver result back to event loop safely
        def _on_done(f):
            try:
                text = f.result()
            except Exception as e:
                print(f"âŒ [STT_FALLBACK_NB] Failed: {e}", flush=True)
                text = ""
            
            # If there's a loop and events queue, use it
            if self.loop and self.events_q:
                events_q = self.events_q  # Type hint helper
                self.loop.call_soon_threadsafe(
                    lambda: events_q.put_nowait(("stt_final_text", text))
                )
            else:
                # Fallback: direct callback (sync mode)
                print(f"ğŸ¤ [STT_FALLBACK_NB] Result: {text[:50] if text else '(empty)'}", flush=True)
        
        fut.add_done_callback(_on_done)

    def _hebrew_stt_wrapper(self, pcm16_8k: bytes, on_partial_cb=None) -> str:
        """
        ğŸ¯ Smart wrapper: streaming (collects from dispatcher) â†’ fallback to single-request
        """
        session = _get_session(self.call_sid) if self.call_sid else None
        
        if not USE_STREAMING_STT or not session:
            # Single-request mode (existing)
            return self._hebrew_stt(pcm16_8k)
        
        try:
            # Streaming mode: collect results from dispatcher
            # Audio is already being fed to session in WS loop
            # Just collect what's been accumulated
            print(f"â±ï¸ [STT_STREAM] Calling _utterance_end...")
            utt_start = time.time()
            result = self._utterance_end()
            utt_duration = time.time() - utt_start
            print(f"â±ï¸ [STT_STREAM] _utterance_end took {utt_duration:.3f}s, result: '{result[:50] if result else '(empty)'}'")
            
            # âœ… FIX: Fallback on empty results
            if not result or not result.strip():
                print("âš ï¸ [STT] Streaming returned empty â†’ fallback to single")
                fallback_start = time.time()
                fallback_result = self._hebrew_stt(pcm16_8k)
                fallback_duration = time.time() - fallback_start
                print(f"â±ï¸ [STT_FALLBACK] Single-request took {fallback_duration:.3f}s, result: '{fallback_result[:50] if fallback_result else '(empty)'}'")
                return fallback_result
                
            return result
            
        except Exception as e:
            # Fallback to single-request on exception
            print(f"âš ï¸ [STT] Streaming failed â†’ fallback to single. err={e}")
            import traceback
            traceback.print_exc()
            return self._hebrew_stt(pcm16_8k)

    def _hebrew_stt(self, pcm16_8k: bytes) -> str:
        """Hebrew STT using Google STT Streaming with speech contexts (×œ×¤×™ ×”×”× ×—×™×•×ª)"""
        try:
            print(f"ğŸµ STT_PROCEED: Processing {len(pcm16_8k)} bytes with Google STT (audio validated)")
            
            # âœ… FIXED: ×‘×“×™×§×ª ××™×›×•×ª ××•×“×™×• ××ª×§×“××ª - ×× ×™×¢×ª ×¢×™×‘×•×“ ×©×œ ×¨×¢×©/×©×§×˜
            import audioop
            max_amplitude = audioop.max(pcm16_8k, 2)
            rms = audioop.rms(pcm16_8k, 2)
            duration = len(pcm16_8k) / (2 * 8000)
            print(f"ğŸ“Š AUDIO_QUALITY_CHECK: max_amplitude={max_amplitude}, rms={rms}, duration={duration:.1f}s")
            
            # âš¡ BUILD 113: RELAXED validation - allow quieter speech for better transcription
            
            # 1. Basic amplitude check - RELAXED threshold (favor accuracy over noise rejection)
            if max_amplitude < 50:  # Lowered from 60 - allow quieter speech
                print(f"ğŸš« STT_BLOCKED: Audio too quiet (max_amplitude={max_amplitude} < 50)")
                return ""
            
            # 2. RMS energy check - RELAXED
            if rms < 30:  # Lowered from 40 - allow quieter audio
                print(f"ğŸš« STT_BLOCKED: Audio energy too low (rms={rms} < 30)")
                return ""
            
            # 3. Duration check
            if duration < 0.15:  # Too short to be meaningful
                print(f"ğŸš« STT_BLOCKED: Audio too short ({duration:.2f}s < 0.15s)")
                return ""
            
            # 4. âœ… Advanced checks with variance/ZCR - INFORMATIONAL + BLOCKING
            try:
                import numpy as np
                pcm_array = np.frombuffer(pcm16_8k, dtype=np.int16)
                energy_variance = np.var(pcm_array.astype(np.float32))
                zero_crossings = np.sum(np.diff(np.sign(pcm_array)) != 0) / len(pcm_array)
                
                # âœ… Block pure silence, DTMF, and carrier tones
                # Pure silence/monotonic: low variance AND low ZCR
                # DTMF tone: very low ZCR (pure sine wave)
                if (energy_variance < 200000 and zero_crossings < 0.02) or (zero_crossings < 0.005):
                    print(f"ğŸš« STT_BLOCKED: Non-speech audio (variance={energy_variance}, zcr={zero_crossings:.3f})")
                    return ""
                
                print(f"âœ… AUDIO_VALIDATED: amp={max_amplitude}, rms={rms}, var={int(energy_variance)}, zcr={zero_crossings:.3f}")
                
            except ImportError:
                print("âš ï¸ numpy not available - skipping advanced audio validation")
            except Exception as numpy_error:
                print(f"âš ï¸ Advanced audio analysis failed: {numpy_error} - using basic validation")
                # ×× × ×›×©×œ× ×• ×‘×‘×“×™×§×•×ª ××ª×§×“××•×ª - ×”××©×š ×¢× ×‘×¡×™×¡×™×•×ª
            
            try:
                from server.services.lazy_services import get_stt_client
                from google.cloud import speech
            except ImportError as import_error:
                print(f"âš ï¸ Google Speech library not available: {import_error} - using Whisper")
                return self._whisper_fallback(pcm16_8k)
            
            client = get_stt_client()
            if not client:
                print("âŒ Google STT client not available - fallback to Whisper")
                return self._whisper_fallback(pcm16_8k)
            
            # âš¡ BUILD 117: FORCE default model - phone_call NOT supported for Hebrew!
            # Google returns error: "The phone_call model is currently not supported for language : iw-IL"
            recognition_config = speech.RecognitionConfig(
                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=8000,  
                language_code="he-IL",   # ×¢×‘×¨×™×ª ×™×©×¨××œ
                model="default",         # âš¡ FORCED: phone_call crashes for Hebrew!
                use_enhanced=True,       # âœ… ENHANCED model for better Hebrew accuracy!
                enable_automatic_punctuation=False,  # ×× ×™×¢×ª ×”×¤×¨×¢×•×ª
                # ×§×•× ×˜×§×¡×˜ ×§×œ - ×¨×§ ×œ×¨××–
                speech_contexts=[
                    speech.SpeechContext(phrases=[
                        "×©×œ×•×", "×ª×•×“×”", "×›×Ÿ", "×œ×", "×‘×¡×“×¨", "× ×”×“×¨", "×‘×™×™",
                        "×“×™×¨×”", "×‘×™×ª", "× ×“×œ×Ÿ", "××©×¨×“", "×—×“×¨×™×", "×©×›×™×¨×•×ª", "×§× ×™×”",
                        "×ª×œ ××‘×™×‘", "×¨××ª ×’×Ÿ", "×¨××œ×”", "×œ×•×“", "××•×“×™×¢×™×Ÿ",
                        "××œ×£", "××™×œ×™×•×Ÿ", "×©×§×œ", "×ª×§×¦×™×‘", "××—×™×¨"
                    ], boost=2.0)
                ]
            )
            
            # Single request recognition (×œ× streaming ×œ××‘×¢ ×§×¦×¨)
            audio = speech.RecognitionAudio(content=pcm16_8k)
            
            # âš¡ AGGRESSIVE TIMEOUT: 1.5s for speed (Hebrew usually < 1s)
            try:
                response = client.recognize(
                    config=recognition_config,
                    audio=audio,
                    timeout=1.5  # âœ… FAST: 1.5s timeout (was 3s)
                )
            except Exception as timeout_error:
                # Timeout = likely empty audio, return empty
                print(f"âš ï¸ STT_TIMEOUT ({timeout_error}) - likely silence")
                return ""
            
            print(f"ğŸ“Š GOOGLE_STT_ENHANCED: Processed {len(pcm16_8k)} bytes")
            
            if response.results and response.results[0].alternatives:
                hebrew_text = response.results[0].alternatives[0].transcript.strip()
                confidence = response.results[0].alternatives[0].confidence
                print(f"ğŸ“Š GOOGLE_STT_RESULT: '{hebrew_text}' (confidence: {confidence:.2f})")
                
                # âš¡ BUILD 111: SMART confidence - prevent false positives
                if confidence < 0.3:  # Very low confidence = not reliable
                    print(f"ğŸš« LOW_CONFIDENCE: {confidence:.2f} < 0.3 - rejecting result")
                    return ""  # Return empty instead of nonsense
                
                # âš¡ BUILD 111: Additional check - reject very short results with low-medium confidence
                word_count = len(hebrew_text.split())
                if word_count <= 2 and confidence < 0.6:
                    print(f"ğŸš« SHORT_LOW_CONFIDENCE: {word_count} words, confidence {confidence:.2f} < 0.6 - likely noise")
                    return ""
                
                print(f"âœ… GOOGLE_STT_SUCCESS: '{hebrew_text}' ({word_count} words, confidence: {confidence:.2f})")
                return hebrew_text
            else:
                # No results = silence
                print("âš ï¸ STT_NO_RESULTS - likely silence")
                return ""
                
        except Exception as e:
            print(f"âŒ GOOGLE_STT_ERROR: {e}")
            return ""
    
    def _whisper_fallback_validated(self, pcm16_8k: bytes) -> str:
        """âœ… FIXED: Whisper fallback with smart validation - ×œ× ×™××¦×™× ××™×œ×™×!"""
        try:
            print(f"ğŸ”„ WHISPER_VALIDATED: Processing {len(pcm16_8k)} bytes with fabrication prevention")
            
            # âœ… ×‘×“×™×§×ª ××™×›×•×ª ××•×“×™×• ×—××•×¨×” ×™×•×ª×¨
            import audioop
            max_amplitude = audioop.max(pcm16_8k, 2)
            rms = audioop.rms(pcm16_8k, 2)
            duration = len(pcm16_8k) / (2 * 8000)
            print(f"ğŸ“Š AUDIO_VALIDATION: max_amplitude={max_amplitude}, rms={rms}, duration={duration:.1f}s")
            
            # âœ… STRICT validation - ××¡×•×¨ ×œ-Whisper ×œ×”××¦×™× ×“×‘×¨×™×!
            if max_amplitude < 200 or rms < 120:  # ×”×¨×‘×” ×™×•×ª×¨ ×—××•×¨!
                print("ğŸš« WHISPER_BLOCKED: Audio too weak - preventing fabrication")
                return ""  # ×¤×©×•×˜ ××œ ×ª×ª×Ÿ ×œ-Whisper ×œ×”××¦×™×!
            
            if duration < 0.3:  # ×¤×—×•×ª ×-300ms
                print("ğŸš« WHISPER_BLOCKED: Audio too short - likely noise")
                return ""
            
            # âœ… ×‘×“×™×§×ª ×©×™×•×•×™ ×× ×¨×’×™×” - ×”×× ×™×© ×“×™×‘×•×¨ ×××™×ª×™?
            try:
                import numpy as np
                pcm_array = np.frombuffer(pcm16_8k, dtype=np.int16)
                energy_variance = np.var(pcm_array.astype(np.float32))
                if energy_variance < 1000000:  # ×× ×¨×’×™×” ××•× ×•×˜×•× ×™×ª = ×¨×¢×©
                    print(f"ğŸš« WHISPER_BLOCKED: Low energy variance ({energy_variance}) - likely background noise")
                    return ""
            except:
                pass  # ×× × ×›×©×œ ×‘×‘×“×™×§×” - ×”××©×š
            
            from server.services.lazy_services import get_openai_client
            client = get_openai_client()
            if not client:
                print("âŒ OpenAI client not available")
                return ""
            
            # Resample to 16kHz for Whisper
            pcm16_16k = audioop.ratecv(pcm16_8k, 2, 1, 8000, 16000, None)[0]
            print(f"ğŸ”„ RESAMPLED: {len(pcm16_8k)} bytes @ 8kHz â†’ {len(pcm16_16k)} bytes @ 16kHz")
            
            # âœ… Whisper ×¢× ×¤×¨××˜×¨×™× ×—××•×¨×™× × ×’×“ ×”××¦××•×ª
            import tempfile
            import wave
            
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_wav:
                with wave.open(temp_wav.name, 'wb') as wav_file:
                    wav_file.setnchannels(1)
                    wav_file.setsampwidth(2)
                    wav_file.setframerate(16000)
                    wav_file.writeframes(pcm16_16k)
                
                with open(temp_wav.name, 'rb') as audio_file:
                    # âœ… FIXED: ×¤×¨××˜×¨×™× ×—××•×¨×™× × ×’×“ ×”××¦××”
                    transcript = client.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio_file,
                        language="he",  # ×—×™×™×‘ ×¢×‘×¨×™×ª
                        prompt="×–×•×”×™ ×©×™×—×ª ×˜×œ×¤×•×Ÿ ×‘×¢×‘×¨×™×ª ×¢×œ × ×“×œ×Ÿ. ×× ××™×Ÿ ×“×™×‘×•×¨ ×‘×¨×•×¨ - ××œ ×ª× ×¡×” ×œ× ×—×©.",  # ×”× ×—×™×” ×—××•×¨×”!
                        temperature=0.1  # × ××•×š ×××•×“ - ×¤×—×•×ª ×™×¦×™×¨×ª×™×•×ª
                    )
            
            import os
            os.unlink(temp_wav.name)
            
            result = transcript.text.strip()
            
            # âœ… FINAL validation - ×‘×“×™×§×ª ×ª×•×¦××” ×—×©×•×“×”
            if not result or len(result) < 2:
                print("âœ… WHISPER_VALIDATED: Empty/minimal result - good!")
                return ""
            
            # âœ… ×‘×“×™×§×ª ××™×œ×™× ×—×©×•×“×•×ª ×©-Whisper ××•×”×‘ ×œ×”××¦×™×
            suspicious_words = ["×ª×•×“×”", "× ×”×“×¨", "× ×”×“×¨×ª", "××¢×•×œ×”", "×‘×¨××‘×•"] 
            if len(result.split()) == 1 and any(word in result for word in suspicious_words):
                print(f"ğŸš« WHISPER_FABRICATION_DETECTED: Suspicious single word '{result}' - blocking")
                return ""
            
            print(f"âœ… WHISPER_VALIDATED_SUCCESS: '{result}'")
            return result
            
        except Exception as e:
            print(f"âŒ WHISPER_VALIDATED_ERROR: {e}")
            return ""
    
    def _whisper_fallback(self, pcm16_8k: bytes) -> str:
        """âš ï¸ DEPRECATED: Old Whisper fallback - ×¢×›×©×™×• ×©×™××•×© ×‘-validated version"""
        try:
            print(f"ğŸ”„ WHISPER_FALLBACK: Processing {len(pcm16_8k)} bytes")
            
            # Check if audio has actual content
            import audioop
            max_amplitude = audioop.max(pcm16_8k, 2)
            rms = audioop.rms(pcm16_8k, 2)
            print(f"ğŸ“Š AUDIO_ANALYSIS: max_amplitude={max_amplitude}, rms={rms}")
            
            if max_amplitude < 100 or rms < 80:  # âœ… ×ª×™×§×•×Ÿ ×œ×¢×‘×¨×™×ª - thresholds × ××•×›×™× ×™×•×ª×¨
                print("ğŸ”‡ WHISPER_SKIP: Audio too quiet or likely noise (Hebrew optimized)")
                return ""
            
            from server.services.lazy_services import get_openai_client
            client = get_openai_client()
            if not client:
                print("âŒ OpenAI client not available")
                return ""
            
            # Resample to 16kHz for Whisper
            pcm16_16k = audioop.ratecv(pcm16_8k, 2, 1, 8000, 16000, None)[0]
            print(f"ğŸ”„ RESAMPLED: {len(pcm16_8k)} bytes @ 8kHz â†’ {len(pcm16_16k)} bytes @ 16kHz")
            
            # Save as temporary WAV file
            import tempfile, wave
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_wav:
                with wave.open(temp_wav.name, 'wb') as wav_file:
                    wav_file.setnchannels(1)
                    wav_file.setsampwidth(2)
                    wav_file.setframerate(16000)
                    wav_file.writeframes(pcm16_16k)
                
                with open(temp_wav.name, 'rb') as audio_file:
                    transcription = client.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio_file,
                        language="he",
                        response_format="text", 
                        temperature=0.2
                    )
                
                hebrew_text = str(transcription).strip() if transcription else ""
                print(f"âœ… WHISPER_FALLBACK_SUCCESS: '{hebrew_text}'")
                
                # Clean up
                import os
                os.unlink(temp_wav.name)
                return hebrew_text
                
        except Exception as e:
            print(f"âŒ WHISPER_FALLBACK_ERROR: {e}")
            return ""
    
    def _load_business_prompts(self, channel: str = 'calls') -> str:
        """×˜×•×¢×Ÿ ×¤×¨×•××¤×˜×™× ××”×“××˜××‘×™×™×¡ ×œ×¤×™ ×¢×¡×§ - ×œ×¤×™ ×”×”× ×—×™×•×ª ×”××“×•×™×§×•×ª"""
        try:
            # âœ… CRITICAL: All DB queries need app_context in Cloud Run/ASGI!
            from server.models_sql import Business, BusinessSettings
            
            app = _get_flask_app()  # âœ… Use singleton
            with app.app_context():
                # âœ… BUILD 100 FIX: ×–×™×”×•×™ business_id ×œ×¤×™ ××¡×¤×¨ ×˜×œ×¤×•×Ÿ - ×©×™××•×© ×‘-phone_e164
                if not self.business_id and self.phone_number:
                    # ×—×¤×© ×¢×¡×§ ×œ×¤×™ ××¡×¤×¨ ×”×˜×œ×¤×•×Ÿ (phone_e164 = ×”×¢××•×“×” ×”×××™×ª×™×ª)
                    business = Business.query.filter(
                        Business.phone_e164 == self.phone_number
                    ).first()
                    if business:
                        self.business_id = business.id
                        print(f"âœ… ×–×™×”×•×™ ×¢×¡×§ ×œ×¤×™ ×˜×œ×¤×•×Ÿ {self.phone_number}: {business.name}")
                
                # ×× ××™×Ÿ ×¢×“×™×™×Ÿ business_id, ×”×©×ª××© ×‘fallback
                if not self.business_id:
                    from server.services.business_resolver import resolve_business_with_fallback
                    self.business_id, status = resolve_business_with_fallback('twilio_voice', '+97233763805')
                    print(f"âœ… ×©×™××•×© ×‘×¢×¡×§ fallback: business_id={self.business_id} ({status})")
                
                if not self.business_id:
                    print("âŒ ×œ× × ××¦× ×¢×¡×§ - ×©×™××•×© ×‘×¤×¨×•××¤×˜ ×‘×¨×™×¨×ª ××—×“×œ")
                    return "××ª×” ×¢×•×–×¨ × ×“×œ×Ÿ ××§×¦×•×¢×™. ×¢×–×•×¨ ×œ×œ×§×•×— ×œ××¦×•× ××ª ×”× ×›×¡ ×”××ª××™×."  # âœ… ×‘×œ×™ ×©× hardcoded
                
                # ×˜×¢×Ÿ ×¤×¨×•××¤×˜ ×-BusinessSettings
                settings = BusinessSettings.query.filter_by(tenant_id=self.business_id).first()
                business = Business.query.get(self.business_id)
            
            if settings and settings.ai_prompt:
                try:
                    # × ×¡×” ×œ×¤×¨×¡×¨ JSON (×¤×•×¨××˜ ×—×“×© ×¢× calls/whatsapp)
                    import json
                    if settings.ai_prompt.startswith('{'):
                        prompt_data = json.loads(settings.ai_prompt)
                        prompt_text = prompt_data.get(channel, prompt_data.get('calls', ''))
                        if prompt_text:
                            print(f"AI_PROMPT loaded tenant={self.business_id} channel={channel}")
                            return prompt_text
                    else:
                        # ×¤×¨×•××¤×˜ ×™×—×™×“ (legacy)
                        print(f"âœ… ×˜×¢×Ÿ ×¤×¨×•××¤×˜ legacy ××“××˜××‘×™×™×¡ ×œ×¢×¡×§ {self.business_id}")
                        return settings.ai_prompt
                except Exception as e:
                    print(f"âš ï¸ ×©×’×™××” ×‘×¤×¨×¡×•×¨ ×¤×¨×•××¤×˜ JSON: {e}")
                    # fallback ×œ×¤×¨×•××¤×˜ ×›×˜×§×¡×˜ ×¨×’×™×œ
                    return settings.ai_prompt
            
            # ×× ××™×Ÿ ×‘-BusinessSettings, ×‘×“×•×§ ××ª business.system_prompt
            if business and business.system_prompt:
                print(f"âœ… ×˜×¢×Ÿ ×¤×¨×•××¤×˜ ××˜×‘×œ×ª businesses ×œ×¢×¡×§ {self.business_id}")
                return business.system_prompt
                
            print(f"âš ï¸ ×œ× × ××¦× ×¤×¨×•××¤×˜ ×œ×¢×¡×§ {self.business_id} - ×©×™××•×© ×‘×‘×¨×™×¨×ª ××—×“×œ")
            return "××ª×” ×¢×•×–×¨ × ×“×œ×Ÿ ××§×¦×•×¢×™. ×¢×–×•×¨ ×œ×œ×§×•×— ×œ××¦×•× ××ª ×”× ×›×¡ ×”××ª××™×."  # âœ… ×‘×œ×™ ×©×/×¢×¡×§ hardcoded
            
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×˜×¢×™× ×ª ×¤×¨×•××¤×˜ ××“××˜××‘×™×™×¡: {e}")
            return "××ª×” ×¢×•×–×¨ × ×“×œ×Ÿ ××§×¦×•×¢×™. ×¢×–×•×¨ ×œ×œ×§×•×— ×œ××¦×•× ××ª ×”× ×›×¡ ×”××ª××™×."  # âœ… ×‘×œ×™ ×©× hardcoded

    def _identify_business_and_get_greeting(self) -> tuple:
        """âš¡ ×–×™×”×•×™ ×¢×¡×§ ×•×˜×¢×™× ×ª ×‘×¨×›×” ×‘×©××™×œ×ª×” ××—×ª - ×—×•×¡×š 50% ×–××Ÿ!"""
        try:
            from server.models_sql import Business
            from sqlalchemy import or_
            
            to_number = getattr(self, 'to_number', None)
            
            print(f"âš¡ FAST: ×–×™×”×•×™ ×¢×¡×§ + ×‘×¨×›×” ×‘×©××™×œ×ª×” ××—×ª: to_number={to_number}")
            
            app = _get_flask_app()  # âœ… Use singleton
            with app.app_context():
                business = None
                
                if to_number:
                    # × ×¨××œ ××¡×¤×¨ ×˜×œ×¤×•×Ÿ
                    normalized_phone = to_number.strip().replace('-', '').replace(' ', '')
                    
                    # âš¡ ×©××™×œ×ª×” ××—×ª - ×¢×¡×§ + ×›×œ ×”× ×ª×•× ×™×!
                    business = Business.query.filter(
                        or_(
                            Business.phone_e164 == to_number,
                            Business.phone_e164 == normalized_phone
                        )
                    ).first()
                    
                    if business:
                        print(f"âœ… ××¦× ×¢×¡×§: {business.name} (id={business.id})")
                
                # Fallback ×× ×œ× × ××¦×
                if not business:
                    business = Business.query.filter_by(is_active=True).first()
                    if not business:
                        business = Business.query.first()
                    print(f"âš ï¸ ×©×™××•×© ×‘×¢×¡×§ fallback: {business.name if business else 'None'}")
                
                # ×¢×“×›×Ÿ business_id + ×—×–×•×¨ ×‘×¨×›×”
                if business:
                    self.business_id = business.id
                    greeting = business.greeting_message or "×©×œ×•×! ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?"
                    business_name = business.name or "×”×¢×¡×§ ×©×œ× ×•"
                    
                    # ×”×—×œ×¤×ª placeholder
                    greeting = greeting.replace("{{business_name}}", business_name)
                    greeting = greeting.replace("{{BUSINESS_NAME}}", business_name)
                    
                    print(f"âš¡ FAST COMPLETE: business_id={self.business_id}, greeting='{greeting[:30]}...'")
                    return (self.business_id, greeting)
                else:
                    self.business_id = 1
                    return (1, "×©×œ×•×! ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?")
        
        except Exception as e:
            print(f"âŒ Fast identification failed: {e}")
            import traceback
            traceback.print_exc()
            self.business_id = 1
            return (1, "×©×œ×•×! ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?")
    
    def _identify_business_from_phone(self):
        """×–×™×”×•×™ business_id ×œ×¤×™ to_number (wrapper for backwards compat)"""
        self._identify_business_and_get_greeting()  # ×§×•×¨× ×œ×¤×•× ×§×¦×™×” ×”×—×“×©×” ×•××ª×¢×œ× ××”×‘×¨×›×”

    def _get_business_greeting_cached(self) -> str:
        """âš¡ ×˜×¢×™× ×ª ×‘×¨×›×” ×¢× cache - ×‘××™×•×—×“ ××”×™×¨ ×œ×‘×¨×›×” ×”×¨××©×•× ×”!"""
        # ×§×•×“× ×›×œ - ×‘×“×•×§ ×× ×™×© business_id
        if not hasattr(self, 'business_id') or not self.business_id:
            print(f"âš ï¸ business_id ×—×¡×¨ ×‘×§×¨×™××” ×œ-_get_business_greeting_cached!")
            return "×©×œ×•×! ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?"
        
        try:
            # âœ… CRITICAL FIX: Must have app_context for DB query in Cloud Run/ASGI!
            from server.app_factory import create_app
            from server.models_sql import Business
            
            app = _get_flask_app()  # âœ… Use singleton
            with app.app_context():
                # âš¡ ×©××™×œ×ª×” ×‘×•×“×“×ª - ×§×œ ×•××”×™×¨
                business = Business.query.get(self.business_id)
                
                if business:
                    # ×§×‘×œ×ª ×”×‘×¨×›×” ×”××•×ª×××ª
                    greeting = business.greeting_message or "×©×œ×•×! ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?"
                    business_name = business.name or "×”×¢×¡×§ ×©×œ× ×•"
                    
                    # ×”×—×œ×¤×ª placeholder ×‘×©× ×”×××™×ª×™
                    greeting = greeting.replace("{{business_name}}", business_name)
                    greeting = greeting.replace("{{BUSINESS_NAME}}", business_name)
                    
                    print(f"âœ… ×‘×¨×›×” × ×˜×¢× ×” ×‘××”×™×¨×•×ª: business_id={self.business_id}, name={business_name}")
                    return greeting
                else:
                    print(f"âš ï¸ Business {self.business_id} ×œ× × ××¦× - ×‘×¨×›×” ×‘×¨×™×¨×ª ××—×“×œ")
                    return "×©×œ×•×! ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?"
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×˜×¢×™× ×ª ×‘×¨×›×”: {e}")
            import traceback
            traceback.print_exc()
            return "×©×œ×•×! ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?"
    
    def _get_business_greeting(self) -> str:
        """×˜×¢×™× ×ª ×‘×¨×›×” ××•×ª×××ª ××™×©×™×ª ××”×¢×¡×§ ×¢× {{business_name}} placeholder"""
        print(f"ğŸ” _get_business_greeting CALLED! business_id={getattr(self, 'business_id', 'NOT SET')}")
        
        try:
            from server.app_factory import create_app
            from server.models_sql import Business
            
            # ×–×™×”×•×™ ×¢×¡×§ ×× ×¢×“×™×™×Ÿ ×œ× ×–×•×”×”
            if not hasattr(self, 'business_id') or not self.business_id:
                print(f"âš ï¸ business_id ×œ× ××•×’×“×¨ - ××–×”×” ×¢×¡×§ ×¢×›×©×™×•...")
                app = _get_flask_app()  # âœ… Use singleton
                with app.app_context():
                    self._identify_business_from_phone()
                print(f"ğŸ” ××—×¨×™ ×–×™×”×•×™: business_id={getattr(self, 'business_id', 'STILL NOT SET')}")
            
            # ×˜×¢×™× ×ª ×‘×¨×›×” ××”-DB
            app = _get_flask_app()  # âœ… Use singleton
            with app.app_context():
                business = Business.query.get(self.business_id)
                print(f"ğŸ” ×©××™×œ×ª×ª business: id={self.business_id}, × ××¦×: {business is not None}")
                
                if business:
                    # ×§×‘×œ×ª ×”×‘×¨×›×” ×”××•×ª×××ª
                    greeting = business.greeting_message or "×©×œ×•×! ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?"
                    business_name = business.name or "×”×¢×¡×§ ×©×œ× ×•"
                    
                    print(f"ğŸ” ×¤×¨×˜×™ ×¢×¡×§: name={business_name}, greeting_message={business.greeting_message}")
                    
                    # ×”×—×œ×¤×ª placeholder ×‘×©× ×”×××™×ª×™
                    greeting = greeting.replace("{{business_name}}", business_name)
                    greeting = greeting.replace("{{BUSINESS_NAME}}", business_name)
                    
                    print(f"âœ… Loaded custom greeting for business {self.business_id} ({business_name}): '{greeting}'")
                    return greeting
                else:
                    print(f"âš ï¸ Business {self.business_id} not found - using default greeting")
                    return "×©×œ×•×! ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?"
        except Exception as e:
            import traceback
            print(f"âŒ Error loading business greeting: {e}")
            print(f"âŒ Traceback: {traceback.format_exc()}")
            return "×©×œ×•×! ××™×š ××¤×©×¨ ×œ×¢×–×•×¨?"

    def _process_dtmf_phone(self, phone_number: str):
        """
        âš¡ BUILD 121: Process phone number collected via DTMF
        Inject as conversation input and generate AI response
        """
        print(f"ğŸ“ Processing DTMF phone: {phone_number}")
        
        # Format as Israeli phone number if needed
        if not phone_number.startswith("+") and not phone_number.startswith("0"):
            phone_number = "0" + phone_number
        
        # Create Hebrew text as if customer said it
        hebrew_text = phone_number  # Just the digits
        
        # Get AI response (Agent will process the phone)
        ai_response = self._ai_response(hebrew_text)
        
        # Speak the response using the correct method
        if ai_response:
            self._speak_simple(ai_response)
            
            # Save to conversation history
            self.conversation_history.append({
                "user": f"[DTMF] {phone_number}",
                "bot": ai_response
            })
        
        print(f"âœ… DTMF phone processed: {phone_number}")
    
    def _ai_response(self, hebrew_text: str) -> str:
        """Generate NATURAL Hebrew AI response using AgentKit - REAL ACTIONS!"""
        try:
            # âš¡ Phase 2C: Track turns and optimize first turn
            self.turn_count = getattr(self, 'turn_count', 0) + 1
            is_first_turn = (self.turn_count == 1)
            
            # ğŸ¤– BUILD 119: Use Agent for REAL ACTIONS (appointments, leads, WhatsApp)
            from server.services.ai_service import AIService
            
            # Build context for the AI
            context = {
                "phone_number": getattr(self, 'phone_number', ''),
                "channel": "voice_call",
                "previous_messages": []
            }
            
            # Add conversation history for context - âœ… FIXED FORMAT
            if hasattr(self, 'conversation_history') and self.conversation_history:
                context["previous_messages"] = [
                    f"×œ×§×•×—: {item['user']}\n×¢×•×–×¨: {item['bot']}"  # âœ… "×¢×•×–×¨" - ×›×œ×œ×™!
                    for item in self.conversation_history[-6:]  # ×¢×“ 6 ×ª×•×¨×•×ª ××—×¨×•× ×™× ×œ×–×™×›×¨×•×Ÿ ××œ×
                ]
            
            # âœ… CRITICAL FIX: Use shared Flask app instance (no recreation!)
            business_id = getattr(self, 'business_id', None)
            if not business_id:
                business_id = 1  # Fallback to business 1
                print(f"âš ï¸ No business_id set, using fallback: {business_id}")
            
            # Get customer name from conversation if available
            customer_name = None
            lead_info = getattr(self, '_last_lead_analysis', None)
            if lead_info:
                customer_name = lead_info.get('customer_name')
            
            # âš¡ CRITICAL: Measure AI response time
            ai_start = time.time()
            
            # âœ… FIX: Use Flask app singleton (CRITICAL - prevents app restart!)
            app = _get_flask_app()
            
            with app.app_context():
                # ğŸ¤– Use Agent for REAL booking actions!
                ai_service = AIService()
                
                # ğŸ” DEBUG: Check if phone_number is set
                caller_phone = getattr(self, 'phone_number', '')
                print(f"\nğŸ“ DEBUG: Caller phone = '{caller_phone}' (type: {type(caller_phone).__name__})")
                print(f"   self.phone_number exists: {hasattr(self, 'phone_number')}")
                if hasattr(self, 'phone_number'):
                    print(f"   self.phone_number value: '{self.phone_number}'")
                
                ai_response = ai_service.generate_response_with_agent(
                    message=hebrew_text,
                    business_id=int(business_id),
                    customer_phone=caller_phone,
                    customer_name=customer_name,
                    context=context,
                    channel='calls',  # âœ… Use 'calls' prompt for phone calls
                    is_first_turn=is_first_turn  # âš¡ Phase 2C: Optimize first turn!
                )
            
            # âš¡ CRITICAL: Save AI timing for TOTAL_LATENCY calculation
            self.last_ai_time = time.time() - ai_start
            print(f"ğŸ¤– AGENT_RESPONSE: Generated {len(ai_response)} chars in {self.last_ai_time:.3f}s (business {business_id})")
            print(f"ğŸ“Š AI_LATENCY: {self.last_ai_time:.3f}s (target: <1.5s)")
            
            return ai_response
            
        except Exception as e:
            print(f"âŒ AI_SERVICE_ERROR: {type(e).__name__}: {e}")
            import traceback
            traceback.print_exc()
            print(f"âš ï¸ Using fallback response instead of agent")
            return self._fallback_response(hebrew_text)
    
    def _fallback_response(self, hebrew_text: str) -> str:
        """Simple fallback response when AI service fails"""
        if "×©×œ×•×" in hebrew_text or "×”×™×™" in hebrew_text:
            return "×©×œ×•×! ××™×š ×× ×™ ×™×›×•×œ×” ×œ×¢×–×•×¨?"  # âœ… ×›×œ×œ×™ - ×œ× ×—×•×©×£ ×©× ×¢×¡×§
        elif "×ª×•×“×”" in hebrew_text or "×‘×™×™" in hebrew_text:
            return "×ª×•×“×” ×¨×‘×”! ×× ×™ ×›××Ÿ ×œ×›×œ ×©××œ×”."
        else:
            return "××™×–×” ××–×•×¨ ××¢× ×™×™×Ÿ ××•×ª×š?"  # âœ… ×›×œ×œ×™ - ×œ× ××“×‘×¨ ×¢×œ ×“×™×¨×•×ª
    
    
    def _hebrew_tts(self, text: str) -> bytes | None:
        """
        âœ… UPGRADED Hebrew TTS with natural voice, SSML, and smart pronunciation
        Uses gcp_tts_live.py with all professional enhancements
        """
        try:
            print(f"ğŸ”Š TTS_START: Generating Natural Hebrew TTS for '{text[:50]}...' ({len(text)} chars)")
            
            # âœ… OPTION 1: Use punctuation polish if enabled
            try:
                from server.services.punctuation_polish import polish_hebrew_text
                text = polish_hebrew_text(text)
                print(f"âœ… Punctuation polished: '{text[:40]}...'")
            except Exception as e:
                print(f"âš ï¸ Punctuation polish unavailable: {e}")
            
            # âœ… OPTION 2: Use upgraded TTS with SSML, natural voice, telephony profile
            try:
                from server.services.gcp_tts_live import get_hebrew_tts, maybe_warmup
                
                # âš¡ Phase 2: Pre-warm TTS (×›×œ 8 ×“×§×•×ª)
                maybe_warmup()
                
                tts_service = get_hebrew_tts()
                audio_bytes = tts_service.synthesize_hebrew_pcm16_8k(text)
                
                if audio_bytes and len(audio_bytes) > 1000:
                    duration_seconds = len(audio_bytes) / (8000 * 2)
                    print(f"âœ… TTS_SUCCESS: {len(audio_bytes)} bytes Natural Wavenet ({duration_seconds:.1f}s)")
                    return audio_bytes
                else:
                    print("âš ï¸ TTS returned empty or too short")
                    return None
                    
            except ImportError as ie:
                print(f"âš ï¸ Upgraded TTS unavailable ({ie}), using fallback...")
                
                # âœ… FALLBACK: Basic Google TTS (if upgraded version fails)
                from server.services.lazy_services import get_tts_client
                from google.cloud import texttospeech
                
                client = get_tts_client()
                if not client:
                    print("âŒ Google TTS client not available")
                    return None
                
                # âœ… ×§×‘×œ×ª ×”×’×“×¨×•×ª ×-ENV - ×œ× ××§×•×“×“!
                voice_name = os.getenv("TTS_VOICE", "he-IL-Wavenet-D")
                speaking_rate = float(os.getenv("TTS_RATE", "0.96"))
                pitch = float(os.getenv("TTS_PITCH", "-2.0"))
                
                synthesis_input = texttospeech.SynthesisInput(text=text)
                voice = texttospeech.VoiceSelectionParams(language_code="he-IL", name=voice_name)
                audio_config = texttospeech.AudioConfig(
                    audio_encoding=texttospeech.AudioEncoding.LINEAR16,
                    sample_rate_hertz=8000,
                    speaking_rate=speaking_rate,
                    pitch=pitch,
                    effects_profile_id=["telephony-class-application"]
                )
                
                response = client.synthesize_speech(
                    input=synthesis_input,
                    voice=voice,
                    audio_config=audio_config
                )
                
                duration_seconds = len(response.audio_content) / (8000 * 2)
                print(f"âœ… TTS_FALLBACK_SUCCESS: {len(response.audio_content)} bytes (voice={voice_name}, rate={speaking_rate}, pitch={pitch}, {duration_seconds:.1f}s)")
                return response.audio_content
            
        except Exception as e:
            print(f"âŒ TTS_CRITICAL_ERROR: {e}")
            print(f"   Text was: '{text}'")
            import traceback
            traceback.print_exc()
            return None
    
    def _tx_loop(self):
        """
        âš¡ BUILD 115.1 FINAL: Production-grade TX loop
        - Precise 20ms/frame timing with next_deadline
        - Back-pressure at 90% threshold
        - Real-time telemetry (fps/q/drops)
        """
        print("ğŸ”Š TX_LOOP_START: Audio transmission thread started")
        
        FRAME_INTERVAL = 0.02  # 20 ms per frame expected by Twilio
        next_deadline = time.monotonic()
        tx_count = 0
        
        # Telemetry
        frames_sent_last_sec = 0
        drops_last_sec = 0
        last_telemetry_time = time.monotonic()
        
        while self.tx_running:
            try:
                item = self.tx_q.get(timeout=0.5)
            except queue.Empty:
                continue
            
            if item.get("type") == "end":
                print("ğŸ”š TX_LOOP_END: End signal received")
                break
            
            # Handle "clear" event
            if item.get("type") == "clear" and self.stream_sid:
                success = self._ws_send(json.dumps({"event": "clear", "streamSid": self.stream_sid}))
                print(f"ğŸ§¹ TX_CLEAR: {'SUCCESS' if success else 'FAILED'}")
                continue
            
            # Handle "media" event with back-pressure and rate limiting
            if item.get("type") == "media":
                # âš¡ Back-pressure: If tx_q is getting full (>90%), slow down
                queue_size = self.tx_q.qsize()
                if queue_size > 108:  # 90% of 120
                    print(f"âš ï¸ tx_q nearly full ({queue_size}/120) â€“ applying back-pressure", flush=True)
                    drops_last_sec += 1
                    time.sleep(FRAME_INTERVAL * 2)  # Double wait to drain queue
                    continue
                
                # Send frame
                success = self._ws_send(json.dumps({
                    "event": "media", 
                    "streamSid": self.stream_sid,
                    "media": {"payload": item["payload"]}
                }))
                tx_count += 1
                frames_sent_last_sec += 1
                
                # âš¡ Precise timing with next_deadline
                next_deadline += FRAME_INTERVAL
                delay = next_deadline - time.monotonic()
                if delay > 0:
                    time.sleep(delay)
                else:
                    # Missed deadline - resync
                    next_deadline = time.monotonic()
                
                # âš¡ Telemetry: Print stats every second (only if issues)
                now = time.monotonic()
                if now - last_telemetry_time >= 1.0:
                    queue_size = self.tx_q.qsize()
                    # Only log if there are drops or queue is getting full
                    if drops_last_sec > 0 or queue_size > 60:
                        print(f"[TX] fps={frames_sent_last_sec} q={queue_size} drops={drops_last_sec}", flush=True)
                    frames_sent_last_sec = 0
                    drops_last_sec = 0
                    last_telemetry_time = now
                
                continue
            
            # Handle "mark" event
            if item.get("type") == "mark":
                success = self._ws_send(json.dumps({
                    "event": "mark", 
                    "streamSid": self.stream_sid,
                    "mark": {"name": item.get("name", "mark")}
                }))
                print(f"ğŸ“ TX_MARK: {item.get('name', 'mark')} {'SUCCESS' if success else 'FAILED'}")
        
        # âš¡ Removed flooding log - TX loop ended naturally
    
    def _speak_with_breath(self, text: str):
        """×“×™×‘×•×¨ ×¢× × ×©×™××” ×× ×•×©×™×ª ×•-TX Queue - ×ª××™×“ ××©×“×¨ ××©×”×•"""
        if not text:
            return
        
        # âš¡ BUILD 117: Stricter barge-in to prevent interruptions
        word_count = len(text.split())
        self.long_response = word_count > 12  # âœ… LOWERED: 12 words = ~2 sentences, disable barge-in
        if self.long_response:
            print(f"ğŸ”’ LONG_RESPONSE ({word_count} words) - BARGE-IN DISABLED")
        else:
            print(f"ğŸ”“ SHORT_RESPONSE ({word_count} words) - BARGE-IN ENABLED")
            
        self.speaking = True
        self.state = STATE_SPEAK
        self.speaking_start_ts = time.time()  # âœ… ×—×œ×•×Ÿ ×—×¡×“ - ×–××Ÿ ×ª×—×™×œ×ª TTS
        
        try:
            # × ×©×™××” ×× ×•×©×™×ª (220-360ms)
            breath_delay = random.uniform(RESP_MIN_DELAY_MS/1000.0, RESP_MAX_DELAY_MS/1000.0)
            time.sleep(breath_delay)
            
            # clear + ×©×™×“×•×¨ ×× ×”×—×™×‘×•×¨ ×ª×§×™×Ÿ
            if self.stream_sid and not self.ws_connection_failed:
                self._tx_enqueue({"type": "clear"})
            elif self.ws_connection_failed:
                print("ğŸ’” SKIPPING TTS clear - WebSocket connection failed")
                return None
            
            # × ×¡×” TTS ×××™×ª×™
            pcm = None
            try:
                pcm = self._hebrew_tts(text)
            except Exception as e:
                print("TTS_ERR:", e)
                
            if not pcm or len(pcm) < 400:
                print("ğŸ”Š TTS FAILED - sending beep")
                pcm = self._beep_pcm16_8k(300)  # ×¦×¤×¦×•×£ 300ms
            else:
                print(f"ğŸ”Š TTS SUCCESS: {len(pcm)} bytes")
            
            # âœ… ×©×œ×— ××ª ×”××•×“×™×• ×“×¨×š TX Queue (×× ×”×—×™×‘×•×¨ ×ª×§×™×Ÿ)
            if pcm and self.stream_sid and not self.ws_connection_failed:
                self._send_pcm16_as_mulaw_frames(pcm)
            elif self.ws_connection_failed:
                print("ğŸ’” SKIPPING audio clear - WebSocket connection failed")
                return
            
            # âœ… Audio already sent by _send_pcm16_as_mulaw_frames() above
            
        finally:
            # âœ… Clean finalization
            self._finalize_speaking()
    
    def _beep_pcm16_8k_v2(self, ms: int) -> bytes:
        """×™×¦×™×¨×ª ×¦×¤×¦×•×£ PCM16 8kHz"""
        samples = int(SR * ms / 1000)
        amp = 9000
        out = bytearray()
        
        for n in range(samples):
            val = int(amp * math.sin(2 * math.pi * 440 * n / SR))
            out.extend(val.to_bytes(2, "little", signed=True))
            
        return bytes(out)
    
    def _detect_area(self, text: str) -> str:
        """×–×™×”×•×™ ××–×•×¨ ××”×˜×§×¡×˜ ×©×œ ×”×œ×§×•×—"""
        text = text.lower()
        
        # ××¨×›×– ×”××¨×¥
        if any(word in text for word in ["×ª×œ ××‘×™×‘", "×“×™×–× ×’×•×£", "×¤×œ×•×¨× ×˜×™×Ÿ", "× ×•×•×” ×¦×“×§"]):
            return "×ª×œ ××‘×™×‘"
        elif any(word in text for word in ["×¨××ª ×’×Ÿ", "×’×‘×¢×ª×™×™×", "×”×‘×•×¨×¡×”"]):
            return "×¨××ª ×’×Ÿ/×’×‘×¢×ª×™×™×"
        elif any(word in text for word in ["×”×¨×¦×œ×™×”", "×¤×™×ª×•×—"]):
            return "×”×¨×¦×œ×™×”"
            
        # ××¨×›×– ×•×“×¨×•×
        elif any(word in text for word in ["×¨××œ×”"]):
            return "×¨××œ×”"
        elif any(word in text for word in ["×œ×•×“"]):
            return "×œ×•×“"
        elif any(word in text for word in ["×¤×ª×— ×ª×§×•×•×”", "×¤×ª×— ×ª×§×•×”"]):
            return "×¤×ª×— ×ª×§×•×•×”"
        elif any(word in text for word in ["××•×“×™×¢×™×Ÿ"]):
            return "××•×“×™×¢×™×Ÿ"
        elif any(word in text for word in ["×¨×—×•×‘×•×ª"]):
            return "×¨×—×•×‘×•×ª"
            
        # ××–×•×¨ ×™×¨×•×©×œ×™×
        elif any(word in text for word in ["×‘×™×ª ×©××©"]):
            return "×‘×™×ª ×©××©"
        elif any(word in text for word in ["××¢×œ×” ××“×•××™×"]):
            return "××¢×œ×” ××“×•××™×"
        elif any(word in text for word in ["×™×¨×•×©×œ×™×"]):
            return "×™×¨×•×©×œ×™×"
            
        return ""  # Return empty string instead of None
    
    def _analyze_lead_completeness(self) -> dict:
        """âœ… × ×™×ª×•×— ×”×©×œ××ª ××™×“×¢ ×œ×™×“ ×œ×ª×™××•× ×¤×’×™×©×”"""
        collected_info = {
            'area': False,
            'property_type': False, 
            'budget': False,
            'timing': False,
            'contact': False
        }
        
        meeting_ready = False
        
        # ×‘×“×•×§ ×”×™×¡×˜×•×¨×™×” ×œ××™×¡×•×£ ××™×“×¢
        if hasattr(self, 'conversation_history') and self.conversation_history:
            full_conversation = ' '.join([turn['user'] + ' ' + turn['bot'] for turn in self.conversation_history])
            
            # ×–×™×”×•×™ ××–×•×¨
            if any(area in full_conversation for area in ['×ª×œ ××‘×™×‘', '×¨××ª ×’×Ÿ', '×¨××œ×”', '×œ×•×“', '×‘×™×ª ×©××©', '××•×“×™×¢×™×Ÿ', '×¤×ª×— ×ª×§×•×•×”', '×¨×—×•×‘×•×ª', '×”×¨×¦×œ×™×”', '×™×¨×•×©×œ×™×']):
                collected_info['area'] = True
            
            # ×–×™×”×•×™ ×¡×•×’ × ×›×¡
            if any(prop_type in full_conversation for prop_type in ['×“×™×¨×”', '×—×“×¨×™×', '2 ×—×“×¨×™×', '3 ×—×“×¨×™×', '4 ×—×“×¨×™×', '××©×¨×“', '×“×•×¤×œ×§×¡']):
                collected_info['property_type'] = True
            
            # ×–×™×”×•×™ ×ª×§×¦×™×‘
            if any(budget_word in full_conversation for budget_word in ['×©×§×œ', '××œ×£', '×ª×§×¦×™×‘', 'â‚ª', '××œ×¤×™×', '××™×œ×™×•×Ÿ']):
                collected_info['budget'] = True
            
            # ×–×™×”×•×™ ×–××Ÿ ×›× ×™×¡×”
            if any(timing in full_conversation for timing in ['××™×™×“×™', '×“×—×•×£', '×—×•×“×©', '×©×‘×•×¢×™×™×', '×‘×§×¨×•×‘', '×¢×›×©×™×•']):
                collected_info['timing'] = True
            
            # ×–×™×”×•×™ ×¤×¨×˜×™ ×§×©×¨
            if any(contact in full_conversation for contact in ['×˜×œ×¤×•×Ÿ', '×•×•××˜×¡××¤', '× ×™×™×“', '××¡×¤×¨', '×¤×¨×˜×™×']):
                collected_info['contact'] = True
        
        # ×¡×¤×™×¨×ª ××™×“×¢ ×©× ××¡×£
        completed_fields = sum(collected_info.values())
        
        # âœ… FIX: ×ª×™××•× ×¤×’×™×©×” ×× ×™×© ×œ×¤×—×•×ª 3 ×©×“×•×ª (××–×•×¨ + ×¡×•×’ × ×›×¡ + ×˜×œ×¤×•×Ÿ)
        # ×œ× ×¦×¨×™×š ×ª×§×¦×™×‘ ×•-timing ×‘×”×›×¨×—!
        meeting_ready = completed_fields >= 3
        
        # ×™×¦×™×¨×ª ×¡×™×›×•×
        summary_parts = []
        if collected_info['area']: summary_parts.append('××–×•×¨')
        if collected_info['property_type']: summary_parts.append('×¡×•×’ × ×›×¡')
        if collected_info['budget']: summary_parts.append('×ª×§×¦×™×‘')
        if collected_info['timing']: summary_parts.append('×–××Ÿ')
        if collected_info['contact']: summary_parts.append('×§×©×¨')
        
        summary = f"{len(summary_parts)}/5 ×©×“×•×ª: {', '.join(summary_parts) if summary_parts else '××™×Ÿ'}"
        
        # ×”×•×“×¢×” ×œ×ª×™××•× ×¤×’×™×©×” ××• ×”×¦×’×ª ××•×¤×¦×™×•×ª
        meeting_prompt = ""
        if meeting_ready:
            meeting_prompt = f"""
×–××Ÿ ×œ×ª×™××•× ×¤×’×™×©×”! ×™×© ××¡×¤×™×§ ××™×“×¢ ({completed_fields}/5 ×©×“×•×ª).

**×—×©×•×‘**: ×›×©×”×œ×§×•×— ××¡×›×™× ×œ×–××Ÿ ×¡×¤×¦×™×¤×™ (×œ×“×•×’××” "××—×¨ ×‘-10" ××• "×™×•× ×¨×‘×™×¢×™ ×‘×¢×¨×‘"):
1. ×—×–×•×¨ ×¢×œ ×”×–××Ÿ ×”××“×•×™×§ ×©×¡×•×›×: "××¦×•×™×Ÿ! × ×§×‘×¢ ×¤×’×™×©×” ×œ[×™×•×] ×‘×©×¢×” [×©×¢×” ××“×•×™×§×ª]"
2. ×ª×Ÿ ×¡×™×›×•× ×§×¦×¨: "× ×¤×’×© ×‘[××™×§×•×/× ×›×¡] ×•× ×¨××” [×¤×¨×˜×™ ×”× ×›×¡]"
3. ××©×¨: "××¨××” ××•×ª×š ×‘[×ª××¨×™×š ×•×©×¢×” ××“×•×™×§×™×]!"

×”×¦×¢ 2-3 ××¤×©×¨×•×™×•×ª ×–××Ÿ ×¡×¤×¦×™×¤×™×•×ª, ×©××¢ ××” ×”×œ×§×•×— ×‘×•×—×¨, ×•×—×–×•×¨ ×¢×œ ×”×–××Ÿ ×”××“×•×™×§ ×©×”×•×¡×›×."""
        elif completed_fields == 3:
            meeting_prompt = """
×™×© ××™×“×¢ ×‘×¡×™×¡×™ ×˜×•×‘! ×¢×›×©×™×• ×ª×Ÿ ×“×•×’××” ××—×ª ×¡×¤×¦×™×¤×™×ª ××ª××™××” ×•×©××œ ×©××œ×” ×××•×§×“×ª ×œ×¤× ×™ ×§×‘×™×¢×ª ×¤×’×™×©×”."""
        else:
            missing = 4 - completed_fields
            meeting_prompt = f"×¦×¨×™×š ×¢×•×“ {missing} ×©×“×•×ª ××™×“×¢ ×œ×¤× ×™ ×”×¦×’×ª ××•×¤×¦×™×•×ª. ×”××©×š ×©×™×—×” ×˜×‘×¢×™×ª ×•×ª×Ÿ ×¤×¨×˜×™× × ×•×¡×¤×™× ×¢×œ ×”×©×•×§ ×•×”××–×•×¨."
        
        return {
            'collected': collected_info,
            'completed_count': completed_fields,
            'meeting_ready': meeting_ready,
            'summary': summary,
            'meeting_prompt': meeting_prompt
        }
    
    def _finalize_call_on_stop(self):
        """âœ… ×¡×™×›×•× ××œ× ×©×œ ×”×©×™×—×” ×‘×¡×™×•× - ×¢×“×›×•×Ÿ call_log ×•×œ×™×“ + ×™×¦×™×¨×ª ×¤×’×™×©×•×ª"""
        try:
            from server.models_sql import CallLog
            from server.services.customer_intelligence import CustomerIntelligence
            from server.app_factory import create_app
            from server.db import db
            import threading
            
            def finalize_in_background():
                try:
                    app = _get_flask_app()  # âœ… Use singleton
                    with app.app_context():
                        # ××¦× call_log
                        call_log = CallLog.query.filter_by(call_sid=self.call_sid).first()
                        if not call_log:
                            print(f"âš ï¸ No call_log found for final summary: {self.call_sid}")
                            return
                        
                        # ×‘× ×” ×¡×™×›×•× ××œ×
                        full_conversation = ""
                        if hasattr(self, 'conversation_history') and self.conversation_history:
                            full_conversation = "\n".join([
                                f"×œ×§×•×—: {turn['user']}\n×¢×•×–×¨: {turn['bot']}"  # âœ… ×›×œ×œ×™ - ×œ× hardcoded!
                                for turn in self.conversation_history
                            ])
                        
                        # ×¦×•×¨ ×¡×™×›×•× AI
                        business_id = getattr(self, 'business_id', 1)
                        ci = CustomerIntelligence(business_id)
                        summary_data = ci.generate_conversation_summary(
                            full_conversation,
                            {'conversation_history': self.conversation_history}
                        )
                        
                        # ×¢×“×›×Ÿ call_log
                        call_log.status = "completed"
                        call_log.transcription = full_conversation  # âœ… FIX: transcription not transcript!
                        call_log.summary = summary_data.get('summary', '')
                        call_log.ai_summary = summary_data.get('detailed_summary', '')
                        
                        db.session.commit()
                        
                        print(f"âœ… CALL FINALIZED: {self.call_sid}")
                        print(f"ğŸ“ Summary: {summary_data.get('summary', 'N/A')}")
                        print(f"ğŸ¯ Intent: {summary_data.get('intent', 'N/A')}")
                        print(f"ğŸ“Š Next Action: {summary_data.get('next_action', 'N/A')}")
                        
                        # ğŸ¤– BUILD 119: Agent handles appointments during conversation!
                        # AUTO-APPOINTMENT disabled - Agent creates appointments in real-time
                        print(f"â„¹ï¸ Appointment handling: Managed by Agent during call (BUILD 119)")
                        
                except Exception as e:
                    print(f"âŒ Failed to finalize call: {e}")
                    import traceback
                    traceback.print_exc()
            
            # ×¨×•×¥ ×‘×¨×§×¢
            thread = threading.Thread(target=finalize_in_background, daemon=True)
            thread.start()
            self.background_threads.append(thread)  # âœ… Track for cleanup
            
        except Exception as e:
            print(f"âŒ Call finalization setup failed: {e}")
    
    def _create_call_log_on_start(self):
        """âœ… ×™×¦×™×¨×ª call_log ××™×“ ×‘×”×ª×—×œ×ª ×©×™×—×” - ×œ×× ×™×¢×ª 'Call SID not found' errors"""
        try:
            from server.models_sql import CallLog
            from server.app_factory import create_app
            from server.db import db
            import threading
            
            def create_in_background():
                try:
                    app = _get_flask_app()  # âœ… Use singleton
                    with app.app_context():
                        # âœ… LOG DATABASE CONNECTION (per ×”× ×—×™×•×ª)
                        db_url = os.getenv('DATABASE_URL', 'NOT_SET')
                        db_driver = db_url.split(':')[0] if db_url else 'none'
                        print(f"ğŸ”§ DB_URL_AT_WRITE: driver={db_driver}, BIZ={getattr(self, 'business_id', 1)}, SID={self.call_sid}", flush=True)
                        
                        # ×‘×“×•×§ ×× ×›×‘×¨ ×§×™×™×
                        existing = CallLog.query.filter_by(call_sid=self.call_sid).first()
                        if existing:
                            print(f"âœ… Call log already exists for {self.call_sid}")
                            return
                        
                        # ×¦×•×¨ call_log ×—×“×©
                        call_log = CallLog()  # type: ignore[call-arg]
                        call_log.business_id = getattr(self, 'business_id', 1)
                        call_log.call_sid = self.call_sid
                        call_log.from_number = str(self.phone_number or "")
                        call_log.to_number = str(getattr(self, 'to_number', '') or '')
                        call_log.call_status = "in_progress"
                        db.session.add(call_log)
                        
                        try:
                            db.session.commit()
                            print(f"âœ… Created call_log on start: call_sid={self.call_sid}, phone={self.phone_number}")
                        except Exception as commit_error:
                            # Handle duplicate key error (race condition)
                            db.session.rollback()
                            error_msg = str(commit_error).lower()
                            if 'unique' in error_msg or 'duplicate' in error_msg:
                                print(f"âš ï¸ Call log already exists (race condition): {self.call_sid}")
                            else:
                                raise
                        
                except Exception as e:
                    print(f"âŒ Failed to create call_log on start: {e}")
                    import traceback
                    traceback.print_exc()
            
            # ×¨×•×¥ ×‘×¨×§×¢
            thread = threading.Thread(target=create_in_background, daemon=True)
            thread.start()
            self.background_threads.append(thread)  # âœ… Track for cleanup
            
        except Exception as e:
            print(f"âŒ Call log creation setup failed: {e}")
    
    def _save_conversation_turn(self, user_text: str, bot_reply: str):
        """âœ… ×©××™×¨×ª ×ª×•×¨ ×©×™×—×” ×‘××¡×“ × ×ª×•× ×™× ×œ×–×™×›×¨×•×Ÿ ×§×‘×•×¢"""
        try:
            from server.models_sql import ConversationTurn, CallLog
            from server.app_factory import create_app
            from server.db import db
            import threading
            
            def save_in_background():
                try:
                    app = _get_flask_app()  # âœ… Use singleton
                    with app.app_context():
                        # ××¦× call_log ×§×™×™× (×××•×¨ ×œ×”×™×•×ª ×›×‘×¨ × ×•×¦×¨ ×‘-_create_call_log_on_start)
                        call_log = None
                        if hasattr(self, 'call_sid') and self.call_sid:
                            call_log = CallLog.query.filter_by(call_sid=self.call_sid).first()
                        
                        if not call_log:
                            print(f"âš ï¸ Call log not found for {self.call_sid} - conversation turn not saved")
                            return
                        
                        # ×©××•×¨ ×ª×•×¨ ××©×ª××©
                        user_turn = ConversationTurn()  # type: ignore[call-arg]
                        user_turn.call_log_id = call_log.id
                        user_turn.call_sid = self.call_sid or f"live_{int(time.time())}"
                        user_turn.speaker = 'user'
                        user_turn.message = user_text
                        user_turn.confidence_score = 1.0
                        db.session.add(user_turn)
                        
                        # ×©××•×¨ ×ª×•×¨ AI
                        bot_turn = ConversationTurn()  # type: ignore[call-arg]
                        bot_turn.call_log_id = call_log.id
                        bot_turn.call_sid = self.call_sid or f"live_{int(time.time())}"
                        bot_turn.speaker = 'assistant'
                        bot_turn.message = bot_reply
                        bot_turn.confidence_score = 1.0
                        db.session.add(bot_turn)
                        
                        db.session.commit()
                        print(f"âœ… Saved conversation turn to DB: call_log_id={call_log.id}")
                        
                except Exception as e:
                    print(f"âŒ Failed to save conversation turn: {e}")
                    import traceback
                    traceback.print_exc()
            
            # ×¨×•×¥ ×‘×¨×§×¢ ×›×“×™ ×œ× ×œ×—×¡×•×
            thread = threading.Thread(target=save_in_background, daemon=True)
            thread.start()
            self.background_threads.append(thread)  # âœ… Track for cleanup
            
        except Exception as e:
            print(f"âŒ Conversation turn save setup failed: {e}")
    
    def _process_customer_intelligence(self, user_text: str, bot_reply: str):
        """
        âœ¨ ×¢×™×‘×•×“ ×—×›× ×©×œ ×”×©×™×—×” ×¢× ×–×™×”×•×™/×™×¦×™×¨×ª ×œ×§×•×— ×•×œ×™×“ ××•×˜×•××˜×™×ª
        """
        try:
            # ×•×•×“× ×©×™×© ××¡×¤×¨ ×˜×œ×¤×•×Ÿ ×•-business_id
            if not self.phone_number or not hasattr(self, 'business_id'):
                print("âš ï¸ Missing phone_number or business_id for customer intelligence")
                return
            
            # Import only when needed to avoid circular imports
            from server.services.customer_intelligence import CustomerIntelligence
            from server.app_factory import create_app
            from server.db import db
            
            # ×”×¨×¦×” ××¡×™× ×›×¨×•× ×™×ª ×›×“×™ ×œ× ×œ×—×¡×•× ××ª ×”×©×™×—×”
            import threading
            
            def process_in_background():
                try:
                    app = _get_flask_app()  # âœ… Use singleton
                    with app.app_context():
                        business_id = getattr(self, 'business_id', 1)
                        ci = CustomerIntelligence(business_id)
                        
                        # ×™×¦×™×¨×ª ×˜×§×¡×˜ ××œ× ××”×”×™×¡×˜×•×¨×™×” ×”× ×•×›×—×™×ª
                        full_conversation = ""
                        if hasattr(self, 'conversation_history') and self.conversation_history:
                            full_conversation = " ".join([
                                f"{turn['user']} {turn['bot']}" 
                                for turn in self.conversation_history[-5:]  # ×¨×§ 5 ××—×¨×•× ×•×ª
                            ])
                        
                        # ×–×™×”×•×™/×™×¦×™×¨×ª ×œ×§×•×— ×•×œ×™×“ ×¢× ×”×ª××œ×•×œ ×”× ×•×›×—×™
                        customer, lead, was_created = ci.find_or_create_customer_from_call(
                            str(self.phone_number or ""),
                            self.call_sid or f"live_{int(time.time())}",
                            full_conversation,
                            conversation_data={'conversation_history': self.conversation_history}
                        )
                        
                        # ×¡×™×›×•× ×—×›× ×©×œ ×”×©×™×—×”
                        conversation_summary = ci.generate_conversation_summary(
                            full_conversation,
                            {'conversation_history': self.conversation_history}
                        )
                        
                        # ×¢×“×›×•×Ÿ ×¡×˜×˜×•×¡ ××•×˜×•××˜×™
                        new_status = ci.auto_update_lead_status(lead, conversation_summary)
                        
                        # ×¢×“×›×•×Ÿ ×¤×ª×§×™×•×ª ×”×œ×™×“ ×¢× ×”×ª×§×“××•×ª ×”×©×™×—×” ×”× ×•×›×—×™×ª
                        if lead.notes:
                            lead.notes += f"\n[Live Call]: {user_text[:100]}... â†’ {bot_reply[:50]}..."
                        else:
                            lead.notes = f"[Live Call]: {user_text[:100]}... â†’ {bot_reply[:50]}..."
                        
                        db.session.commit()
                        
                        # ×¨×™×©×•× ×œ×•×’×™× ××¤×•×¨×˜×™×
                        print(f"ğŸ¯ Live Call AI Processing: Customer {customer.name} ({'NEW' if was_created else 'EXISTING'})")
                        print(f"ğŸ“‹ Live Summary: {conversation_summary.get('summary', 'N/A')}")
                        print(f"ğŸ­ Live Intent: {conversation_summary.get('intent', 'N/A')}")
                        print(f"ğŸ“Š Live Status: {new_status}")
                        print(f"âš¡ Live Next Action: {conversation_summary.get('next_action', 'N/A')}")
                        
                except Exception as e:
                    print(f"âŒ Customer Intelligence background processing failed: {e}")
                    import traceback
                    traceback.print_exc()
            
            # ×”×¨×¥ ×‘×¨×§×¢ ×›×“×™ ×œ× ×œ×—×¡×•× ××ª ×”×©×™×—×”
            thread = threading.Thread(target=process_in_background, daemon=True)
            thread.start()
            self.background_threads.append(thread)  # âœ… Track for cleanup
            
        except Exception as e:
            print(f"âŒ Customer Intelligence setup failed: {e}")
            # ××œ ×ª×§×¨×™×¡ ××ª ×”×©×™×—×” - ×”××©×š ×¨×’×™×œ