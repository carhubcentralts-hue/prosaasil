"""
BUILD 204: Dynamic STT Enhancement Service
Provides business-specific transcription improvements using:
1. Dynamic STT prompts based on business vocabulary
2. GPT-4o-mini semantic post-processing for low-confidence transcripts
3. 100% database-driven - zero hardcoded values
"""
import logging
import json
from typing import Optional, Dict, List, Any
from dataclasses import dataclass
import os

logger = logging.getLogger(__name__)

# Cache for business vocabularies (thread-safe with simple dict)
_vocabulary_cache: Dict[int, Dict] = {}
_cache_expiry: Dict[int, float] = {}
CACHE_TTL_SECONDS = 300  # 5 minutes


@dataclass
class STTEnhancement:
    """Result of STT enhancement"""
    original_text: str
    enhanced_text: str
    confidence: float
    corrections_made: List[str]
    semantic_fix_applied: bool


def get_business_vocabulary(business_id: int) -> Dict[str, Any]:
    """
    Load business vocabulary from database
    
    Returns dict with keys: services, staff, products, locations, business_name, business_type, business_context
    All 100% from DB - no hardcoded values
    """
    import time
    
    # Check cache
    now = time.time()
    if business_id in _vocabulary_cache:
        if now < _cache_expiry.get(business_id, 0):
            return _vocabulary_cache[business_id]
    
    try:
        from server.models_sql import BusinessSettings, Business
        
        settings = BusinessSettings.query.filter_by(tenant_id=business_id).first()
        business = Business.query.get(business_id)
        
        vocab = {
            "services": [],
            "staff": [],
            "products": [],
            "locations": [],
            "business_name": business.name if business else "",
            "business_type": business.business_type if business else "general",
            "business_context": ""
        }
        
        if settings:
            # Load vocabulary JSON
            if settings.stt_vocabulary_json:
                try:
                    stt_vocab = settings.stt_vocabulary_json
                    if isinstance(stt_vocab, str):
                        stt_vocab = json.loads(stt_vocab)
                    
                    vocab["services"] = stt_vocab.get("services", [])
                    vocab["staff"] = stt_vocab.get("staff", [])
                    vocab["products"] = stt_vocab.get("products", [])
                    vocab["locations"] = stt_vocab.get("locations", [])
                    logger.info(f"âœ… [STT-VOCAB] Loaded vocabulary for business {business_id}: "
                               f"{len(vocab['services'])} services, {len(vocab['staff'])} staff")
                except (json.JSONDecodeError, TypeError) as e:
                    logger.warning(f"âš ï¸ [STT-VOCAB] Invalid JSON for business {business_id}: {e}")
            
            # Load business context
            if settings.business_context:
                vocab["business_context"] = settings.business_context
        
        # Cache result
        _vocabulary_cache[business_id] = vocab
        _cache_expiry[business_id] = now + CACHE_TTL_SECONDS
        
        return vocab
        
    except Exception as e:
        logger.error(f"âŒ [STT-VOCAB] Failed to load vocabulary for business {business_id}: {e}")
        return {
            "services": [],
            "staff": [],
            "products": [],
            "locations": [],
            "business_name": "",
            "business_type": "general",
            "business_context": ""
        }


def build_dynamic_stt_prompt(business_id: int, active_task: str = "") -> str:
    """
    Build a TELEPHONY-OPTIMIZED STT prompt for OpenAI transcription
    
    ğŸ”¥ BUILD 206: Expert recommendations for 8kHz G.711 Î¼-law telephony:
    - Keep prompt VERY short (under 100 chars)
    - Focus on BEHAVIOR not vocabulary lists
    - Tell model what NOT to do (prevent hallucinations)
    - Business name + 4-6 key terms MAX
    
    Args:
        business_id: Business ID
        active_task: Current task context (e.g., "booking", "inquiry")
    
    Returns:
        Telephony-optimized transcription prompt
    """
    vocab = get_business_vocabulary(business_id)
    
    business_name = vocab.get("business_name", "")
    
    # ğŸ”¥ BUILD 206: TELEPHONY-OPTIMIZED prompt structure
    # Core instruction: behavior-focused, not vocabulary-focused
    # Expert recommendation: "×ª××œ×œ ×¢×‘×¨×™×ª ×‘×©×™×—×” ×˜×œ×¤×•× ×™×ª. ×”×™×× ×¢ ××”×•×¡×¤×ª ××™×œ×™×."
    
    # Start with core telephony instruction
    prompt_parts = ["×ª××œ×œ ×¢×‘×¨×™×ª ×‘×©×™×—×” ×˜×œ×¤×•× ×™×ª."]
    
    # Add business context (very brief)
    if business_name:
        prompt_parts.append(f"×¢×¡×§: {business_name}.")
    
    # Add ONLY 4-6 key hints (expert recommendation)
    hints = []
    services = vocab.get("services", [])[:3]
    staff = vocab.get("staff", [])[:2]
    if services:
        hints.extend(services)
    if staff:
        hints.extend(staff)
    
    if hints:
        prompt_parts.append(f"××™×œ×™×: {', '.join(hints[:5])}.")
    
    # Critical: anti-hallucination instruction
    prompt_parts.append("×¨×§ ×ª××œ×œ, ×œ× ×œ×”×•×¡×™×£.")
    
    prompt = " ".join(prompt_parts)
    
    # Ensure prompt stays under 100 chars for optimal performance
    if len(prompt) > 100:
        prompt = f"×ª××œ×œ ×¢×‘×¨×™×ª ×˜×œ×¤×•× ×™×ª. ×¢×¡×§: {business_name[:15] if business_name else '×›×œ×œ×™'}. ×¨×§ ×ª××œ×œ."
    
    logger.debug(f"ğŸ“ [STT-PROMPT] Telephony prompt for business {business_id}: '{prompt}' ({len(prompt)} chars)")
    return prompt


async def semantic_post_process(
    transcript: str,
    business_id: int,
    confidence: float = 1.0,
    min_confidence_for_fix: float = 0.7
) -> STTEnhancement:
    """
    Post-process transcript using GPT-4o-mini for semantic correction
    
    Only applies to low-confidence transcripts to avoid latency on good transcriptions.
    Uses business vocabulary for context-aware corrections.
    
    Args:
        transcript: Original transcript text
        business_id: Business ID for vocabulary lookup
        confidence: Transcript confidence (0-1)
        min_confidence_for_fix: Only process if confidence below this threshold
    
    Returns:
        STTEnhancement with original and corrected text
    """
    # Fast path: high confidence transcripts pass through
    if confidence >= min_confidence_for_fix or not transcript or len(transcript.strip()) < 3:
        return STTEnhancement(
            original_text=transcript,
            enhanced_text=transcript,
            confidence=confidence,
            corrections_made=[],
            semantic_fix_applied=False
        )
    
    try:
        import openai
        
        vocab = get_business_vocabulary(business_id)
        
        # Build context for GPT
        context_parts = []
        if vocab["business_name"]:
            context_parts.append(f"×¢×¡×§: {vocab['business_name']}")
        if vocab["business_type"] != "general":
            context_parts.append(f"×¡×•×’: {vocab['business_type']}")
        if vocab["services"]:
            context_parts.append(f"×©×™×¨×•×ª×™×: {', '.join(vocab['services'][:5])}")
        if vocab["staff"]:
            context_parts.append(f"×¦×•×•×ª: {', '.join(vocab['staff'][:3])}")
        if vocab["products"]:
            context_parts.append(f"××•×¦×¨×™×: {', '.join(vocab['products'][:3])}")
        
        context = " | ".join(context_parts) if context_parts else "×¢×¡×§ ×›×œ×œ×™"
        
        # Call GPT-4o-mini for semantic fix
        client = openai.AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0,
            max_tokens=100,
            messages=[
                {
                    "role": "system",
                    "content": f"""××ª×” ××ª×§×Ÿ ×ª××œ×•×œ×™× ×¢×‘×¨×™×™×. ×”×§×©×¨: {context}
×ª×¤×§×™×“×š: ×ª×§×Ÿ ×©×’×™××•×ª ×ª××œ×•×œ ×‘×¨×•×¨×•×ª ×‘×”×ª×× ×œ×”×§×©×¨ ×”×¢×¡×§×™.
×›×œ×œ×™×:
1. ×¨×§ ×ª×§×Ÿ ×˜×¢×•×™×•×ª ×‘×¨×•×¨×•×ª (×›××• "×ª×¤×•×¨×ª" â†’ "×ª×¡×¤×•×¨×ª")
2. ××œ ×ª×•×¡×™×£ ××• ×ª××¦×™× ××™×œ×™×
3. ×× ×”×˜×§×¡×˜ × ×›×•×Ÿ ××• ×œ× ×‘×¨×•×¨ - ×”×—×–×¨ ××•×ª×• ×›××• ×©×”×•×
4. ×”×—×–×¨ ×¨×§ ××ª ×”×˜×§×¡×˜ ×”××ª×•×§×Ÿ, ×‘×œ×™ ×”×¡×‘×¨×™×"""
                },
                {
                    "role": "user",
                    "content": f"×ª×§×Ÿ: {transcript}"
                }
            ]
        )
        
        corrected = (response.choices[0].message.content or "").strip()
        
        # Track corrections
        corrections = []
        if corrected != transcript:
            corrections.append(f"'{transcript}' â†’ '{corrected}'")
            logger.info(f"ğŸ”§ [SEMANTIC-FIX] Corrected for business {business_id}: {corrections[0]}")
        
        return STTEnhancement(
            original_text=transcript,
            enhanced_text=corrected,
            confidence=confidence,
            corrections_made=corrections,
            semantic_fix_applied=len(corrections) > 0
        )
        
    except Exception as e:
        logger.warning(f"âš ï¸ [SEMANTIC-FIX] Failed for business {business_id}: {e}")
        # Return original on failure
        return STTEnhancement(
            original_text=transcript,
            enhanced_text=transcript,
            confidence=confidence,
            corrections_made=[],
            semantic_fix_applied=False
        )


def apply_vocabulary_corrections(
    transcript: str,
    business_id: int
) -> tuple[str, Dict[str, str]]:
    """
    Apply fast vocabulary-based corrections using fuzzy matching
    
    ğŸ”¥ BUILD 204: CONSERVATIVE APPROACH - Only fix obvious near-misses, never damage critical data
    
    NEVER TOUCH:
    - Numbers (phone numbers, times, dates, amounts)
    - Very short tokens (< 3 chars)
    - Words that are already exact matches
    - Pure punctuation
    
    Args:
        transcript: Original transcript
        business_id: Business ID
    
    Returns:
        Tuple of (corrected_transcript, corrections_dict)
    """
    import re
    
    if not transcript or len(transcript.strip()) < 2:
        return transcript, {}
    
    try:
        from rapidfuzz import fuzz, process
        
        vocab = get_business_vocabulary(business_id)
        
        # Build vocabulary set for matching
        dictionary = set()
        for key in ("services", "products", "staff", "locations"):
            for item in vocab.get(key) or []:
                item = (item or "").strip()
                if item:
                    dictionary.add(item)
        
        if not dictionary:
            return transcript, {}
        
        words = transcript.split()
        corrections = {}
        corrected_words = []
        
        for w in words:
            # Strip punctuation for matching, but preserve it
            clean = w.strip(".,!?;:\"'")
            
            # ğŸ”’ SAFETY: Skip tokens we should NEVER modify
            # 1. Too short (< 3 chars)
            if len(clean) < 3:
                corrected_words.append(w)
                continue
            
            # 2. Contains digits (times, dates, phone numbers, amounts)
            if re.search(r'\d', clean):
                corrected_words.append(w)
                continue
            
            # 3. Looks like a phone number pattern
            if re.match(r'^[\d\-\+\(\)]+$', clean):
                corrected_words.append(w)
                continue
            
            # 4. Already an exact match in vocabulary
            if clean in dictionary:
                corrected_words.append(w)
                continue
            
            # 5. Pure Hebrew numbers (×©×ª×™×™×, ×©×œ×•×©, etc.) - don't modify!
            hebrew_numbers = ["××—×“", "××—×ª", "×©×ª×™×™×", "×©× ×™×™×", "×©×œ×•×©", "×©×œ×•×©×”", "××¨×‘×¢", "××¨×‘×¢×”",
                           "×—××©", "×—××™×©×”", "×©×©", "×©×™×©×”", "×©×‘×¢", "×©×‘×¢×”", "×©××•× ×”", "×ª×©×¢", "×ª×©×¢×”",
                           "×¢×©×¨", "×¢×©×¨×”", "×¢×©×¨×™×", "×©×œ×•×©×™×", "××¨×‘×¢×™×", "×—××™×©×™×", "×××”", "××œ×£"]
            if clean in hebrew_numbers:
                corrected_words.append(w)
                continue
            
            # Try fuzzy match with conservative threshold
            result = process.extractOne(
                clean,
                dictionary,
                scorer=fuzz.WRatio,  # ğŸ”¥ WRatio is better for Hebrew partial matches
                score_cutoff=78  # 78% threshold - conservative
            )
            
            if result:
                matched_term, score, _ = result
                # Only correct if it's a clear win
                if score >= 78 and matched_term != clean:
                    # Preserve original punctuation
                    if w.endswith(tuple(".,!?;:\"\'")):
                        new_word = matched_term + w[-1]
                    else:
                        new_word = matched_term
                    
                    corrections[clean] = matched_term
                    corrected_words.append(new_word)
                    logger.info(f"ğŸ”§ [STT_CORRECTION] original='{clean}', corrected='{matched_term}', score={score:.0f}, business_id={business_id}")
                else:
                    corrected_words.append(w)
            else:
                corrected_words.append(w)
        
        corrected_text = " ".join(corrected_words)
        
        if corrections:
            logger.info(f"ğŸ”§ [VOCAB-FIX] Applied {len(corrections)} corrections for business {business_id}: {corrections}")
        
        return corrected_text, corrections
        
    except ImportError:
        logger.debug("âš ï¸ RapidFuzz not available for vocabulary corrections")
        return transcript, {}
    except Exception as e:
        logger.warning(f"âš ï¸ [VOCAB-FIX] Failed: {e}")
        return transcript, {}


def clear_vocabulary_cache(business_id: Optional[int] = None):
    """Clear vocabulary cache (call after settings update)"""
    global _vocabulary_cache, _cache_expiry
    
    if business_id:
        _vocabulary_cache.pop(business_id, None)
        _cache_expiry.pop(business_id, None)
        logger.info(f"ğŸ—‘ï¸ Cleared STT vocabulary cache for business {business_id}")
    else:
        _vocabulary_cache.clear()
        _cache_expiry.clear()
        logger.info("ğŸ—‘ï¸ Cleared all STT vocabulary caches")


async def semantic_repair(text: str, business_id: int) -> str:
    """
    ğŸ”¥ BUILD 301: Enhanced semantic repair for short/unclear transcriptions
    
    Uses GPT-4o-mini to fix obvious transcription errors in short Hebrew text
    from telephony (8kHz Î¼-law) audio.
    
    Examples of fixes:
    - "×¨××ª ××™×‘" â†’ "×¨××ª ××‘×™×‘"
    - "×§×¨×™×ª ×¢×Ÿ" â†’ "×§×¨×™×™×ª ×™×"  
    - "×ª×¤×•×¨×ª" â†’ "×ª×¡×¤×•×¨×ª"
    - "× ×ª×™×‘×•×ª" kept as-is (correct city name)
    
    Args:
        text: Short transcript to repair (typically < 12 chars or 1-2 tokens)
        business_id: Business ID for vocabulary context
    
    Returns:
        Repaired text (or original if no repair needed/possible)
    """
    if not text or len(text.strip()) < 2:
        return text
    
    try:
        import openai
        import re
        
        vocab = get_business_vocabulary(business_id)
        
        # Build vocabulary context
        vocab_items = []
        for key in ["services", "staff", "products", "locations"]:
            vocab_items.extend(vocab.get(key, [])[:5])
        vocab_str = ", ".join(vocab_items[:15]) if vocab_items else ""
        
        business_context = vocab.get("business_context", "") or ""
        business_name = vocab.get("business_name", "") or ""
        
        # ğŸ”¥ BUILD 301: Enhanced repair prompt per expert guidelines
        # Focus on: Israeli cities, Israeli first names, business vocabulary
        prompt = f"""You receive a short, noisy HEBREW transcription from an 8kHz Î¼-law phone call.
Task:
1. If the text is clearly Hebrew but slightly distorted, fix it to the most likely correct Hebrew phrase.
2. Prefer valid Israeli city names, Israeli first names, and business-related terms.
3. Do NOT change phone numbers, times, or dates.
4. If you are not sure, return the original text unchanged.

Business: {business_name}
Context: {business_context}
Vocabulary: {vocab_str}

Return ONLY the repaired text, nothing else.

Input: "{text}"
"""
        
        client = openai.AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0,
            max_tokens=20,
            messages=[{"role": "user", "content": prompt}]
        )
        
        repaired = (response.choices[0].message.content or "").strip()
        
        # Remove quotes if the model added them
        if repaired.startswith('"') and repaired.endswith('"'):
            repaired = repaired[1:-1]
        if repaired.startswith("'") and repaired.endswith("'"):
            repaired = repaired[1:-1]
        
        # Log repair if changed
        if repaired and repaired != text:
            logger.info(f"ğŸ”§ [STT_REPAIRED] '{text}' â†’ '{repaired}' (business={business_id})")
            return repaired
        
        return text
        
    except Exception as e:
        logger.warning(f"âš ï¸ [SEMANTIC_REPAIR] Failed: {e}")
        return text


def should_apply_semantic_repair(text: str) -> bool:
    """
    ğŸ”¥ BUILD 301: Enhanced criteria for semantic repair
    
    Criteria:
    - Text <= 12 characters
    - OR 1-2 tokens only (single word / short phrase)
    - OR low Hebrew character ratio (suggests garbled text)
    """
    import re
    
    if not text:
        return False
    
    text = text.strip()
    
    # Short text always benefits from repair
    if len(text) <= 12:
        return True
    
    # ğŸ”¥ BUILD 301: 1-2 tokens = apply repair (per Watchdog doc)
    tokens = text.split()
    if len(tokens) <= 2:
        return True
    
    # Check Hebrew ratio - low ratio suggests garbled text
    hebrew_chars = len(re.findall(r'[\u0590-\u05FF]', text))
    total_chars = len(re.sub(r'\s', '', text))
    
    if total_chars > 0:
        hebrew_ratio = hebrew_chars / total_chars
        # If less than 50% Hebrew in what should be Hebrew text, repair it
        if hebrew_ratio < 0.5 and total_chars > 3:
            return True
    
    return False
