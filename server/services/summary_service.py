"""
Summary Service - AI-powered conversation summarization
×©×™×¨×•×ª ×¡×™×›×•× ×—×›× - ×¡×™×›×•× ×©×™×—×•×ª ×¢× GPT
"""
import os
import logging
from typing import Optional

log = logging.getLogger(__name__)

def summarize_conversation(transcription: str, call_sid: Optional[str] = None) -> str:
    """
    ×¡×™×›×•× ××§×¦×•×¢×™ ×•××¤×•×¨×˜ ×©×œ ×©×™×—×” - ×›×•×œ×œ ×›×œ ×”×¤×¨×˜×™× ×”×—×©×•×‘×™×
    
    Args:
        transcription: ×”×ª××œ×•×œ ×”××œ× ×©×œ ×”×©×™×—×”
        call_sid: ××–×”×” ×©×™×—×” ×œ×œ×•×’×™×
        
    Returns:
        ×¡×™×›×•× ××§×¦×•×¢×™ ×‘×¢×‘×¨×™×ª (80-150 ××™×œ×™×) ×¢× ×›×œ ×”×¤×¨×˜×™×
    """
    if not transcription or len(transcription.strip()) < 10:
        return "×©×™×—×” ×§×¦×¨×” ×œ×œ× ×ª×•×›×Ÿ"
    
    try:
        from openai import OpenAI
        
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        # âœ… ×¤×¨×•××¤×˜ ××§×¦×•×¢×™ ×•××¤×•×¨×˜ - BUILD 106
        prompt = f"""×¡×›× ××ª ×”×©×™×—×” ×”×‘××” ×‘×¢×‘×¨×™×ª ×‘×¦×•×¨×” **××§×¦×•×¢×™×ª ×•××¤×•×¨×˜×ª** (80-150 ××™×œ×™×).

ğŸ“‹ ××‘× ×” ×”×¡×™×›×•× ×”× ×“×¨×©:

1. **×¡×•×’ ×”×¤× ×™×™×”**: ××” ×”×œ×§×•×— ××—×¤×©? (××›×™×¨×”/×”×©×›×¨×”/×™×™×¢×•×¥)

2. **×¤×¨×˜×™ ×”× ×›×¡ ×”××‘×•×§×©**:
   - ×¡×•×’ × ×›×¡: (×“×™×¨×”/×‘×™×ª/××©×¨×“/×§×¨×§×¢)
   - ××–×•×¨/×¢×™×¨: (××” ×”××–×•×¨ ×”××•×¢×“×£?)
   - ×ª×§×¦×™×‘: (×›×•×œ×œ ×˜×•×•×— ××—×™×¨×™× - ×—×©×•×‘ ×œ×¦×™×™×Ÿ ××™×œ×™×•×Ÿ/××œ×£!)
   - ××¡×¤×¨ ×—×“×¨×™×: (×× ×¦×•×™×Ÿ)
   - ×’×•×“×œ: (×"×¨ ×× ×¦×•×™×Ÿ)
   - ×“×¨×™×©×•×ª ××™×•×—×“×•×ª: (×—× ×™×”, ××"×“, ××¢×œ×™×ª ×•×›×•')

3. **×¤×¨×˜×™ ×§×©×¨**:
   - ×©× ×”×œ×§×•×—: (×× × ××¡×¨)
   - ×˜×œ×¤×•×Ÿ: (×× ×¦×•×™×Ÿ ×‘××¤×•×¨×©)
   - ××™×š ×œ×™×¦×•×¨ ×§×©×¨: (××™×™×œ, ×˜×œ×¤×•×Ÿ, WhatsApp)

4. **×¡×˜×˜×•×¡ ×•××¢×§×‘**:
   - ×”×× × ×§×‘×¢×” ×¤×’×™×©×”? (×× ×›×Ÿ - ××ª×™ ×•×‘××™×–×• ×©×¢×”?)
   - ×“×—×™×¤×•×ª: (×’×‘×•×”×”/×‘×™× ×•× ×™×ª/× ××•×›×”)
   - ×¤×¢×•×œ×•×ª ××¢×§×‘ × ×“×¨×©×•×ª: (×”×ª×§×©×¨×•×ª ×—×•×–×¨×ª, ×©×œ×™×—×ª × ×›×¡×™×, ×•×›×•')

5. **×”×¢×¨×•×ª × ×•×¡×¤×•×ª**: ×›×œ ××™×“×¢ ×—×©×•×‘ ×©×¦×•×™×Ÿ ×‘×©×™×—×”

×ª××œ×•×œ ×”×©×™×—×”:
{transcription}

ğŸ“ **×¡×™×›×•× ××§×¦×•×¢×™**:"""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # ××•×“×œ ××”×™×¨ ×•×–×•×œ
            messages=[
                {"role": "system", "content": "××ª×” ××•××—×” ×¡×™×›×•× ×©×™×—×•×ª × ×“×œ\"×Ÿ ×‘×¢×‘×¨×™×ª. ×ª×›×ª×•×‘ ×¡×™×›×•××™× **××§×¦×•×¢×™×™×, ××¤×•×¨×˜×™× ×•××•×‘× ×™×** ×©××›×™×œ×™× ××ª ×›×œ ×”××™×“×¢ ×”×—×©×•×‘ ××”×©×™×—×”. ×”×©×ª××© ×‘×¤×•×¨××˜ ×‘×¨×•×¨ ×¢× ×›×•×ª×¨×•×ª ×•×¡×¢×™×¤×™×."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=300,  # âœ… ××¡×¤×™×§ ×œ-150 ××™×œ×™× ××¤×•×¨×˜×•×ª ×‘×¢×‘×¨×™×ª
            temperature=0.2  # ×™×¦×™×‘×•×ª ×’×‘×•×”×” - ×¡×™×›×•××™× ×¢×§×‘×™×™×
        )
        
        summary = response.choices[0].message.content
        if summary:
            summary = summary.strip()
            log.info(f"âœ… Summary generated for {call_sid}: {len(summary)} chars")
            return summary
        else:
            log.warning(f"âš ï¸ Empty summary for {call_sid}")
            return "×œ× × ×™×ª×Ÿ ×œ×¡×›×"
            
    except Exception as e:
        log.error(f"âŒ Summary generation failed for {call_sid}: {e}")
        # fallback - ×”×—×–×¨ ×§×˜×¢ ×¨××©×•×Ÿ ××”×ª××œ×•×œ
        return _fallback_summary(transcription)

def _fallback_summary(transcription: str) -> str:
    """×¡×™×›×•× fallback ×¤×©×•×˜ - 30 ××™×œ×™× ×¨××©×•× ×•×ª"""
    words = transcription.strip().split()
    if len(words) <= 30:
        return transcription.strip()
    
    summary = " ".join(words[:30]) + "..."
    return summary

def extract_lead_info(transcription: str) -> dict:
    """
    ×—×™×œ×•×¥ ××™×“×¢ ×—×©×•×‘ ××”×©×™×—×” (××–×•×¨, ×¡×•×’ × ×›×¡, ×ª×§×¦×™×‘)
    
    Args:
        transcription: ×”×ª××œ×•×œ ×”××œ×
        
    Returns:
        dict ×¢×: {area, property_type, budget, intent}
    """
    if not transcription or len(transcription.strip()) < 10:
        return {}
    
    try:
        from openai import OpenAI
        
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        prompt = f"""×—×œ×¥ ××™×“×¢ ××”×©×™×—×” ×”×‘××”:

×ª××œ×•×œ:
{transcription}

×”×—×–×¨ JSON ×‘×¤×•×¨××˜:
{{
  "area": "××–×•×¨ ××‘×•×§×© ××• null",
  "property_type": "×“×™×¨×”/×‘×™×ª/××©×¨×“ ××• null",
  "budget": "×ª×§×¦×™×‘ ××• ×˜×•×•×— ××• null",
  "intent": "××›×™×¨×”/×”×©×›×¨×” ××• null",
  "meeting_scheduled": true/false
}}
"""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "××ª×” ××•××—×” ×œ×—×™×œ×•×¥ ××™×“×¢ ×× ×“×œ\"×Ÿ. ×”×—×–×¨ ×¨×§ JSON ×ª×§×™×Ÿ."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=150,
            temperature=0.1
        )
        
        import json
        result = json.loads(response.choices[0].message.content)
        log.info(f"âœ… Lead info extracted: {result}")
        return result
        
    except Exception as e:
        log.error(f"âŒ Lead info extraction failed: {e}")
        return {}
