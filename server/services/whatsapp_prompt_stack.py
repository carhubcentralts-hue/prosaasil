"""
WhatsApp Prompt Stack Builder - Clean Separation of Concerns
=============================================================

This module implements the "Prompt Stack" architecture where:
- SYSTEM prompts = Framework only (tools, rules, format, memory, safety)
- DB prompts = Single source of truth for business behavior
- Context injection = Customer data, history, state

The SYSTEM prompt is minimal and never contains:
- Sales scripts or conversation examples
- Appointment processes or detailed flows
- Business descriptions, services, pricing
- Personality beyond general tone

All business behavior comes from business.whatsapp_system_prompt in DB.
"""
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
import pytz

logger = logging.getLogger(__name__)

# ============================================================================
# FRAMEWORK SYSTEM PROMPT - SHORT & MECHANICAL
# ============================================================================
# This prompt contains ONLY:
# 1. Tool usage rules
# 2. Memory/context rules
# 3. Format rules (WhatsApp: short, one message, one question)
# 4. Safety rules (don't invent facts, ask if missing info)
# 5. CRM update rules (when to update after changes)
# ============================================================================

FRAMEWORK_SYSTEM_PROMPT = """××ª×” ×¢×•×–×¨ ×“×™×’×™×˜×œ×™ ×‘-WhatsApp.

ğŸ”§ ×›×œ×œ×™ ×¢×‘×•×“×” ×¢× ×›×œ×™× (Tools):
- ×× ××ª×” ×¦×¨×™×š ××™×“×¢ ×¢×œ ×œ×§×•×—/×¡×˜×˜×•×¡/×”×™×¡×˜×•×¨×™×”/×©×™×¨×•×ª×™× - ×”×©×ª××© ×‘×›×œ×™× ×”×–××™× ×™×.
- ×× ×™×© ×¦×•×¨×š ×œ×¢×“×›×Ÿ CRM ×œ××—×¨ ×©×™× ×•×™ ××©××¢×•×ª×™ - ×”×©×ª××© ×‘×›×œ×™ ×”×¢×“×›×•×Ÿ.

ğŸ§  ×›×œ×œ×™ ×–×™×›×¨×•×Ÿ ×•×”×§×©×¨:
- ×× ×™×© summary/last_state: ××œ ×ª×ª× ×”×’ ×›××™×œ×• ×–×• ×©×™×—×” ×—×“×©×”.
- ×©××œ ××ª ×”×œ×§×•×—: "×¨××™×ª×™ ×©×¢×¦×¨× ×• ×‘-X. ×œ×”××©×™×š ××©× ××• ×œ×”×ª×—×™×œ ××—×“×©?"
- ×”×©×ª××© ×‘×”×™×¡×˜×•×¨×™×” ×›×“×™ ×œ×”×‘×™×Ÿ ××ª ×”×”×§×©×¨, ××œ ×ª×—×–×•×¨ ×¢×œ ××” ×©×›×‘×¨ × ×©××œ.
- ×× ×”×œ×§×•×— ×›×‘×¨ ×¢× ×” ×¢×œ ×©××œ×” - ××œ ×ª×©××œ ××•×ª×” ×©×•×‘! ×”××©×š ×œ×©××œ×” ×”×‘××”.

ğŸ“± ×›×œ×œ×™ ×¤×•×¨××˜ ×‘-WhatsApp:
- ×ª×¢× ×” ×§×¦×¨ - ×”×•×“×¢×” ××—×ª ×‘×›×œ ×¤×¢×.
- ×©××œ×” ××—×ª ×‘×›×œ ×ª×’×•×‘×”.
- ××œ ×ª×©×œ×— ×™×•×ª×¨ ×-2-3 ×©×•×¨×•×ª.
- ×ª×”×™×” ×™×©×™×¨ ×•×œ×¢× ×™×™×Ÿ.

ğŸ”„ ×›×œ×œ×™ ×”×ª×§×“××•×ª ×‘×©×™×—×”:
- ×× ×™×© history_count >= 2 - ×–×• ×œ× ×©×™×—×” ×—×“×©×”! ××œ ×ª×‘×¨×š ×©×•×‘.
- ×× ×”×œ×§×•×— ×¢× ×” ×¢×œ ×”×©××œ×” ×©×œ×š - ×”××©×š ×œ×©××œ×” ×”×‘××”, ××œ ×ª×—×–×•×¨ ×¢×œ ×”×‘×¨×›×”.
- ×‘×“×•×§ ××ª ×”×”×™×¡×˜×•×¨×™×” ×œ×¨××•×ª ××” ×›×‘×¨ × ×©××œ ×•××” ×›×‘×¨ × ×¢× ×”.
- ×›×œ ×ª×’×•×‘×” ×©×œ×š ×¦×¨×™×›×” ×œ×”×ª×§×“× ×‘×ª×”×œ×™×š, ×œ× ×œ×—×–×•×¨ ×¢×œ ××” ×©×›×‘×¨ × ×××¨.

ğŸ›¡ï¸ ×›×œ×œ×™ ×‘×˜×™×—×•×ª ×•×™×¦×™×‘×•×ª:
- ×× ×—×¡×¨ ×œ×š ××™×“×¢ - ×©××œ ××ª ×”×œ×§×•×— ×‘××§×•× ×œ×”××¦×™×.
- ××œ ×ª×‘×˜×™×— ×“×‘×¨×™× ×©××ª×” ×œ× ×‘×˜×•×— ×‘×”×.
- ×× ×™×© ×©×’×™××” - ×”×•×“×” ×•×©××œ ×œ× ×¡×•×ª ×©×•×‘.

ğŸ“ ×›×œ×œ×™ ×ª×™×¢×•×“:
- ×œ××—×¨ ×©×™× ×•×™ ××©××¢×•×ª×™ - ×¢×“×›×Ÿ ××ª ×”-CRM ×“×¨×š ×”×›×œ×™×.

×–×”×•. ×›×œ ×©××¨ ×”×”×ª× ×”×’×•×ª ××’×™×¢×” ××”×¤×¨×•××¤×˜ ×”×¢×¡×§×™ ×©×œ×š."""


def build_whatsapp_prompt_stack(
    business_id: int,
    db_prompt: str,
    context: Optional[Dict[str, Any]] = None
) -> List[Dict[str, str]]:
    """
    Build the complete WhatsApp prompt stack with clean separation.
    
    Stack structure:
    1. SYSTEM Framework Prompt (fixed, short)
    2. DB Business Prompt (from database - single source of truth)
    3. Context Injection (customer info, history, state)
    4. User Message (added by caller)
    
    Args:
        business_id: Business ID for logging
        db_prompt: Business prompt from database (whatsapp_system_prompt)
        context: Optional context dict with:
            - lead_id: Lead ID (if exists)
            - customer_name: Customer name (if exists)
            - summary: Conversation summary (if exists)
            - last_state: Last conversation state (if exists)
            - last_intent: Last detected intent (if exists)
            - previous_messages: List of last N messages (formatted as "×œ×§×•×—: ..." or "×¢×•×–×¨: ...")
            - last_user_message: Last user message (if exists)
            - last_agent_message: Last agent message (if exists)
            - conversation_has_history: Boolean flag indicating if this is not first message
            - anti_repeat_instruction: Special instruction to prevent repetition (if needed)
    
    Returns:
        List of message dicts ready for LLM
    """
    messages = []
    
    # ============================================================================
    # LAYER 1: SYSTEM FRAMEWORK (Fixed - Never changes unless tools change)
    # ============================================================================
    messages.append({
        "role": "system",
        "content": FRAMEWORK_SYSTEM_PROMPT
    })
    
    # ============================================================================
    # LAYER 2: DB BUSINESS PROMPT (Single source of truth for behavior)
    # ============================================================================
    if not db_prompt or not db_prompt.strip():
        logger.error(f"âŒ NO DB PROMPT for business {business_id}! Cannot build prompt stack.")
        # Return minimal stack with error - AI will fail and skip sending
        return [{
            "role": "system",
            "content": "âŒ ERROR: No business prompt configured. Cannot respond."
        }]
    
    messages.append({
        "role": "system",
        "content": f"ğŸ“‹ ×”× ×—×™×•×ª ×¢×¡×§×™×•×ª:\n{db_prompt}"
    })
    
    logger.info(f"âœ… Prompt stack built: framework={len(FRAMEWORK_SYSTEM_PROMPT)} + db={len(db_prompt)} chars")
    
    # ============================================================================
    # LAYER 3: CONTEXT INJECTION (Customer data & state)
    # ============================================================================
    if context:
        context_parts = []
        
        # Business & Lead IDs
        if business_id:
            context_parts.append(f"business_id: {business_id}")
        if context.get('lead_id'):
            context_parts.append(f"lead_id: {context['lead_id']}")
        
        # Customer name
        if context.get('customer_name'):
            context_parts.append(f"×©× ×œ×§×•×—: {context['customer_name']}")
        
        # ğŸ”¥ FIX: Add conversation history indicator
        if context.get('conversation_has_history'):
            context_parts.append(f"âš ï¸ ×–×• ×œ× ×©×™×—×” ×—×“×©×”! ×›×‘×¨ ×™×© ×”×™×¡×˜×•×¨×™×” ×©×œ ×”×•×“×¢×•×ª.")
        
        # Conversation state (if exists)
        if context.get('summary'):
            context_parts.append(f"×¡×™×›×•× ×©×™×—×” ×§×•×“××ª: {context['summary']}")
        
        if context.get('last_state'):
            context_parts.append(f"××¦×‘ ××—×¨×•×Ÿ: {context['last_state']}")
        
        if context.get('last_intent'):
            context_parts.append(f"×›×•×•× ×” ××—×¨×•× ×”: {context['last_intent']}")
        
        # ğŸ”¥ FIX: Add last exchange information
        if context.get('last_user_message'):
            msg = context['last_user_message']
            # Only add '...' if message is actually truncated
            display = msg[:100] + ('...' if len(msg) > 100 else '')
            context_parts.append(f"×”×•×“×¢×” ××—×¨×•× ×” ××”×œ×§×•×—: {display}")
        
        if context.get('last_agent_message'):
            msg = context['last_agent_message']
            # Only add '...' if message is actually truncated
            display = msg[:100] + ('...' if len(msg) > 100 else '')
            context_parts.append(f"×”×ª×©×•×‘×” ×”××—×¨×•× ×” ×©×œ×š: {display}")
        
        if context_parts:
            messages.append({
                "role": "system",
                "content": "ğŸ” ×”×§×©×¨ × ×•×›×—×™:\n" + "\n".join(context_parts)
            })
        
        # ğŸ”¥ CRITICAL FIX: Convert history to actual user/assistant messages
        # Instead of system message with text, we need proper conversation history
        # This allows the AI to understand context properly!
        if context.get('previous_messages'):
            history = context['previous_messages']
            # Limit to last 10 messages maximum for token efficiency
            history = history[-10:] if len(history) > 10 else history
            
            if history:
                logger.info(f"ğŸ“œ Converting {len(history)} history messages to user/assistant format")
                
                # Convert each message to proper role format
                for msg in history:
                    # Format is "×œ×§×•×—: text" or "×¢×•×–×¨: text"
                    if msg.startswith("×œ×§×•×—:"):
                        messages.append({
                            "role": "user",
                            "content": msg.replace("×œ×§×•×—:", "").strip()
                        })
                    elif msg.startswith("×¢×•×–×¨:") or msg.startswith("×¢×•×–×¨×ª:"):
                        # Remove prefix and add as assistant
                        content = msg.replace("×¢×•×–×¨:", "").replace("×¢×•×–×¨×ª:", "").strip()
                        messages.append({
                            "role": "assistant",
                            "content": content
                        })
                    else:
                        # If no prefix, assume it's user message
                        logger.warning(f"[HISTORY] Message without prefix: {msg[:50]}...")
                        messages.append({
                            "role": "user",
                            "content": msg
                        })
                
                logger.info(f"âœ… Added {len(history)} history messages as user/assistant (NOT system text)")
        
        # ğŸ”¥ FIX: Add anti-repetition instruction if there's a history
        if context.get('anti_repeat_instruction'):
            messages.append({
                "role": "system",
                "content": f"âš ï¸ ×”×•×¨××” ×—×©×•×‘×”:\n{context['anti_repeat_instruction']}"
            })
    
    return messages


def get_db_prompt_for_whatsapp(business_id: int) -> str:
    """
    Get the DB prompt for WhatsApp - the single source of truth for behavior.
    
    Priority order:
    1. business.whatsapp_system_prompt (primary)
    2. BusinessSettings.ai_prompt['whatsapp'] (fallback)
    3. Emergency minimal fallback (only if nothing exists)
    
    Args:
        business_id: Business ID
    
    Returns:
        Prompt string from database
    """
    from server.models_sql import Business, BusinessSettings
    from server.db import db
    import json
    
    try:
        # Priority 1: business.whatsapp_system_prompt
        business = Business.query.get(business_id)
        if business and hasattr(business, 'whatsapp_system_prompt') and business.whatsapp_system_prompt:
            prompt = business.whatsapp_system_prompt.strip()
            if prompt:
                logger.info(f"âœ… Loaded WhatsApp prompt from business.whatsapp_system_prompt ({len(prompt)} chars)")
                return prompt
        
        # Priority 2: BusinessSettings.ai_prompt (JSON with 'whatsapp' key)
        settings = BusinessSettings.query.filter_by(tenant_id=business_id).first()
        if settings and settings.ai_prompt:
            try:
                if settings.ai_prompt.strip().startswith('{'):
                    prompt_obj = json.loads(settings.ai_prompt)
                    if 'whatsapp' in prompt_obj:
                        prompt = prompt_obj['whatsapp'].strip()
                        if prompt:
                            logger.info(f"âœ… Loaded WhatsApp prompt from BusinessSettings.ai_prompt ({len(prompt)} chars)")
                            return prompt
            except json.JSONDecodeError:
                pass
        
        # Priority 3: Emergency minimal fallback (ONLY if nothing exists)
        logger.error(f"âŒ NO WhatsApp prompt found for business {business_id}! Cannot respond without DB prompt.")
        return ""  # Return empty - this will prevent bot from responding
        
    except Exception as e:
        logger.error(f"âŒ Error loading WhatsApp prompt for business {business_id}: {e}")
        return "××ª×” ×¢×•×–×¨ ×“×™×’×™×˜×œ×™. ×ª×¢× ×” ×‘×¢×‘×¨×™×ª ×•×ª×”×™×” ×—× ×•××“×™×‘."


def validate_prompt_stack_usage(messages: List[Dict[str, str]]) -> Dict[str, Any]:
    """
    Validate that the prompt stack is being used correctly.
    
    This function checks:
    - Framework prompt is present
    - DB prompt is present
    - No duplicate system prompts
    - Total token count is reasonable
    
    Args:
        messages: List of message dicts
    
    Returns:
        Validation result dict with warnings/errors
    """
    result = {
        "valid": True,
        "warnings": [],
        "errors": [],
        "stats": {}
    }
    
    # Count system messages
    system_messages = [m for m in messages if m.get("role") == "system"]
    result["stats"]["system_message_count"] = len(system_messages)
    
    # Check for framework prompt
    has_framework = any("×›×œ×œ×™ ×¢×‘×•×“×” ×¢× ×›×œ×™×" in m.get("content", "") for m in system_messages)
    if not has_framework:
        result["errors"].append("Framework prompt missing!")
        result["valid"] = False
    
    # Check for DB prompt
    has_db_prompt = any("×”× ×—×™×•×ª ×¢×¡×§×™×•×ª" in m.get("content", "") for m in system_messages)
    if not has_db_prompt:
        result["errors"].append("DB prompt missing!")
        result["valid"] = False
    
    # Check total length
    total_chars = sum(len(m.get("content", "")) for m in messages)
    result["stats"]["total_chars"] = total_chars
    
    if total_chars > 5000:
        result["warnings"].append(f"Prompt stack is large ({total_chars} chars). Consider reducing history.")
    
    # Rough token estimate (1 token â‰ˆ 4 chars for Hebrew)
    estimated_tokens = total_chars // 4
    result["stats"]["estimated_tokens"] = estimated_tokens
    
    if estimated_tokens > 2000:
        result["warnings"].append(f"Estimated {estimated_tokens} tokens. May cause latency.")
    
    return result
