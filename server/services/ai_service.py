"""
AI Service - Unified OpenAI Service for All Communication Channels
×©×™×¨×•×ª AI ×××•×—×“ - ××—×‘×¨ ×¤×¨×•××¤×˜×™× ×“×™× ××™×™× ××”××¡×“ × ×ª×•× ×™× ×¢× OpenAI
âœ¨ BUILD 119: AgentKit integration for real actions (appointments, leads, WhatsApp)
"""
import os
import logging
import time
from typing import Dict, Any, Optional, List
from openai import OpenAI
from server.models_sql import BusinessSettings, PromptRevisions, Business, AgentTrace
from server.db import db
from datetime import datetime

# ğŸ”¥ CRITICAL: Import agent modules at TOP of file (not inside function!)
# This prevents re-importing on every call and speeds up response time
try:
    from server.agent_tools import get_agent, AGENTS_ENABLED
    from agents import Runner
    AGENT_MODULES_LOADED = True
    logger_temp = logging.getLogger(__name__)
    logger_temp.info("âœ… Agent modules pre-loaded at module level")
except ImportError as e:
    AGENT_MODULES_LOADED = False
    AGENTS_ENABLED = False
    logger_temp = logging.getLogger(__name__)
    logger_temp.warning(f"âš ï¸ Agent modules not available: {e}")

logger = logging.getLogger(__name__)

# ğŸ¯ Intent Router - Fast Hebrew intent detection (no LLM needed!)
def route_intent(message: str) -> str:
    """
    âš¡ FAST intent detection for Hebrew messages - determines routing
    
    Returns:
        'book' - Customer wants to schedule appointment
        'reschedule' - Change existing appointment
        'cancel' - Cancel appointment
        'info' - Asking for information (price, hours, location, etc.)
        'whatsapp' - Request WhatsApp message
        'human' - Want to speak to human
        'other' - General conversation
    """
    msg_lower = message.lower().strip()
    
    # Info intent - CHECK FIRST (before booking)
    # People asking about hours/price/location shouldn't trigger booking
    info_keywords = [
        "×›××” ×¢×•×œ×”", "××—×™×¨", "×¢×œ×•×ª", "×ª×©×œ×•×", "×›×©×¨", "×›×©×¨×•×ª",
        "××™×§×•×", "××™×¤×”", "×›×ª×•×‘×ª", "×—× ×™×”", "××–×•×¨", 
        "×©×¢×•×ª ×¤×ª×™×—×”", "×¤×ª×•×—", "×¡×’×•×¨", "×¢×•×‘×“×™×", "××ª×™ ×¤×ª×•×—×™×",
        "×’×•×“×œ", "×—×“×¨", "×× ×©×™×", "××§×¡×™××•×", "××” ×™×©", "××” ×–×”",
        "×–××™× ×™×", "×–××™× ×•×ª", "×¤× ×•×™×™×", "×¤×ª×•×—×™× ×‘×¢×¨×‘", "×¢×•×‘×“×™× ×‘×©×‘×ª",
        "××” ×”×©×¢×•×ª", "×¢×“ ××ª×™", "××” ×”×–××™× ×•×ª", "×ª×¤×¨×™×˜", "×©×™×¨×•×ª×™×"
    ]
    
    if any(kw in msg_lower for kw in info_keywords):
        return "info"
    
    # WhatsApp intent
    whatsapp_keywords = ["×•×•××˜×¡××¤", "whatsapp", "×©×œ×— ×œ×™", "×§×™×©×•×¨"]
    if any(kw in msg_lower for kw in whatsapp_keywords):
        return "whatsapp"
    
    # Human intent
    human_keywords = ["× ×¦×™×’", "×‘×Ÿ ××“×", "×‘× ××“×", "×œ×“×‘×¨ ×¢×", "×× ×”×œ"]
    if any(kw in msg_lower for kw in human_keywords):
        return "human"
    
    # Reschedule intent
    reschedule_keywords = ["×œ×”×–×™×–", "×œ×”×§×“×™×", "×œ×“×—×•×ª", "×œ×”×—×œ×™×£", "×œ×©× ×•×ª ×ª×•×¨"]
    if any(kw in msg_lower for kw in reschedule_keywords):
        return "reschedule"
    
    # Cancel intent
    cancel_keywords = ["×œ×‘×˜×œ", "×ª×‘×˜×œ", "×œ× ××’×™×¢", "×œ× ×™×›×•×œ", "×‘×™×˜×•×œ"]
    if any(kw in msg_lower for kw in cancel_keywords):
        return "cancel"
    
    # Booking intent - REQUIRES explicit scheduling action + time/day
    # Strong booking signals (explicit intent)
    strong_booking = ["×œ×§×‘×•×¢", "×ª×•×¨", "×¤×’×™×©×”", "×ª×™××•×", "×‘×“×•×§ ×œ×™", 
                      "×–××™×Ÿ", "×¤× ×•×™", "×™×© ××§×•×", "×œ×”×–××™×Ÿ", "×¨×•×¦×” ×œ×§×‘×•×¢"]
    
    # Time expressions (need these WITH day words)
    import re
    has_time = bool(re.search(r'\d{1,2}(:\d{2})?|\b×‘-\d|\b×‘×©×¢×”', msg_lower))
    
    # Day words (only booking if combined with time or strong intent)
    day_words = ["××—×¨", "×”×™×•×", "×¨××©×•×Ÿ", "×©× ×™", "×©×œ×™×©×™", "×¨×‘×™×¢×™", "×—××™×©×™", "×©×‘×ª", "××•×¦×´×©"]
    has_day = any(day in msg_lower for day in day_words)
    
    # Classify as booking ONLY if:
    # 1. Strong booking keyword, OR
    # 2. Day word + time expression together
    if any(kw in msg_lower for kw in strong_booking):
        return "book"
    if has_day and has_time:
        return "book"
    
    return "other"

# Global AI service instance for cache sharing
_global_ai_service = None

def get_ai_service():
    """Get or create global AI service instance"""
    global _global_ai_service
    if _global_ai_service is None:
        _global_ai_service = AIService()
        # âš¡ CRITICAL: Warmup cache at startup
        _warmup_ai_cache(_global_ai_service)
    return _global_ai_service

def _warmup_ai_cache(service: 'AIService'):
    """âš¡ Preload cache for common business IDs to prevent first-turn latency"""
    try:
        import time
        start = time.time()
        
        # Warmup business 1 and 11 (most common)
        for business_id in [1, 11]:
            for channel in ['calls', 'whatsapp']:
                try:
                    service.get_business_prompt(business_id, channel)
                    logger.info(f"âœ… WARMUP: Preloaded business {business_id} {channel}")
                except Exception as e:
                    logger.warning(f"âš ï¸ WARMUP failed for business {business_id} {channel}: {e}")
        
        warmup_time = time.time() - start
        logger.info(f"âœ… AI_CACHE_WARMUP: Completed in {warmup_time:.3f}s")
    except Exception as e:
        logger.error(f"âŒ AI cache warmup failed: {e}")

def invalidate_business_cache(business_id: int):
    """ğŸ”¥ CRITICAL: Invalidate cache for business - called after prompt updates"""
    service = get_ai_service()
    cache_keys_to_remove = [
        f"business_{business_id}_calls",
        f"business_{business_id}_whatsapp"
    ]
    for key in cache_keys_to_remove:
        if key in service._cache:
            del service._cache[key]
            logger.info(f"âœ… Cache invalidated: {key}")

class AIService:
    """×× ×’× ×•×Ÿ AI ××¨×›×–×™ ×©×˜×•×¢×Ÿ ×¤×¨×•××¤×˜×™× ××”××¡×“ × ×ª×•× ×™× ×•××—×‘×¨ ×¢× OpenAI"""
    
    def __init__(self):
        # âš¡ RELIABLE OpenAI client with production timeout
        self.client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            timeout=2.5  # ğŸ”¥ REDUCED: 2.5s timeout for faster real-time conversations (was 3.5s)
        )
        self._cache = {}  # ×§××© ×¤×¨×•××¤×˜×™× ×œ×‘×™×¦×•×¢×™×
        self._cache_timeout = 300  # âš¡ 5 ×“×§×•×ª - ××¡×¤×™×§ ××¨×•×š ×œ×©×™×—×” ×©×œ××”
        
    def get_business_prompt(self, business_id: int, channel: str = "calls") -> Dict[str, Any]:
        """×˜×¢×™× ×ª ×¤×¨×•××¤×˜ ×¢×¡×§ ××”××¡×“ × ×ª×•× ×™× ×¢× ×§××© - ×œ×¤×™ ×¢×¨×•×¥ (calls/whatsapp)"""
        cache_key = f"business_{business_id}_{channel}"
        now = datetime.now().timestamp()
        
        # ×‘×“×™×§×ª ×§××©
        if cache_key in self._cache:
            cached_data, timestamp = self._cache[cache_key]
            if now - timestamp < self._cache_timeout:
                logger.info(f"âœ… CACHE_HIT: business {business_id} {channel}")
                return cached_data
        
        try:
            # âš¡ CRITICAL: Measure DB query time
            import time
            db_start = time.time()
            
            # ×˜×¢×™× ×ª ×”×’×“×¨×•×ª ×¢×¡×§
            settings = BusinessSettings.query.filter_by(tenant_id=business_id).first()
            business = Business.query.get(business_id)
            
            db_time = time.time() - db_start
            logger.info(f"ğŸ“Š DB_QUERY: {db_time:.3f}s for business {business_id}")
            
            # âœ… ×©× ×¢×¡×§ ×œ×©×™××•×© ×‘-placeholders
            business_name = business.name if business else "×”×¢×¡×§ ×©×œ× ×•"
            
            # ×‘×—×™×¨×ª ×¤×¨×•××¤×˜ ×—×›××” - ×¢× fallback ×œ-business.system_prompt
            system_prompt = ""
            if settings and settings.ai_prompt and settings.ai_prompt.strip():
                # ×™×© ×¤×¨×•××¤×˜ ×‘-settings - ×ª××™×“ ×ª×©×ª××© ×‘×•! (×œ×œ× ×‘×“×™×§×ª ××•×¨×š)
                import json
                try:
                    # × ×¡×™×•×Ÿ ×œ×¤×¨×•×¡ ×›-JSON (×¤×•×¨××˜ ×—×“×© ×¢× calls/whatsapp)
                    if settings.ai_prompt.strip().startswith('{'):
                        prompt_obj = json.loads(settings.ai_prompt)
                        # ×‘×—×™×¨×ª ×”×¤×¨×•××¤×˜ ×”× ×›×•×Ÿ ×œ×¤×™ channel
                        system_prompt = prompt_obj.get(channel, prompt_obj.get('calls', settings.ai_prompt))
                        logger.info(f"âœ… Using {channel} prompt for business {business_id} from settings")
                        logger.info(f"ğŸ” DEBUG: Loaded prompt starts with: {system_prompt[:100]}...")
                    else:
                        # ×¤×¨×•××¤×˜ ×˜×§×¡×˜ ×¤×©×•×˜ (legacy)
                        system_prompt = settings.ai_prompt
                        logger.info(f"âœ… Using legacy text prompt for business {business_id}")
                except json.JSONDecodeError:
                    # ×× ×–×” ×œ× JSON ×ª×§×™×Ÿ, ×”×©×ª××© ×‘×–×” ×›×˜×§×¡×˜
                    system_prompt = settings.ai_prompt
                    logger.info(f"âœ… Using non-JSON prompt for business {business_id}")
            elif business and business.system_prompt and business.system_prompt.strip():
                # fallback ×œ×¤×¨×•××¤×˜ ×”××œ× ××˜×‘×œ×ª business
                system_prompt = business.system_prompt
                logger.info(f"âœ… Using fallback prompt from business.system_prompt for {business_id}")
            else:
                # fallback ××—×¨×•×Ÿ ×œ×¤×¨×•××¤×˜ ×‘×¨×™×¨×ª ××—×“×œ
                system_prompt = self._get_default_hebrew_prompt(business_name, channel)
                logger.info(f"âš ï¸ Using default prompt for business {business_id} - no custom prompt found")
            
            # âœ… ×”×—×œ×¤×ª placeholders ×“×™× ××™×™× ×‘×¤×¨×•××¤×˜
            system_prompt = system_prompt.replace("{{business_name}}", business_name)
            system_prompt = system_prompt.replace("{{BUSINESS_NAME}}", business_name)
            logger.info(f"âœ… Replaced {{{{business_name}}}} with '{business_name}'")
            
            # âš¡ BUILD 118: Warn if prompt is too long (causes OpenAI timeouts)
            if len(system_prompt) > 3000:
                logger.warning(f"âš ï¸ PROMPT_TOO_LONG: {len(system_prompt)} chars (recommended: <3000) - may cause OpenAI timeouts!")
            else:
                logger.info(f"âœ… Prompt length OK: {len(system_prompt)} chars")
            
            if not settings:
                # âš¡ BUILD 117: INCREASED - allow complete sentences without truncation
                prompt_data = {
                    "system_prompt": system_prompt,
                    "model": "gpt-4o-mini",  # Fast model
                    "max_tokens": 350,  # âš¡ BUILD 117: 350 tokens for COMPLETE sentences (no mid-sentence cuts!)
                    "temperature": 0.3  # Balanced temperature for natural responses
                }
            else:
                prompt_data = {
                    "system_prompt": system_prompt,
                    "model": settings.model,
                    "max_tokens": min(settings.max_tokens, 350),  # âš¡ BUILD 117: Cap at 350 for complete sentences
                    "temperature": min(settings.temperature, 0.4)  # Balanced temperature
                }
            
            # ×©××™×¨×” ×‘×§××©
            self._cache[cache_key] = (prompt_data, now)
            return prompt_data
            
        except Exception as e:
            logger.error(f"Error loading business prompt {business_id}: {e}")
            # âš¡ FAST fallback - ×˜×¢×™× ×ª ×©× ×¢×¡×§ ××”-DB
            try:
                business = Business.query.get(business_id)
                business_name = business.name if business else "×”×¢×¡×§ ×©×œ× ×•"
            except:
                business_name = "×”×¢×¡×§ ×©×œ× ×•"
            
            return {
                "system_prompt": self._get_default_hebrew_prompt(business_name, channel),
                "model": "gpt-4o-mini",
                "max_tokens": 350,  # âš¡ BUILD 117: 350 tokens for COMPLETE sentences
                "temperature": 0.3  # Balanced
            }
    
    def _get_default_hebrew_prompt(self, business_name: str = "×”×¢×¡×§ ×©×œ× ×•", channel: str = "calls") -> str:
        """×¤×¨×•××¤×˜ ×‘×¨×™×¨×ª ××—×“×œ ×‘×¢×‘×¨×™×ª ×œ× ×“×œ"×Ÿ - ××•×ª×× ×œ×¢×¨×•×¥ - âœ… ×‘×œ×™ ×©× hardcoded!"""
        if channel == "whatsapp":
            return f"""××ª×” ×”×¢×•×–×¨ ×”×“×™×’×™×˜×œ×™ ×©×œ {business_name} ×‘-WhatsApp.

×›×œ×œ×™× ×—×©×•×‘×™×:
- ×ª×¢× ×” ×‘×¢×‘×¨×™×ª, ×ª×©×•×‘×•×ª ×§×¦×¨×•×ª (×¢×“ 150 ××™×œ×™×)
- ×ª×”×™×” ×—× ×•×™×“×™×“×•×ª×™ ×‘×¡×’× ×•×Ÿ WhatsApp
- ×ª×‘×§×© ×¤×¨×˜×™×: ××–×•×¨, ×¡×•×’ × ×›×¡, ×ª×§×¦×™×‘
- ×›×©××ª×” ××–×›×™×¨ ××—×™×¨×™×/×ª×§×¦×™×‘ - ×ª××™×“ ×¦×™×™×Ÿ "××™×œ×™×•×Ÿ", "××œ×£", "××™×œ×™××¨×“" (×œ× ×¨×§ ××¡×¤×¨×™×!)
- ×ª×¦×™×¢ ×œ×§×‘×•×¢ ×¤×’×™×©×” ×›×©×™×© ××™×“×¢ ××¡×¤×™×§
- âš ï¸ ××œ ×ª×—×–×•×¨ ×¢×œ ×©××š ×‘×›×œ ××©×¤×˜! ×–×” ××¢×¦×‘×Ÿ ×•×œ× ×˜×‘×¢×™
- ×“×‘×¨ ×™×©×¨ ×œ×¢× ×™×™×Ÿ ×‘×œ×™ ×œ×”×¦×™×’ ××ª ×¢×¦××š ×›×œ ×¤×¢× ××—×“×©

**×›×©×œ×§×•×— ××¡×›×™× ×œ×–××Ÿ ×¤×’×™×©×”:**
ğŸ¯ **×—×–×•×¨ ×¢×œ ×”×–××Ÿ ×”××“×•×™×§ ×©×”×œ×§×•×— ×××¨!**
×“×•×’×××•×ª:
- ×œ×§×•×—: "××—×¨ ×‘-10" â†’ ××ª×”: "××¢×•×œ×”! × ×§×‘×¢ ×œ×š ×¤×’×™×©×” ×œ××—×¨ ×‘×©×¢×” 10:00."
- ×œ×§×•×—: "××—×¨ ×‘-15" â†’ ××ª×”: "××¢×•×œ×”! × ×§×‘×¢ ×œ×š ×¤×’×™×©×” ×œ××—×¨ ×‘×©×¢×” 15:00."
âš ï¸ **××œ ×ª×©× ×” ××ª ×”×©×¢×” - ×—×–×•×¨ ×¢×œ ××” ×©×”×œ×§×•×— ×××¨!**

×ª×¤×§×™×“×š: ×œ×¢×–×•×¨ ×œ××¦×•× × ×›×¡ ×•×œ×”×•×‘×™×œ ×œ×¤×’×™×©×”."""
        else:
            # âœ¨ Calls - ×¤×¨×•××¤×˜ ××¤×•×¨×˜ ×œ×©×™×—×•×ª ×–×•×¨××•×ª ×•×˜×‘×¢×™×•×ª
            return f"""××ª×” ×”×¢×•×–×¨ ×”×“×™×’×™×˜×œ×™ ×©×œ {business_name}. ××ª×” ×›××Ÿ ×›×“×™ ×œ×¢×–×•×¨ ×œ×œ×§×•×—×•×ª ×œ××¦×•× ××ª ×”× ×›×¡ ×”××•×©×œ× - ×“×™×¨×•×ª ×œ××›×™×¨×”, ×“×™×¨×•×ª ×œ×”×©×›×¨×”, ×‘×ª×™×, ×•××©×¨×“×™×.

×”×ª× ×”×œ×•×ª ×‘×©×™×—×”:
â€¢ ×“×‘×¨ ×‘×¢×‘×¨×™×ª ×‘×œ×‘×“, ×‘×¦×•×¨×” ×˜×‘×¢×™×ª ×•×–×•×¨××ª ×›××• ×©×™×—×” ×¨×’×™×œ×” ×‘×˜×œ×¤×•×Ÿ
â€¢ ×”×™×” ×—×, ×™×“×™×“×•×ª×™, ××‘×œ ××§×¦×•×¢×™ - ×›××• ×¡×•×›×Ÿ × ×“×œ"×Ÿ ×× ×•×¡×”
â€¢ ×ª×©×•×‘×•×ª ×§×¦×¨×•×ª - 2-3 ××©×¤×˜×™× ×‘×›×œ ×ª×’×•×‘×” (×¢×“ 200 ××™×œ×™×)
â€¢ ×“×‘×¨ ×™×©×™×¨×•×ª ×œ×¢× ×™×™×Ÿ, ×‘×œ×™ ××™×œ×•×™ ××• ×¡×™×¤×•×¨×™× ××¨×•×›×™×
â€¢ âš ï¸ ×—×©×•×‘ ×××•×“: ××œ ×ª×—×–×•×¨ ×¢×œ ×©××š ×‘×›×œ ××©×¤×˜! ×–×” ×œ× ×˜×‘×¢×™ ×•××¢×¦×‘×Ÿ
â€¢ ×”×¦×’ ××ª ×¢×¦××š ×¨×§ ×‘×‘×¨×›×” ×”×¨××©×•× ×”, ××—×¨ ×›×š ×“×‘×¨ ×™×©×¨ ×œ×¢× ×™×™×Ÿ

××™×¡×•×£ ××™×“×¢ ×—×›×:
×©××œ ×©××œ×” ××—×ª ×‘×›×œ ×¤×¢×, ×‘×¡×“×¨ ×”×–×”:
1. ×ª×—×™×œ×”: ××” ×”×œ×§×•×— ××—×¤×©? (×“×™×¨×”/×‘×™×ª/××©×¨×“, ××›×™×¨×”/×”×©×›×¨×”)
2. ××–×•×¨ ××‘×•×§×© ××• ×¢×™×¨ (×—×©×•×‘ ×××•×“!)
3. ×ª×§×¦×™×‘ ××• ×˜×•×•×— ××—×™×¨×™× - âš ï¸ ×—×©×•×‘: ×ª××™×“ ×”×–×›×¨ ××ª ×¡×“×¨ ×”×’×•×“×œ! ×××•×¨ "××™×œ×™×•×Ÿ ×©×§×œ", "×××” ××œ×£ ×©×§×œ", "×—×¦×™ ××™×œ×™×•×Ÿ" ×•×›×•'. ×œ×¢×•×œ× ××œ ×ª×’×™×“ ×¨×§ ××ª ×”××¡×¤×¨ (×œ××©×œ "1000000") ×‘×œ×™ ×œ×”×–×›×™×¨ ×× ×–×” ××œ×£/××™×œ×™×•×Ÿ/××™×œ×™××¨×“!
4. ××¡×¤×¨ ×—×“×¨×™× / ×’×•×“×œ
5. ×¤×¨×˜×™ ×§×©×¨: ×©× ××œ× ×•××™×™×œ ×× ×œ× × ×™×ª× ×•

××ª×™ ×œ×§×‘×•×¢ ×¤×’×™×©×”:
×›×©×™×© ×œ×š ×œ×¤×—×•×ª: ×¡×•×’ × ×›×¡ + ××–×•×¨ + ×ª×§×¦×™×‘ â†’ ×”×¦×¢ ×œ×§×‘×•×¢ ×¤×’×™×©×” ×¢× ×”×¡×•×›×Ÿ. ×ª×’×™×“: "××¢×•×œ×”! ×™×© ×œ×™ ×›××” ××¤×©×¨×•×™×•×ª ××¦×•×™× ×•×ª. ××©××— ×œ×§×‘×•×¢ ×œ×š ×¤×’×™×©×” ×¢× ××—×“ ×”×¡×•×›× ×™× ×©×œ× ×• ×©×™×¦×™×’ ×œ×š ××ª ×”× ×›×¡×™×. ××ª×™ × ×•×— ×œ×š?"

âš ï¸ **×—×©×•×‘ ×××•×“ - ×›×©×”×œ×§×•×— ××¡×›×™× ×œ×–××Ÿ:**
ğŸ¯ **×—×•×§ ×‘×¨×–×œ: ×—×–×•×¨ ×¢×œ ×”×–××Ÿ ×”××“×•×™×§ ×©×”×œ×§×•×— ×××¨ - ×œ× ×œ×”××¦×™× ×©×¢×•×ª!**

×›×©×”×œ×§×•×— ××•××¨ ×–××Ÿ ×¡×¤×¦×™×¤×™:
- ×œ×§×•×—: "××—×¨ ×‘-10" â†’ ××ª×”: "××¢×•×œ×”! × ×§×‘×¢ ×œ×š ×¤×’×™×©×” ×œ××—×¨ ×‘×©×¢×” 10:00."
- ×œ×§×•×—: "××—×¨ ×‘-16" â†’ ××ª×”: "××¢×•×œ×”! × ×§×‘×¢ ×œ×š ×¤×’×™×©×” ×œ××—×¨ ×‘×©×¢×” 16:00."
- ×œ×§×•×—: "×™×•× ×©×œ×™×©×™ ×‘-14:30" â†’ ××ª×”: "××¢×•×œ×”! × ×§×‘×¢ ×œ×š ×¤×’×™×©×” ×œ×™×•× ×©×œ×™×©×™ ×‘×©×¢×” 14:30."

×›×©×”×œ×§×•×— ××•××¨ ×–××Ÿ ×›×œ×œ×™ (×‘×•×§×¨/×¦×”×¨×™×™×/××—×”"×¦):
- ×œ×§×•×—: "××—×¨ ×‘×‘×•×§×¨" â†’ ××ª×”: "××¢×•×œ×”! × ×§×‘×¢ ×œ×š ×¤×’×™×©×” ×œ××—×¨ ×‘×©×¢×” 10:00."
- ×œ×§×•×—: "×™×•× ×©×œ×™×©×™ ××—×¨ ×”×¦×”×¨×™×™×" â†’ ××ª×”: "××¢×•×œ×”! × ×§×‘×¢ ×œ×š ×¤×’×™×©×” ×œ×™×•× ×©×œ×™×©×™ ×‘×©×¢×” 14:00."

âš ï¸ **××œ ×ª×©× ×” ××ª ×”×©×¢×” ×©×”×œ×§×•×— ×××¨! ×× ×”×•× ×××¨ 16 - ×ª××©×¨ 16, ×œ× 10!**

×—×©×•×‘: ××œ ×ª××¦×™× ××™×“×¢! ×× ×œ× ×™×•×“×¢ ××©×”×• - ×”×¤× ×” ×œ×¡×•×›×Ÿ ×× ×•×©×™. ×× ×”×œ×§×•×— ×¢×¦×‘× ×™ ××• ××ª×œ×•× ×Ÿ - ×”×™×” ×××¤×˜×™ ×•×”×¦×¢ ×“×™×‘×•×¨ ×¢× ×× ×”×œ."""

    def generate_response(self, message: str, business_id: int = 1, context: Optional[Dict[str, Any]] = None, channel: str = "calls", is_first_turn: bool = False) -> str:
        """×™×¦×™×¨×ª ×ª×’×•×‘×” ××¤×¨×•××¤×˜ ×“×™× ××™ + ×”×§×©×¨ - ×œ×¤×™ ×¢×¨×•×¥ (calls/whatsapp)"""
        try:
            # ×˜×¢×™× ×ª ×¤×¨×•××¤×˜ ×¢×¡×§ ×œ×¤×™ ×¢×¨×•×¥
            prompt_data = self.get_business_prompt(business_id, channel)
            
            # âš¡ BUILD 117: First turn - NO SPECIAL LIMIT! Let AI finish complete sentences
            # User requirement: "×× ×”×™× ×¦×¨×™×›×” ×œ×”×¡×‘×™×¨ ×“×§×” ×©×ª×¡×‘×™×¨ ×“×§×”" - let it speak as long as needed
            if is_first_turn:
                # Don't reduce max_tokens for first turn - keep the default 350 for complete sentences
                logger.info(f"ğŸ¯ First turn - using full {prompt_data['max_tokens']} tokens for complete sentences")
            
            # ×‘× ×™×™×ª ×”×•×“×¢×•×ª
            messages: List[Dict[str, str]] = [
                {"role": "system", "content": prompt_data["system_prompt"]}
            ]
            
            # âœ… ×”×•×¡×¤×ª ×–××™× ×•×ª ×œ×•×— ×©× ×” (×¨×§ ×œ-WhatsApp - ×œ× ×œ×˜×œ×¤×•×Ÿ ×‘×’×œ×œ latency!)
            if channel == "whatsapp":
                calendar_info = self._get_calendar_availability(business_id)
                if calendar_info:
                    messages.append({
                        "role": "system",
                        "content": f"ğŸ“… ×œ×•×— ×©× ×”:\n{calendar_info}\n×›×©×”×œ×§×•×— ××•×›×Ÿ ×œ×¤×’×™×©×”, ×”×¦×¢ ×ª××¨×™×›×™× ×¤× ×•×™×™× ××”×¨×©×™××” ×œ××¢×œ×”."
                    })
            
            # ×”×•×¡×¤×ª ×”×§×©×¨ ×× ×§×™×™×
            if context:
                # ×”×•×¡×¤×ª ××™×“×¢ ×‘×¡×™×¡×™ ×¢×œ ×”×œ×§×•×—
                context_info = []
                if context.get("customer_name"):
                    context_info.append(f"×©× ×”×œ×§×•×—: {context['customer_name']}")
                if context.get("phone_number"):
                    context_info.append(f"×˜×œ×¤×•×Ÿ: {context['phone_number']}")
                
                if context_info:
                    messages.append({
                        "role": "system", 
                        "content": "××™×“×¢ ×¢×œ ×”×œ×§×•×—:\n" + "\n".join(context_info)
                    })
                
                # âœ… BUILD 92: ×©×œ×™×—×ª previous_messages ×›×©×™×—×” ×××™×ª×™×ª - 10 ×”×•×“×¢×•×ª ×œ×–×™×›×¨×•×Ÿ ××œ×!
                if context.get("previous_messages"):
                    prev_msgs = context["previous_messages"][-10:]  # âœ… 10 ×”×•×“×¢×•×ª ××—×¨×•× ×•×ª (×œ× 6!)
                    for msg in prev_msgs:
                        # âœ… ×”××‘× ×” ×”×•× "×œ×§×•×—: ..." ××• "×¢×•×–×¨×ª: ..." (××• "×œ××”:" legacy)
                        if msg.startswith("×œ×§×•×—:"):
                            messages.append({
                                "role": "user",
                                "content": msg.replace("×œ×§×•×—:", "").strip()
                            })
                        elif msg.startswith("×¢×•×–×¨×ª:") or msg.startswith("×œ××”:"):  # âœ… ×ª××™×›×” ×‘×©× ×™×”×!
                            content = msg.replace("×¢×•×–×¨×ª:", "").replace("×œ××”:", "").strip()
                            messages.append({
                                "role": "assistant",
                                "content": content
                            })
            
            # ×”×•×¡×¤×ª ×”×•×“×¢×ª ×”××©×ª××© ×”× ×•×›×—×™×ª
            messages.append({"role": "user", "content": message})
            
            # âš¡ CRITICAL: Measure OpenAI call time
            import time
            openai_start = time.time()
            
            # âš¡ BUILD 118: Add explicit timeout to prevent long waits
            try:
                response = self.client.chat.completions.create(
                    model=prompt_data["model"],
                    messages=messages,  # type: ignore
                    max_tokens=prompt_data["max_tokens"],
                    temperature=prompt_data["temperature"],
                    timeout=2.5  # ğŸ”¥ REDUCED: 2.5s timeout for real-time conversations (was 3.5s)
                )
                
                openai_time = time.time() - openai_start
                logger.info(f"âœ… OPENAI_SUCCESS: {openai_time:.3f}s")
                
                ai_response = response.choices[0].message.content
                if ai_response:
                    ai_response = ai_response.strip()
                else:
                    ai_response = "××¦×˜×¢×¨, ×œ× ×”×¦×œ×—×ª×™ ×œ×™×™×¦×¨ ×ª×’×•×‘×” ×›×¨×’×¢."
                logger.info(f"AI response generated for business {business_id}: {len(ai_response)} chars")
                return ai_response
                
            except Exception as openai_error:
                openai_time = time.time() - openai_start
                error_type = type(openai_error).__name__
                logger.error(f"ğŸ”´ OPENAI_FAILED: {error_type} after {openai_time:.3f}s: {str(openai_error)[:200]}")
                raise  # Re-raise to outer exception handler
            
        except Exception as e:
            logger.error(f"ğŸ”´ AI_GENERATION_FAILED: {type(e).__name__}: {str(e)[:200]}")
            return self._get_fallback_response(message)
    
    def _get_fallback_response(self, message: str) -> str:
        """×ª×’×•×‘×ª ×—×™×¨×•× ×× ×”-AI × ×›×©×œ"""
        message_lower = message.lower().strip()
        
        if any(word in message_lower for word in ["×©×œ×•×", "×”×™×™", "×”×œ×•"]):
            return "×©×œ×•×! ××™×š ××•×›×œ ×œ×¢×–×•×¨ ×œ×š?"  # âœ… ×›×œ×œ×™ - ×œ× ×—×•×©×£ ×©× ×¢×¡×§ ×©×’×•×™
        elif any(word in message_lower for word in ["×“×™×¨×”", "×‘×™×ª", "× ×›×¡"]):
            return "××©××— ×œ×¢×–×•×¨ ×œ×š! ××ª×” ××—×¤×© ×œ×§× ×™×” ××• ×”×©×›×¨×”? ×‘××™×–×” ××–×•×¨?"
        else:
            return "×ª×•×“×” ×¢×œ ×”×¤× ×™×™×”! ××—×–×•×¨ ××œ×™×š ×‘×”×§×“× ×¢× ××¢× ×” ××¤×•×¨×˜."
    
    def _get_calendar_availability(self, business_id: int) -> str:
        """×‘×“×™×§×ª ×–××™× ×•×ª ×‘×œ×•×— ×”×©× ×” ×œ-7 ×™××™× ×”×§×¨×•×‘×™×"""
        try:
            from server.models_sql import Appointment
            from datetime import datetime, timedelta
            
            # âš¡ FAST: Limit query time with LIMIT
            # ×˜×•×•×— ×ª××¨×™×›×™×: ×”×™×•× + 7 ×™××™×
            today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
            week_end = today + timedelta(days=7)
            
            # ×©×œ×™×¤×ª ×¤×’×™×©×•×ª ×§×™×™××•×ª (LIMIT 10 ×œ××”×™×¨×•×ª!)
            appointments = Appointment.query.filter(
                Appointment.business_id == business_id,
                Appointment.start_time >= today,
                Appointment.start_time < week_end,
                Appointment.status.in_(['confirmed', 'pending'])
            ).order_by(Appointment.start_time).limit(10).all()
            
            # ×”×¦×¢×ª ×–×× ×™× ×¤× ×•×™×™× (9:00-17:00, ×›×œ ×™×•×, ×œ××¢×˜ ×©×‘×ª)
            available_slots = []
            for i in range(7):
                day = today + timedelta(days=i)
                # ×“×œ×’ ×¢×œ ×©×‘×ª (5 = ×©×‘×ª)
                if day.weekday() == 5:
                    continue
                    
                day_name = day.strftime("%A")
                day_name_he = {"Monday": "×©× ×™", "Tuesday": "×©×œ×™×©×™", "Wednesday": "×¨×‘×™×¢×™", 
                              "Thursday": "×—××™×©×™", "Friday": "×©×™×©×™", "Sunday": "×¨××©×•×Ÿ"}.get(day_name, day_name)
                
                # ×‘×“×•×§ ×× ×™×© ×¤×’×™×©×•×ª ×‘×™×•× ×”×–×”
                day_start = day.replace(hour=9, minute=0)
                day_end = day.replace(hour=17, minute=0)
                
                day_appointments = [apt for apt in appointments if day_start <= apt.start_time < day_end]
                
                if len(day_appointments) < 4:  # ×× ×¤×—×•×ª ×-4 ×¤×’×™×©×•×ª - ×¢×“×™×™×Ÿ ×™×© ××§×•×
                    date_str = day.strftime("%d/%m")
                    available_slots.append(f"×™×•× {day_name_he} {date_str} (×‘×•×§×¨/××—×”\"×¦)")
            
            # ×‘× ×™×™×ª ×˜×§×¡×˜
            result = []
            if available_slots:
                result.append("âœ… ×–××™× ×•×ª ×”×©×‘×•×¢:")
                result.extend([f"  â€¢ {slot}" for slot in available_slots[:5]])  # ×¨×§ 5 ×¨××©×•× ×™×
            else:
                result.append("âš ï¸ ××™×Ÿ ×–××™× ×•×ª ×”×©×‘×•×¢ - ×”×¦×¢ ×©×‘×•×¢ ×”×‘×")
            
            return "\n".join(result)
            
        except Exception as e:
            logger.error(f"Calendar check failed: {e}")
            return "ğŸ“… ×œ×•×— ×”×©× ×”: × × ×œ×ª×× ×™×©×™×¨×•×ª ×¢× ×”×¡×•×›×Ÿ"
    
    def invalidate_cache(self, business_id: int):
        """××—×™×§×ª ×§××© ×¢×¡×§ ××¡×•×™× (×œ××—×¨ ×¢×“×›×•×Ÿ ×¤×¨×•××¤×˜)"""
        cache_key = f"business_{business_id}"
        if cache_key in self._cache:
            del self._cache[cache_key]
            logger.info(f"Cache invalidated for business {business_id}")
    
    def save_conversation_history(self, business_id: int, phone_number: str, 
                                 message: str, response: str, channel: str = "whatsapp"):
        """×©××™×¨×ª ×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×” ×œ××™×“×¢ ×¢×ª×™×“×™ (××•×¤×¦×™×•× ×œ×™)"""
        try:
            # ×›××Ÿ ××¤×©×¨ ×œ×”×•×¡×™×£ ×œ×•×’×™×§×” ×œ×©××™×¨×ª ×©×™×—×•×ª ××¨×•×›×•×ª
            # ×œ×¦×¨×›×™ ×”×§×©×¨ ×¢×ª×™×“×™ ××• ×× ×œ×™×˜×™×§×”
            pass
        except Exception as e:
            logger.error(f"Failed to save conversation history: {e}")
    
    def _generate_faq_response(self, message: str, business_id: int, channel: str) -> str:
        """
        âš¡ FAST FAQ response without AgentKit (info/other intents)
        Uses lightweight GPT-4o-mini with business prompt, no tools
        ~0.8s latency
        """
        try:
            # Get business prompt for context
            prompt_data = self.get_business_prompt(business_id, channel)
            business_prompt = prompt_data.get("system_prompt", "")
            business_name = prompt_data.get("business_name", "×”×¢×¡×§")
            
            # Build minimal system prompt
            system_msg = f"You are answering questions about {business_name}. Keep responses SHORT (1-2 sentences in Hebrew).\n\n{business_prompt[:500]}"
            
            # Quick OpenAI call - no tools, minimal tokens
            client = self.get_client()
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_msg},
                    {"role": "user", "content": message}
                ],
                max_tokens=50,  # Very short responses
                temperature=0.3
            )
            
            answer = response.choices[0].message.content.strip()
            print(f"âš¡ FAQ_RESPONSE: {answer} ({len(answer)} chars)")
            return answer
            
        except Exception as e:
            logger.error(f"FAQ response failed: {e}")
            return "×¡×œ×™×—×”, ×™×© ×œ×™ ×‘×¢×™×” ×˜×›× ×™×ª. ××¤×©×¨ ×œ× ×¡×•×ª ×©×•×‘?"
    
    def _handle_direct_booking(self, message: str, business_id: int, customer_phone: Optional[str] = None) -> Optional[str]:
        """
        âš¡ FAST-PATH: Direct booking for simple requests (e.g., "××—×¨ ×‘-2")
        Bypasses AgentKit entirely - parses time with regex + calls calendar tools directly
        ~1.5s latency
        
        Returns:
            Hebrew confirmation string if successful, None if parsing failed (fallback to AgentKit)
        """
        import re
        from datetime import datetime, timedelta
        import pytz
        
        try:
            # Parse hour from message
            hour_match = re.search(r"(\d{1,2})(?::(\d{2}))?", message)
            if not hour_match:
                print("âš ï¸ FAST-PATH: No hour found, fallback to AgentKit")
                return None
            
            hour = int(hour_match.group(1))
            minute = int(hour_match.group(2) or 0)
            
            # Afternoon default for numbers 1-8
            if hour <= 8:
                hour += 12
            
            # Parse day
            tz = pytz.timezone("Asia/Jerusalem")
            target = datetime.now(tz)
            
            msg_lower = message.lower()
            if "××—×¨" in msg_lower:
                target += timedelta(days=1)
            elif "×¨××©×•×Ÿ" in msg_lower:
                target += timedelta(days=(6 - target.weekday()) % 7)
            elif "×©× ×™" in msg_lower:
                target += timedelta(days=(7 - target.weekday()) % 7)
            # Add more day parsing as needed...
            
            target = target.replace(hour=hour, minute=minute, second=0, microsecond=0)
            date_iso = target.strftime("%Y-%m-%d")
            time_iso = target.strftime("%H:%M")
            
            print(f"âš¡ FAST-PATH: Parsed time â†’ {date_iso} {time_iso}")
            
            # Import calendar tools
            from server.agent_tools.tools_calendar import calendar_find_slots_impl, calendar_create_appointment_impl
            from flask import g
            
            # Build minimal context
            context = {
                "business_id": business_id,
                "customer_phone": customer_phone,
                "channel": "calls"
            }
            
            # Check availability
            slots_result = calendar_find_slots_impl(date_iso=date_iso, duration_min=60, context=context)
            
            if not slots_result.get("ok") or not slots_result.get("slots"):
                print(f"âš ï¸ FAST-PATH: No slots available for {date_iso} {time_iso}")
                return f"××¦×˜×¢×¨, ××™×Ÿ ×–××™× ×•×ª ×‘-{time_iso}. ×¨×•×¦×” ×©××‘×“×•×§ ×©×¢×” ××—×¨×ª?"
            
            # Verify requested time is in available slots
            requested_datetime = target.strftime("%Y-%m-%d %H:%M")
            available_slots = [s["start"] for s in slots_result["slots"]]
            
            if requested_datetime not in available_slots:
                # Offer first 2 alternatives
                alternatives = available_slots[:2]
                alt_times = [s.split()[1] for s in alternatives]
                return f"××™×Ÿ ×–××™× ×•×ª ×‘-{time_iso}. ×™×© {' ××• '.join(alt_times)}?"
            
            # Need phone before booking
            if not customer_phone:
                print(f"âš ï¸ FAST-PATH: Need phone number for booking")
                return None  # Fallback to AgentKit to collect phone
            
            # Create appointment
            # Note: This is simplified - full implementation would need customer_name too
            print(f"âš¡ FAST-PATH: Attempting booking for {requested_datetime}")
            # For now, fallback to AgentKit for actual booking (needs name + phone collection)
            return None
            
        except Exception as e:
            logger.error(f"Fast-path booking failed: {e}")
            print(f"âš ï¸ FAST-PATH ERROR: {e}, fallback to AgentKit")
            return None  # Fallback to full AgentKit on any error
    
    def generate_response_with_agent(self, message: str, business_id: int = 1, 
                                     context: Optional[Dict[str, Any]] = None,
                                     channel: str = "calls",
                                     is_first_turn: bool = False,
                                     customer_phone: Optional[str] = None,
                                     customer_name: Optional[str] = None) -> str:
        """
        âœ¨ BUILD 119: Agent-enhanced response generation WITH SMART ROUTING
        
        Routes based on intent:
        - FAQ/Info â†’ Lightweight GPT-4o-mini (~0.8s)
        - Simple booking â†’ Fast-path with direct calendar calls (~1.5s)
        - Complex booking â†’ Full AgentKit (~2-3s)
        
        Args:
            message: Customer's message
            business_id: Business ID
            context: Conversation context
            channel: calls/whatsapp
            is_first_turn: First message in conversation
            customer_phone: Customer phone for lead creation
            customer_name: Customer name for personalization
            
        Returns:
            AI response (potentially enhanced with tool actions)
        """
        # Check if agents are enabled (default: enabled)
        agents_enabled = os.getenv("AGENTS_ENABLED", "1") == "1"
        print(f"ğŸ¯ AGENTS_ENABLED = {agents_enabled}")
        logger.info(f"ğŸ¯ AGENTS_ENABLED = {agents_enabled}")
        
        if not agents_enabled:
            # Fallback to regular response
            print("âš ï¸ Agents disabled - using regular response")
            logger.warning("âš ï¸ Agents disabled - using regular response")
            return self.generate_response(message, business_id, context, channel, is_first_turn)
        
        # ğŸš€ AGENTKIT GATE - Detect intent and route accordingly
        agentkit_booking_only = os.getenv("AGENTKIT_BOOKING_ONLY", "1") == "1"
        fast_path_enabled = os.getenv("FAST_PATH_ENABLED", "1") == "1"
        
        intent = route_intent(message)
        print(f"ğŸ¯ INTENT_DETECTED: {intent} (booking_only={agentkit_booking_only}, fast_path={fast_path_enabled})")
        logger.info(f"ğŸ¯ Intent: {intent}, Message: '{message[:50]}...'")
        
        # Route 1: FAQ/Info Path - NO AgentKit needed (~0.8s)
        if agentkit_booking_only and intent in ['info', 'other', 'whatsapp', 'human']:
            print(f"âš¡ ROUTE: FAQ path for '{intent}' intent")
            return self._generate_faq_response(message, business_id, channel)
        
        # Route 2: Fast-Path for simple booking (~1.5s)
        if fast_path_enabled and intent == 'book':
            print(f"âš¡ ROUTE: Attempting fast-path for booking...")
            fast_result = self._handle_direct_booking(message, business_id, customer_phone)
            if fast_result:
                print(f"âœ… FAST-PATH SUCCESS: {fast_result}")
                return fast_result
            else:
                print(f"âš ï¸ FAST-PATH FAILED: Fallback to AgentKit")
        
        # Route 3: Full AgentKit for complex booking/reschedule/cancel (~2-3s)
        print(f"ğŸ¤– ROUTE: Full AgentKit for '{intent}' intent")
        
        # âš¡ Capture start time BEFORE try block for error logging
        start_time = time.time()
        
        try:
            # ğŸ”¥ FIX: Modules now imported at top of file - no re-import needed!
            if not AGENT_MODULES_LOADED:
                # Double-check - agents not available
                print("âš ï¸ AGENTS_ENABLED=False in module - using regular response")
                logger.warning("âš ï¸ AGENTS_ENABLED=False in module - using regular response")
                return self.generate_response(message, business_id, context, channel, is_first_turn)
            
            # Get business name
            db_start = time.time()
            business = Business.query.get(business_id)
            business_name = business.name if business else "×”×¢×¡×§ ×©×œ× ×•"
            
            # ğŸ¯ BUILD 119: Load custom prompt from database!
            prompt_data = self.get_business_prompt(business_id, channel)
            custom_prompt = prompt_data.get("system_prompt", "")  # Extract just the prompt text
            db_time = (time.time() - db_start) * 1000
            print(f"â±ï¸ DB query time: {db_time:.0f}ms")
            logger.info(f"ğŸ“‹ Loaded prompt for business {business_id}: {len(custom_prompt)} chars")
            
            # ğŸ”¥ NEW: Try to get cached agent first!
            from server.services.agent_cache import get_agent_cache
            agent_cache = get_agent_cache()
            
            agent_create_start = time.time()
            agent = agent_cache.get(business_id, channel)
            
            if agent:
                # Cache HIT - reuse existing agent!
                agent_create_time = (time.time() - agent_create_start) * 1000
                print(f"â™»ï¸  REUSING cached agent: business={business_name}, business_id={business_id}, channel={channel}")
                print(f"â±ï¸ Cache lookup time: {agent_create_time:.0f}ms")
                logger.info(f"â™»ï¸  Agent CACHE HIT for {business_name} ({channel})")
            else:
                # Cache MISS - create new agent and cache it
                print(f"ğŸ—ï¸  Creating NEW agent: type=booking, business={business_name}, business_id={business_id}, channel={channel}")
                logger.info(f"ğŸ—ï¸  Creating agent: type=booking, business={business_name}, business_id={business_id}, channel={channel}")
                agent = get_agent(agent_type="booking", business_name=business_name, custom_instructions=custom_prompt, business_id=business_id, channel=channel)
                agent_create_time = (time.time() - agent_create_start) * 1000
                print(f"â±ï¸ Agent creation time: {agent_create_time:.0f}ms")
                
                # Cache the new agent for future reuse
                if agent:
                    agent_cache.set(business_id, channel, agent, business_name)
                    print(f"ğŸ’¾ Agent cached for future reuse")
            
            if not agent:
                print("âŒ Failed to create agent - falling back to regular response")
                logger.error("âŒ Failed to create agent - falling back to regular response")
                return self.generate_response(message, business_id, context, channel, is_first_turn)
            
            print(f"âœ… Agent created successfully: {agent.name}")
            logger.info(f"âœ… Agent created successfully: {agent.name}")
            
            # Build enhanced context for agent
            agent_context = {
                "business_id": business_id,
                "business_name": business_name,
                "customer_phone": customer_phone,
                "customer_name": customer_name,
                "channel": channel,
                "is_first_turn": is_first_turn,
                **(context or {})
            }
            
            # ğŸ”¥ CRITICAL: Store context in Flask g so tools can access it!
            from flask import g
            g.agent_context = agent_context
            print(f"âœ… Stored agent_context in Flask g: phone={customer_phone}, name={customer_name}")
            
            # Run agent using Runner (with proper async handling for eventlet threads)
            print(f"ğŸ¤– Running agent for business {business_id}, channel={channel}")
            print(f"   ğŸ“ User message: '{message[:100]}...'")
            print(f"   ğŸ“‹ Context: business_id={business_id}, phone={customer_phone}, name={customer_name}")
            logger.info(f"ğŸ¤– Running agent for business {business_id}, channel={channel}")
            logger.info(f"   ğŸ“ User message: '{message[:100]}...'")
            logger.info(f"   ğŸ“‹ Context: business_id={business_id}, phone={customer_phone}, name={customer_name}")
            
            import asyncio
            
            # Create new event loop for this thread (eventlet compatibility)
            try:
                loop = asyncio.get_event_loop()
            except RuntimeError:
                # No event loop in current thread - create one
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            
            # ğŸ”¥ BUILD CONVERSATION HISTORY for Agent SDK
            # âš¡ OPTIMIZATION: Keep last 8 messages - balances latency with booking context
            # (8 messages = 4 turns, enough for most booking flows while reducing tokens)
            history_start = time.time()
            conversation_messages = []
            if context and "previous_messages" in context:
                prev_msgs = context["previous_messages"][-8:]  # ğŸ”¥ 8 messages = 4 full turns
                print(f"ğŸ“š Found {len(context['previous_messages'])} messages, using last {len(prev_msgs)} for latency")
                
                # Convert to Agent SDK format
                # prev_msgs is list of strings like "×œ×§×•×—: XXX" or "×¢×•×–×¨: YYY"
                for msg in prev_msgs:
                    content = None
                    if msg.startswith("×œ×§×•×—:"):
                        content = msg.replace("×œ×§×•×—:", "").strip()[-250:]  # ğŸ”¥ Truncate long messages
                        conversation_messages.append({"role": "user", "content": content})
                    elif msg.startswith("×¢×•×–×¨:"):
                        content = msg.replace("×¢×•×–×¨:", "").strip()[-250:]  # ğŸ”¥ Truncate long messages
                        conversation_messages.append({"role": "assistant", "content": content})
                
                history_time = (time.time() - history_start) * 1000
                print(f"âœ… Converted to {len(conversation_messages)} messages for Agent ({history_time:.0f}ms)")
                
            # Add current message
            conversation_messages.append({
                "role": "user",
                "content": message
            })
            
            runner = Runner()
            print(f"ğŸ”„ Created Runner with {len(conversation_messages)-1} history messages, executing agent.run()...")
            logger.info(f"â±ï¸ PERFORMANCE: Starting Runner.run() at {time.time()}")
            
            # Use input parameter with conversation history
            result = loop.run_until_complete(
                runner.run(starting_agent=agent, input=conversation_messages, context=agent_context)
            )
            duration_ms = int((time.time() - start_time) * 1000)
            print(f"âœ… Runner.run() completed in {duration_ms}ms")
            logger.info(f"â±ï¸ PERFORMANCE: Runner.run() completed in {duration_ms}ms")
            
            # Extract response using final_output_as
            reply_text = result.final_output_as(str)
            print(f"ğŸ“ Agent final response: '{reply_text[:100] if reply_text else '(EMPTY!)'}...'")
            
            # âœ… CRITICAL: Validate that agent returned a response!
            if not reply_text or not reply_text.strip():
                print(f"âŒ CRITICAL: Agent returned EMPTY response! Falling back...")
                logger.error(f"âŒ Agent returned empty response for message: {message[:100]}")
                return self.generate_response(message, business_id, context, channel, is_first_turn)
            
            # DEBUG: Check result structure
            print(f"ğŸ” Result type: {type(result).__name__}")
            print(f"ğŸ” Has new_items: {hasattr(result, 'new_items')}")
            if hasattr(result, 'new_items'):
                print(f"ğŸ” new_items value: {result.new_items}")
                print(f"ğŸ” new_items length: {len(result.new_items) if result.new_items else 0}")
            
            # Extract tool calls from new_items
            tool_calls_data = []
            tool_count = 0
            booking_successful = False  # Track if booking actually succeeded
            
            if hasattr(result, 'new_items') and result.new_items:
                print(f"ğŸ“Š Agent returned {len(result.new_items)} items")
                logger.info(f"ğŸ“Š Agent returned {len(result.new_items)} items")
                # Filter for ToolCallItem types and extract tool names
                for idx, item in enumerate(result.new_items):
                    item_type = type(item).__name__
                    print(f"   - Item #{idx}: {item_type}")
                    logger.info(f"   - Item type: {item_type}")
                    
                    if item_type == 'ToolCallItem':
                        tool_count += 1
                        
                        # ğŸ” FULL DEBUG: Print ALL attributes to find tool name
                        print(f"  ğŸ” DEBUG ToolCallItem #{tool_count}:")
                        all_attrs = [a for a in dir(item) if not a.startswith('_')]
                        print(f"     All attributes: {all_attrs}")
                        
                        # Try to access common attributes
                        for attr in ['name', 'tool_name', 'tool_call', 'function', 'tool']:
                            if hasattr(item, attr):
                                val = getattr(item, attr)
                                print(f"     {attr} = {val}")
                        
                        # Try multiple ways to get tool name
                        tool_name = getattr(item, 'name', None)
                        if not tool_name:
                            tool_name = getattr(item, 'tool_name', None)
                        if not tool_name and hasattr(item, 'tool_call'):
                            tc = getattr(item, 'tool_call')
                            if isinstance(tc, dict):
                                tool_name = tc.get('name') or tc.get('function', {}).get('name')
                            elif hasattr(tc, 'name'):
                                tool_name = tc.name
                            elif hasattr(tc, 'function'):
                                tool_name = getattr(tc.function, 'name', None)
                        if not tool_name and hasattr(item, 'tool'):
                            tool_obj = getattr(item, 'tool')
                            tool_name = getattr(tool_obj, 'name', None)
                        if not tool_name:
                            tool_name = 'unknown'
                        
                        print(f"  ğŸ”§ Tool call #{tool_count}: {tool_name}")
                        logger.info(f"  âœ… Tool call #{tool_count}: {tool_name}")
                        tool_calls_data.append({
                            "tool": tool_name,
                            "status": "success",
                            "result": None  # Result is in separate ToolCallOutputItem
                        })
                    
                    elif item_type == 'ToolCallOutputItem':
                        # Extract tool output/result
                        output = getattr(item, 'output', None)
                        print(f"  ğŸ“¤ Tool output: {str(output)[:200] if output else 'None'}...")
                        if output:
                            logger.info(f"     Tool returned: {str(output)[:100]}")
                            
                            # ğŸ” CHECK if this is a successful booking
                            if isinstance(output, dict):
                                if output.get('ok') is True and output.get('appointment_id'):
                                    booking_successful = True
                                    print(f"     âœ… DETECTED SUCCESSFUL BOOKING: appointment_id={output.get('appointment_id')}")
                
                if tool_count > 0:
                    print(f"âœ… Agent executed {tool_count} tool actions")
                    logger.info(f"âœ… Agent executed {tool_count} tool actions")
                else:
                    print(f"âš ï¸ Agent DID NOT call any tools! (message: '{message[:50]}...')")
                    logger.warning(f"âš ï¸ Agent DID NOT call any tools! (message: '{message[:50]}...')")
            else:
                print(f"âš ï¸ Result has NO new_items or new_items is empty!")
            
            # ğŸš¨ BUILD 138: VALIDATION - Detect "hallucinated bookings"
            # If agent claims action without executing tool, BLOCK response
            claim_words = ["×§×‘×¢×ª×™", "×©×œ×—×ª×™", "×™×¦×¨×ª×™", "×”×¤×’×™×©×” × ×§×‘×¢×”", "×”×¤×’×™×©×” ×§×‘×•×¢×”", "×¡×’×¨×ª×™", "× ×§×‘×¢", "×”×ª×•×¨ × ×§×‘×¢", "×”×ª×•×¨ ×§×‘×•×¢"]
            claimed_action = any(word in reply_text for word in claim_words)
            
            # Check if calendar_create_appointment was called (with or without _wrapped suffix)
            booking_tool_called = any(
                tc.get("tool") in ["calendar_create_appointment", "calendar_create_appointment_wrapped"]
                for tc in tool_calls_data
            )
            
            # ğŸ”¥ WORKAROUND: Also check if we detected a successful booking in the output
            # (in case tool name extraction failed but booking actually succeeded)
            print(f"  ğŸ” VALIDATION CHECK:")
            print(f"     claimed_action={claimed_action}")
            print(f"     booking_tool_called={booking_tool_called}")
            print(f"     booking_successful={booking_successful}")
            
            if claimed_action and not booking_tool_called and not booking_successful:
                print(f"ğŸš¨ BLOCKED HALLUCINATED BOOKING!")
                print(f"   Agent claimed: '{reply_text[:80]}...'")
                print(f"   But NO calendar_create_appointment was called AND no successful booking detected!")
                logger.error(f"ğŸš¨ Blocked hallucinated booking: agent claimed action without tool call")
                
                # Override response with corrective message
                reply_text = "×× ×™ ×¢×“×™×™×Ÿ ×¦×¨×™×š ×œ×‘×“×•×§ ×–××™× ×•×ª. ××™×–×” ×™×•× ×•×©×¢×” ×”×™×™×ª ×¨×•×¦×”?"
                print(f"   âœ… Replaced with: '{reply_text}'")
            
            # âœ¨ Save trace to database
            try:
                trace = AgentTrace(
                    business_id=business_id,
                    agent_type="booking",
                    channel=channel,
                    customer_phone=customer_phone,
                    customer_name=customer_name,
                    user_message=message[:1000],  # Limit length
                    agent_response=reply_text[:2000],
                    tool_calls=tool_calls_data if tool_calls_data else None,
                    tool_count=tool_count,
                    status="success",
                    duration_ms=duration_ms
                )
                db.session.add(trace)
                db.session.commit()
                logger.info(f"ğŸ“Š Saved agent trace #{trace.id} (duration: {duration_ms}ms)")
            except Exception as trace_error:
                logger.error(f"Failed to save agent trace: {trace_error}")
                # Don't fail the whole request just because trace failed
                db.session.rollback()
            
            return reply_text
            
        except Exception as e:
            logger.error(f"Agent error (falling back to regular response): {e}")
            import traceback
            traceback.print_exc()
            
            # âœ¨ Save error trace with duration
            try:
                error_duration_ms = int((time.time() - start_time) * 1000)
                trace = AgentTrace(
                    business_id=business_id,
                    agent_type="booking",
                    channel=channel,
                    customer_phone=customer_phone,
                    customer_name=customer_name,
                    user_message=message[:1000],
                    agent_response=None,
                    tool_calls=None,
                    tool_count=0,
                    status="error",
                    error_message=str(e)[:500],
                    duration_ms=error_duration_ms
                )
                db.session.add(trace)
                db.session.commit()
                logger.info(f"ğŸ“Š Saved error trace (duration: {error_duration_ms}ms)")
            except:
                db.session.rollback()
            
            # Fallback to regular response
            return self.generate_response(message, business_id, context, channel, is_first_turn)

def generate_ai_response(message: str, business_id: int = 1, 
                        context: Optional[Dict[str, Any]] = None, channel: str = "calls",
                        is_first_turn: bool = False) -> str:
    """×¤×•× ×§×¦×™×” ×¢×–×¨ ×œ×§×¨×™××” ××”×™×¨×” ×œ×©×™×¨×•×ª AI - ×œ×¤×™ ×¢×¨×•×¥"""
    return get_ai_service().generate_response(message, business_id, context, channel, is_first_turn)

