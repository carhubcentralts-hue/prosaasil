"""
AI Service - Unified OpenAI Service for All Communication Channels
×©×™×¨×•×ª AI ×××•×—×“ - ××—×‘×¨ ×¤×¨×•××¤×˜×™× ×“×™× ××™×™× ××”××¡×“ × ×ª×•× ×™× ×¢× OpenAI
âœ¨ BUILD 119: AgentKit integration for real actions (appointments, leads, WhatsApp)
"""
import os
import logging
import time
from typing import Dict, Any, Optional, List
from openai import OpenAI
from server.models_sql import BusinessSettings, PromptRevisions, Business, AgentTrace
from server.db import db
from datetime import datetime

logger = logging.getLogger(__name__)

# Global AI service instance for cache sharing
_global_ai_service = None

def get_ai_service():
    """Get or create global AI service instance"""
    global _global_ai_service
    if _global_ai_service is None:
        _global_ai_service = AIService()
        # âš¡ CRITICAL: Warmup cache at startup
        _warmup_ai_cache(_global_ai_service)
    return _global_ai_service

def _warmup_ai_cache(service: 'AIService'):
    """âš¡ Preload cache for common business IDs to prevent first-turn latency"""
    try:
        import time
        start = time.time()
        
        # Warmup business 1 and 11 (most common)
        for business_id in [1, 11]:
            for channel in ['calls', 'whatsapp']:
                try:
                    service.get_business_prompt(business_id, channel)
                    logger.info(f"âœ… WARMUP: Preloaded business {business_id} {channel}")
                except Exception as e:
                    logger.warning(f"âš ï¸ WARMUP failed for business {business_id} {channel}: {e}")
        
        warmup_time = time.time() - start
        logger.info(f"âœ… AI_CACHE_WARMUP: Completed in {warmup_time:.3f}s")
    except Exception as e:
        logger.error(f"âŒ AI cache warmup failed: {e}")

def invalidate_business_cache(business_id: int):
    """ğŸ”¥ CRITICAL: Invalidate cache for business - called after prompt updates"""
    service = get_ai_service()
    cache_keys_to_remove = [
        f"business_{business_id}_calls",
        f"business_{business_id}_whatsapp"
    ]
    for key in cache_keys_to_remove:
        if key in service._cache:
            del service._cache[key]
            logger.info(f"âœ… Cache invalidated: {key}")

class AIService:
    """×× ×’× ×•×Ÿ AI ××¨×›×–×™ ×©×˜×•×¢×Ÿ ×¤×¨×•××¤×˜×™× ××”××¡×“ × ×ª×•× ×™× ×•××—×‘×¨ ×¢× OpenAI"""
    
    def __init__(self):
        # âš¡ RELIABLE OpenAI client with production timeout
        self.client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            timeout=3.5  # âœ… Production timeout - allows Hebrew responses with margin
        )
        self._cache = {}  # ×§××© ×¤×¨×•××¤×˜×™× ×œ×‘×™×¦×•×¢×™×
        self._cache_timeout = 300  # âš¡ 5 ×“×§×•×ª - ××¡×¤×™×§ ××¨×•×š ×œ×©×™×—×” ×©×œ××”
        
    def get_business_prompt(self, business_id: int, channel: str = "calls") -> Dict[str, Any]:
        """×˜×¢×™× ×ª ×¤×¨×•××¤×˜ ×¢×¡×§ ××”××¡×“ × ×ª×•× ×™× ×¢× ×§××© - ×œ×¤×™ ×¢×¨×•×¥ (calls/whatsapp)"""
        cache_key = f"business_{business_id}_{channel}"
        now = datetime.now().timestamp()
        
        # ×‘×“×™×§×ª ×§××©
        if cache_key in self._cache:
            cached_data, timestamp = self._cache[cache_key]
            if now - timestamp < self._cache_timeout:
                logger.info(f"âœ… CACHE_HIT: business {business_id} {channel}")
                return cached_data
        
        try:
            # âš¡ CRITICAL: Measure DB query time
            import time
            db_start = time.time()
            
            # ×˜×¢×™× ×ª ×”×’×“×¨×•×ª ×¢×¡×§
            settings = BusinessSettings.query.filter_by(tenant_id=business_id).first()
            business = Business.query.get(business_id)
            
            db_time = time.time() - db_start
            logger.info(f"ğŸ“Š DB_QUERY: {db_time:.3f}s for business {business_id}")
            
            # âœ… ×©× ×¢×¡×§ ×œ×©×™××•×© ×‘-placeholders
            business_name = business.name if business else "×”×¢×¡×§ ×©×œ× ×•"
            
            # ×‘×—×™×¨×ª ×¤×¨×•××¤×˜ ×—×›××” - ×¢× fallback ×œ-business.system_prompt
            system_prompt = ""
            if settings and settings.ai_prompt and settings.ai_prompt.strip():
                # ×™×© ×¤×¨×•××¤×˜ ×‘-settings - ×ª××™×“ ×ª×©×ª××© ×‘×•! (×œ×œ× ×‘×“×™×§×ª ××•×¨×š)
                import json
                try:
                    # × ×¡×™×•×Ÿ ×œ×¤×¨×•×¡ ×›-JSON (×¤×•×¨××˜ ×—×“×© ×¢× calls/whatsapp)
                    if settings.ai_prompt.strip().startswith('{'):
                        prompt_obj = json.loads(settings.ai_prompt)
                        # ×‘×—×™×¨×ª ×”×¤×¨×•××¤×˜ ×”× ×›×•×Ÿ ×œ×¤×™ channel
                        system_prompt = prompt_obj.get(channel, prompt_obj.get('calls', settings.ai_prompt))
                        logger.info(f"âœ… Using {channel} prompt for business {business_id} from settings")
                        logger.info(f"ğŸ” DEBUG: Loaded prompt starts with: {system_prompt[:100]}...")
                    else:
                        # ×¤×¨×•××¤×˜ ×˜×§×¡×˜ ×¤×©×•×˜ (legacy)
                        system_prompt = settings.ai_prompt
                        logger.info(f"âœ… Using legacy text prompt for business {business_id}")
                except json.JSONDecodeError:
                    # ×× ×–×” ×œ× JSON ×ª×§×™×Ÿ, ×”×©×ª××© ×‘×–×” ×›×˜×§×¡×˜
                    system_prompt = settings.ai_prompt
                    logger.info(f"âœ… Using non-JSON prompt for business {business_id}")
            elif business and business.system_prompt and business.system_prompt.strip():
                # fallback ×œ×¤×¨×•××¤×˜ ×”××œ× ××˜×‘×œ×ª business
                system_prompt = business.system_prompt
                logger.info(f"âœ… Using fallback prompt from business.system_prompt for {business_id}")
            else:
                # fallback ××—×¨×•×Ÿ ×œ×¤×¨×•××¤×˜ ×‘×¨×™×¨×ª ××—×“×œ
                system_prompt = self._get_default_hebrew_prompt(business_name, channel)
                logger.info(f"âš ï¸ Using default prompt for business {business_id} - no custom prompt found")
            
            # âœ… ×”×—×œ×¤×ª placeholders ×“×™× ××™×™× ×‘×¤×¨×•××¤×˜
            system_prompt = system_prompt.replace("{{business_name}}", business_name)
            system_prompt = system_prompt.replace("{{BUSINESS_NAME}}", business_name)
            logger.info(f"âœ… Replaced {{{{business_name}}}} with '{business_name}'")
            
            # âš¡ BUILD 118: Warn if prompt is too long (causes OpenAI timeouts)
            if len(system_prompt) > 3000:
                logger.warning(f"âš ï¸ PROMPT_TOO_LONG: {len(system_prompt)} chars (recommended: <3000) - may cause OpenAI timeouts!")
            else:
                logger.info(f"âœ… Prompt length OK: {len(system_prompt)} chars")
            
            if not settings:
                # âš¡ BUILD 117: INCREASED - allow complete sentences without truncation
                prompt_data = {
                    "system_prompt": system_prompt,
                    "model": "gpt-4o-mini",  # Fast model
                    "max_tokens": 350,  # âš¡ BUILD 117: 350 tokens for COMPLETE sentences (no mid-sentence cuts!)
                    "temperature": 0.3  # Balanced temperature for natural responses
                }
            else:
                prompt_data = {
                    "system_prompt": system_prompt,
                    "model": settings.model,
                    "max_tokens": min(settings.max_tokens, 350),  # âš¡ BUILD 117: Cap at 350 for complete sentences
                    "temperature": min(settings.temperature, 0.4)  # Balanced temperature
                }
            
            # ×©××™×¨×” ×‘×§××©
            self._cache[cache_key] = (prompt_data, now)
            return prompt_data
            
        except Exception as e:
            logger.error(f"Error loading business prompt {business_id}: {e}")
            # âš¡ FAST fallback - ×˜×¢×™× ×ª ×©× ×¢×¡×§ ××”-DB
            try:
                business = Business.query.get(business_id)
                business_name = business.name if business else "×”×¢×¡×§ ×©×œ× ×•"
            except:
                business_name = "×”×¢×¡×§ ×©×œ× ×•"
            
            return {
                "system_prompt": self._get_default_hebrew_prompt(business_name, channel),
                "model": "gpt-4o-mini",
                "max_tokens": 350,  # âš¡ BUILD 117: 350 tokens for COMPLETE sentences
                "temperature": 0.3  # Balanced
            }
    
    def _get_default_hebrew_prompt(self, business_name: str = "×”×¢×¡×§ ×©×œ× ×•", channel: str = "calls") -> str:
        """×¤×¨×•××¤×˜ ×‘×¨×™×¨×ª ××—×“×œ ×‘×¢×‘×¨×™×ª ×œ× ×“×œ"×Ÿ - ××•×ª×× ×œ×¢×¨×•×¥ - âœ… ×‘×œ×™ ×©× hardcoded!"""
        if channel == "whatsapp":
            return f"""××ª×” ×”×¢×•×–×¨ ×”×“×™×’×™×˜×œ×™ ×©×œ {business_name} ×‘-WhatsApp.

×›×œ×œ×™× ×—×©×•×‘×™×:
- ×ª×¢× ×” ×‘×¢×‘×¨×™×ª, ×ª×©×•×‘×•×ª ×§×¦×¨×•×ª (×¢×“ 150 ××™×œ×™×)
- ×ª×”×™×” ×—× ×•×™×“×™×“×•×ª×™ ×‘×¡×’× ×•×Ÿ WhatsApp
- ×ª×‘×§×© ×¤×¨×˜×™×: ××–×•×¨, ×¡×•×’ × ×›×¡, ×ª×§×¦×™×‘
- ×›×©××ª×” ××–×›×™×¨ ××—×™×¨×™×/×ª×§×¦×™×‘ - ×ª××™×“ ×¦×™×™×Ÿ "××™×œ×™×•×Ÿ", "××œ×£", "××™×œ×™××¨×“" (×œ× ×¨×§ ××¡×¤×¨×™×!)
- ×ª×¦×™×¢ ×œ×§×‘×•×¢ ×¤×’×™×©×” ×›×©×™×© ××™×“×¢ ××¡×¤×™×§
- âš ï¸ ××œ ×ª×—×–×•×¨ ×¢×œ ×©××š ×‘×›×œ ××©×¤×˜! ×–×” ××¢×¦×‘×Ÿ ×•×œ× ×˜×‘×¢×™
- ×“×‘×¨ ×™×©×¨ ×œ×¢× ×™×™×Ÿ ×‘×œ×™ ×œ×”×¦×™×’ ××ª ×¢×¦××š ×›×œ ×¤×¢× ××—×“×©

**×›×©×œ×§×•×— ××¡×›×™× ×œ×–××Ÿ ×¤×’×™×©×”:**
ğŸ¯ **×—×–×•×¨ ×¢×œ ×”×–××Ÿ ×”××“×•×™×§ ×©×”×œ×§×•×— ×××¨!**
×“×•×’×××•×ª:
- ×œ×§×•×—: "××—×¨ ×‘-10" â†’ ××ª×”: "××¢×•×œ×”! × ×§×‘×¢ ×œ×š ×¤×’×™×©×” ×œ××—×¨ ×‘×©×¢×” 10:00."
- ×œ×§×•×—: "××—×¨ ×‘-15" â†’ ××ª×”: "××¢×•×œ×”! × ×§×‘×¢ ×œ×š ×¤×’×™×©×” ×œ××—×¨ ×‘×©×¢×” 15:00."
âš ï¸ **××œ ×ª×©× ×” ××ª ×”×©×¢×” - ×—×–×•×¨ ×¢×œ ××” ×©×”×œ×§×•×— ×××¨!**

×ª×¤×§×™×“×š: ×œ×¢×–×•×¨ ×œ××¦×•× × ×›×¡ ×•×œ×”×•×‘×™×œ ×œ×¤×’×™×©×”."""
        else:
            # âœ¨ Calls - ×¤×¨×•××¤×˜ ××¤×•×¨×˜ ×œ×©×™×—×•×ª ×–×•×¨××•×ª ×•×˜×‘×¢×™×•×ª
            return f"""××ª×” ×”×¢×•×–×¨ ×”×“×™×’×™×˜×œ×™ ×©×œ {business_name}. ××ª×” ×›××Ÿ ×›×“×™ ×œ×¢×–×•×¨ ×œ×œ×§×•×—×•×ª ×œ××¦×•× ××ª ×”× ×›×¡ ×”××•×©×œ× - ×“×™×¨×•×ª ×œ××›×™×¨×”, ×“×™×¨×•×ª ×œ×”×©×›×¨×”, ×‘×ª×™×, ×•××©×¨×“×™×.

×”×ª× ×”×œ×•×ª ×‘×©×™×—×”:
â€¢ ×“×‘×¨ ×‘×¢×‘×¨×™×ª ×‘×œ×‘×“, ×‘×¦×•×¨×” ×˜×‘×¢×™×ª ×•×–×•×¨××ª ×›××• ×©×™×—×” ×¨×’×™×œ×” ×‘×˜×œ×¤×•×Ÿ
â€¢ ×”×™×” ×—×, ×™×“×™×“×•×ª×™, ××‘×œ ××§×¦×•×¢×™ - ×›××• ×¡×•×›×Ÿ × ×“×œ"×Ÿ ×× ×•×¡×”
â€¢ ×ª×©×•×‘×•×ª ×§×¦×¨×•×ª - 2-3 ××©×¤×˜×™× ×‘×›×œ ×ª×’×•×‘×” (×¢×“ 200 ××™×œ×™×)
â€¢ ×“×‘×¨ ×™×©×™×¨×•×ª ×œ×¢× ×™×™×Ÿ, ×‘×œ×™ ××™×œ×•×™ ××• ×¡×™×¤×•×¨×™× ××¨×•×›×™×
â€¢ âš ï¸ ×—×©×•×‘ ×××•×“: ××œ ×ª×—×–×•×¨ ×¢×œ ×©××š ×‘×›×œ ××©×¤×˜! ×–×” ×œ× ×˜×‘×¢×™ ×•××¢×¦×‘×Ÿ
â€¢ ×”×¦×’ ××ª ×¢×¦××š ×¨×§ ×‘×‘×¨×›×” ×”×¨××©×•× ×”, ××—×¨ ×›×š ×“×‘×¨ ×™×©×¨ ×œ×¢× ×™×™×Ÿ

××™×¡×•×£ ××™×“×¢ ×—×›×:
×©××œ ×©××œ×” ××—×ª ×‘×›×œ ×¤×¢×, ×‘×¡×“×¨ ×”×–×”:
1. ×ª×—×™×œ×”: ××” ×”×œ×§×•×— ××—×¤×©? (×“×™×¨×”/×‘×™×ª/××©×¨×“, ××›×™×¨×”/×”×©×›×¨×”)
2. ××–×•×¨ ××‘×•×§×© ××• ×¢×™×¨ (×—×©×•×‘ ×××•×“!)
3. ×ª×§×¦×™×‘ ××• ×˜×•×•×— ××—×™×¨×™× - âš ï¸ ×—×©×•×‘: ×ª××™×“ ×”×–×›×¨ ××ª ×¡×“×¨ ×”×’×•×“×œ! ×××•×¨ "××™×œ×™×•×Ÿ ×©×§×œ", "×××” ××œ×£ ×©×§×œ", "×—×¦×™ ××™×œ×™×•×Ÿ" ×•×›×•'. ×œ×¢×•×œ× ××œ ×ª×’×™×“ ×¨×§ ××ª ×”××¡×¤×¨ (×œ××©×œ "1000000") ×‘×œ×™ ×œ×”×–×›×™×¨ ×× ×–×” ××œ×£/××™×œ×™×•×Ÿ/××™×œ×™××¨×“!
4. ××¡×¤×¨ ×—×“×¨×™× / ×’×•×“×œ
5. ×¤×¨×˜×™ ×§×©×¨: ×©× ××œ× ×•××™×™×œ ×× ×œ× × ×™×ª× ×•

××ª×™ ×œ×§×‘×•×¢ ×¤×’×™×©×”:
×›×©×™×© ×œ×š ×œ×¤×—×•×ª: ×¡×•×’ × ×›×¡ + ××–×•×¨ + ×ª×§×¦×™×‘ â†’ ×”×¦×¢ ×œ×§×‘×•×¢ ×¤×’×™×©×” ×¢× ×”×¡×•×›×Ÿ. ×ª×’×™×“: "××¢×•×œ×”! ×™×© ×œ×™ ×›××” ××¤×©×¨×•×™×•×ª ××¦×•×™× ×•×ª. ××©××— ×œ×§×‘×•×¢ ×œ×š ×¤×’×™×©×” ×¢× ××—×“ ×”×¡×•×›× ×™× ×©×œ× ×• ×©×™×¦×™×’ ×œ×š ××ª ×”× ×›×¡×™×. ××ª×™ × ×•×— ×œ×š?"

âš ï¸ **×—×©×•×‘ ×××•×“ - ×›×©×”×œ×§×•×— ××¡×›×™× ×œ×–××Ÿ:**
ğŸ¯ **×—×•×§ ×‘×¨×–×œ: ×—×–×•×¨ ×¢×œ ×”×–××Ÿ ×”××“×•×™×§ ×©×”×œ×§×•×— ×××¨ - ×œ× ×œ×”××¦×™× ×©×¢×•×ª!**

×›×©×”×œ×§×•×— ××•××¨ ×–××Ÿ ×¡×¤×¦×™×¤×™:
- ×œ×§×•×—: "××—×¨ ×‘-10" â†’ ××ª×”: "××¢×•×œ×”! × ×§×‘×¢ ×œ×š ×¤×’×™×©×” ×œ××—×¨ ×‘×©×¢×” 10:00."
- ×œ×§×•×—: "××—×¨ ×‘-16" â†’ ××ª×”: "××¢×•×œ×”! × ×§×‘×¢ ×œ×š ×¤×’×™×©×” ×œ××—×¨ ×‘×©×¢×” 16:00."
- ×œ×§×•×—: "×™×•× ×©×œ×™×©×™ ×‘-14:30" â†’ ××ª×”: "××¢×•×œ×”! × ×§×‘×¢ ×œ×š ×¤×’×™×©×” ×œ×™×•× ×©×œ×™×©×™ ×‘×©×¢×” 14:30."

×›×©×”×œ×§×•×— ××•××¨ ×–××Ÿ ×›×œ×œ×™ (×‘×•×§×¨/×¦×”×¨×™×™×/××—×”"×¦):
- ×œ×§×•×—: "××—×¨ ×‘×‘×•×§×¨" â†’ ××ª×”: "××¢×•×œ×”! × ×§×‘×¢ ×œ×š ×¤×’×™×©×” ×œ××—×¨ ×‘×©×¢×” 10:00."
- ×œ×§×•×—: "×™×•× ×©×œ×™×©×™ ××—×¨ ×”×¦×”×¨×™×™×" â†’ ××ª×”: "××¢×•×œ×”! × ×§×‘×¢ ×œ×š ×¤×’×™×©×” ×œ×™×•× ×©×œ×™×©×™ ×‘×©×¢×” 14:00."

âš ï¸ **××œ ×ª×©× ×” ××ª ×”×©×¢×” ×©×”×œ×§×•×— ×××¨! ×× ×”×•× ×××¨ 16 - ×ª××©×¨ 16, ×œ× 10!**

×—×©×•×‘: ××œ ×ª××¦×™× ××™×“×¢! ×× ×œ× ×™×•×“×¢ ××©×”×• - ×”×¤× ×” ×œ×¡×•×›×Ÿ ×× ×•×©×™. ×× ×”×œ×§×•×— ×¢×¦×‘× ×™ ××• ××ª×œ×•× ×Ÿ - ×”×™×” ×××¤×˜×™ ×•×”×¦×¢ ×“×™×‘×•×¨ ×¢× ×× ×”×œ."""

    def generate_response(self, message: str, business_id: int = 1, context: Optional[Dict[str, Any]] = None, channel: str = "calls", is_first_turn: bool = False) -> str:
        """×™×¦×™×¨×ª ×ª×’×•×‘×” ××¤×¨×•××¤×˜ ×“×™× ××™ + ×”×§×©×¨ - ×œ×¤×™ ×¢×¨×•×¥ (calls/whatsapp)"""
        try:
            # ×˜×¢×™× ×ª ×¤×¨×•××¤×˜ ×¢×¡×§ ×œ×¤×™ ×¢×¨×•×¥
            prompt_data = self.get_business_prompt(business_id, channel)
            
            # âš¡ BUILD 117: First turn - NO SPECIAL LIMIT! Let AI finish complete sentences
            # User requirement: "×× ×”×™× ×¦×¨×™×›×” ×œ×”×¡×‘×™×¨ ×“×§×” ×©×ª×¡×‘×™×¨ ×“×§×”" - let it speak as long as needed
            if is_first_turn:
                # Don't reduce max_tokens for first turn - keep the default 350 for complete sentences
                logger.info(f"ğŸ¯ First turn - using full {prompt_data['max_tokens']} tokens for complete sentences")
            
            # ×‘× ×™×™×ª ×”×•×“×¢×•×ª
            messages: List[Dict[str, str]] = [
                {"role": "system", "content": prompt_data["system_prompt"]}
            ]
            
            # âœ… ×”×•×¡×¤×ª ×–××™× ×•×ª ×œ×•×— ×©× ×” (×¨×§ ×œ-WhatsApp - ×œ× ×œ×˜×œ×¤×•×Ÿ ×‘×’×œ×œ latency!)
            if channel == "whatsapp":
                calendar_info = self._get_calendar_availability(business_id)
                if calendar_info:
                    messages.append({
                        "role": "system",
                        "content": f"ğŸ“… ×œ×•×— ×©× ×”:\n{calendar_info}\n×›×©×”×œ×§×•×— ××•×›×Ÿ ×œ×¤×’×™×©×”, ×”×¦×¢ ×ª××¨×™×›×™× ×¤× ×•×™×™× ××”×¨×©×™××” ×œ××¢×œ×”."
                    })
            
            # ×”×•×¡×¤×ª ×”×§×©×¨ ×× ×§×™×™×
            if context:
                # ×”×•×¡×¤×ª ××™×“×¢ ×‘×¡×™×¡×™ ×¢×œ ×”×œ×§×•×—
                context_info = []
                if context.get("customer_name"):
                    context_info.append(f"×©× ×”×œ×§×•×—: {context['customer_name']}")
                if context.get("phone_number"):
                    context_info.append(f"×˜×œ×¤×•×Ÿ: {context['phone_number']}")
                
                if context_info:
                    messages.append({
                        "role": "system", 
                        "content": "××™×“×¢ ×¢×œ ×”×œ×§×•×—:\n" + "\n".join(context_info)
                    })
                
                # âœ… BUILD 92: ×©×œ×™×—×ª previous_messages ×›×©×™×—×” ×××™×ª×™×ª - 10 ×”×•×“×¢×•×ª ×œ×–×™×›×¨×•×Ÿ ××œ×!
                if context.get("previous_messages"):
                    prev_msgs = context["previous_messages"][-10:]  # âœ… 10 ×”×•×“×¢×•×ª ××—×¨×•× ×•×ª (×œ× 6!)
                    for msg in prev_msgs:
                        # âœ… ×”××‘× ×” ×”×•× "×œ×§×•×—: ..." ××• "×¢×•×–×¨×ª: ..." (××• "×œ××”:" legacy)
                        if msg.startswith("×œ×§×•×—:"):
                            messages.append({
                                "role": "user",
                                "content": msg.replace("×œ×§×•×—:", "").strip()
                            })
                        elif msg.startswith("×¢×•×–×¨×ª:") or msg.startswith("×œ××”:"):  # âœ… ×ª××™×›×” ×‘×©× ×™×”×!
                            content = msg.replace("×¢×•×–×¨×ª:", "").replace("×œ××”:", "").strip()
                            messages.append({
                                "role": "assistant",
                                "content": content
                            })
            
            # ×”×•×¡×¤×ª ×”×•×“×¢×ª ×”××©×ª××© ×”× ×•×›×—×™×ª
            messages.append({"role": "user", "content": message})
            
            # âš¡ CRITICAL: Measure OpenAI call time
            import time
            openai_start = time.time()
            
            # âš¡ BUILD 118: Add explicit timeout to prevent long waits
            try:
                response = self.client.chat.completions.create(
                    model=prompt_data["model"],
                    messages=messages,  # type: ignore
                    max_tokens=prompt_data["max_tokens"],
                    temperature=prompt_data["temperature"],
                    timeout=3.5  # âš¡ 3.5s timeout for real-time conversations
                )
                
                openai_time = time.time() - openai_start
                logger.info(f"âœ… OPENAI_SUCCESS: {openai_time:.3f}s")
                
                ai_response = response.choices[0].message.content
                if ai_response:
                    ai_response = ai_response.strip()
                else:
                    ai_response = "××¦×˜×¢×¨, ×œ× ×”×¦×œ×—×ª×™ ×œ×™×™×¦×¨ ×ª×’×•×‘×” ×›×¨×’×¢."
                logger.info(f"AI response generated for business {business_id}: {len(ai_response)} chars")
                return ai_response
                
            except Exception as openai_error:
                openai_time = time.time() - openai_start
                error_type = type(openai_error).__name__
                logger.error(f"ğŸ”´ OPENAI_FAILED: {error_type} after {openai_time:.3f}s: {str(openai_error)[:200]}")
                raise  # Re-raise to outer exception handler
            
        except Exception as e:
            logger.error(f"ğŸ”´ AI_GENERATION_FAILED: {type(e).__name__}: {str(e)[:200]}")
            return self._get_fallback_response(message)
    
    def _get_fallback_response(self, message: str) -> str:
        """×ª×’×•×‘×ª ×—×™×¨×•× ×× ×”-AI × ×›×©×œ"""
        message_lower = message.lower().strip()
        
        if any(word in message_lower for word in ["×©×œ×•×", "×”×™×™", "×”×œ×•"]):
            return "×©×œ×•×! ××™×š ××•×›×œ ×œ×¢×–×•×¨ ×œ×š?"  # âœ… ×›×œ×œ×™ - ×œ× ×—×•×©×£ ×©× ×¢×¡×§ ×©×’×•×™
        elif any(word in message_lower for word in ["×“×™×¨×”", "×‘×™×ª", "× ×›×¡"]):
            return "××©××— ×œ×¢×–×•×¨ ×œ×š! ××ª×” ××—×¤×© ×œ×§× ×™×” ××• ×”×©×›×¨×”? ×‘××™×–×” ××–×•×¨?"
        else:
            return "×ª×•×“×” ×¢×œ ×”×¤× ×™×™×”! ××—×–×•×¨ ××œ×™×š ×‘×”×§×“× ×¢× ××¢× ×” ××¤×•×¨×˜."
    
    def _get_calendar_availability(self, business_id: int) -> str:
        """×‘×“×™×§×ª ×–××™× ×•×ª ×‘×œ×•×— ×”×©× ×” ×œ-7 ×™××™× ×”×§×¨×•×‘×™×"""
        try:
            from server.models_sql import Appointment
            from datetime import datetime, timedelta
            
            # âš¡ FAST: Limit query time with LIMIT
            # ×˜×•×•×— ×ª××¨×™×›×™×: ×”×™×•× + 7 ×™××™×
            today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
            week_end = today + timedelta(days=7)
            
            # ×©×œ×™×¤×ª ×¤×’×™×©×•×ª ×§×™×™××•×ª (LIMIT 10 ×œ××”×™×¨×•×ª!)
            appointments = Appointment.query.filter(
                Appointment.business_id == business_id,
                Appointment.start_time >= today,
                Appointment.start_time < week_end,
                Appointment.status.in_(['confirmed', 'pending'])
            ).order_by(Appointment.start_time).limit(10).all()
            
            # ×”×¦×¢×ª ×–×× ×™× ×¤× ×•×™×™× (9:00-17:00, ×›×œ ×™×•×, ×œ××¢×˜ ×©×‘×ª)
            available_slots = []
            for i in range(7):
                day = today + timedelta(days=i)
                # ×“×œ×’ ×¢×œ ×©×‘×ª (5 = ×©×‘×ª)
                if day.weekday() == 5:
                    continue
                    
                day_name = day.strftime("%A")
                day_name_he = {"Monday": "×©× ×™", "Tuesday": "×©×œ×™×©×™", "Wednesday": "×¨×‘×™×¢×™", 
                              "Thursday": "×—××™×©×™", "Friday": "×©×™×©×™", "Sunday": "×¨××©×•×Ÿ"}.get(day_name, day_name)
                
                # ×‘×“×•×§ ×× ×™×© ×¤×’×™×©×•×ª ×‘×™×•× ×”×–×”
                day_start = day.replace(hour=9, minute=0)
                day_end = day.replace(hour=17, minute=0)
                
                day_appointments = [apt for apt in appointments if day_start <= apt.start_time < day_end]
                
                if len(day_appointments) < 4:  # ×× ×¤×—×•×ª ×-4 ×¤×’×™×©×•×ª - ×¢×“×™×™×Ÿ ×™×© ××§×•×
                    date_str = day.strftime("%d/%m")
                    available_slots.append(f"×™×•× {day_name_he} {date_str} (×‘×•×§×¨/××—×”\"×¦)")
            
            # ×‘× ×™×™×ª ×˜×§×¡×˜
            result = []
            if available_slots:
                result.append("âœ… ×–××™× ×•×ª ×”×©×‘×•×¢:")
                result.extend([f"  â€¢ {slot}" for slot in available_slots[:5]])  # ×¨×§ 5 ×¨××©×•× ×™×
            else:
                result.append("âš ï¸ ××™×Ÿ ×–××™× ×•×ª ×”×©×‘×•×¢ - ×”×¦×¢ ×©×‘×•×¢ ×”×‘×")
            
            return "\n".join(result)
            
        except Exception as e:
            logger.error(f"Calendar check failed: {e}")
            return "ğŸ“… ×œ×•×— ×”×©× ×”: × × ×œ×ª×× ×™×©×™×¨×•×ª ×¢× ×”×¡×•×›×Ÿ"
    
    def invalidate_cache(self, business_id: int):
        """××—×™×§×ª ×§××© ×¢×¡×§ ××¡×•×™× (×œ××—×¨ ×¢×“×›×•×Ÿ ×¤×¨×•××¤×˜)"""
        cache_key = f"business_{business_id}"
        if cache_key in self._cache:
            del self._cache[cache_key]
            logger.info(f"Cache invalidated for business {business_id}")
    
    def save_conversation_history(self, business_id: int, phone_number: str, 
                                 message: str, response: str, channel: str = "whatsapp"):
        """×©××™×¨×ª ×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×” ×œ××™×“×¢ ×¢×ª×™×“×™ (××•×¤×¦×™×•× ×œ×™)"""
        try:
            # ×›××Ÿ ××¤×©×¨ ×œ×”×•×¡×™×£ ×œ×•×’×™×§×” ×œ×©××™×¨×ª ×©×™×—×•×ª ××¨×•×›×•×ª
            # ×œ×¦×¨×›×™ ×”×§×©×¨ ×¢×ª×™×“×™ ××• ×× ×œ×™×˜×™×§×”
            pass
        except Exception as e:
            logger.error(f"Failed to save conversation history: {e}")
    
    def generate_response_with_agent(self, message: str, business_id: int = 1, 
                                     context: Optional[Dict[str, Any]] = None,
                                     channel: str = "calls",
                                     is_first_turn: bool = False,
                                     customer_phone: Optional[str] = None,
                                     customer_name: Optional[str] = None) -> str:
        """
        âœ¨ BUILD 119: Agent-enhanced response generation
        
        Uses AgentKit to perform real actions (appointments, leads, WhatsApp)
        Falls back to regular generate_response if agents are disabled
        
        Args:
            message: Customer's message
            business_id: Business ID
            context: Conversation context
            channel: calls/whatsapp
            is_first_turn: First message in conversation
            customer_phone: Customer phone for lead creation
            customer_name: Customer name for personalization
            
        Returns:
            AI response (potentially enhanced with tool actions)
        """
        # Check if agents are enabled (default: enabled)
        agents_enabled = os.getenv("AGENTS_ENABLED", "1") == "1"
        print(f"ğŸ¯ AGENTS_ENABLED = {agents_enabled}")
        logger.info(f"ğŸ¯ AGENTS_ENABLED = {agents_enabled}")
        
        if not agents_enabled:
            # Fallback to regular response
            print("âš ï¸ Agents disabled - using regular response")
            logger.warning("âš ï¸ Agents disabled - using regular response")
            return self.generate_response(message, business_id, context, channel, is_first_turn)
        
        # âš¡ Capture start time BEFORE try block for error logging
        start_time = time.time()
        
        try:
            print("ğŸ“¦ Importing agent modules...")
            logger.info("ğŸ“¦ Importing agent modules...")
            from server.agents import get_agent, AGENTS_ENABLED
            from agents import Runner
            print(f"âœ… Agent modules imported. AGENTS_ENABLED={AGENTS_ENABLED}")
            logger.info(f"âœ… Agent modules imported. AGENTS_ENABLED={AGENTS_ENABLED}")
            
            if not AGENTS_ENABLED:
                # Double-check - agents not available
                print("âš ï¸ AGENTS_ENABLED=False in module - using regular response")
                logger.warning("âš ï¸ AGENTS_ENABLED=False in module - using regular response")
                return self.generate_response(message, business_id, context, channel, is_first_turn)
            
            # Get business name
            business = Business.query.get(business_id)
            business_name = business.name if business else "×”×¢×¡×§ ×©×œ× ×•"
            
            # ğŸ¯ BUILD 119: Load custom prompt from database!
            prompt_data = self.get_business_prompt(business_id, channel)
            custom_prompt = prompt_data.get("system_prompt", "")  # Extract just the prompt text
            logger.info(f"ğŸ“‹ Loaded prompt for business {business_id}: {len(custom_prompt)} chars")
            
            # Get booking agent with custom prompt and business_id
            print(f"ğŸ—ï¸  Creating agent: type=booking, business={business_name}, business_id={business_id}")
            logger.info(f"ğŸ—ï¸  Creating agent: type=booking, business={business_name}, business_id={business_id}")
            agent = get_agent(agent_type="booking", business_name=business_name, custom_instructions=custom_prompt, business_id=business_id)
            
            if not agent:
                print("âŒ Failed to create agent - falling back to regular response")
                logger.error("âŒ Failed to create agent - falling back to regular response")
                return self.generate_response(message, business_id, context, channel, is_first_turn)
            
            print(f"âœ… Agent created successfully: {agent.name}")
            logger.info(f"âœ… Agent created successfully: {agent.name}")
            
            # Build enhanced context for agent
            agent_context = {
                "business_id": business_id,
                "business_name": business_name,
                "customer_phone": customer_phone,
                "customer_name": customer_name,
                "channel": channel,
                "is_first_turn": is_first_turn,
                **(context or {})
            }
            
            # ğŸ”¥ CRITICAL: Store context in Flask g so tools can access it!
            from flask import g
            g.agent_context = agent_context
            print(f"âœ… Stored agent_context in Flask g: phone={customer_phone}, name={customer_name}")
            
            # Run agent using Runner (with proper async handling for eventlet threads)
            print(f"ğŸ¤– Running agent for business {business_id}, channel={channel}")
            print(f"   ğŸ“ User message: '{message[:100]}...'")
            print(f"   ğŸ“‹ Context: business_id={business_id}, phone={customer_phone}, name={customer_name}")
            logger.info(f"ğŸ¤– Running agent for business {business_id}, channel={channel}")
            logger.info(f"   ğŸ“ User message: '{message[:100]}...'")
            logger.info(f"   ğŸ“‹ Context: business_id={business_id}, phone={customer_phone}, name={customer_name}")
            
            import asyncio
            
            # Create new event loop for this thread (eventlet compatibility)
            try:
                loop = asyncio.get_event_loop()
            except RuntimeError:
                # No event loop in current thread - create one
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            
            # ğŸ”¥ BUILD CONVERSATION HISTORY for Agent SDK
            # Agent SDK needs conversation history in specific format
            conversation_messages = []
            if context and "previous_messages" in context:
                prev_msgs = context["previous_messages"]
                print(f"ğŸ“š Found {len(prev_msgs)} previous messages in context")
                
                # Convert to Agent SDK format
                # prev_msgs is list of strings like "×œ×§×•×—: XXX" or "×¢×•×–×¨: YYY"
                for msg in prev_msgs:
                    if msg.startswith("×œ×§×•×—:"):
                        # User message
                        conversation_messages.append({
                            "role": "user",
                            "content": msg.replace("×œ×§×•×—:", "").strip()
                        })
                    elif msg.startswith("×¢×•×–×¨:"):
                        # Assistant message
                        conversation_messages.append({
                            "role": "assistant",
                            "content": msg.replace("×¢×•×–×¨:", "").strip()
                        })
                
                print(f"âœ… Converted to {len(conversation_messages)} messages for Agent")
                
            # Add current message
            conversation_messages.append({
                "role": "user",
                "content": message
            })
            
            runner = Runner()
            print(f"ğŸ”„ Created Runner with {len(conversation_messages)-1} history messages, executing agent.run()...")
            
            # Use input parameter with conversation history
            result = loop.run_until_complete(
                runner.run(starting_agent=agent, input=conversation_messages, context=agent_context)
            )
            duration_ms = int((time.time() - start_time) * 1000)
            print(f"âœ… Runner.run() completed in {duration_ms}ms")
            
            # Extract response using final_output_as
            reply_text = result.final_output_as(str)
            print(f"ğŸ“ Agent final response: '{reply_text[:100] if reply_text else '(EMPTY!)'}...'")
            
            # âœ… CRITICAL: Validate that agent returned a response!
            if not reply_text or not reply_text.strip():
                print(f"âŒ CRITICAL: Agent returned EMPTY response! Falling back...")
                logger.error(f"âŒ Agent returned empty response for message: {message[:100]}")
                return self.generate_response(message, business_id, context, channel, is_first_turn)
            
            # DEBUG: Check result structure
            print(f"ğŸ” Result type: {type(result).__name__}")
            print(f"ğŸ” Has new_items: {hasattr(result, 'new_items')}")
            if hasattr(result, 'new_items'):
                print(f"ğŸ” new_items value: {result.new_items}")
                print(f"ğŸ” new_items length: {len(result.new_items) if result.new_items else 0}")
            
            # Extract tool calls from new_items
            tool_calls_data = []
            tool_count = 0
            
            if hasattr(result, 'new_items') and result.new_items:
                print(f"ğŸ“Š Agent returned {len(result.new_items)} items")
                logger.info(f"ğŸ“Š Agent returned {len(result.new_items)} items")
                # Filter for ToolCallItem types and extract tool names
                for idx, item in enumerate(result.new_items):
                    item_type = type(item).__name__
                    print(f"   - Item #{idx}: {item_type}")
                    logger.info(f"   - Item type: {item_type}")
                    
                    if item_type == 'ToolCallItem':
                        tool_count += 1
                        # Try multiple ways to get tool name
                        tool_name = getattr(item, 'name', None)
                        if not tool_name:
                            tool_name = getattr(item, 'tool_name', None)
                        if not tool_name and hasattr(item, 'tool'):
                            tool_name = getattr(item.tool, 'name', None)
                        if not tool_name:
                            tool_name = 'unknown'
                        
                        print(f"  ğŸ”§ Tool call #{tool_count}: {tool_name}")
                        print(f"     ğŸ“‹ Item attributes: {dir(item)[:10]}...")  # First 10 attributes
                        logger.info(f"  âœ… Tool call #{tool_count}: {tool_name}")
                        tool_calls_data.append({
                            "tool": tool_name,
                            "status": "success",
                            "result": None  # Result is in separate ToolCallOutputItem
                        })
                    
                    elif item_type == 'ToolCallOutputItem':
                        # Extract tool output/result
                        output = getattr(item, 'output', None)
                        print(f"  ğŸ“¤ Tool output: {str(output)[:200] if output else 'None'}...")
                        if output:
                            logger.info(f"     Tool returned: {str(output)[:100]}")
                
                if tool_count > 0:
                    print(f"âœ… Agent executed {tool_count} tool actions")
                    logger.info(f"âœ… Agent executed {tool_count} tool actions")
                else:
                    print(f"âš ï¸ Agent DID NOT call any tools! (message: '{message[:50]}...')")
                    logger.warning(f"âš ï¸ Agent DID NOT call any tools! (message: '{message[:50]}...')")
            else:
                print(f"âš ï¸ Result has NO new_items or new_items is empty!")
            
            # âœ¨ Save trace to database
            try:
                trace = AgentTrace(
                    business_id=business_id,
                    agent_type="booking",
                    channel=channel,
                    customer_phone=customer_phone,
                    customer_name=customer_name,
                    user_message=message[:1000],  # Limit length
                    agent_response=reply_text[:2000],
                    tool_calls=tool_calls_data if tool_calls_data else None,
                    tool_count=tool_count,
                    status="success",
                    duration_ms=duration_ms
                )
                db.session.add(trace)
                db.session.commit()
                logger.info(f"ğŸ“Š Saved agent trace #{trace.id} (duration: {duration_ms}ms)")
            except Exception as trace_error:
                logger.error(f"Failed to save agent trace: {trace_error}")
                # Don't fail the whole request just because trace failed
                db.session.rollback()
            
            return reply_text
            
        except Exception as e:
            logger.error(f"Agent error (falling back to regular response): {e}")
            import traceback
            traceback.print_exc()
            
            # âœ¨ Save error trace with duration
            try:
                error_duration_ms = int((time.time() - start_time) * 1000)
                trace = AgentTrace(
                    business_id=business_id,
                    agent_type="booking",
                    channel=channel,
                    customer_phone=customer_phone,
                    customer_name=customer_name,
                    user_message=message[:1000],
                    agent_response=None,
                    tool_calls=None,
                    tool_count=0,
                    status="error",
                    error_message=str(e)[:500],
                    duration_ms=error_duration_ms
                )
                db.session.add(trace)
                db.session.commit()
                logger.info(f"ğŸ“Š Saved error trace (duration: {error_duration_ms}ms)")
            except:
                db.session.rollback()
            
            # Fallback to regular response
            return self.generate_response(message, business_id, context, channel, is_first_turn)

def generate_ai_response(message: str, business_id: int = 1, 
                        context: Optional[Dict[str, Any]] = None, channel: str = "calls",
                        is_first_turn: bool = False) -> str:
    """×¤×•× ×§×¦×™×” ×¢×–×¨ ×œ×§×¨×™××” ××”×™×¨×” ×œ×©×™×¨×•×ª AI - ×œ×¤×™ ×¢×¨×•×¥"""
    return get_ai_service().generate_response(message, business_id, context, channel, is_first_turn)

