"""
Real-time Streaming STT for Hebrew with Google Cloud Speech
Optimized for ultra-low latency phone conversations

‚ö° BUILD 115: Dynamic model selection with smart fallback
- Session-per-call architecture
- Automatic model availability probing
- Graceful fallback (phone_call ‚Üí default)
- Thread-safe for concurrent calls
"""
import os
import json
import time
import threading
import queue
import logging
from google.cloud import speech

log = logging.getLogger("gcp_stt_stream")

# ‚ö° SPEED OPTIMIZED: Ultra-low latency for real-time Hebrew transcription
BATCH_MS = int(os.getenv("STT_BATCH_MS", "30"))        # ‚ö° 30ms (was 40ms) - faster batching
DEBOUNCE_MS = int(os.getenv("STT_PARTIAL_DEBOUNCE_MS", "80"))  # ‚ö° 80ms (was 120ms) - faster partial results
TIMEOUT_MS = int(os.getenv("STT_TIMEOUT_MS", "300"))    # ‚ö° 300ms (was 400ms) - ULTRA-FAST timeout
LANG = os.getenv("GCP_STT_LANGUAGE", "he-IL")
PUNCTUATION_INTERIM = os.getenv("GCP_STT_PUNCTUATION_INTERIM", "false").lower() == "true"
PUNCTUATION_FINAL = os.getenv("GCP_STT_PUNCTUATION_FINAL", "true").lower() == "true"


# ‚ö° BUILD 117: FORCE default - phone_call NOT supported for Hebrew (iw-IL)!
# Google returns: "The phone_call model is currently not supported for language : iw-IL"
# ALWAYS use "default" regardless of env var - ignore any GCP_STT_MODEL setting
MODEL = "default"  # HARD-CODED - phone_call crashes for Hebrew!
USE_ENHANCED = True  # ◊í◊ï◊í◊ú ◊û◊™◊¢◊ú◊û◊™ ◊ê◊ù ◊ú◊ê ◊†◊™◊û◊ö; ◊ú◊ê ◊ß◊ï◊®◊°

print(f"üéØ STT Configuration: model={MODEL} (FORCED - phone_call not supported for he-IL), enhanced={USE_ENHANCED}, language={LANG}", flush=True)


class StreamingSTTSession:
    """
    ONE session per call - lives for entire conversation.
    Audio is fed continuously via push_audio().
    Callbacks fire for partial/final results across ALL utterances.
    """
    
    def __init__(self, on_partial, on_final):
        """
        Initialize streaming session with callbacks.
        
        Args:
            on_partial: Callback for interim results (called frequently ~180ms)
            on_final: Callback for final results (end of utterance)
        """
        # ‚ö° BUILD 115.1: Initialize Google Speech client (NO custom endpoint - production fix)
        try:
            self.client = speech.SpeechClient()
            log.info(f"‚úÖ StreamingSTTSession: Client initialized")
        except Exception as e:
            log.error(f"‚ùå Failed to initialize Speech client: {e}")
            raise
        
        self._on_partial = on_partial
        self._on_final = on_final
        
        # Audio queue for receiving from WS thread (48 = ~960ms buffer @ 20ms frames)
        # ‚ö° BUILD 112.1: Increased from 16 to 48 to prevent dropped frames
        self._q = queue.Queue(maxsize=48)
        self._stop = threading.Event()
        
        # Debouncing state
        self._last_partial = ""
        self._last_emit_ms = 0
        self._early_finalized = False  # Track if we already sent early-final for this utterance
        
        # Metrics
        self._dropped_frames = 0
        
        # Start worker thread
        self._t = threading.Thread(target=self._run, daemon=True)
        self._t.start()
        log.info("üöÄ StreamingSTTSession: Worker thread started")
    
    def push_audio(self, pcm_bytes: bytes):
        """
        Feed PCM16 8kHz audio to the streaming session.
        Called from WS loop - non-blocking.
        """
        if not pcm_bytes:
            return
        try:
            self._q.put_nowait(pcm_bytes)
        except queue.Full:
            # Under pressure, drop frame rather than increase latency
            self._dropped_frames += 1
            if self._dropped_frames % 10 == 1:  # Log every 10th drop
                log.warning(f"‚ö†Ô∏è Audio queue full, dropped {self._dropped_frames} frames total (queue size: {self._q.qsize()})")
    
    def close(self):
        """
        Stop streaming session and cleanup.
        Called at end of call.
        """
        log.info("üõë Closing StreamingSTTSession...")
        self._stop.set()
        try:
            self._q.put_nowait(None)  # Signal EOF
        except queue.Full:
            pass
        self._t.join(timeout=2.0)
        log.info("‚úÖ StreamingSTTSession closed")
    
    def _config(self):
        """Build recognition config"""
        speech_contexts = [
            speech.SpeechContext(
                phrases=[
                    # ‚ö° ACCURACY FIX: Added ALL Hebrew numbers for "◊ó◊û◊ô◊©◊ô◊ù ◊ê◊§◊©◊®" etc.
                    # Numbers 1-100 in Hebrew
                    "◊ê◊ó◊ì", "◊©◊†◊ô◊ô◊ù", "◊©◊†◊ô◊ù", "◊©◊ú◊ï◊©", "◊©◊ú◊ï◊©◊î", "◊ê◊®◊ë◊¢", "◊ê◊®◊ë◊¢◊î", "◊ó◊û◊©", "◊ó◊û◊ô◊©◊î", 
                    "◊©◊©", "◊©◊ô◊©◊î", "◊©◊ë◊¢", "◊©◊ë◊¢◊î", "◊©◊û◊ï◊†◊î", "◊™◊©◊¢", "◊™◊©◊¢◊î", "◊¢◊©◊®", "◊¢◊©◊®◊î",
                    "◊¢◊©◊®◊ô◊ù", "◊©◊ú◊ï◊©◊ô◊ù", "◊ê◊®◊ë◊¢◊ô◊ù", "◊ó◊û◊ô◊©◊ô◊ù", "◊©◊ô◊©◊ô◊ù", "◊©◊ë◊¢◊ô◊ù", "◊©◊û◊ï◊†◊ô◊ù", "◊™◊©◊¢◊ô◊ù", "◊û◊ê◊î",
                    "◊û◊ê◊™◊ô◊ô◊ù", "◊©◊ú◊ï◊© ◊û◊ê◊ï◊™", "◊ê◊®◊ë◊¢ ◊û◊ê◊ï◊™", "◊ó◊û◊© ◊û◊ê◊ï◊™", "◊ê◊ú◊£", "◊ê◊ú◊§◊ô◊ù",
                    
                    # üî• BUILD 138: MASSIVELY EXPANDED - 150+ phrases for perfect STT!
                    # Greetings & politeness
                    "◊©◊ú◊ï◊ù", "◊î◊ô◊ô", "◊ë◊ï◊ß◊® ◊ò◊ï◊ë", "◊¶◊î◊®◊ô◊ô◊ù ◊ò◊ï◊ë◊ô◊ù", "◊¢◊®◊ë ◊ò◊ï◊ë", "◊ú◊î◊™◊®◊ê◊ï◊™", "◊™◊ï◊ì◊î", "◊™◊ï◊ì◊î ◊®◊ë◊î",
                    "◊°◊ú◊ô◊ó◊î", "◊ë◊ë◊ß◊©◊î", "◊õ◊ü", "◊ú◊ê", "◊ë◊°◊ì◊®", "◊û◊¢◊ï◊ú◊î", "◊†◊î◊ì◊®", "◊û◊¶◊ï◊ô◊ü", "◊û◊¢◊†◊ô◊ô◊ü", "◊ê◊ï◊ß◊ô◊ô",
                    "◊©◊ú◊ï◊ù ◊ú◊ö", "◊û◊î ◊©◊ú◊ï◊û◊ö", "◊ê◊ô◊ö ◊ê◊™◊î", "◊õ◊ú ◊ò◊ï◊ë", "◊ô◊ï◊§◊ô", "◊û◊¶◊ï◊ô◊ü", "◊°◊ë◊ë◊î", "◊ê◊ó◊ú◊î",
                    
                    # üî• FIX: Short words that STT struggles with (user reported)
                    "◊õ◊©◊®", "◊õ◊©◊®◊ï◊™", "◊û◊ô◊ß◊ï◊ù", "◊õ◊™◊ï◊ë◊™", "◊ê◊ô◊§◊î", "◊û◊™◊ô", "◊û◊î", "◊ê◊ô◊ö", "◊ú◊û◊î", "◊õ◊û◊î",
                    
                    # üî• BUILD 200: Generic business words only - no industry-specific terms
                    "◊©◊ô◊®◊ï◊™", "◊¢◊°◊ß", "◊ó◊ë◊®◊î", "◊ú◊ß◊ï◊ó", "◊¢◊ñ◊®◊î", "◊û◊ô◊ì◊¢", "◊§◊®◊ò◊ô◊ù",
                    
                    # üî• BUILD 186: NO hardcoded cities - generic location words only
                    # Cities should come from business settings, not hardcoded
                    "◊¢◊ô◊®", "◊ô◊ô◊©◊ï◊ë", "◊ê◊ñ◊ï◊®", "◊©◊õ◊ï◊†◊î", "◊®◊ó◊ï◊ë", "◊õ◊™◊ï◊ë◊™", "◊û◊ô◊ß◊ï◊ù",
                    "◊¶◊§◊ï◊ü", "◊ì◊®◊ï◊ù", "◊û◊®◊õ◊ñ", "◊û◊ñ◊®◊ó", "◊û◊¢◊®◊ë",
                    
                    # Money & numbers - generic only
                    "◊©◊ß◊ú", "◊©◊ß◊ú◊ô◊ù", "◊ê◊ú◊£", "◊ê◊ú◊§◊ô◊ù", "◊û◊ô◊ú◊ô◊ï◊ü", "◊û◊ó◊ô◊®", "◊¢◊ú◊ï◊™",
                    
                    # Hebrew numbers
                    "◊ê◊§◊°", "◊ê◊ó◊ì", "◊©◊†◊ô◊ô◊ù", "◊©◊™◊ô◊ô◊ù", "◊©◊ú◊ï◊©", "◊ê◊®◊ë◊¢", "◊ó◊û◊©", "◊©◊©", "◊©◊ë◊¢", "◊©◊û◊ï◊†◊î", "◊™◊©◊¢", "◊¢◊©◊®",
                    "◊ê◊ó◊ì ◊¢◊©◊®", "◊©◊†◊ô◊ù ◊¢◊©◊®", "◊©◊ú◊ï◊© ◊¢◊©◊®◊î", "◊ê◊®◊ë◊¢ ◊¢◊©◊®◊î", "◊ó◊û◊© ◊¢◊©◊®◊î", "◊©◊© ◊¢◊©◊®◊î",
                    "◊¢◊©◊®◊ô◊ù", "◊©◊ú◊ï◊©◊ô◊ù", "◊ê◊®◊ë◊¢◊ô◊ù", "◊ó◊û◊ô◊©◊ô◊ù", "◊©◊ô◊©◊ô◊ù", "◊©◊ë◊¢◊ô◊ù", "◊©◊û◊ï◊†◊ô◊ù", "◊™◊©◊¢◊ô◊ù",
                    "◊û◊ê◊î", "◊û◊ê◊™◊ô◊ô◊ù", "◊©◊ú◊ï◊© ◊û◊ê◊ï◊™", "◊ê◊®◊ë◊¢ ◊û◊ê◊ï◊™", "◊ó◊û◊© ◊û◊ê◊ï◊™",
                    
                    # Appointments & scheduling - CRITICAL FOR BOOKING!
                    "◊™◊ï◊®", "◊§◊í◊ô◊©◊î", "◊§◊†◊ï◊ô", "◊™◊§◊ï◊°", "◊û◊ó◊®", "◊û◊ó◊®◊™◊ô◊ô◊ù", "◊©◊ë◊ï◊¢", "◊ó◊ï◊ì◊©", "◊ô◊ï◊ù",
                    "◊®◊ê◊©◊ï◊ü", "◊©◊†◊ô", "◊©◊ú◊ô◊©◊ô", "◊®◊ë◊ô◊¢◊ô", "◊ó◊û◊ô◊©◊ô", "◊©◊ô◊©◊ô", "◊©◊ë◊™", "◊°◊ï◊£ ◊©◊ë◊ï◊¢",
                    "◊ë◊ï◊ß◊®", "◊¶◊î◊®◊ô◊ô◊ù", "◊ë◊¶◊î◊®◊ô◊ô◊ù", "◊ê◊ó◊® ◊î◊¶◊î◊®◊ô◊ô◊ù", "◊¢◊®◊ë", "◊ú◊ô◊ú◊î", "◊©◊¢◊î", "◊ì◊ß◊î",
                    "◊ß◊ë◊¢ ◊™◊ï◊®", "◊ú◊ß◊ë◊ï◊¢", "◊†◊ß◊ë◊¢", "◊ß◊ë◊¢◊™◊ô", "◊ê◊©◊û◊ó ◊ú◊ß◊ë◊ï◊¢", "◊®◊ï◊¶◊î ◊ú◊ß◊ë◊ï◊¢",
                    "◊™◊ê◊ù", "◊ú◊™◊ê◊ù", "◊ß◊ï◊ë◊¢◊ô◊ù", "◊ú◊ß◊ë◊ô◊¢◊™", "◊™◊ô◊ê◊ï◊ù", "◊î◊ê◊ù ◊ô◊© ◊©◊¢◊î ◊§◊†◊ï◊ô◊î",
                    "◊ñ◊û◊ô◊ü", "◊§◊†◊ï◊ô◊î", "◊™◊§◊ï◊°◊î", "◊™◊§◊ï◊°", "◊û◊©◊î◊ï ◊ê◊ó◊®", "◊©◊¢◊î ◊ê◊ó◊®◊™", "◊ô◊ï◊ù ◊ê◊ó◊®",
                    "◊ô◊û◊ô ◊®◊ê◊©◊ï◊ü", "◊ô◊û◊ô ◊©◊†◊ô", "◊ô◊û◊ô ◊©◊ú◊ô◊©◊ô", "◊ô◊û◊ô ◊®◊ë◊ô◊¢◊ô", "◊ô◊û◊ô ◊ó◊û◊ô◊©◊ô", "◊ô◊û◊ô ◊©◊ô◊©◊ô",
                    
                    # Common names (Hebrew first names)
                    "◊ì◊ï◊ì", "◊û◊©◊î", "◊ô◊ï◊°◊ô", "◊ê◊ë◊ô", "◊®◊ï◊†◊ô", "◊¢◊û◊ô", "◊ì◊†◊ô", "◊©◊ô", "◊í◊ô◊ú", "◊ê◊ï◊®",
                    "◊©◊®◊î", "◊®◊ó◊ú", "◊ú◊ê◊î", "◊û◊®◊ô◊ù", "◊ì◊ô◊†◊î", "◊®◊ï◊†◊ô◊™", "◊ò◊ú◊ô", "◊†◊¢◊û◊ô", "◊¢◊†◊™",
                    "◊õ◊î◊ü", "◊ú◊ï◊ô", "◊û◊ñ◊®◊ó◊ô", "◊ë◊ô◊ò◊ï◊ü", "◊ê◊ï◊ó◊ô◊ï◊ü", "◊§◊®◊•", "◊ì◊î◊ü", "◊ê◊ú◊ï◊ü", "◊ë◊®",
                    
                    # Common verbs & phrases
                    "◊®◊ï◊¶◊î", "◊¶◊®◊ô◊ö", "◊û◊ó◊§◊©", "◊û◊¢◊ï◊†◊ô◊ô◊ü", "◊û◊™◊ê◊ô◊ù", "◊ô◊õ◊ï◊ú", "◊ê◊§◊©◊®", "◊ë◊ê ◊ú◊ô",
                    "◊û◊¢◊ì◊ô◊£", "◊®◊ï◊¶◊î ◊ú◊ì◊¢◊™", "◊®◊ï◊¶◊î ◊ú◊©◊û◊ï◊¢", "◊û◊î ◊ô◊©", "◊ê◊ô◊ñ◊î", "◊õ◊û◊î",
                    "◊°◊§◊® ◊ú◊ô", "◊™◊í◊ô◊ì ◊ú◊ô", "◊û◊î ◊ê◊™◊î ◊ô◊õ◊ï◊ú", "◊û◊î ◊ô◊© ◊ú◊ö", "◊ë◊ï◊ê ◊†◊ß◊ë◊¢",
                    
                    # Phone numbers
                    "◊ò◊ú◊§◊ï◊ü", "◊û◊°◊§◊®", "◊†◊ô◊ô◊ì", "◊ê◊§◊° ◊ó◊û◊©", "◊ó◊û◊© ◊ê◊§◊°", "◊°◊ï◊ú◊û◊ô◊™", "◊õ◊ï◊õ◊ë◊ô◊™",
                    
                    # üî• BUILD 200: Generic service words only - no specific business types!
                    "◊©◊ô◊®◊ï◊™", "◊°◊ô◊ì◊ï◊®", "◊ô◊ô◊¢◊ï◊•",
                    
                    # üî• FIX: Food & Kashrut (user reported STT issues)
                    "◊î◊ê◊ï◊õ◊ú", "◊ê◊ï◊õ◊ú", "◊™◊§◊®◊ô◊ò", "◊õ◊©◊®◊ï◊™", "◊õ◊©◊®", "◊ë◊©◊®◊ô", "◊ó◊ú◊ë◊ô", "◊§◊®◊ï◊ï◊î", 
                    "◊û◊©◊ß◊ê◊ï◊™", "◊©◊™◊ô◊ô◊î", "◊û◊†◊ï◊™", "◊ê◊®◊ï◊ó◊î", "◊ê◊ï◊õ◊ú◊ô◊ù",
                    
                    # Time expressions
                    "◊¢◊õ◊©◊ô◊ï", "◊û◊ô◊ì", "◊î◊ô◊ï◊ù", "◊û◊ó◊®", "◊û◊ó◊®◊™◊ô◊ô◊ù", "◊î◊©◊ë◊ï◊¢", "◊©◊ë◊ï◊¢ ◊î◊ë◊ê",
                    "◊ó◊ï◊ì◊© ◊î◊ë◊ê", "◊ë◊©◊ë◊ï◊¢", "◊ë◊ô◊ï◊ù", "◊ë◊©◊¢◊î", "◊ë", "◊ú◊§◊†◊ô", "◊ê◊ó◊®◊ô",
                    
                    # English/Mixed (code-switching common in Hebrew phone calls)
                    "WhatsApp", "OK", "Appointment", "zero five", "phone", "email"
                
                ],
                boost=20.0  # üî• MAX boost for best accuracy
            )
        ]
        
        return speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=8000,
            language_code=LANG,
            model=MODEL,
            use_enhanced=USE_ENHANCED,  # ‚ö° BUILD 115: Dynamically selected based on availability
            enable_automatic_punctuation=PUNCTUATION_FINAL,
            speech_contexts=speech_contexts
        )
    
    def _streaming_config(self):
        """Build streaming config"""
        return speech.StreamingRecognitionConfig(
            config=self._config(),
            interim_results=True,
            single_utterance=False  # CRITICAL: Allow multiple utterances in one session
        )
    
    def _requests(self):
        """Generator yielding batched audio requests"""
        buf = bytearray()
        last = time.monotonic()
        
        while not self._stop.is_set():
            try:
                # ‚ö° CRITICAL: Short timeout (20ms) to consume queue aggressively
                chunk = self._q.get(timeout=0.02)
            except queue.Empty:
                # No data, check if should flush buffer
                now = time.monotonic()
                if buf and (now - last) * 1000 >= BATCH_MS:
                    yield speech.StreamingRecognizeRequest(audio_content=bytes(buf))
                    buf.clear()
                    last = now
                continue
            
            if chunk is None:
                # EOF signal - flush and exit
                if buf:
                    log.info(f"üîö Flushing final {len(buf)} bytes")
                    yield speech.StreamingRecognizeRequest(audio_content=bytes(buf))
                break
            
            buf.extend(chunk)
            now = time.monotonic()
            
            # Send batch if enough data or enough time passed
            if (now - last) * 1000 >= BATCH_MS:
                yield speech.StreamingRecognizeRequest(audio_content=bytes(buf))
                buf.clear()
                last = now
    
    def _emit_partial(self, text: str):
        """Emit partial result with debouncing"""
        if not text:
            return
        
        now = time.monotonic() * 1000
        if text != self._last_partial and now - self._last_emit_ms >= DEBOUNCE_MS:
            self._last_partial = text
            self._last_emit_ms = now
            try:
                self._on_partial(text)
            except Exception as e:
                log.error(f"Partial callback error: {e}")
    
    def _should_finalize_early(self, partial_text: str) -> bool:
        """
        ‚ö° BUILD 116: Early-finalize aggressive strategy
        Cuts 300-500ms by finalizing strong partials without waiting for silence
        """
        if not partial_text:
            return False
        
        # Strong partial: >=12 chars with punctuation
        if len(partial_text) >= 12 and any(p in partial_text for p in ".?!‚Ä¶"):
            return True
        
        # Medium partial without punctuation: >=18 chars (short sentence)
        if len(partial_text) >= 18:
            return True
        
        return False
    
    def _emit_final(self, text: str, early=False):
        """Emit final result"""
        if text:
            try:
                if early:
                    log.info(f"‚ö° EARLY-FINAL: {text} (saved ~400ms)")
                self._on_final(text)
            except Exception as e:
                log.error(f"Final callback error: {e}")
        # Reset partial after final
        self._last_partial = ""
        self._early_finalized = early  # Track if this was early-finalized
    
    def _run(self):
        """
        Worker thread - maintains continuous connection to GCP.
        Runs for entire duration of call.
        """
        log.info("üì° StreamingSTTSession: Starting GCP streaming recognize...")
        try:
            responses = self.client.streaming_recognize(
                self._streaming_config(),
                self._requests()
            )
            
            for resp in responses:
                if self._stop.is_set():
                    break
                
                for result in resp.results:
                    if not result.alternatives:
                        continue
                    
                    transcript = result.alternatives[0].transcript.strip()
                    if not transcript:
                        continue
                    
                    if result.is_final:
                        # Skip if we already early-finalized this utterance
                        if self._early_finalized:
                            log.debug(f"üîµ Skipping FINAL (already early-finalized): {transcript}")
                            self._early_finalized = False  # Reset for next utterance
                        else:
                            log.info(f"üü¢ FINAL: {transcript}")
                            self._emit_final(transcript, early=False)
                    else:
                        # ‚ö° BUILD 116: Check if we should early-finalize this partial
                        if not self._early_finalized and self._should_finalize_early(transcript):
                            # Treat this partial as final - saves 300-500ms!
                            self._emit_final(transcript, early=True)
                        else:
                            log.debug(f"üü° PARTIAL: {transcript}")
                            self._emit_partial(transcript)
                        
        except Exception as e:
            error_str = str(e)
            # ‚ö° CRITICAL: Handle Audio Timeout gracefully
            if "Audio Timeout" in error_str or "OUT_OF_RANGE" in error_str:
                log.warning(f"‚ö†Ô∏è STT Audio Timeout (normal during AI processing) - session will auto-recover on next audio")
            else:
                log.error(f"‚ùå Streaming worker error: {e}")
                import traceback
                traceback.print_exc()
        finally:
            log.info("üì° StreamingSTTSession: Worker stopped")

class GcpStreamingSTT:
    """
    Thread-safe streaming STT service
    Designed to work with sync WebSocket handlers
    """
    
    def __init__(self, sample_rate_hz=8000):
        self.client = None
        self.rate = sample_rate_hz
        
        # Audio queue for batching (48 = ~960ms buffer @ 20ms frames)
        # ‚ö° BUILD 112.1: Increased from 16 to 48 to prevent dropped frames
        self._audio_queue = queue.Queue(maxsize=48)
        self._batch_size_bytes = int(sample_rate_hz * 2 * (BATCH_MS / 1000.0))  # PCM16
        self._dropped_frames = 0  # Metrics
        
        # Results
        self._partial_callback = None
        self._final_callback = None
        self._last_partial_time = 0.0
        self._last_partial_text = ""
        
        # Control
        self._streaming = False
        self._worker_thread = None
        
    def _ensure_client(self):
        """Lazy initialization of Speech client"""
        if self.client is None:
            try:
                sa_json = os.getenv('GOOGLE_CLOUD_SERVICE_ACCOUNT_JSON')
                if sa_json:
                    credentials_info = json.loads(sa_json)
                    self.client = speech.SpeechClient.from_service_account_info(credentials_info)
                    log.info("‚úÖ Streaming STT client initialized (service account)")
                else:
                    self.client = speech.SpeechClient()
                    log.info("‚úÖ Streaming STT client initialized (default)")
            except Exception as e:
                log.error(f"‚ùå Failed to initialize Speech client: {e}")
                raise
        
    def start_streaming(self, on_partial=None, on_final=None):
        """
        Start streaming recognition
        
        Args:
            on_partial: Callback for interim results (text)
            on_final: Callback for final results (text)
        """
        if self._streaming:
            log.warning("‚ö†Ô∏è Already streaming")
            return
            
        self._ensure_client()
        self._partial_callback = on_partial
        self._final_callback = on_final
        self._streaming = True
        
        self._worker_thread = threading.Thread(target=self._stream_worker, daemon=True)
        self._worker_thread.start()
        log.info("üöÄ Real-time streaming STT started")
        
    def stop_streaming(self):
        """Stop streaming and flush remaining audio"""
        if not self._streaming:
            return
            
        log.info("üõë Stopping streaming STT...")
        self._streaming = False
        
        # Signal end of stream
        try:
            self._audio_queue.put(None, timeout=0.5)
        except queue.Full:
            pass
            
        if self._worker_thread:
            self._worker_thread.join(timeout=2.0)
            
        log.info("‚úÖ Streaming STT stopped")
        
    def push_audio(self, pcm16_data):
        """
        Push PCM16 audio data to the stream
        Thread-safe, non-blocking
        """
        if not self._streaming:
            return
            
        try:
            self._audio_queue.put_nowait(pcm16_data)
        except queue.Full:
            self._dropped_frames += 1
            if self._dropped_frames % 10 == 1:  # Log every 10th drop
                log.warning(f"‚ö†Ô∏è Audio queue full, dropped {self._dropped_frames} frames total (queue size: {self._audio_queue.qsize()})")
            
    def _stream_worker(self):
        """Background worker that handles streaming recognition"""
        try:
            # ‚ö° BUILD 115: Use dynamically selected model configuration
            log.info(f"üìû Using model='{MODEL}' with ENHANCED={USE_ENHANCED} for {LANG}")
            
            # üî• BUILD 186: NO hardcoded cities - generic Hebrew only
            speech_contexts = [
                speech.SpeechContext(
                    phrases=[
                        "◊©◊ú◊ï◊ù", "◊î◊ô◊ô", "◊™◊ï◊ì◊î", "◊ë◊ë◊ß◊©◊î", "◊õ◊ü", "◊ú◊ê", "◊ë◊°◊ì◊®",
                        "◊™◊ï◊®", "◊§◊í◊ô◊©◊î", "◊û◊ó◊®", "◊î◊ô◊ï◊ù", "◊©◊ë◊ï◊¢", "◊ó◊ï◊ì◊©",
                        "◊ê◊ó◊ì", "◊©◊†◊ô◊ô◊ù", "◊©◊ú◊ï◊©", "◊ê◊®◊ë◊¢", "◊ó◊û◊©", "◊¢◊©◊®", "◊¢◊©◊®◊ô◊ù"
                    ],
                    boost=15.0
                )
            ]
            
            config = speech.RecognitionConfig(
                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                language_code=LANG,
                sample_rate_hertz=self.rate,
                enable_automatic_punctuation=PUNCTUATION_INTERIM,  # Usually false for speed
                model=MODEL,
                speech_contexts=speech_contexts,
                use_enhanced=USE_ENHANCED
            )
            
            streaming_config = speech.StreamingRecognitionConfig(
                config=config,
                interim_results=True,
                single_utterance=False,
            )
            
            def request_generator():
                """Generate batched audio requests"""
                buffer = bytearray()
                last_send = time.time()
                
                while self._streaming:
                    try:
                        # ‚ö° CRITICAL: Short timeout (20ms) to consume queue aggressively
                        chunk = self._audio_queue.get(timeout=0.02)
                        
                        if chunk is None:
                            # End signal
                            break
                            
                        buffer.extend(chunk)
                        
                        # Send batch if enough data or enough time passed
                        now = time.time()
                        time_since_send = (now - last_send) * 1000
                        
                        if len(buffer) >= self._batch_size_bytes or time_since_send >= BATCH_MS:
                            if buffer:
                                yield speech.StreamingRecognizeRequest(audio_content=bytes(buffer))
                                buffer.clear()
                                last_send = now
                                
                    except queue.Empty:
                        # No audio available, check if we should send buffered data
                        if buffer and (time.time() - last_send) * 1000 >= BATCH_MS:
                            yield speech.StreamingRecognizeRequest(audio_content=bytes(buffer))
                            buffer.clear()
                            last_send = time.time()
                            
                # Flush remaining buffer
                if buffer:
                    log.info(f"üîö Flushing final {len(buffer)} bytes")
                    yield speech.StreamingRecognizeRequest(audio_content=bytes(buffer))
            
            # Start streaming recognition
            responses = self.client.streaming_recognize(streaming_config, request_generator())
            
            for response in responses:
                if not self._streaming:
                    break
                    
                for result in response.results:
                    if not result.alternatives:
                        continue
                        
                    transcript = result.alternatives[0].transcript.strip()
                    if not transcript:
                        continue
                    
                    if result.is_final:
                        # Final result
                        log.info(f"üü¢ FINAL: {transcript}")
                        if self._final_callback:
                            self._final_callback(transcript)
                    else:
                        # Interim result with debounce
                        current_time = time.time()
                        time_since_last = (current_time - self._last_partial_time) * 1000
                        
                        # Debounce: only send if enough time passed OR text changed significantly
                        # üî• FIX: Save LONGEST partial, not last! Google STT sometimes sends shorter corrections
                        should_emit = time_since_last >= DEBOUNCE_MS or transcript != self._last_partial_text
                        
                        if should_emit:
                            log.debug(f"üü° PARTIAL: {transcript}")
                            self._last_partial_time = current_time
                            
                            # Only update if new partial is longer (better)
                            if len(transcript) > len(self._last_partial_text):
                                self._last_partial_text = transcript
                                log.debug(f"‚úÖ BEST_PARTIAL updated: '{transcript}' ({len(transcript)} chars)")
                            else:
                                log.debug(f"‚ö†Ô∏è PARTIAL ignored (shorter): '{transcript}' ({len(transcript)} chars) vs '{self._last_partial_text}' ({len(self._last_partial_text)} chars)")
                            
                            # Always call callback with current transcript (even if not saved)
                            if self._partial_callback:
                                self._partial_callback(transcript)
                                
        except Exception as e:
            log.error(f"‚ùå Streaming worker error: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self._streaming = False
            log.info("üì° Stream worker stopped")


# Factory function for backward compatibility
def create_streaming_stt(sample_rate_hz=8000):
    """Factory function for creating streaming STT instance"""
    return GcpStreamingSTT(sample_rate_hz=sample_rate_hz)


# Legacy class name for backward compatibility
GcpHebrewStreamer = GcpStreamingSTT
